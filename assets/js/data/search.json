[ { "title": "[Logical Writing Study 01] Subject : Should Generative A.I. Be Regulated by Law?", "url": "/bioinfo.github.io/posts/logical_writing1/", "categories": "Logical thinking training, Logical & academic writing training, English writing training", "tags": "writing, study, training, english", "date": "2024-09-20 00:00:00 +0900", "snippet": "Subject 01 : Should Generative A.I. be regulated by law?Thesis statementGenerative A.I. must be regulated by law because it is prone to technological self-destruction and collapses human social systems by spreading social distrust and endangering human life.Why the technology must be regulatedFrom a technological perspective, indiscreet development of generative A.I. systems carries the risk that train data sets will be filled with A.I.-generated data, leading to poor model performance. From a societal perspective, generative AI can spread disinformation [1]. Also, generative A.I. destroys human jobs, especially those of content creators [2]. The job losses further lead to deepening social inequality. These issues are becoming imminent threats to humanity, so regulations should take place to seek coexistence between the system and humans.The examples of regulationsLabeling of AI-created content [3] and profit sharing between AI service companies and original content creators [2] can be the form of regulations to solve the above problems. First, all AI-created content should be labeled as “the creation of AI” to clarify the creator of the content. The labeling will give people a chance to make discreet decisions based on the information generated by AI. Second, AI service development companies should buy data usage licenses from data creators in the form of profit sharing. The profit sharing can protect the data creators from losing their jobs while producing authentic data sets suitable for model training. Protecting data creators’ jobs and preserving their income prevents the social inequality caused by technology.Expected obstacles on the suggested solutionsHowever, several issues such as geopolitical mistrust, global competition among countries to gain economic interest from the technology, and lack of AI literacy among lawmakers become obstacles that prevent the regulations from becoming effective and practical. The India’s technology minister Rajeev Chandrasekhar insisted that potential beneficiaries of the technology will be the rich, developed countries, not the underdeveloped or developing countries [1]. Such mistrust prevents countries from uniting to make proper universal regulations on the technology. Global competition is also the main obstacle to global cooperation. All countries are focused on gaining economic advantage from the technology and do not want to suppress its potential [1]. Most importantly, the lack of A.I. literacy among lawmakers is becoming a huge obstacle to making proper regulations. For example, members of the U.S. Congress have finally admitted that they don’t know how the system works [1]. Big tech companies like Google and OpenAI are lobbying them while giving them lectures on the technology [1].SummaryIn summary, regulating generative AI is crucial to prevent its negative consequences, such as filling global data repositories with poor-quality information, promoting misinformation, and threatening human livelihoods. Potential solutions include mandatory labeling of AI-generated content and profit-sharing mechanisms for content creators to safeguard their work. Since AI has global implications, regulations need to be international and collaborative. However, achieving this faces major hurdles, including geopolitical distrust, international competition for technological dominance, and the insufficient understanding of AI among policymakers, all of which undermine the effectiveness of potential regulations.References[1] Adam Satariano and Cecilia Kang, “How Nations Are Losing a Global Race to Tackle A.I.’s Harms”, The New York Times, 6 December 2023, https://www.nytimes.com/2023/12/06/technology/ai-regulation-policies.html[2] Nico Grant and Cade Metz, “The Push to Develop Generative A.I. Without All the Lawsuits”, The New York Times, 19 July 2024, https://www.nytimes.com/2024/07/19/technology/generative-ai-getty-shutterstock.html[3] Cecilia Kang and Adam Satariano, “Five Ways A.I. Could Be Regulated”, The New York Times, 6 December 2023, https://www.nytimes.com/2023/12/06/technology/artificial-intelligence-regulation.html" }, { "title": "[알고리즘/지도학습] 회귀문제 - 선형회귀, 의사결정회귀나무, 의사결정회귀나무 앙상블(그래디언트 부스트)", "url": "/bioinfo.github.io/posts/regressor/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-08-13 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 선형회귀, 의사결정회귀나무, 의사결정회귀나무 앙상블을 공부하고 나서, 그 내용을 내 언어로 바꾸어 기록한다.회귀문제분류문제는 타겟값이 카테고리 확률변수였다.$\\Rightarrow$ 회귀문제는 타겟값이 연속확률변수다.아래는 회귀문제 해결하는 데 사용할 수 있는, 회귀 알고리즘 들이다.선형회귀 (Linear regression) 알고리즘정의여러 독립변수들과, 종속변수 사이 관계 선형으로 나타낸 것.목표현실에서 얻은 표본값들과 기댓값 예측치 사이 오차 가장 작게 하는, 독립변수 $i$ 의 가중치 $\\beta_{i}$ 찾기.종류단순선형회귀 독립변수 1개와 종속변수 사이 관계 나타낸 것. $\\hat{y} = \\beta_{0} + \\beta_{1}x_{1}$ or $y = \\beta_{0} + \\beta_{1}x_{1} + \\epsilon$, $\\epsilon$ 은 오차. $\\beta_{0}$ 은 독립변수 가중치 $0$ 일 때 $\\hat{y}$ 값다중선형회귀 독립변수 $n$개와 종속변수 사이 관계 나타낸 것. $\\hat{y} = \\beta_{0} + \\beta_{1}x_{1} + … + \\beta_{n}x_{n}$ or $y = \\beta_{0} + \\beta_{1}x_{1} + … \\beta_{n}x_{n} + \\epsilon$, $\\epsilon$ 은 오차. $\\beta_{0}$ 은 독립변수 가중치 $0$ 일 때 $\\hat{y}$ 값선형회귀모델 예측값 $\\hat{y}$ 의미기댓값 예측치.선형회귀모델 손실함수(RMSE)Root Mean Squared Error.오차제곱합에 루트 씌운 것. $\\Rightarrow$ 모델의 전반적 오차.$loss = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y}^{i} - y^{i})^{2}}$선형회귀모형으로 회귀문제 해결하기데이터셋 로드import pandas as pd df = pd.read_csv('/Users/kibeomkim/Desktop/auto.csv') ; df df.describe()df.info() df.isnull().sum() 데이터셋 전처리# 데이터 파이프라인 정의 def pipeline(df) : df.drop('NAME', axis=1, inplace=True) df = df.apply(pd.to_numeric, errors='coerce') df.fillna(0, inplace=True) return df df = pipeline(df)훈련용 데이터셋과 테스트용 데이터셋으로, 전체 데이터셋 분리하기# 전처리 후, 훈련셋과 검증셋으로 데이터셋 나누기 print(df.shape)from sklearn.model_selection import train_test_split # 타겟y = df['MPG'].values# 특성변수들 X = df.values x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)선형회귀모델 훈련시키기이 경우 여러 독립변수와 종속변수 1개 사용했으므로, 모델이 다중선형회귀모델이 된다.# 선형회귀 모델 훈련시키기 from sklearn.linear_model import LinearRegression regressor = LinearRegression()# 회귀모델 훈련 regressor.fit(x_train, y_train)모델 예측y_pred = regressor.predict(x_test)# Regressor 성능 평가 ; RMSEfrom sklearn.metrics import mean_squared_error from math import sqrtprint(sqrt(mean_squared_error(y_test, y_pred))) RMSE value: 2.7248410669138417e-14의사결정회귀나무타겟값이 연속형이라는 것 제외하면, 의사결정나무(분류기)와 거의 같다. 기댓값 예측치 뽑아낸다.의사결정회귀나무 모형으로 회귀문제 해결하기from sklearn.tree import DecisionTreeRegressor# 최대 깊이=3 인 의사결정 회귀나무 정의 regressor = DecisionTreeRegressor(max_depth=3)# 모델 훈련 regressor.fit(x_train, y_train)# 테스트 데이터에 대해 기댓값 근사치 예측 수행 y_pred = regressor.predict(x_test)print(sqrt(mean_squared_error(y_test, y_pred)))RMSE value: 1.4008722335107024그레디언트 부스팅 알고리즘경사하강으로 손실 계속 줄여가며 모델 (성능) 업데이트 하기.앙상블에 계속 추가하는 개별 약 분류기로, 의사결정회귀나무 사용한다.회귀문제 해결하기from sklearn.ensemble import GradientBoostingRegressor # 그레디언트 부스팅 회귀모델 정의 regressor = GradientBoostingRegressor(n_estimators=500, max_depth=4, min_samples_split=2, learning_rate=0.01, loss='ls')# 회귀모델 훈련 regressor.fit(x_train, y_train)GradientBoostingRegressor(learning_rate=0.01, loss=’ls’, max_depth=4, n_estimators=500)# 테스트셋에 대해 예측 y_pred = regressor.predict(x_test)# 회귀모델 성능 print(sqrt(mean_squared_error(y_test, y_pred)))print('단일 의사결정 회귀나무 보다, 의사결정회귀나무 앙상블이 성능 더 좋았다 (1.4 &gt; 0.265)')RMSE value: 0.265994740897516단일 의사결정 회귀나무 보다, 의사결정회귀나무 앙상블이 성능 더 좋았다 (1.4 &gt; 0.265)아래는 선형회귀모델, 단일 의사결정회귀나무, 의사결정회귀나무 앙상블(그래디언트 부스팅) 성능 비교 한 것이다.result = pd.DataFrame({ 'Algorithm' : ['Linear regression', 'Regression tree', 'Gradient Boosting'], 'RMSE' : [2.7404298600226993e-15, 1.4008722335107024, 0.265994740897516] })result데이터프레임 시각화plt.bar(range(len(result['RMSE'].values )), result['RMSE'].values )plt.xticks(range(len(result['RMSE'].values)), result['Algorithm'].values)plt.title('RMSE result')plt.show() 이 경우엔 선형회귀모델, 그레디언트 부스팅, 의사결정 회귀나무 순으로 성능 잘 나왔다." }, { "title": "[알고리즘/지도학습] 로지스틱 회귀, 서포트벡터 머신, 나이브 베이즈 알고리듬, 분류모형 별 성능 비교", "url": "/bioinfo.github.io/posts/classifier/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-08-13 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 로지스틱 회귀, 서포트벡터 머신, 나이브 베이즈 알고리듬을 공부하고 나서, 그 내용을 내 언어로 바꾸어 기록한다.로지스틱 회귀(Logistic Regression) 분류 알고리즘이진분류에 로지스틱 함수(시그모이드 함수) 사용하는, 이진분류 알고리즘이다.목표모델 손실 최소화 하는, 최적의 $W$, $j$ 찾기.사용조건 모든 특성변수는 서로 독립이어야 한다.예측값 계산$\\hat{y} = \\sigma{(wX + j)}$ $\\hat{y}$ 는 타겟 $y$ 예측값 $X$ 가 입력 데이터셋 $w$ 는 가중치 $\\sigma{()}$ 는 로지스틱(시그모이드) 함수로지스틱 함수$\\sigma{(x)} = \\frac{1}{1 + e^{-x}}$import numpy as np def logistic(x) : return 1/(1+np.e**(-x))xx = np.linspace(-6, 6, 100000) yy = logistic(xx)plt.plot(xx, yy)plt.title('Logistic(Sigmoid) function')plt.axhline(0.5, c='r', ls='--')plt.axhline(1, c='g')plt.axhline(0, c='g')plt.show() $wX + j$ 값을 계산 후 로지스틱 함수 $\\sigma$ 에 넣는다.그러면 위와 같은 형상이 생성된다.1개 데이터레코드의 결과값이 0.5 를 넘으면 1, 0.5보다 낮으면 0으로 이진분류 한다.개별 데이터레코드에 대한 손실함수$loss = -(y^{i}\\log{\\hat{y}^{i}} + (1-y^{i})\\log{(1-\\hat{y}^{i})})$if $y^{i} = 1$ $\\Rightarrow$ $loss = -\\log{\\hat{y}^{i}}$이 경우 손실이 최소화 되려면 $\\hat{y}^{i}$ 가 최대화 되어야 한다(1쪽으로 가야한다)xx = np.linspace(0, 1, 10000)def loss1(y) : return -np.log(y)yy = loss1(xx) plt.plot(xx, yy)plt.xlabel('$\\hat{y}$')plt.ylabel('loss')plt.title('if $y^{i} = 1$')plt.show() if $y^{i} = 0 \\Rightarrow loss = -\\log{(1-\\hat{y}^{i})}$이 경우 손실이 최소화 되려면 $\\hat{y}^{i}$ 가 최소화 되어야 한다(0쪽으로 가야한다)xx = np.linspace(0, 1, 10000)def loss2(y) : return -np.log(1-y)yy = loss2(xx) plt.plot(xx, yy)plt.xlabel('$\\hat{y}$')plt.ylabel('loss')plt.title('if $y^{i} = 0$')plt.show() 로지스틱 회귀 한게로지스틱 회귀모델은 입력 데이터가 복잡해질 수록 성능 떨어지는 경향, 있다.로지스틱 회귀는 단순한 패턴 분석 및 분류할 때 괜찮은 성능 기록한다.로지스틱 회귀모델로 붓꽃 이진분류 하기%matplotlib inline # 로지스틱 회귀모형 이용한 이진분류 from sklearn.datasets import load_iris from sklearn.model_selection import train_test_splitfrom sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score data = load_iris()X = data.data y = data.target idx0 = np.where(y==0)idx1 = np.where(y==1)idx = np.concatenate([idx0, idx1], axis=1)# 특성변수들 X = X[idx, :]# 레이블y = y[idx]# 훈련용 셋과 테스트용 셋으로 입력 데이터셋 분리 x_train, x_test, y_train, y_test = train_test_split(X[0], y[0], test_size=0.25) # 로지스틱 회귀모형 정의 from sklearn.linear_model import LogisticRegression classifier = LogisticRegression(random_state=0) # random_state=0 ; 모형에 데이터 투입할 때 Shuffle 하기 위해서 지정classifier.fit(x_train, y_train) # 훈련 데이터에 대해 학습# 테스트 데이터 예측 y_pred = classifier.predict(x_test)# 혼동행렬 출력; 모델이 레이블 잘 맞췄는지 확인cm = confusion_matrix(y_test, y_pred) ; cm array([[16, 0], [ 0, 9]], dtype=int64)accuracy_score(y_test, y_pred)1.0로지스틱 회귀모델로 임의 생성 데이터셋 이진분류 하기# 데이터셋 호출 from sklearn.datasets import make_gaussian_quantiles# 임의 생성 데이터셋x1, y1 = make_gaussian_quantiles(cov=2.0, random_state=0, n_samples=200, n_features=2, n_classes=2, shuffle=True)x2, y2 = make_gaussian_quantiles(cov=2.0, random_state=1, n_samples=200, n_features=2, n_classes=2, shuffle=True)# X: 입력 데이터셋 , y: 타겟 X = np.concatenate([x1, x2], axis=0) ; y = np.concatenate([y1, y2], axis=0) idx_0 = np.where(y==0); idx_1 = np.where(y==1)# 데이터셋 시각화 plt.scatter(X[idx_0, 0], X[idx_0,1], c='r', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='g', label='class=1')plt.legend()plt.title('Sample Data')plt.show() 모델 성능 검증에 쓸 데이터셋 생성# 모델 성능 검증에 쓸 데이터셋 형태 둘러보기 x1_min, x1_max = X[:,0].min(), X[:,0].max() x2_min, x2_max = X[:,1].min(), X[:,1].max() xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 1), np.arange(x2_min, x2_max, 1))plt.scatter(xx1, xx2)plt.axis('off')plt.show() xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02))plt.scatter(xx1, xx2)# 로지스틱 회귀 분류기 학습 classifier.fit(X, y)# 로지스틱 회귀 분류기 새 데이터 예측 xx_predict = np.c_[xx1.ravel(), xx2.ravel()]Y = classifier.predict(xx_predict).reshape(xx1.shape)# 예측 결과 시각화 cs = plt.contourf(xx1, xx2, Y)plt.colorbar(cs)idx_0 = np.where(y==0); idx_1 = np.where(y==1)plt.scatter(X[idx_0, 0], X[idx_0,1], c='c', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='m', label='class=1')plt.legend()plt.title('Logistic Regression Model; Prediction Result')plt.show() 로지스틱 회귀모델로 이진분류 한 결과, XGBoost(그래디언트 부스트) 모델 결과와 비교하기# xgboost 모델 정의 후 학습 import xgboostxgb_model = xgboost.XGBClassifier(n_estimators=100, max_depth=1, random_state=0)xgb_model.fit(X, y)XGBClassifier(base_score=0.5, booster=’gbtree’, callbacks=None, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None, enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1, grow_policy=’depthwise’, importance_type=None, interaction_constraints=’’, learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=1, max_leaves=0, min_child_weight=1, missing=nan, monotone_constraints=’()’, n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=’auto’, random_state=0, reg_alpha=0, reg_lambda=1, …)# xgboost 모델 예측 xgb_Y = xgb_model.predict(xx_predict).reshape(xx1.shape)# 예측 결과 시각화 cs = plt.contourf(xx1, xx2, xgb_Y)plt.colorbar(cs)idx_0 = np.where(y==0); idx_1 = np.where(y==1)plt.scatter(X[idx_0, 0], X[idx_0,1], c='c', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='m', label='class=1')plt.legend()plt.title('XGBoost model; prediction result')plt.show() 이 경우, 로지스틱 회귀모형은 xgboost 모형보다 분류 정확성이 떨어졌다.로지스틱 회귀모형으로 분류문제 해결하기 - 2날씨 예측하기# 데이터셋 로드 df = pd.read_csv('/Users/kibeomkim/Desktop/weather.csv')dfdf.info() df.describe() df.isnull().sum() mean = df['WindGustSpeed'].mean()df['WindGustSpeed'] = df['WindGustSpeed'].fillna(mean)mean = df['Sunshine'].mean()df['Sunshine'] = df['Sunshine'].fillna(mean)df['WindSpeed9am'] = df[['WindGustDir', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am']].iloc[:,3].fillna(df['WindSpeed9am'].mean())df.drop('Date', axis=1, inplace=True)y = df['RainTomorrow'].valuesy_idx = np.where(y=='Yes')n_idx = np.where(y=='No')y[y_idx] = 1 ; y[n_idx] = 0df.drop('RainTomorrow', axis=1, inplace=True)# 타겟 y # 이 값들 타겟으로 잡으면 이진분류 문제가 된다. # 5, 7, 8, 19; string 값 가진 특성변수 제외 new_df = df.drop(['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], axis=1)new_df.isnull().sum() # 입력 특성변수들 X = new_df.values ; X 모델 훈련시키기# 훈련용 셋과 테스트용 셋으로 분리 x_train, x_test, y_train, y_test = train_test_split(X, np.array(list(y)), test_size=0.25, random_state=0)from sklearn.linear_model import LogisticRegression model = LogisticRegression()# 모델 훈련시키기model.fit(x_train, y_train)모델 성능 확인# 테스트 데이터에 대해 모델 예측 y_pred = model.predict(x_test)# 정확도 계산 (모델 성능지표 계산)from sklearn.metrics import accuracy_scoreacc_score = accuracy_score(y_test, y_pred) print(f'로지스틱회귀 이진분류 모델 정확도:{round(acc_score*100, 2)}%')로지스틱회귀 이진분류 모델 정확도: 97.83%서포트벡터 머신 (Support Vector Machine) 알고리즘이진분류 알고리즘이다.정의마진 최대화 하는, 초평면 찾기. 마진: 초평면과 서포트벡터 사이 거리 서포트벡터: 초평면에서 가장 가까운 벡터들을 서포트벡터(support vector) 라고 한다.$\\Rightarrow$ 두 클래스 가장 ‘잘’ 구분하는, 초평면 찾기.서포트벡터 머신 모형으로 이진분류 문제 해결하기# 임의 데이터셋 생성 x1, y1 = make_gaussian_quantiles(mean=[4,2],cov=1, random_state=3, n_samples=200, n_features=2, n_classes=1, shuffle=True)x2, y2 = make_gaussian_quantiles(mean=[-2,0],cov=1, random_state=1, n_samples=200, n_features=2, n_classes=1, shuffle=True)y1 = [1]*len(y1)# X: 특성변수들, y: 타겟값들 X = np.concatenate([x1, x2], axis=0) ; y = np.concatenate([y1, y2], axis=0) idx_0 = np.where(y==0); idx_1 = np.where(y==1)# 생성된 데이터셋 시각화 plt.scatter(X[idx_0, 0], X[idx_0,1], c='r', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='g', label='class=1')plt.legend()plt.title('New Sample Data')plt.show() x1_min, x1_max = X[:,0].min(), X[:,0].max() x2_min, x2_max = X[:,1].min(), X[:,1].max() xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02))plt.scatter(xx1, xx2)# 서포트벡터 머신 from sklearn.svm import SVCclassifier_svm = SVC(kernel='linear', random_state=0)# 모델 학습 classifier_svm.fit(X, y)# 모델 예측 xx_predict = np.c_[xx1.ravel(), xx2.ravel()]Y = classifier_svm.predict(xx_predict).reshape(xx1.shape)# 예측 결과 시각화 cs = plt.contourf(xx1, xx2, Y)plt.colorbar(cs)idx_0 = np.where(y==0); idx_1 = np.where(y==1)plt.scatter(X[idx_0, 0], X[idx_0,1], c='c', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='m', label='class=1')plt.legend()plt.title('Support Vector Machine; Prediction Result')plt.show() 나이브 베이즈 알고리즘확률론 기반 분류 알고리즘.특징 입력 데이터셋 모든 특성변수가 서로 독립 이라는, ‘나이브(naive)’ 한 기본 가정 사용한다. 베이즈 정리 사용한다.나이브 베이즈 모형으로 이진분류 문제 해결하기from sklearn.naive_bayes import GaussianNB# 나이브 베이즈 분류모형 classifier = GaussianNB() # 모형 학습 classifier.fit(X, y)# 모형 예측yy = classifier.predict(xx_predict).reshape(xx1.shape)# 모형 에측 결과 시각화 cs = plt.contourf(xx1, xx2, yy)plt.colorbar(cs)idx_0 = np.where(y==0); idx_1 = np.where(y==1)plt.scatter(X[idx_0, 0], X[idx_0,1], c='c', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='m', label='class=1')plt.legend()plt.title('Naive Bayes; Prediction Result')plt.show() 분류 알고리즘 별 성능 비교 의사결정나무 xgboost(앙상블-부스트-그래디언트 부스트) 랜덤포레스트(앙상블-취합-배깅) 로지스틱 회귀 서포트벡터 머신 나이브 베이즈같은 분류문제에 대해 위 6개 분류 알고리즘 분류성능을 비교할 것이다.# 분류알고리즘 별 성능 비교 from sklearn.tree import DecisionTreeClassifierimport xgboostfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.linear_model import LogisticRegressionfrom sklearn.svm import SVCfrom sklearn.naive_bayes import GaussianNB# 유방암 데이터셋 로드 from sklearn.datasets import load_breast_cancer data = load_breast_cancer() X = data.data y = data.target feature_names = data.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['y'] = ydfdf.shape(569, 31)df.isnull().sum()mean radius 0mean texture 0mean perimeter 0mean area 0mean smoothness 0mean compactness 0mean concavity 0mean concave points 0mean symmetry 0mean fractal dimension 0radius error 0texture error 0perimeter error 0area error 0smoothness error 0compactness error 0concavity error 0concave points error 0symmetry error 0fractal dimension error 0worst radius 0worst texture 0worst perimeter 0worst area 0worst smoothness 0worst compactness 0worst concavity 0worst concave points 0worst symmetry 0worst fractal dimension 0y 0dtype: int64# 데이터셋 훈련용 vs 테스트용으로 분리from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)print(x_train.shape) ; print(x_test.shape)(426, 30)(143, 30)# 분류모형 호출 및 훈련데이터 학습 # 의사결정나무 분류모델 decisiontree_model = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=0).fit(x_train, y_train)# xgboost xgb_model = xgboost.XGBClassifier(n_estimators=100, max_depth=1, random_state=0).fit(x_train, y_train)# random forest randomforest_model = RandomForestClassifier(max_depth=1, n_estimators=100, random_state=0).fit(x_train, y_train)# logistic regrssionlogistic_model = LogisticRegression(random_state=0).fit(x_train, y_train)# svm xvm_model = SVC(kernel='linear', random_state=0).fit(x_train, y_train)# naive bayes naive_model = GaussianNB().fit(x_train, y_train)모델 분류 정확도, 재현율, 정밀도 출력하는 함수 정의from sklearn.metrics import accuracy_score from sklearn.metrics import precision_scorefrom sklearn.metrics import recall_score def result_presentation(model) : y_pred = model.predict(x_test) acc_score = accuracy_score(y_test, y_pred) prc_score = precision_score(y_test, y_pred) rec_score = recall_score(y_test, y_pred) return acc_score, prc_score, rec_score # 분류 정확도, 정밀도, 재현율acc_score1, prc_score1, rec_score1 = result_presentation(decisiontree_model)acc_score2, prc_score2, rec_score2 = result_presentation(xgb_model)acc_score3, prc_score3, rec_score3 = result_presentation(randomforest_model)acc_score4, prc_score4, rec_score4 = result_presentation(logistic_model)acc_score5, prc_score5, rec_score5 = result_presentation(xvm_model)acc_score6, prc_score6, rec_score6 = result_presentation(naive_model)결과물 시각화 하는 데이터프레임 생성result_df = pd.DataFrame({ '알고리즘' : ['TR', 'XGB', 'RF', 'LR', 'SVM', 'NB'], '정확도' : [acc_score1, acc_score2, acc_score3, acc_score4, acc_score5, acc_score6], '재현율' : [rec_score1, rec_score2, rec_score3, rec_score4, rec_score5, rec_score6], '정밀도' : [prc_score1, prc_score2, prc_score3, prc_score4, prc_score5, prc_score6]}) ; result_df막대 그래프로 위 데이터프레임 내용 시각화plt.figure(figsize=(10,5))plt.subplot(1,3,1)plt.bar(range(len(result_df['알고리즘'].values)), result_df['정확도'].values) plt.xticks(range(len(result_df['알고리즘'].values)), result_df['알고리즘'].values)plt.ylabel('Accuracy_score')plt.subplot(1,3,2)plt.bar(range(len(result_df['알고리즘'].values)), result_df['재현율'].values) plt.xticks(range(len(result_df['알고리즘'].values)), result_df['알고리즘'].values)plt.ylabel('Recall_score')plt.subplot(1,3,3)plt.bar(range(len(result_df['알고리즘'].values)), result_df['정밀도'].values) plt.xticks(range(len(result_df['알고리즘'].values)), result_df['알고리즘'].values)plt.ylabel('Precision_score')plt.suptitle('Models Score')plt.tight_layout()plt.show() 이 경우엔 대체로 서포트벡터 머신 모형이 가장 높은 성능 기록했다." }, { "title": "[알고리즘/지도학습] 앙상블 알고리즘-부스팅(에이다 부스트, 그래디언트 부스트)", "url": "/bioinfo.github.io/posts/boosting/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-08-09 00:00:00 +0900", "snippet": "2. 부스팅(Boosting)정의모델 1개로 시작해서, 모델 집합에 약 분류기 계속 추가해 나가는 앙상블 알고리즘. 한번에 모델 1개씩 만 추가한다. 약 분류기 모두 추가한 최종 모형은, 개별 모형의 가중선형조합 형태다. $c_{m} = \\alpha_{1}k_{1} + … + a_{m}k_{m}$ 부스팅은 이진분류를 위해 사용하며, 부스팅 모형 출력은 1 또는 -1 이다. $\\Rightarrow c_{m} = sign(\\alpha_{1}k_{1} + … + a_{m}k_{m})$에이다 부스트(Adaptive Boost)정의모델 집합 내 기존 모델들이 데이터 맞추는/틀리는 ‘상황에 맞춰서(Adaptive)’, 기존 모델들이 잘 틀렸던 문제 가장 잘 맞추는 새 모델을 집합에 추가하는, 앙상블 알고리즘. ‘기존 모델들이 잘 틀렸거나/ 잘 맞춘 문제’ 표현 위해, 데이터포인트 별 가중치 $w_{m, i}$ (m= m번째 모델이 사용할 가중치, i= i번째 데이터포인트의 가중치) 사용한다. 데이터포인트 별 가중치 높을 수록 모델들이 잘 틀리는 문제, 낮을 수록 모델들이 잘 맞추는 문제다.모델 업데이트 방법첫째.$L = \\sum{w_{m,i}I(k_{m}(x_{i}) \\ne y_{i})}$ 최소화 하는 모델 $k_{m}$ 찾는다. 이 손실함수는 ‘후보 모델이 틀린 데이터포인트의 가중치 합’ 이다. 데이터포인트 별 가중치 $w_{m, i}$ 는 맨 처음에는 $\\frac{1}{n}$ 으로, 모든 데이터포인트에 같은 값 부여한다.둘째.$k_{m}$ 찾았으면 모델 가중치 $\\alpha_{m}$ 계산한다.$\\epsilon_{m} = \\frac{\\sum_{i=1}^{N}w_{m,i}I(k_{m}(x_{i})\\ne y_{i})}{\\sum_{i=1}^{N}w_{m, i}}$$\\alpha_{m} = \\frac{1}{2}\\log(\\frac{1-\\epsilon_{m}}{\\epsilon_{m}})$셋째.모델 집합 구성한다.$c_{m} = \\alpha_{1}k_{1} + … + \\alpha_{m}k_{m}$모델 집합에 데이터셋 넣어서, 각 데이터포인트에 대해 모델 앙상블이 맞추는지, 틀리는지 확인한다.넷째.모델 집합이 데이터포인트를 맞혔느냐 / 틀렸느냐에 따라서, 데이터포인트 별 가중치 업데이트 한다.모델 집합이 틀린 데이터포인트는 가중치 크기 증가하고, 맞춘 데이터포인트는 가중치 크기 감소한다.데이터포인트 가중치 증가/감소 시킬 때는 지수함수 $e^{x}$ 를 사용해서, 모델이 맞춘 데이터포인트 가중치는 크게 감소, 틀린 데이터포인트 가중치는 크게 증가시킨다.업데이트 된, 새 데이터포인트 가중치 $w_{m,i}$ :$w_{m,i} = w_{m-1,i}exp(-y_{i}c_{m-1})$ if $c_{m-1} = y_{i} : w_{m,i} = w_{m-1,i}e^{-1}$ if $c_{m-1} \\ne y_{i} : w_{m,i} = w_{m-1}e^{1}$모델이 데이터포인트 맞출 때 마다, 기존 가중치의 $e$ 승수를 -1 감소시킨다.모델이 데이터포인트 틀릴 때 마다, 기존 가중치의 $e$ 승수를 1 증가시킨다.모델 앙상블 분류 결과에 기반해서 데이터포인트 별 가중치 업데이트 한 뒤, 다시 첫번째 과정으로 돌아가서 1번부터 4번 과정 반복한다.구현# 에이다부스트 구현 from sklearn.tree import DecisionTreeClassifierfrom sklearn.ensemble import AdaBoostClassifier# 데이터셋 생성 X1, y1 = make_gaussian_quantiles(cov=2., n_samples=100, n_features=2, n_classes=2, random_state=1)X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5, n_samples=200, n_features=2, n_classes=2, random_state=1)# 특성변수들X = np.concatenate((X1, X2))# 타겟값들y = np.concatenate((y1, - y2 + 1))#---# 에이다부스트 클래스 상속받는 클래스를 만든다. 원본 에이다부스트 클래스의 전체 코드 플로우는 그대로 흐르고# 코드 17번째 줄에서 데이터포인트 별 가중치만 중간에 살짝 복사해 빼내도록 했다. class MyAdaBoostClassifier(AdaBoostClassifier): def __init__(self, base_estimator=None, n_estimators=50, learning_rate=1., algorithm='SAMME.R', random_state=None): super(MyAdaBoostClassifier, self).__init__( base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, random_state=random_state) self.sample_weight = [None] * n_estimators def _boost(self, iboost, X, y, sample_weight, random_state): sample_weight, estimator_weight, estimator_error = super(MyAdaBoostClassifier, self)._boost(iboost, X, y, sample_weight, random_state) self.sample_weight[iboost] = sample_weight.copy() # 데이터포인트 별 가중치만 살짝 복사해 받아오기 return sample_weight, estimator_weight, estimator_error# 약 분류기로 20개 얕은 의사결정나무 사용한, 에이다부스트 모형 정의 및 학습 model_ada = MyAdaBoostClassifier(DecisionTreeClassifier(max_depth=1, random_state=0), n_estimators=20)model_ada.fit(X, y)# 분류 결과 시각화 함수 정의def plot_result(model, title=\"분류결과\", legend=False, s=50): # 전체 배경 직사각형 구성하는 벡터 생성 위한 코드 x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1 x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02)) #--- # 전체 배경 직사각형 구성하는 벡터 하나하나에 대해 모델 예측: Y= 0또는 1 if isinstance(model, list): Y = model[0].predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape) for i in range(len(model) - 1): Y += model[i + 1].predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape) else: Y = model.predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape) # 직사각형과 각 벡터 예측값 나타내는 3차원 그래프를 2차원에 색상으로 표현 cs = plt.contourf(xx1, xx2, Y, cmap=plt.cm.Paired, alpha=0.5) # 훈련 데이터셋 X, y 를 스캐터플롯으로 표시; 0=파랑, 1=빨강 for i, n, c in zip(range(2), \"01\", \"br\"): idx = np.where(y == i) plt.scatter(X[idx, 0], X[idx, 1], c=c, s=s, alpha=0.5, label=\"Class %s\" % n) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.xlabel('x1') plt.ylabel('x2') plt.title(title) # 3차원 고도(등고선) 을 컬러 바(bar) 로 표현 plt.colorbar(cs) if legend: plt.legend() plt.grid(False)# 분류 결과 출력 plot_result(model_ada, \"에이다부스트(m=20) 분류 결과\")i 번째 모델집합 분류결과 반영한, 데이터포인트 별 가중치 시각화 - 1막대 그래프 사용해서 시각화 했다.for i in range(1, 21) : plt.subplot(4,5,i) xx = model_ada.sample_weight[i-1] # i 번째 모델 집합 분류결과 반영한 데이터포인트 별 가중치 plt.bar(range(len(xx)), xx) plt.title(f'{i}') plt.axis('off')plt.suptitle('300개 데이터 별 가중치 변화')plt.tight_layout() plt.show() i 번째 모델집합 분류결과 반영한, 데이터포인트 별 가중치 시각화 - 2스캐터플롯 사용해서 시각화 했다.가중치 크면(모델들이 자주 틀린 데이터포인트면) 점 크기 크고,모델들이 잘 맞춘 데이터포인트면 점 크기 작다.def plot_result2(model, legend=False, s=50, title='분류결과') : x1_min, x1_max = X[:,0].min() - 1 , X[:,0].max() + 1 # 입력행렬 X의 X 축 최솟값 &amp; 최댓값 x2_min, x2_max = X[:,1].min() - 1, X[:, 1].max() + 1 # 입력행렬 X 의 Y 축 최솟값 &amp; 최댓값 # x 축 최소 최대, y축 최소 최대 이용해서 정사각형 좌표 생성 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02)) # xx1 = 정사각형 x 좌표, xx2 = 정사각형 y 좌표 # 정사각형 2차원 평면 위 각 점에 대한 모델의 예측 결과: Y. 1 또는 0이다. Y = model.predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape) # 정사각형 각 위 점에 예측 결과 Y 결합; 3차원 그래프 2차원 평면에 색깔로 표현. cs = plt.contourf(xx1, xx2, Y, alpha=0.5) # 맨 처음 표본 데이터 그래프에 함께 표현 for i, n, c in zip(range(2), '01', 'br') : idx = np.where(y == i) # y 정답값이 i 인 X 행렬 레코드 행. plt.scatter(X[idx, 0], X[idx, 1], c=c, s=s[idx], alpha=0.7, label=f'class {i}') plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.xlabel('x1') plt.ylabel('x2') plt.title(title) plt.colorbar(cs) if legend : plt.legend() plt.grid(False) plt.show() for i in range(11, 19) : plot_result2(model_ada.estimators_[i], legend=True, s=(4000*model_ada.sample_weight[i-1]).astype(int), title=f'{i}번 모형 분류 결과')결과 이미지는 11번 모형과 18번 모형 둘 만 기록했다.학습률과 과적합에이다부스트 모델 집합에 약 분류기 계속 추가 할 수록, 모델은 훈련 데이터에 과적합 되는 경향이 있다.잘 틀리는 데이터 가장 잘 맞추는 약 분류기(개별모형) 계속 모델 집합에 추가하다 보니 나타나는 현상이다.에이다부스트 모델 과적합 억제하려면, 학습률(learning rate) 을 1 미만으로 적절히 낮추면 된다.학습률에 따라 학습/검증 상황이 어떻게 달라지는 지 보자.learning_list = np.arange(0.001, 0.011, 0.001)ind = 1for i in learning_list : train_acc = [] test_acc = [] for n in range(1, 1101, 100) : model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=n, learning_rate=i).fit(x_train, y_train) train_acc.append(accuracy_score(y_train, model.predict(x_train))) test_acc.append(cross_val_score(model, x_test, y_test, cv=5).mean()) plt.subplot(2,5,ind) plt.plot(range(len(range(1, 1101, 100))), train_acc) plt.plot(range(len(range(1, 1101, 100))), test_acc) ind += 1plt.tight_layout() 위 그래프 10개는 학습률을 0.001 부터 0.01 까지 10개 줬을 때, 각각 약 분류기 갯수 1에서 100까지 늘려가며 학습 정확도 / 검증 교차검증 정확도 평균 을 그래프로 시각화 한 것이다.한편 아래 경우는 ‘개별 모델 갯수 증가할 때, 학습률 높으면 과적합이 잘 발생한다’를 위 경우보다 더 분명하게 보여준다.빨간색이 테스트셋에서 검증 성능, 파란색이 훈련셋에서 성능 나타낸다. 학습률이 0.8 일 때 까지는 과적합 나타나지 않다가, 0.9가 되면서 과적합이 나타났다.그래디언트 부스트(Gradient Boost)정의최적화 알고리즘 중 최급강하법(Gradient Descent) 이용해, 끊임없이 손실 줄이며 모델 업데이트 하는 알고리즘.최급강하법 알고리즘정의:시작위치에서 손실 가장 크게 감소하는 방향(손실함수 기울기 가장 가파르게 감소하는 방향) 으로 계속 이동하며, 손실함수 최소점 찾는 알고리즘.손실함수 위 점과 점 이동:$x_{m+1} = x_{m} - \\mu\\frac{df}{dx}$다음 위치 $x_{m+1}$ : 시작점 $x_{m}$ 에서의 그레디언트 벡터 반대 방향으로, 스텝사이즈 $\\mu$ 만큼 이동한 위치 다음 위치 $x_{m+1}$ 은 $x_{m}$ 보다 손실 감소한 위치다.위 식을 변형하면 아래와 같다.$\\Rightarrow x_{m+1} = x_{m} + \\mu(-\\frac{df(x_{m})}{dx})$$x_{m}$ 은 벡터다.$-\\frac{df(x_{m})}{dx}$ 은 벡터 $x_{m}$ 의 그레디언트 벡터에 - 를 취한 것이다. 곧, 그레디언트 벡터 방향 정 반대로 바꾼 것이다.$-\\frac{df(x_{m})}{dx}$ 에 스텝사이즈 $\\mu$ 곱하면 negative gradient 의 길이가 조정된다.벡터 $x_{m}$ 에 $\\mu(-\\frac{df(x_{m})}{dx})$ 를 더한 위치가 손실 감소한 다음 위치 $x_{m+1}$ 이다.*벡터 $x_{m}$ 에 $\\mu(-\\frac{df(x_{m})}{dx})$ 를 더한 결과는 시점이 $x_{m}$ 이고 화살표 끝 점이 $x_{m+1}$ 인 벡터와도 같다.그래디언트 부스팅은 위 최급강하법 알고리즘을 모델 업데이트에 적용한 앙상블 알고리즘이다.모델 업데이트 방법$c_{m} = c_{m-1} -\\alpha_{m}\\frac{\\partial{L(y, c_{m-1})}}{\\partial{c_{m-1}}}$$\\Rightarrow c_{m} = c_{m-1} +\\alpha_{m}(-\\frac{\\partial{L(y, c_{m-1})}}{\\partial{c_{m-1}}})$ $c_{m}$ : 새 모델(손실함수 위 새 위치) $c_{m-1}$ : 기존 모델(손실함수 위 기존 위치) $\\alpha_{m}$ : 스텝사이즈(이동거리) $-\\frac{\\partial{L(y, c_{m-1})}}{\\partial{c_{m-1}}}$: negative gradient. 방향 정 반대로 바꾼, 점 $c_{m-1}$ 에서의 그레디언트 벡터. $c_{m-1}$ 이 이동해야 할 방향이다.모델 $c_{m}, c_{m-1}$ 을 손실함수 위 점(벡터)로 생각하면 된다.위 식의 의미를 해석하면, ‘기존 모델 $c_{m-1}$ 보다 손실 감소하는 방향과 거리에 위치한 새 모델 $c_{m}$ 을 찾은 것’ 이다.그래디언트 부스팅 알고리즘은 위 식 계산을 반복적으로 수행하며, 계속 손실 줄이는 방식으로 모델 반복적 업데이트 한다.전체 알고리즘 진행 과정[ 이미지 출처: https://m.blog.naver.com/winddori2002/221837065744?view=img_2 ] 특성변수들과 타겟값으로 이루어진 훈련용 데이터셋 준비, 모델 업데이트 할 총 횟수 $M$ 지정, 그리고 미분가능한 손실함수 $L(y, f(x))$를 정의한다. 손실함수 위 첫 시작위치로, $F_{0}(x) = argmin_{r}{(\\sum_{i=1}^{n}{L(y_{i}, r)})}$ 를 만족하는 상수 $r$ 을 찾는다. 예컨대 만약 손실함수 $L$ 이 오차 제곱 이라면, 훈련 데이터셋 타겟값 $y_{i}$ 와 오차 제곱합 최소로 만드는 상수 $r$ 을 찾고, 최적화 시작점으로 삼는다. $(F_{0}{(x)} = r)$ 최적화 시작점 $r$ 에서의 negative gradient 벡터를 찾는다. 타겟값 $y_{i} (i=1,…,n)$ 별로 서로 다른 negative gradient $n$ 개 생성된다. $r_{im} = negative$ $gradient_{1…n}$ 앙상블 약 분류기인, 임의의 의사결정회귀나무 $h_{m}(x)$ 를 3에서 구한 negative gradient 들을 타겟값으로 삼아 훈련시킨다. 즉, 1의 훈련용 데이터셋에서 $x$ 특성변수들은 그대로 두고, $y$ 타겟값만 negative gradient 들로 바꾼 뒤 $h_{m}(x)$ 모델에 넣어 훈련시킨다. 모델이 학습하는 것은 긱 데이터포인트에 대해, ‘손실 최소화 하기 위한 손실함수 위 이동 방향’ 이다. 이제 $h_{m}(x)$ 모델은 임의의 새로운 입력 $x$ 를 받게 되면 $x$ 에 대응되는 negative gradient 예측값을 내놓을 것이다. 즉, ‘현재모델 $F_{m-1}(x)$ 기준, 모델 손실 최소화 할 수 있는 방향 예측치’를 출력할 것이다. $r_{m} = argmin_{r_{m}}{\\sum_{i=1}^{n}(y_{i} - F_{m-1}(x_{i}) + r_{m} h_{m}(x_{i}))^{2}}$ 만족하는 스텝사이즈 $r_{m}$ 찾는다. 기존모델 $F_{m-1}(x) +$ 스텝사이즈 $r_{m}$ $\\times$ negative gradient 예측치 출력하는 약 분류기 $h_{m}(x)$ $=$ 업데이트 된 모델 $F_{m}(x)$ 위 3번에서 6번 과정을 $M$ 번 반복한다. 손실을 계속 줄여가면서, 모델이 계속 업데이트 된다.그래디언트 부스트 기반 알고리즘 종류 XGBoost LightGBM구현# 사이킷런 그래디언트 부스트 분류기 호출from sklearn.ensemble import GradientBoostingClassifier # 내부 약 분류기로 의사결정회귀나무 사용# 분류 모델 준비 model_grad = GradientBoostingClassifier(n_estimators=100, max_depth=2, random_state=0) # {약 분류기 갯수: 100개, 약 분류기 깊이: 2, 랜덤시드:0}샘플 데이터셋 구성%%time %matplotlib inline # 데이터셋 호출 from sklearn.datasets import make_gaussian_quantiles# 임의 생성 데이터셋x1, y1 = make_gaussian_quantiles(cov=2.0, random_state=0, n_samples=200, n_features=2, n_classes=2, shuffle=True)x2, y2 = make_gaussian_quantiles(cov=2.0, random_state=1, n_samples=200, n_features=2, n_classes=2, shuffle=True)X = np.concatenate([x1, x2], axis=0) ; y = np.concatenate([y1, y2], axis=0) idx_0 = np.where(y==0); idx_1 = np.where(y==1)# 데이터셋 시각화 plt.scatter(X[idx_0, 0], X[idx_0,1], c='r', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='g', label='class=1')plt.legend()plt.title('Sample Data')plt.show() 이렇게 생긴 데이터셋이다.# 모델 성능 검증에 쓸 데이터셋 형태 둘러보기 x1_min, x1_max = x1[:,0].min(), x1[:,0].max() x2_min, x2_max = x2[:,0].min(), x2[:,0].max() xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 1), np.arange(x2_min, x2_max, 1))plt.scatter(xx1, xx2)plt.axis('off')plt.show() xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02))plt.scatter(xx1, xx2)그래디언트 부스트 분류기에 훈련용 데이터 학습시키기%%time # 그래디언트부스트 분류기, 훈련용 데이터 학습 fitted_model = model_grad.fit(X, y)그래디언트 부스트 분류기로 새 데이터셋의 정답 예측# 그래디언트부스트 분류기, 새 데이터셋 예측 xx_predict = np.c_[xx1.ravel(), xx2.ravel()]Y = fitted_model.predict(xx_predict).reshape(xx1.shape)# 새 데이터셋 예측 결과 시각화 cs = plt.contourf(xx1, xx2, Y)plt.colorbar(cs)idx_0 = np.where(y==0); idx_1 = np.where(y==1)plt.scatter(X[idx_0, 0], X[idx_0,1], c='c', label='class=0')plt.scatter(X[idx_1, 0], X[idx_1,1], c='m', label='class=1')plt.legend()plt.title('gradient boost model prediction result on test data')plt.show() 손실 계속 줄여가며 모델 업데이트하는 그래디언트부스트 모델이 상당히 정확하게 예측해냈음을 확인할 수 있었다.개별 약 분류기 분류 결과 시각화; 1번째 약 분류기(의사결정회귀나무)print(f'앙상블 weak learner 갯수: {len(fitted_model.estimators_)}')print(fitted_model.estimators_[0][0]) # 약 분류기는 모두 의사결정회귀나무다. # 시각화 함수 정의def plot_result(model,x1, x2, X, y) : x1_min, x1_max = x1[:,0].min(), x1[:,0].max() x2_min, x2_max = x2[:,0].min(), x2[:,0].max() xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02)) fitted_model = model.fit(X, y) xx_predict = np.c_[xx1.ravel(), xx2.ravel()] Y = fitted_model.predict(xx_predict).reshape(xx1.shape) cs = plt.contourf(xx1, xx2, Y) plt.colorbar(cs) idx_0 = np.where(y==0); idx_1 = np.where(y==1) plt.scatter(X[idx_0, 0], X[idx_0,1], c='c', label='class=0') plt.scatter(X[idx_1, 0], X[idx_1,1], c='m', label='class=1') plt.legend() plt.title('gradient boost model prediction result on test data') plt.show() # 첫번째 개별 분류기 분류결과 plot_result(fitted_model.estimators_[0][0],x1,x2, X, y)에이다부스트 모델 분류 결과와 비교# 에이다부스트모델 결과와 비교 from sklearn.ensemble import AdaBoostClassifierfrom sklearn.tree import DecisionTreeClassifier# 에이다부스트 모델 adamodel = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=100)fitted_ada = adamodel.fit(X, y)plot_result(adamodel, x1, x2, X, y)XGBoost 알고리즘정의모든 작업을 병렬처리하는, 그래디언트 부스트 알고리즘.효용 과적합에 robust 하다. 성능과 효율 모두 뛰어나다.구현%%time # 작업수행시간 측정import xgboost # xgboost 모델 정의 model_xgb = xgboost.XGBClassifier(n_estimators=100, max_depth=1, random_state=0)model_xgb.fit(X,y)CPU times: total: 266 msWall time: 83.7 msXGBoost 분류기; 설정 가능한 하이퍼파라미터들XGBClassifier(base_score=0.5, booster=’gbtree’, callbacks=None, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None, enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1, grow_policy=’depthwise’, importance_type=None, interaction_constraints=’’, learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=1, max_leaves=0, min_child_weight=1, missing=nan, monotone_constraints=’()’, n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=’auto’, random_state=0, reg_alpha=0, reg_lambda=1, …)새 데이터셋에 대한 분류 결과 시각화# 새 데이터셋 분류 결과 시각화 plot_result(model_xgb, x1, x2, X, y)LightGBM 알고리즘XGBoost 알고리즘과 마찬가지로, 그래디언트 부스트 알고리즘을 기반으로 한다.효용 속도가 빠르다 (GB &gt; XGBoost &gt; LightGBM)단점 데이터셋 갯수가 10,000 개 이하일 때는 과적합에 빠지기 쉽다. 따라서 갯수가 10,000개 초과하는 데이터셋에 사용하는 것이 좋다.구현%%time import lightgbm# lightgbm 모델 정의model_lgbm = lightgbm.LGBMClassifier(n_estimators=100, max_depth=1, random_state=0)# 모델 학습model_lgbm.fit(X, y)# 결과 시각화 plot_result(model_lgbm, x1, x2, X, y)" }, { "title": "[알고리즘/지도학습] 앙상블 알고리즘-취합(다수결 투표, 배깅, 랜덤포레스트)", "url": "/bioinfo.github.io/posts/ensemble/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-08-08 00:00:00 +0900", "snippet": "모델 앙상블(ensemble)정의여러 모델 조합해서, 데이터 분류하는 알고리즘효과 개별 모형보다 과적합 잘 억제할 수 있다. 개별 모형 성능 떨어져도, 여러 개 묶어놓으면 성능 더 향상된다.종류취합(aggregation) 다수결 투표(hard, soft voting) 배깅(bagging; boostrap aggregation) 랜덤포레스트(배깅의 한 종류)부스팅(boosting) 에이다부스트(adaboost) 그레디언트부스트(gradient boost)1. 취합(aggregation)다수결 투표 hard voting soft voting 모델 집단에 여러 종류 모델 포함할 수 있다.Hard Voting정의단순 다수결 투표.모델 집단에서 최다득점한 클래스로, 데이터 분류한다.예컨대 모델 집단에 5개 모델이 있고, 데이터포인트 1개에 대한 각 모델 분류결과가 $(0:2)$, $(1:3)$ 이라고 하자. 단순 다수결 방식에 의하면 이 데이터포인트는 1로 분류된다.구현파이썬 사이킷런 라이브러리 사용해서 hard voting 방식 모델 앙상블을 구현하고, 개별 모델과 성능 비교했다.그 후 새 데이터셋에 대한 예측 결과 시각화해서, 각 모델 별 예측 결과 비교했다.# 모델 학습하고 성능평가할 데이터셋 구축%matplotlib inline from sklearn.datasets import make_gaussian_quantilesx1, y1 = make_gaussian_quantiles(cov=2, n_samples=200, n_features=2, n_classes=2, random_state=0)x2, y2 = make_gaussian_quantiles(mean=(3,3), cov=1.5, n_samples=200, n_features=2, n_classes=2, random_state=0)plt.title('sample data')plt.scatter(x1[:,0], x1[:,1]) ; plt.scatter(x2[:,0], x2[:,1], c='b')plt.show()클래스 2개 (0과 1), 특성값 2개, 총 400개 데이터포인트(레코드)로 구성된 데이터셋이다.# 두 파트로 구성된 데이터셋을 하나로 합친다; X, yX = np.concatenate([x1, x2], axis=0)y = np.concatenate([y1, y2], axis=0) # 모델 훈련 데이터와 검증 데이터로 분리한다. from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)두 파트로 구성된 데이터셋을 하나로 합치고, 훈련셋과 검증셋 두 파트로 분리했다.# 모델 앙상블 구축 from sklearn.linear_model import LogisticRegressionfrom sklearn.naive_bayes import GaussianNBfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysisfrom sklearn.ensemble import VotingClassifierfrom sklearn.metrics import accuracy_score model1 = LogisticRegression(random_state=1)model2 = GaussianNB()model3 = QuadraticDiscriminantAnalysis()# 모델 앙상블model_ensemble = VotingClassifier(estimators=[('lr', model1), ('gnb', model2), ('qda', model3)], voting='hard')result1 = accuracy_score(y_test, model1.fit(x_train, y_train).predict(x_test))result2 = accuracy_score(y_test, model2.fit(x_train, y_train).predict(x_test))result3 = accuracy_score(y_test, model3.fit(x_train, y_train).predict(x_test))result4 = accuracy_score(y_test, model_ensemble.fit(x_train, y_train).predict(x_test))print(f'로지스틱회귀 검증셋 정확도: {result1}') ; print(f'가우시안 나이브베이즈 검증셋 정확도 : {result2}') ; print(f'QDA 모형 검증셋 정확도: {result3}') 로지스틱 회귀, GNB, QDA, 그리고 셋을 조합한 모델 앙상블을 구축했다. 모델 앙상블의 voting 방식은 hard voting을 적용했다. 따라서 모델 앙상블 구성하는 세 모델의 분류 결과를 가지고 단순 다수결 투표 한 게 최종 결과가 될 것이다.개별 모델들과 모델 앙상블의 정확도 출력했다. 로지스틱회귀 검증셋 정확도: 0.36 가우시안 나이브베이즈 검증셋 정확도 : 0.63 QDA 모형 검증셋 정확도: 0.82 모델 앙상블 검증셋 정확도: 0.7 아래 막대그래프는 위 모델 별 정확도를 시각화 한 것이다.import seaborn as sns sns.barplot([1,2,3,4], [result1, result2, result3, result4])plt.xticks([0,1,2,3], ['lr', 'gnb', 'qda', 'ensemble'])plt.xlabel('models')plt.ylabel('accuracy score')plt.title('Accuracy Score per models')plt.show() 이 데이터에 대해서는 QDA 가 가장 성능이 높게 나왔다.하지만 앙상블도 LR, GNB보다 높은 성능을 보였고, QDA와도 그렇게까지 큰 성능차 나지 않았다.이제부터 새 데이터셋에 대해 예측하고, 예측 결과를 시각화 할 것이다.# 모델 예측 결과 시각화 - 2x1min, x1max = X[:,0].min(), X[:,0].max() x2min, x2max = X[:,1].min(), X[:,1].max()# 예측할 샘플 데이터셋 xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, 0.01), np.arange(x2min, x2max, 0.01)) X2 = np.c_[xx1.ravel() , xx2.ravel()]plt.scatter(xx1, xx2)위 데이터셋은 다음과 같이 생겼다.무수히 많은 점들이 직사각형을 이루고 있다. 점들 간 간격을 늘리면 아래와 같아진다.xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, 1), np.arange(x2min, x2max, 1)) plt.scatter(xx1, xx2)이제 앞에서 훈련한 모델들에게 위 데이터셋을 예측하도록 시켰다.# 개별모델3, 앙상블1 훈련 model1 = model1.fit(x_train, y_train)model2 = model2.fit(x_train, y_train)model3 = model3.fit(x_train, y_train)ensemble = model_ensemble.fit(x_train, y_train)# 샘플 데이터셋 X2 예측 Y1 = model1.predict(X2).reshape(xx1.shape)Y2 = model2.predict(X2).reshape(xx1.shape)Y3 = model3.predict(X2).reshape(xx1.shape)Y4 = ensemble.predict(X2).reshape(xx1.shape)plt.subplot(2,2,1)plt.contourf(xx1, xx2, Y1)plt.title(f'lr; acc={result1}')plt.subplot(2,2,2)plt.contourf(xx1, xx2, Y2)plt.title(f'gnb; acc={result2}')plt.subplot(2,2,3)plt.contourf(xx1, xx2, Y3)plt.title(f'qda; acc={result3}')plt.subplot(2,2,4)plt.contourf(xx1, xx2, Y4)plt.title(f'ensemble; acc={result4}')plt.suptitle('Model Prediction Results')plt.tight_layout() plt.show() 실제 데이터셋 0과 1 분포idx0 = np.where(y == 0) idx1 = np.where(y == 1)plt.title('sample data')plt.scatter(X[idx0,0], X[idx0,1], c='r', label='class:0') ; plt.scatter(X[idx1,0], X[idx1,1], c='b', label='class:1')plt.legend() plt.show()Soft Voting - 평균 방식정의각 모델, 클래스별 조건부확률 평균 비교해서. 평균값 가장 큰 클래스로 데이터포인트 분류하는 방법.예컨대 이진분류 문제이고, 앙상블 모델 집단에 모델 1,2,3,4 가 있다고 가정하자.1개 데이터포인트에 대해서;모델1 조건부확률분포: $[0.3, 0.7]$모델2 조건부확률분포: $[0.2, 0.8]$모델3 조건부확률분포: $[0.5, 0.5]$모델4 조건부확률분포: $[0.6, 0.4]$라고 가정하자.0 클래스 조건부확률 평균 $= \\frac{0.3+0.2+0.5+0.6}{4} = 0.4$1 클래스 조건부확률 평균 $= \\frac{0.7+0.8+0.5+0.4}{4} = 0.6$1 클래스 조건부확률 평균이 더 크므로, 이 데이터포인트는 클래스 1로 분류된다.Soft Voting - 가중합 방식정의각 모델, 클래스별 조건부확률 가중합($\\sum$ 모델 별 가중치 $\\times$ 클래스 별 조건부확률) 비교해서 결과값 가장 큰 클래스로 데이터포인트 분류하는 방법.예컨대 이진분류 문제이고, 앙상블 모델 집단에 모델 1,2,3 이 있다고 가정하자.1개 데이터포인트에 대해서;모델 1 조건부확률분포: $[0.3, 0.7]$, 모델 가중치 2모델 2 조건부확률분포: $[0.2, 0.8]$, 모델 가중치 1모델 3 조건부확률분포: $[0.6, 0.4]$, 모델 가중치 1이라고 가정하자.0 클래스 가중합 $= (0.3\\times{2}) + (0.2\\times{1}) + (0.6 \\times{1}) = 1.4$1 클래스 가중합 $= (0.7\\times{2}) + (0.8\\times{1}) + (0.4\\times{1}) = 2.6$$\\therefore$ 1 클래스 가중합 결과가 더 크므로, 이 데이터포인트는 클래스 1로 분류된다.Soft Voting 구현1- soft voting 평균 방식# soft voting 방식 - 평균 방식model1 = LogisticRegression(random_state=1)model2 = GaussianNB()model3 = QuadraticDiscriminantAnalysis()# 모델 앙상블model_ensemble = VotingClassifier(estimators=[('lr', model1), ('gnb', model2), ('qda', model3)], voting='soft')result1 = accuracy_score(y_test, model1.fit(x_train, y_train).predict(x_test))result2 = accuracy_score(y_test, model2.fit(x_train, y_train).predict(x_test))result3 = accuracy_score(y_test, model3.fit(x_train, y_train).predict(x_test))result4 = accuracy_score(y_test, model_ensemble.fit(x_train, y_train).predict(x_test))print(f'로지스틱회귀 검증셋 정확도: {result1}') ; print(f'가우시안 나이브베이즈 검증셋 정확도 : {result2}') ; print(f'QDA 모형 검증셋 정확도: {result3}') print(f'모델 앙상블 검증셋 정확도: {result4}')로지스틱회귀 검증셋 정확도: 0.36가우시안 나이브베이즈 검증셋 정확도 : 0.63QDA 모형 검증셋 정확도: 0.82모델 앙상블 검증셋 정확도: 0.83import seaborn as sns sns.barplot([1,2,3,4], [result1, result2, result3, result4])plt.xticks([0,1,2,3], ['lr', 'gnb', 'qda', 'ensemble'])plt.xlabel('models')plt.ylabel('accuracy score')plt.title('Accuracy Score per models')plt.show() 각 모델에 대한 새 데이터셋 예측 결과# 모델 예측 결과 시각화 - 2x1min, x1max = X[:,0].min(), X[:,0].max() x2min, x2max = X[:,1].min(), X[:,1].max()# 예측할 샘플 데이터셋 xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, 0.01), np.arange(x2min, x2max, 0.01)) X2 = np.c_[xx1.ravel() , xx2.ravel()]# 개별모델3, 앙상블1 훈련 model1 = model1.fit(x_train, y_train)model2 = model2.fit(x_train, y_train)model3 = model3.fit(x_train, y_train)ensemble = model_ensemble.fit(x_train, y_train)# 샘플 데이터셋 X2 예측 Y1 = model1.predict(X2).reshape(xx1.shape)Y2 = model2.predict(X2).reshape(xx1.shape)Y3 = model3.predict(X2).reshape(xx1.shape)Y4 = ensemble.predict(X2).reshape(xx1.shape)# 시각화plt.subplot(2,2,1)plt.contourf(xx1, xx2, Y1)plt.title(f'lr; acc={result1}')plt.subplot(2,2,2)plt.contourf(xx1, xx2, Y2)plt.title(f'gnb; acc={result2}')plt.subplot(2,2,3)plt.contourf(xx1, xx2, Y3)plt.title(f'qda; acc={result3}')plt.subplot(2,2,4)plt.contourf(xx1, xx2, Y4)plt.title(f'ensemble; acc={result4}')plt.suptitle('Model Prediction Results')plt.tight_layout() plt.show() soft voting 가중합 방식 사용하려면 모델 앙상블 객체 생성할 때, weight 파라미터에 모델 별 가중치 배열을 넣어주면 된다.Voting 연습문제breast_cancer 데이터셋에 모델 앙상블 적용해서 분류하기.from sklearn.datasets import load_breast_cancerdata = load_breast_cancer()x = data.data y = data.target feature_names = data.feature_names df = pd.DataFrame(x, columns=feature_names ) ; dfdf.describe() df.info()df.isnull().sum().valuesarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)from sklearn.model_selection import cross_val_score model1 = LogisticRegression(random_state=1)model2 = QuadraticDiscriminantAnalysis()model3 = GaussianNB()ensemble = VotingClassifier([('lr', model1), ('qda', model2), ('gnb', model3)], voting='hard')result_train = [(cross_val_score(model, x_train, y_train, scoring='accuracy', cv=5).mean(), np.std(cross_val_score(model, x_train, y_train, scoring='accuracy'))# 시각화 plt.subplot(1,2,1)plt.bar(np.arange(4), [r[0] for r in result_train], color='g')plt.plot(np.arange(4), [r[0] for r in result_train ], 'ro-')plt.ylim([0, 1.1])plt.title('performance mean')plt.xticks(np.arange(4), ['LR', 'QDA', 'GNB', 'ensem'])plt.subplot(1,2,2)plt.bar(np.arange(4), [r[1] for r in result_train], color='r')plt.plot(np.arange(4), [r[1] for r in result_train], 'go-')plt.xticks(np.arange(4), ['LR', 'QDA', 'GNB', 'ensem'])plt.title('standard diviation')plt.tight_layout()plt.show()result_test = [model.fit(x_train, y_train).predict(x_test) for model in (model1, model2, model3, ensemble)] from sklearn.metrics import accuracy_score test_acc = [accuracy_score(r, y_test) for r in result_test]plt.plot(np.arange(4), test_acc, 'ro-')plt.xticks(np.arange(4), ['lr', 'qda', 'gnb', 'ensem'])plt.title('accuracy_score for test data')plt.show()$\\therefore$ 앙상블 모델이 개별모델보다 더 높은 성능 기록했다.배깅(Bagging)Boostrap Aggregation정의부스트랩으로 생성된 여러 데이터셋으로 여러 약한 분류기(weak learner) 훈련시키고, 훈련된 약분류기들의 분류 결과를 다수결 투표 하는 분류 알고리즘. 모델 집합으로, 같은 종류 모형 여러 개 쓴다.부스트랩(Boostrap)정의: 원본 데이터셋 특성변수들 랜덤으로 선발해서, 데이터셋 여러 개 만들기예시 랜덤포레스트(Random Forest)구현의사결정나무를 약 분류기로 사용한, 배깅 모형from sklearn.ensemble import BaggingClassifier from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifieriris = load_iris() x, y = iris.data[:, [0,2]], iris.target x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.25)# 단일 의사결정나무 분류기model1 = DecisionTreeClassifier(max_depth=10, random_state=0).fit(x_train, y_train)# 배깅 모형 분류기; 100개 단일 의사결정나무 모형으로 구성. model2 = BaggingClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=100, random_state=0).fit(x_train, y_train) # 단일 의사결정나무 분류기 예측 print(f'단일 의사결정나무 분류기 예측 정확도: {accuracy_score(model1.predict(x_test), y_test)}')# 배깅 모형 분류기 예측 print(f'배깅 모형 분류기 예측 정확도: {accuracy_score(model2.predict(x_test), y_test)}')단일 의사결정나무 분류기 예측 정확도: 0.8947368421052632배깅 모형 분류기 예측 정확도: 0.8947368421052632$\\Rightarrow$ 단일 모형보다 훨씬 깊이 얕은 의사결정나무 100개 엮었더니, 단일모형과 같은 예측 정확도 달성했다.연습문제breast cancer 데이터셋에 배깅 모형 적용해서 분류문제 해결하기## 연습문제 2from sklearn.datasets import load_breast_cancerbc = load_breast_cancer() x = bc.data y = bc.target x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)from sklearn.svm import SVCfrom sklearn.ensemble import BaggingClassifiermodel = BaggingClassifier(SVC(), n_estimators=10, random_state=0).fit(x_train, y_train)model2 = SVC().fit(x_train, y_train)model_result = cross_val_score(model, x_test, y_test, scoring='accuracy', cv=5).mean()model2_result = cross_val_score(model2, x_test, y_test, scoring='accuracy', cv=5).mean() print(f'배깅모델 교차검증 정확도: {model_result}')print(f'단일모델 교차검증 정확도: {model2_result}')배깅모델 교차검증 정확도: 0.9302521008403362단일모델 교차검증 정확도: 0.9184873949579831$\\Rightarrow$ 배깅모형의 교차검증 정확도가 단일모델보다 약간 더 높았다.랜덤포레스트(Random Forest)정의약 분류기로 의사결정나무를 사용한, 배깅 모델. 각 하위 의사결정나무에서 노드 분리 시, 데이터셋 독립변수 차원을 랜덤하게 감소시킨 뒤, 남은 독립변수들 중에서 분류규칙을 결정한다. 각 하위 의사결정나무에서, 노드 분리 할 때 마다 랜덤하게 분류규칙 정하는 경우, Extremely Randomized Trees 모형 이라고 별칭한다. 구현# 랜덤포레스트 - 배깅모델의 한 종류from sklearn.datasets import load_irisfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.ensemble import RandomForestClassifier# iris 데이터셋 로드 iris = load_iris() x, y = iris.data[:, [0,2]], iris.target # 훈련, 테스트용 데이터셋으로 분리 x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.25)# 단일 의사결정나무 분류기model1 = DecisionTreeClassifier(max_depth=10, random_state=10).fit(x_train, y_train)# 랜덤포레스트 분류기; 100개 의사결정나무로 구성model2 = RandomForestClassifier(max_depth=2, n_estimators=100, random_state=0).fit(x_train, y_train)print(f'단일 의사결정나무 정확도: {accuracy_score(y_test, model1.predict(x_test))}')print(f'랜덤포레스트 정확도: {accuracy_score(y_test, model2.predict(x_test))}')단일 의사결정나무 정확도: 0.8947368421052632랜덤포레스트 정확도: 0.8947368421052632랜덤포레스트; 특성변수 별 중요도 계산$a_{i} = $ 하위 의사결정나무(약 분류기) $i$ 내 특성변수 별 정보획득량 평균$n = $ 랜덤포레스트 내부 의사결정나무 갯수특성변수 별 중요도 $= \\frac{1}{n}\\sum{a_{i}}$예제# 분류모델 테스트용; 조건에 맞는 가상데이터 생성from sklearn.datasets import make_classification from sklearn.ensemble import ExtraTreesClassifier# 모델 테스트용 가상데이터x, y = make_classification(n_samples=1000, n_features=10, n_informative=3, n_redundant=0, n_classes=2, random_state=0, shuffle=False) # 의사결정나무 250개로 구성된 extreme 랜덤포레스트 forest = ExtraTreesClassifier(n_estimators=250, random_state=0)forest.fit(x, y)# 랜덤포레스트 알고리즘 내에서, 각 특성변수 별 중요도importances = forest.feature_importances_# 일반 랜덤포레스트에 대해서도 정보획득량 평균 구할 수 있다. rf = RandomForestClassifier(max_depth=2, n_estimators=100, random_state=0).fit(x, y)rf.feature_importances_# 여러 하위 의사결정나무에 걸친, 특성변수 중요도 표준편차std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)# 내림차순 정렬했을 때 요소들 리스트 순서 indicies = np.argsort(importances)[::-1]# 시각화 plt.bar(range(10), importances[indicies], color= 'r', yerr=std[indicies], align='center')plt.xticks(range(x.shape[1]), indicies)plt.xlim([-1, x.shape[1]])plt.title('The importance of feature variables')plt.xlabel('n_feature variables')plt.ylabel('importance')plt.show()0~9번 특성변수 별 중요도 및 표준편차예제 2; 각 이미지 분류하는 데 결정적 기여하는, 중요한 픽셀만 골라내기# 올리베티 얼굴사진 데이터에 랜덤포레스트 적용하기 from sklearn.datasets import fetch_olivetti_facesfrom sklearn.ensemble import ExtraTreesClassifierdata = fetch_olivetti_faces()x = data.data ; y = data.targetx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.25)r_forest = RandomForestClassifier(random_state=2, n_estimators=250).fit(x_train, y_train)픽셀 별 중요도 시각화# 각 픽셀 별 정보획득량 평균(픽셀 별 중요도)fi = r_forest.feature_importances_fi_2 = fi.reshape(data.images[0].shape)plt.imshow(fi_2, cmap=plt.cm.bone_r)plt.axis('off')plt.title('Each pixcel importance')plt.show()중요 픽셀일 수록 정보획득량 평균이 높아 진하게 표시,덜 중요한 픽셀 일 수록 정보획득량 평균이 낮아 연하게 표시된다.accuracy_score(y_test, r_forest.predict(x_test))0.97연습문제breast cancer 데이터에 랜덤포레스트 적용해서 데이터포인트 분류하기# 연습문제 3from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_splitfrom sklearn.ensemble import ExtraTreesClassifierfrom sklearn.model_selection import cross_val_score data = load_breast_cancer()x = data.datay = data.target x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)# extreme random forest 모델 tree = ExtraTreesClassifier(random_state=0, n_estimators=250)tree.fit(x_train, y_train)print(f'훈련용 데이터에 대해 교차검증 평균성능 : {cross_val_score(tree, x_train, y_train, scoring=\"accuracy\", cv=5).mean()}')print(f'테스트용 데이터에 대해 교차검증 평균성능: {cross_val_score(tree, x_test, y_test, scoring=\"accuracy\",cv=5).mean()}')훈련용 데이터에 대해 교차검증 평균성능 : 0.9623734177215191테스트용 데이터에 대해 교차검증 평균성능: 0.9532773109243697importances = tree.feature_importances_indice = np.argsort(importances)%matplotlib inlineplt.barh(range(len(importances)), importances[indice])plt.yticks(range(len(importances)), data.feature_names[indice])plt.tight_layout()plt.show()" }, { "title": "[알고리즘/지도학습] 의사결정나무(Decision Tree) 알고리듬", "url": "/bioinfo.github.io/posts/decision_tree/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-08-03 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 의사결정나무 알고리듬을 공부. 복습하고나서, 그 내용을 내 언어로 바꾸어 기록한다.의사결정나무(Decision Tree)정의각 데이터포인트(레코드) 가장 잘 분류할 수 있는 특성변수와 기준점 찾고, 그 기준점에 따라 데이터포인트 분류하기.$\\Rightarrow$ 최적의 분류규칙 찾아서, 확률변수 Y의 분포 엔트로피 최소화 해 나가기.과정 부모노드는 특정 레이블로 분류되는, 데이터포인트 집합을 갖는다. 부모노드를 확률변수 Y 라고 잡는다. 확률변수 Y가 갖는, 레이블 별 분포의 엔트로피 최소화 시키는, 특성변수와 기준점 찾는다. 즉, 조건 X(특성변수와 기준점) 에 대한 Y의 조건부 엔트로피 $H[Y\\vert{X}]$ 가 최소화되는 X 찾는다. 또는 정보획득량(Information Gain: $H[Y]-H[Y\\vert{X}]$)을 최대로 만드는 X 찾는다. 분류규칙보다 작은 데이터포인트들 vs 분류규칙보다 큰 데이터포인트들 로 데이터포인트를 이진분류한다. 이진분류된 데이터포인트들은 각각 부모노드의 왼쪽, 오른쪽 자식노드에 들어간다. 2에서 4 과정을 반복한다.*루트노드에서 시작한다.*‘가장 잘 분류할 수 있는 특성변수 &amp; 기준점’을 ‘분류규칙’ 이라 한다.*만약 자식노드에 분류된 데이터포인트의 클래스가 1개 뿐이면. 그 노드는 더 이상 나누지 않고 분기 종료한다.예측가장 마지막 이파리 노드에 담긴 데이터포인트 집합에서, 각 레이블에 속하는 데이터포인트 별 비율 구한다.이 비율들을 조건부 확률분포로 본다.$P(Y=k_{i}\\vert{X}) \\approx \\frac{N_{k_{i}}}{N_{X}}$ $X =$ 가장 마지막 이파리노드에 담긴 데이터포인트 집합 $k_{i} =$ 레이블 $N_{X} =$ 데이터포인트 집합에 속한 데이터포인트 갯수 $N_{k_{i}} =$ 특정 레이블에 속한 데이터포인트 갯수 $\\Rightarrow$ 예측값: $\\hat{Y} = argmax_{k}(P(Y=k_{i}\\vert{X}))$분류문제 해결하기 - 1붓꽃 분류문제from sklearn.datasets import load_iris data = load_iris() y = data.target # 정답값(타겟값)들 x = data.data[:, 2:] # 입력데이터셋feature_names = data.feature_names[2:]# 의사결정나무 클래스 from sklearn.tree import DecisionTreeClassifier # 분류기준 찾는 데 사용할 척도: 엔트로피, 의사결정나무 최대깊이:3tree1 = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0).fit(x, y) 특성변수는 ‘petal length (cm)’, ‘petal width (cm)’ 두 가지만 사용한다.혼동행렬로 모델 분류 결과 파악하기from sklearn.metrics import confusion_matrixconfusion_matrix(y, tree1.predict(x))혼동행렬 의미는 다음과 같다.행: 0,1,2 / 열: 0,1,2.(1,1) 의 50은 실제 레이블 0인데 0으로 분류한 것 갯수다.(2,2) 의 47은 실제 레이블 1인데 1로 분류한 것 갯수다.(2,3) 의 3은 실제 레이블 1인데 2로 분류한 것 갯수다.(오분류)나머지 1과 49도 위 논리로 읽으면 된다.한편, 혼동행렬 뿐 아니라 각종 모델 성능 측정지표도 출력할 수 있다.# 의사결정나무 모델 성능평가 지표from sklearn.metrics import classification_reportprint('훈련데이터에 대한 모델 성능평가')print(classification_report(y, tree1.predict(x)))모델 분류결과의 정밀도, 재현율, F1 점수, 빈도, 정확도 등 나타낸다.전체적으로 모델이 0.97 의 분류 정확도 기록했다.의사결정나무 모델 시각화from sklearn.tree import plot_treeplt.figure(figsize=(100,50), max_depth=3)plot_tree(tree1)plt.show()예컨대 가장 첫번째 노드를 보자.위에서 부터 순서대로, 확률변수 Y 의 조건부확률분포 엔트로피 최소화 시키는, 특성변수 &amp; 기준점(0.8). 이 기준 갖고 각 데이터포인트(레코드) 왼쪽과 오른쪽 자식노드에 나눈다. 확률변수 Y 조건부확률분포의 엔트로피. 이 노드의 조건부확률분포는 value = $[50,50,50]$ 이다. 이 분포의 엔트로피 = 1.585 이 노드가 갖고 있는 총 데이터포인트 갯수. 이 노드는 150개 데이터포인트 갖고 있다. 확률변수 Y 의 조건부확률분포.한편 가장 마지막 이파리 노드 중 하나를 보자.이 노드는 43개, 클래스 2인 데이터포인트들만 갖고 있다.데이터포인트들의 클래스가 1개 뿐이므로 분기를 종료한다.한편, value 조건부확률분포에서, 클래스 0의 조건부확률 값은 0, 1의 조건부확률값 0, 클래스 2의 조건부확률값 1 이므로클래스 2의 조건부확률값이 가장 크다. 따라서 이 경우, 데이터포인트를 2로 분류(예측)한다.분류문제 해결하기 - 2타이타닉 분류문제 (생존 or 사망 이진분류문제)# 타이타닉호 생존자 예측 연습문제 # 타이타닉 데이터셋 로드 df = sns.load_dataset('titanic')df.head()# pclass, age, sex 3 가지 특징변수만 사용할 거다. feature_names = ['pclass', 'age', 'sex']dfx = df[feature_names].copy()dfy = df['survived'].copy()dfx.head() # 훈련용 데이터셋 from sklearn.preprocessing import LabelEncoder dfx['sex'] = LabelEncoder().fit_transform(dfx['sex']) # 성별 특징변수 값 --&gt; 0과 1로 변환dfx.tail()dfx['age'].fillna(dfx['age'].mean(), inplace=True) # age 특징변수 null 값 전부 나이 평균값으로 대체해넣기 dfx.isnull().sum()pclass 0age 0sex 0dtype: int64from sklearn.preprocessing import LabelBinarizer dfx2 = pd.DataFrame(LabelBinarizer().fit_transform(dfx['pclass']), columns=['c1', 'c2', 'c3'], index=dfx.index) # 카테고리 변수인 pclass 특징변수 원핫인코딩 벡터 꼴로 변환dfx = pd.concat([dfx, dfx2], axis=1);dfxdel(dfx['pclass'])dfx.tail()from sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeClassifier x_train, x_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.25, random_state=0) # 훈련용데이터 75, 테스트데이터 25 로 전체 데이터 분할model = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=5, max_depth=100).fit(x_train, y_train) # 의사결정나무 모델 정의 후 훈련confusion_matrix(y_train, model.predict(x_train)) # 혼동행렬로 분류결과 확인# 의사결정나무 분류결과 시각화 plt.figure(figsize=(100,50))plot_tree(model)plt.show()의사결정나무 장점분류 과정과 결과를 쉽게 ‘설명가능’하다. 이렇게 분류결과를 설명할 수 있는 모델들을 화이트박스 모델 이라고도 한다.의사결정나무 단점 트리 깊이가 너무 깊어지면, 모델이 훈련데이터에 과적합 될 수 있다. 의사결정나무는 탐욕 알고리즘의 일종이기 때문에, 매 순간 선택한 분류기준이 전체 관점에서는 최적 분류기준이 아닐 수 있다." }, { "title": "[알고리즘] 너비우선탐색, 깊이우선탐색, K-평균 클러스터링, 계층적 클러스터링, FP-Growth 알고리즘(연관규칙 마이닝)", "url": "/bioinfo.github.io/posts/bfs_dfs_clustering_fpgrowth_algorithms/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-29 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 너비우선탐색, 깊이우선탐색, 비지도학습-클러스터링 알고리즘, 연관규칙마이닝-빈출 패턴 성장알고리즘을 공부. 복습하고나서, 그 내용을 내 언어로 바꾸어 기록한다.그래프 알고리듬 - 2그래프 순회정의그래프 탐색(검색) 방법.원칙모든 정점과 간선 단 한번씩만 방문한다.종류너비우선탐색(BFS)깊이우선탐색(DFS)너비우선탐색(BFS)그래프에 계층이 있을 때; 그래프 형상이 트리일 때 가장 효율적인 탐색 알고리즘이다.정의루트노드에서 시작해서, 트리 레벨 별로 정점들 방문하는. 그래프 탐색 방법.구현# 그래프 표현한 인접 리스트graph = { 'amin' : ['wasim', 'nick', 'mike'], 'wasim' : ['amin', 'imran'], 'nick' : ['amin'], 'mike' : ['amin'], 'imran' : ['wasim', 'faras'], 'faras' : ['imran']}# 너비우선탐색 구현 def bfs(graph, start) : que = [start] # 방문해야 할 곳 visited = [] # 방문한 곳 while que : n = que.pop(0) if n not in visited : visited.append(n) for neighbor in graph[n] : que.append(neighbor) return visited bfs(graph, 'amin')[‘amin’, ‘wasim’, ‘nick’, ‘mike’, ‘imran’, ‘faras’]깊이우선탐색(DFS)정의왼쪽부터 모든 경로 세로로 순차 탐색하는 알고리즘.구현# 깊이우선탐색 구현 def dfs(graph, node, visited = []) : if len(visited) == 0 : visited = [] if node not in visited : visited.append(node) for neighbor in graph[node] : dfs(graph, neighbor, visited) return visited 테스트 1dfs(graph, 'amin')[‘amin’, ‘wasim’, ‘imran’, ‘faras’, ‘nick’, ‘mike’]테스트 2graph2 = { '2' : ['6', '3', '4', '5'], '6' : ['2', '7','9', '12'], '3' : ['2', '81'], '4' : ['2', '27'], '5' : ['2', '31', '51'], '7' : ['6', '8'], '9' : ['6', '11'], '12' : ['6', '19'], '81' : ['3'], '27' : ['4', '29'], '31' : ['5', '24'], '51' : ['5'], '8' : ['7'], '11' : ['9'], '19' : ['12'], '29' : ['27', '1'], '24' : ['31', '71'], '1': ['29'], '71' : ['24']}for n in dfs(graph2, '2') : print(n, end=' ')2 6 7 8 9 11 12 19 3 81 4 27 29 1 5 31 24 71 51비지도 학습정의비정형 데이터를 정형 데이터로 변환하는 과정.비지도 학습 알고리듬클러스터링 알고리듬비슷한 것끼리 묶기.묶는 방법: 벡터 공간에서, 각 데이터포인트들의 ‘유사도’ 이용해서 비슷한 것끼리 묶는다.벡터 간 유사도 종류1. 유클리드 거리정의: 두 벡터 점 사이 거리.공식: $d(A, B) = \\sqrt{\\sum_{i=1}^{n}{(a_{i}-b_{i})^{2}}}$2. 맨해튼 거리정의: 두 벡터 점 사이 가장 긴 거리.공식: $d(A, B) = \\sum_{i=1}^{n}{\\vert{a_{i}-b_{i}}\\vert}$3. 코사인 유사도정의: 두 벡터(화살표) 사이 코사인 각도 값.공식: $cos\\theta = \\frac{a^{T}b}{\\vert\\vert{a}\\vert\\vert \\vert\\vert{b}\\vert\\vert}$ 차원 높아질 수록 코사인 유사도가 두 벡터 사이 유사도 구하는 데 좋다.1. K-평균 클러스터링 알고리듬정의평균값 중심으로, 벡터들 군집화 하는 알고리듬.과정 임의로 중심벡터 $n$ 개 설정한다. ($n$개 클러스터) 각 중심벡터와 유사도 높은(유클리드 거리가 가까운) 벡터들 군집화 한다. 각 $n$ 개 클러스터에 속한 벡터들 평균값으로 중심벡터 조정한다. 중심벡터가 더 이상 안 변할 때 까지 2와 3 과정 반복한다.본래 K-평균 클러스터링 알고리즘 종료 조건은 ‘중심벡터가 더 이상 안 변할 것’ 이지만 다른 종료조건 설정할 수도 있다. 최대반복횟수 지정 최대실행시간 지정구현from sklearn import cluster import pandas as pd import numpy as np import matplotlib.pyplot as plt # k-평균 클러스터링에 사용할 임의 데이터 생성 dataset = pd.DataFrame({ 'x' : [11,21,28, 17, 29, 33, 24, 45, 45, 52, 51, 52, 55, 53, 55, 61, 62, 70, 72, 10], 'y' : [39, 36, 30, 52, 53, 46, 55, 59, 63, 70, 66, 63, 58, 23, 14, 8, 18, 7, 24, 10]})# 클러스터 갯수 k 임의로 설정하기: 3 kmeans = cluster.KMeans(n_clusters=3)# k-평균 클러스터링 실행kmeans.fit(dataset)# 각 벡터 점이 어떤 클러스터로 '클러스터링' 되었나? labels = kmeans.labels_pd.DataFrame({ 'vector' : list(range(20)), 'result_clustered' : labels })# 클러스터 별 중심점; 3개 중심점. centers = kmeans.cluster_centers_print(centers)pd.DataFrame({ 'vector' : list(range(3)), 'x_coordinate' : [centers[x][0] for x in range(3)], 'y_coodinate' : [centers[y][1] for y in range(3)]})# 클러스터 시각화 %matplotlib inlineplt.figure(figsize=(20,10))plt.scatter(dataset['x'], dataset['y'], s=10)plt.scatter([centers[x][0] for x in range(3)], [centers[y][1] for y in range(3)], s=100)plt.title('K-means clustering result')plt.xlabel('x')plt.ylabel('y')plt.show() 주황색은 중심벡터한계 클러스터 갯수를 직접, 미리 지정해줘야 한다. 이상치에 약하다. 중심점이 벡터들 평균이므로, 중심점 조정할 때 마다 중심점이 아웃라이어에 질질 끌려 다닌다. 초창기 중심점 설정은 무작위 이므로, 알고리듬 실행할 때 마다 결과가 조금씩 달라질 수 있다. 각 데이터 포인트가 오직 1개 클러스터에만 할당된다.2. 계층적 클러스터링 알고리듬정의전체 데이터포인트가 최종 1개 군집에 속할 때 까지, 비슷한 클러스터(데이터포인트) 끼리 클러스터링 하는 알고리듬.k-평균 클러스터링 알고리듬과 비교했을 때, 장점: 임의로 $N$ 개 클러스터 지정 안 해도 된다.과정 각각 데이터포인트를 1개 클러스터로 취급한다. 서로 거리 가장 가까운 클러스터 2개씩 묶는다.*종료조건 임의로 지정해줄 수 있다; 예컨대, 클러스터가 3개 만들어졌을 때 종료. *계층적 클러스터링 결과로 나온 클러스터 구조를 ‘덴드로그램’ 이라고 한다.구현from sklearn.cluster import AgglomerativeClustering # 임의 2차원 벡터 20개 생성dataset = pd.DataFrame({ 'x' : [11, 21, 28, 17, 29, 33, 24, 45, 45, 52, 51, 52, 55, 53, 55, 61, 62, 70, 72, 10], 'y' : [39, 36, 30, 52, 53, 46, 55, 59, 63, 70, 66, 63, 58, 23, 14, 8, 18, 7, 24, 10]})datasetplt.scatter(dataset['x'], dataset['y'])# 하이퍼파라미터 지정 # 개별 벡터 간 유사도: 벡터간 유클리드 거리로 측정. # 클러스터 간 거리 측정방식: 클러스터에 속한 벡터간 거리 평균cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='average')cluster.fit_predict(dataset) # 20개 벡터에 대해 계층적 클러스터링 실행 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1], dtype=int64)print(cluster.labels_)[0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 1]# 덴드로그램 시각화; 계층적 클러스터링 결과 시각화 from scipy.cluster.hierarchy import linkage, dendrogrammergings = linkage(dataset, method='average')# 덴드로그램 그리기 plt.figure(figsize=(4, 20))dendrogram(mergings)plt.show()클러스터링 결과 품질 분석: 실루엣 분석실루엣 분석각 데이터포인트의 실루엣 계수 구하고, 실루엣 계수 이용해서 클러스터링이 잘 됬는지, 안 됬는지. 그 품질 분석한다.실루엣 계수정의개별 데이터 포인트의 ‘군집도’. 같은 군집 내의 데이터들과 얼마나 가깝게 군집화 되어 있고, 다른 군집에 속한 데이터와는 얼마나 멀리 분리되어 있는지 동시에 나타내는 지표다. 실루엣 계수값이 1에 가까울 수록 근처 군집과는 멀리, 군집 내에서는 다른 점들과 가까이 위치한다는 뜻이다. 실루엣 계수값이 0에 가까울 수록 근처 군집과 가깝고, 군집 내에서 다른 점들과 멀다는 뜻이다. 실루엣 계수값이 -1에 가까우면 데이터 포인트가 아예 다른 군집에 잘못 클러스터링 되었음을 뜻한다.‘잘 된 군집화’ 는 2가지 조건 만족해야 한다 전체 데이터 포인트에 대한 실루엣 계수 평균값(전체적으로 데이터가 클러스터링 잘 된 정도)이 1에 가까워야 한다. 전체 실루엣 계수 평균값과 각 개별 군집의 실루엣 계수 평균값 사이 편차가 크지 않아야 한다.한편 개별 군집의 실루엣 계수 평균값이 0에 가까우면 다른 클러스터로 부터 제대로 떨어져 나오지 못한 군집, 1에 가까우면 확실히 분리된(clear-cut) 한 군집이다.실루엣 분석 실행# 클러스터링 결과 품질 평가 방법: 실루엣 분석 from sklearn.metrics import silhouette_samples, silhouette_scoress = silhouette_samples(dataset, labels);print(ss);print()ss2 = silhouette_score(dataset, labels) ; print(ss2)각 데이터포인트(벡터) 실루엣 계숫값[0.56696738 0.57743412 0.44825528 0.45067759 0.17040846 0.20428702 0.28313587 0.7177684 0.77066252 0.78630094 0.83981177 0.84146727 0.75371487 0.59110102 0.7231076 0.75778881 0.77111825 0.73332291 0.61443136 0.288133 ]전체 데이터포인트 실루엣 계숫값 평균0.5944947210534494클러스터 별 실루엣 계숫값 평균 및 전체 평균과 편차clusterss = pd.DataFrame({ 'sil' : ss, 'label' : labels}) ;clusterss# 0 클러스터 실루엣 계수 평균cluster_zero_mean = clusterss.query('label == 0')['sil'].values.mean() ; print(cluster_zero_mean)# 1 클러스터 실루엣 계수 평균cluster_zero_one = clusterss.query('label == 1')['sil'].values.mean() ; print(cluster_zero_one)# 2 클러스터 실루엣 계수 평균cluster_zero_two = clusterss.query('label == 2')['sil'].values.mean() ; print(cluster_zero_two)print(f'실루엣 계수 전체 평균 : {ss2}')plt.bar(range(4), [cluster_zero_mean, cluster_zero_one, cluster_zero_two, ss2])plt.xlabel([0,1,2,'mean'])plt.show()0.78495429504900970.69847832220606210.37366233969231955실루엣 계수 전체 평균 : 0.5944947210534494연관규칙 마이닝각 변수 사이 ‘연관관계’ 파악하기.대표적 사례: 장바구니 분석. 장바구니 각 항목 간 연관관계 분석. (‘맥주와 기저귀’)변수 간 연관규칙은 아래와 같이 표현한다.${A, B} \\Rightarrow {C}$ 고객이 A, B를 함께 구입하면 C도 같이 사더라. 장바구니 분석에서, ${A, B}$, ${C}$ 는 $itemset$ 라고 한다. 말 그대로 고객이 구입한 물품 집합이다.패턴, 연관규칙 평가 지표 지지도(support) 신뢰도(confidence) 향상도(lift)1. 지지도(support)정의특정 패턴의 등장빈도.공식$support(itemset) = \\frac{num_{transaction}}{total_{transaction}}$ $num_{transaction}$: 전체 거래기록 중 특정 패턴($itemset$) 이 포함된 것 수 $total_{transaction}$ : 전체 거래기록 갯수2. 신뢰도(confidence)정의변수 $X$ 와 $Y$ 의 ‘연관도’.변수 $X$ 가 $Y$ 로 이어질 확률 뜻한다.예컨대 ${A,B} \\Rightarrow {C}$, ${A,B} = X$, ${C}= Y$ , 연관관계의 신뢰도가 $70\\%$ 이면.소비자가 장바구니에 ${A,B}$ 담고 있으면 $70\\%$ 확률로 ${C}$ 도 구매함을 뜻한다.공식$confidence(X\\Rightarrow{Y}) = \\frac{support(X Union Y)}{support(X)}$3. 향상도(lift)정의연관규칙의 효용성 측정 지표. Y 구매 예측이 연관규칙 사용 안 할 때 보다 향상된 정도.공식$lift(X \\Rightarrow Y) = \\frac{support(X union Y)}{support(X) \\times support(Y)}$연관규칙 마이닝 알고리듬1. Apriori 알고리듬정의가능한 모든 패턴($itemset$) 이용해서, 변수 간 연관규칙(관게) 찾는 알고리듬.과정 전체 item 갯수가 $n$ 개 면. $2^{n}$ 개 패턴이 생성될 수 있다. 이 $2^{n}$ 개 패턴을 ‘후보패턴’으로 둔다. 모든 후보패턴에 대해서, 변수 간 연관규칙 찾고 그 신뢰도 계산한다. 일정 이하 신뢰도 갖는 연관규칙은 걸러낸다.단점item 갯수가 커질 수록, 후보패턴 갯수도 기하급수적으로 많아진다. 결국 후보패턴 생성 시간이 엄청나게 길어진다.Apriori 알고리듬은 후보패턴 생성 못하면 그 다음 과정도 수행 못한다. 정리하면, item 갯수 많아질 수록 알고리듬 처리 시간이 엄청나게 지연된다.2. FP-Growth 알고리듬빈출 패턴 성장알고리듬.정의빈출패턴 집합 이용해서, 변수 간 연관규칙(관계) 찾는 알고리듬. Apriori 알고리듬이 가능한 모든 후보패턴 이용해서 연관규칙 찾았다면, FP-Growth 알고리듬은 FP 트리 이용해. 지지도 일정 이상인 빈출패턴만 찾고 이거 이용해서 변수 간 연관규칙 및 신뢰도 구한다.특징 및 장점Apriori 알고리듬의 item 갯수 많아질 수록 속도 느려지는 단점 보완한 알고리듬이다.구현# FP-Growth 알고리듬 구현 import pyfpgrowth as fp dict2 = { 'id' : [0,1,2,3], 'items' : [['wickets', 'pads'], ['bat', 'wickets', 'pads', 'helmet'], ['helmet', 'ball'], ['bat', 'pads', 'helmet']]}transactionset = pd.DataFrame(dict2) ; transactionset빈출패턴 찾기; 1 이상 빈도 가진 패턴만 남긴다.patterns = fp.find_frequent_patterns(transactionset['items'], 1) ; patterns # 패턴 별 빈도 출력 {(‘ball’,): 1, (‘ball’, ‘helmet’): 1, (‘wickets’,): 2, (‘pads’, ‘wickets’): 2, (‘bat’, ‘wickets’): 1, (‘helmet’, ‘wickets’): 1, (‘bat’, ‘pads’, ‘wickets’): 1, (‘helmet’, ‘pads’, ‘wickets’): 1, (‘bat’, ‘helmet’, ‘wickets’): 1, (‘bat’, ‘helmet’, ‘pads’, ‘wickets’): 1, (‘bat’,): 2, (‘bat’, ‘helmet’): 2, (‘bat’, ‘pads’): 2, (‘bat’, ‘helmet’, ‘pads’): 2, (‘pads’,): 3, (‘helmet’,): 3, (‘helmet’, ‘pads’): 2}빈출패턴으로부터 연관규칙 및 신뢰도 찾기# 빈출패턴으로부터 연관규칙 및 신뢰도 찾기 rules = fp.generate_association_rules(patterns, 0.3) # 신뢰도 0.3 이상인 연관규칙만 생성rules {(‘ball’,): ((‘helmet’,), 1.0), (‘helmet’,): ((‘pads’,), 0.6666666666666666), (‘pads’,): ((‘helmet’,), 0.6666666666666666), (‘wickets’,): ((‘bat’, ‘helmet’, ‘pads’), 0.5), (‘bat’,): ((‘helmet’, ‘pads’), 1.0), (‘bat’, ‘pads’): ((‘helmet’,), 1.0), (‘bat’, ‘wickets’): ((‘helmet’, ‘pads’), 1.0), (‘pads’, ‘wickets’): ((‘bat’, ‘helmet’), 0.5), (‘helmet’, ‘pads’): ((‘bat’,), 1.0), (‘helmet’, ‘wickets’): ((‘bat’, ‘pads’), 1.0), (‘bat’, ‘helmet’): ((‘pads’,), 1.0), (‘bat’, ‘helmet’, ‘pads’): ((‘wickets’,), 0.5), (‘bat’, ‘helmet’, ‘wickets’): ((‘pads’,), 1.0), (‘bat’, ‘pads’, ‘wickets’): ((‘helmet’,), 1.0), (‘helmet’, ‘pads’, ‘wickets’): ((‘bat’,), 1.0)}" }, { "title": "[알고리즘] 페이지랭크(PageRank) 알고리듬, 선형계획법(LP 문제)", "url": "/bioinfo.github.io/posts/page_rank_algorithm/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-25 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 페이지랭크 알고리듬, 선형계획법 알고리듬을 공부. 복습하고나서, 그 내용을 내 언어로 바꾸어 기록한다.페이지랭크(PageRank) 알고리듬정의다른 웹페이지로 부터 받은 링크 수에 따라, 웹페이지 별 중요도 매기는 알고리듬.근간 아이디어“다른 웹페이지로부터 링크 많이 받을 수록, 중요한 페이지다”문제 기능적 요구사항 입력: 웹페이지 간 연결 나타낸 그래프(인접행렬) 출력: 페이지 별 가중치(중요도) 여기서는 각 페이지 가중치 계산 및 출력까지 안 가고, 인접행렬 이용해서 전이행렬 계산(출력) 하는 것 까지만 알고리즘 구현했다.구현웹페이지 간 연결 상태 표현한 그래프# 웹페이지 간 연결 그래프 import numpy as np import networkx as nximport matplotlib.pyplot as plt myweb = nx.DiGraph() mypages = range(1,6) # 1~5번 페이지 # 페이지 간 연결상태 connections = [(1,3), (2,1), (2,3), (3,1), (3,2), (3,4), (4,5), (5,1), (5,1), (5,4)]myweb.add_nodes_from(mypages) # 그래프에 노드 5개 추가 myweb.add_edges_from(connections) # 각 노드 사이 간선 추가 pos = nx.shell_layout(myweb)nx.draw(myweb, pos, arrows=True, with_labels= True)plt.title('sample graph(network)')plt.show()시각적으로 표현한 웹페이지 간 연결상태페이지랭크 알고리듬 입력: 그래프(인접행렬) 출력: 전이행렬# 페이지랭크 알고리듬 구현 def pagerank_algorithm(agraph) : m = nx.to_numpy_matrix(agraph)# 그래프를 인접행렬로 변환 sum = np.squeeze(np.asarray(np.sum(m, axis=1))) prob_sum = np.array([1.0/x if x &gt; 0 else 0 for x in sum]) G = np.asarray(np.multiply(m.T, prob_sum)) p = np.ones(len(agraph))/len(agraph) return G,p# 결과물 출력 pagerank_algorithm(myweb)첫번째 array 가 알고리듬 출력인 전이행렬이다.각 열이 각각 1,2,3,4,5 번 웹페이지를 나타내고, 열마다 각 값은 그 열에 해당하는 웹페이지가 다른 웹페이지로 연결될 확률 나타낸다.예컨대 3번 열은 1,2,4 번 3개 웹페이지와 연결되어 있기 때문에, 각 값이 0.33333 으로 나온 것이다.선형 계획법(Linear programming; LP문제)정의선형함수에 대해, 부등식/등식 제한조건 걸고 최적화 하는 알고리듬.책 예제목적함수에서 사용하는 변수 : $x, y$ (각 로봇 생산량 의미한다)목적함수 : $f(x,y) = 5000x + 2500y$제약조건 : $x \\ge 0$ (로봇 A 생산량은 0이거나 0보다 큰 양의 정수) $y \\ge 0$ (로봇 B 생산량은 0이거나 0보다 큰 양의 정수) $3x+2y \\leq 20$ $4x+3y \\leq 30$ $4x+3y \\leq 44$이 책에서는 pulp 라이브러리 이용해서 선형 목적함수 최대화 하는 최적 입력 $x, y$ 찾았다.# 선형 목적함수 부등식 제약조건 최적화 하기 import pulp # 문제 정의problem = pulp.LpProblem('Profit_maximizing_problem', pulp.LpMaximize)# 문제에서 쓸 변수 정의 x = pulp.LpVariable('x', lowBound = 0, cat='Integer')y = pulp.LpVariable('y', lowBound = 0, cat='Integer')# 목적함수 정의 problem += 5000*x + 2500*y # 부등식 제약조건 정의 problem += 3*x + 2*y &lt;= 20 problem += 4*x + 3*y &lt;= 30 problem += 4*x + 3*y &lt;= 44# 성능함수 최적해 계산 problem.solve() # 1 = True 1 (최적해 계산에 성공했다)# 최적화 결과 확인 print(pulp.LpStatus[problem.status]) # 최적값 찾았다. # x, y 최적해 출력 print(x.varValue);print(y.varValue) # x = 6, y = 1 최적해. # 최적해 에서 목적함수 최대화된 값(maximized value) # = 목적함수에 최적해 집어넣은 출력값print(pulp.value(problem.objective)) Optimal6.01.032500.0" }, { "title": "[알고리즘] 그래프 기본 개념, 그래프 분석 이론 기초", "url": "/bioinfo.github.io/posts/graph/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-25 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 그래프 기본 개념, 그래프 분석 이론 기초를 공부. 복습하고나서, 그 내용을 내 언어로 바꾸어 기록한다.그래프 알고리듬 - 1그래프 알고리듬은 주로 효율적인 검색 알고리듬으로 쓰인다.그래프 정의정점(vertex)과 간선(edge) 집합. 간선은 두 정점 사이 ‘관계’ 나타낸다.파이썬 networkx 라이브러리 사용해서 그래프 표현하기빈 그래프 생성# 빈 그래프 생성 import networkx as nx g = nx.Graph()그래프에 정점 1개 추가# 정점 추가 g.add_node('mike')그래프에 정점 여러 개 한번에 추가# 정점 여러 개 한번에 추가 g.add_nodes_from(['amine', 'wasim', 'nick'])두 정점 사이 간선 추가# mike 정점과 amine 정점 사이 간선(관계) 추가g.add_edge('mike', 'amine')그래프 정점 목록 출력# 그래프 정점 목록 list(g.nodes)[‘mike’, ‘amine’, ‘wasim’, ‘nick’]그래프 간선 목록# 그래프 간선 목록 list(g.edges)[(‘mike’, ‘amine’)]아직 추가 안 된 정점에 대해서 간선 생성하기; 결과로 정점도 자동 생성된다.# 아직 추가 안 된 정점에 대해 간선 생성하기 --&gt; 결과로 imran 정점도 같이 생성된다. g.add_edge('amine', 'imran')print(list(g.edges))print(list(g.nodes))[(‘mike’, ‘amine’), (‘amine’, ‘imran’)][‘mike’, ‘amine’, ‘wasim’, ‘nick’, ‘imran’]그래프 4 가지 유형 무방향 그래프 방향 그래프 무방향 멀티그래프 방향 멀티그래프간선에 방향이 있으면 ‘방향’, 없으면 ‘무방향’ 그래프. 방향이 있는 경우 관계에 위계가 있는 것, 무방향이면 위계가 없다.두 노드 사이 간선이 2개 이상이면 ‘멀티그래프’.특수한 유형의 간선(edge) 2 가지 셀프 간선(엣지): 자기자신에게 다시 연결된 간선. 하이퍼 간선(엣지): 3개 이상 노드에 연결된 간선. 그래프에 하이퍼 간선이 1개 이상 존재하면, 그 그래프를 ‘하이퍼 그래프’ 라고 부른다.에고 중심 네트워크정의특정 중심정점과 그 이웃들로 이루어진 네트워크. 중심정점을 ‘에고’라고 한다. 에고에 바로 인접한 정점들을 ‘알터(alter)’ 라고 한다. ‘그 이웃들’ 은 에고에 바로 인접한 정점들만 의미할 수도 있고, n개 엣지 만큼 떨어진 이웃들까지 의미할 수도 있다. 핵심은 중심정점 ‘에고’를 중심으로 한 네트워크 라는 것이다.네트워크 분석 이론주요 기본 용어 정리경로시작점과 끝점 사이 정점 집합. ‘집합’ 이기 때문에, 경로 내 중복된 정점은 있을 수 없다.경로 길이엣지(간선) 개수최단 경로여러 경로 중 엣지 수가 가장 적은, 경로.삼각형 그래프세 개 정점이 세 개 엣지로 연결된 그래프. 삼각형 그래프에서 각 정점은 서로 밀접한 ‘관계’를 맺고 있다. 세 정점이 서로 모두 연결되어 있기 때문이다.네트워크 밀도$density =\\frac{Edges_{observed}}{Edges_{total}}$ 주어진 네트워크에서 실제로 목격된 엣지 수와, 주어진 네트워크가 완전 연결 네트워크 일 때 가질 수 있는 최대 엣지 수 비율. 삼각형 그래프처럼, 각 정점이 서로 모두 엣지로 연결되어 있는 네트워크를 완전 연결 네트워크(fully connected network) 라고 한다. 완전 연결 네트워크는 그 엣지 수가 ‘허용가능한 최대’다. $n$ 개 정점으로 구성된 완전 연결 네트워크의 엣지 수는 아래 공식을 통해 구할 수 있다. $Edges_{total} = \\frac{n(n-1)}{2}$ 밀도의 최댓값은 $1$ 이다.정점 중심성 지표중심성 지표 = 정점 중요도(가중치).정점 중심성 지표로 사용할 수 있는 주요 지표로 아래 4가지가 있다.1. 도수 중심성(degree centrality)도수(degree): 특정 정점에 연결된 엣지(간선) 수.정점 도수가 높을 수록(=정점에 연결된 엣지 수가 많을 수록), 중요한 정점이라고 간주한다.정점의 도수 중심성은 아래 간단한 공식으로 계산한다.$C_{dc_{a}} = \\frac{degree_{a}}{\\vert{V}\\vert-1}$ $degree_{a}$ : 정점 $a$ 도수 $\\vert{V}\\vert$ : 그래프 총 정점 수2. 매개 중심성(betweeness centrality)특정 정점이 다른 정점들 사이에 끼어있는 정도.$C_{betweeness_{a}} = \\frac{n_{shortest_{a}}}{n_{shortest_{total}}}$ $n_{shortest_{a}}$ : 모든 정점 페어 간 최단경로 중 정점 $a$ 를 지나는 최단경로 갯수 $n_{shortest_{total}}$ : 모든 정점 페어 간 최단경로 총 갯수3. 공정성과 근접 중심성공정성: 자기자신과 그래프 내 다른 모든 정점과의 최단 경로 길이 총합.$\\Rightarrow$ $\\sum_{j=1}^{n}{shortest_{a-j}}$근접중심성: 공정성의 역수. 즉 $\\frac{1}{\\sum_{j=1}^{n}{shortest_{a-j}}}$4. 고유벡터 중심성(eigenvector centrality)정점 중심성 지표 계산하기임의로 그래프 만들어서, 정점 별 중심성 지표(정점 별 중요도) 계산해보자.# networkx 라이브러리 사용해 예시 네트워크 생성 import networkx as nx import matplotlib.pyplot as plt # 10개 정점 vertexes = range(1,10) # 간선edges = [(7,2), (2,3), (7,4), (4,5), (7,3), (7,5), (1,6), (1,7), (2,8), (2,9)] # 빈 그래프 생성 g = nx.Graph() # 정점 10개 빈 그래프에 추가 g.add_nodes_from(vertexes)# 간선 빈 그래프에 추가 g.add_edges_from(edges) # 정점과 간선 추가된 그래프 시각화 nx.draw(g, with_labels=True, node_color='r', node_size=800)1 도수 중심성 지표 계산# 도수 중심성 지표 계산 # 1. 도수 중심성 지표 계산 nx.degree_centrality(g)# 시각화 plt.bar(nx.degree_centrality(g).keys(), nx.degree_centrality(g).values()){1: 0.25, 2: 0.5, 3: 0.25, 4: 0.25, 5: 0.25, 6: 0.125, 7: 0.625, 8: 0.125, 9: 0.125}2 매개 중심성 지표 계산# 2. 매개 중심성 print(nx.betweenness_centrality(g))# 시각화 plt.bar(nx.betweenness_centrality(g).keys(), nx.betweenness_centrality(g).values()){1: 0.25, 2: 0.46428571428571425, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.7142857142857142, 8: 0.0, 9: 0.0}3 근접 중심성 지표 계산# 3. 근접중심성 print(nx.closeness_centrality(g)) # 시각화 plt.bar(nx.closeness_centrality(g).keys(), nx.closeness_centrality(g).values()){1: 0.5, 2: 0.6153846153846154, 3: 0.5333333333333333, 4: 0.47058823529411764, 5: 0.47058823529411764, 6: 0.34782608695652173, 7: 0.7272727272727273, 8: 0.4, 9: 0.4}4 고유벡터 중심성 지표 계산# 고유벡터 중심성 centrality = nx.eigenvector_centrality(g)print(sorted([(v, round(c, 2)) for v, c in centrality.items()]))# 시각화 plt.bar(centrality.keys(), centrality.values())[(1, 0.24), (2, 0.45), (3, 0.36), (4, 0.32), (5, 0.32), (6, 0.08), (7, 0.59), (8, 0.16), (9, 0.16)]4 가지 중심성 지표에서, 정점 7이 항상 가장 높은 중심성 지표 기록했다.$\\Rightarrow$ 정점 7 중요도가 가장 높다. 정점 7이 그래프에서 가장 중요한 정점이다." }, { "title": "[알고리즘/문제해결전략] 분할 정복 전략, 동적 계획법, 탐욕 알고리듬", "url": "/bioinfo.github.io/posts/designing_algorithms/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-22 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 3가지 문제 해결 전략을 공부. 복습하고나서, 그 내용을 내 언어로 바꾸어 기록한다.알고리듬 설계에 적용할, 문제해결 전략 분할 정복 전략(divide and conquer) 동적 계획법 탐욕 알고리듬1. 분할 정복 전략정의문제를 작은 문제로 쪼개어 각개격파 한 뒤 결과물을 모으는 문제해결 방식.2. 동적 계획법‘기억하며 풀기’정의문제를 하위 문제 여러 개로 나누어, ‘최적의 방법으로’ 해결한 뒤 결과물 모으는, 분할 정복 전략.메모이제이션 통해서 하위 문제들을 최적 방법으로 해결한다. 메모이제이션: 하위 문제 연산 결과를 저장하고 있다가 중복되는 문제 등장하면 연산없이 곧바로 해결하기.3. 탐욕 알고리듬(Greedy algorithm)현재상황에서 최선의 선택, 항상 내리기.정의알고리듬 오버헤드 최소화 하는 문제 해결 전략. 알고리듬 오버헤드: 알고리듬 실행에 소요되는 부가적인 시간, 메모리 등 자원.장점빠르다.단점찾은 해가 전역 최적해라는 보장이 없다.$\\Rightarrow$ 근사 알고리듬의 일종이다.탐욕 알고리듬 활용 사례: 외판원 문제규칙 모든 도시를 한번씩 만 방문할 수 있다. 여정 끝에 시작한 도시로 다시 돌아와야 한다. 도시 간 거리는 모두 알려져 있다.*도시가 $n$ 개 있으면, 가능한 여정은 $(n-1)!$ 개 이다.문제 기능적 요구사항 파악 입력: $n$ 개 도시 리스트, $n$ 개 도시 서로 간 거리 출력: 여정거리 최소 되는 투어 경로문제 해결 전략 1: 무차별 대입 전략무차별 대입(brute-force strategy): 무식하게 직접 하나하나 노가다 해서 원하는 출력 찾는 전략.비밀번호 4자리가 있으면, 가능한 모든 수를 모든 자리에 일일이 넣어보면서 정답 찾는 전략이다.경우의 수가 적을 때는 오히려 정확한 답 찾는 데 효과적이다.하지만 경우의 수가 많아지면 알고리즘 시간복잡도가 기하급수적으로 증가하기 때문에 좋은 전략이 못 된다.무차별 대입 전략 구현해서 문제 해결하기# 무차별 대입 전략 구현하기 import random from itertools import permutations # permuations: 리스트 받아서 가능한 순열 모두 생성한다. alltours = permutations # distance_tour: 총 여정거리 계산하는 함수. sum 함수 안에서도 리스트 축약식처럼 for문 사용 가능하다는 점 눈여겨 봐 두자. def distance_tour(atour) : return sum(distance_points(atour[i-1], atour[i]) for i in range(len(atour)))# complex 는 a+bj 꼴 복소수 생성하는 클래스다. a: 실수부, bj는 허수부. 복소수 1개는 벡터와 같다. 각 도시를 2차원 벡터공간 상의 벡터로 표현하기 위해 사용한다. acity = complex # first 벡터와 second 벡터 사이 유클리드 거리 계산하는 함수(도시 간 거리 계산).def distance_points(first, second) : return abs(first-second) # 가로 500, 세로 300인 2차원 벡터공간에 무작위로 벡터 생성한다. 각 벡터는 도시 상징한다. def generate_cities(number_of_cities) : seed = 10 width = 500 height = 300 random.seed((number_of_cities, seed)) return frozenset( # x 축에서 랜덤하게 좌표 생성 acity(random.randint(1, width), # y 축에서 랜덤하게 좌표 생성 random.randint(1, height)) # 도시 수 만큼 반복해서 벡터 생성(중복 frozenset으로 제거) for c in range(number_of_cities))무차별 대입 함수 구현. 총 여정거리 최소인 투어 경로 찾아서 산출한다.import matplotlib.pyplot as plt # 무차별 대입 함수 구현 : 여러 투어 후보군 중 최소 투어 찾아서 출력def brute_force(cities) : return shortest_tour(alltours(cities)) # 총 거리 최소인 투어 반환def shortest_tour(tours) : return min(tours , key = distance_tour)def visualize_tour(tour) : # 투어 크기 일정 이상 커지면, 전체 이미지 크기 조정 if len(tour) &gt; 1000 : plt.figure(figsize=(15,10)) # 여정 시작점 start = tour[0:1] # 경로 시각화. 여정 마지막점 == 시작점 되기 위해 tour + start 한다. visualize_segment(tour+start) # 여정 시작점은 빨간색으로 칠해서 돋보이게 해라 visualize_segment(start, 'rD')# 리스트 받아서 2차원 벡터공간에 (x좌표, y좌표) 찍어 시각화 하는 함수. def visualize_segment(segment, style='bo-') : plt.plot([x(c) for c in segment], [y(c) for c in segment], style) # x축, y축 이미지에서 제거 plt.axis('scaled') plt.axis('off')# 복소수 입력으로 받아서 실수부만 추출하는 함수. 벡터의 x축 좌표와 같다. def x(c): return c.real # 복소수 입력으로 받아서 허수부만 추출하는 함수. 벡터의 y축 좌표와 같다. def y(c) : return c.imag문제 해결# 리스트 각 요소 갯수 세서 딕셔너리 반환해준다from collections import Counter import time def tsp(algorithm, cities) : t0 = time.perf_counter() # 알고리듬 시작시간 tour = algorithm(cities) # 거리 최소인 투어(여정 경로) 산출. t1 = time.perf_counter() # 알고리듬 종료시간 # 결과 경로가 모든 도시 한번씩만 방문했는지 검증 assert Counter(tour) == Counter(cities) # 결과 경로 2차원 벡터공간 상에 시각화 visualize_tour(tour) # 결과 print(f'무차별 대입 전략 : {len(cities)} cities =&gt; tour length : {round(distance_tour(tour))} (in {round(t1-t0,4)} sec)')# 10개 도시에 대해 총 여정거리 최소인 경로 찾기 tsp(brute_force, generate_cities(10))문제 해결 전략 2: 탐욕 알고리듬(그리디 알고리듬)무차별 대입 전략은 방문해야 할 도시 수가 적을 때는 정확한 정답 찾는 유용한 문제해결 전략이다.하지만 방문해야 할 도시 수가 많아지면 많아질 수록, 가능한 후보 경로 수가 기하급수적으로 많아진다($n-1!$). 이 경우에 무차별 대입 전략 사용할 경우 말 그대로 억겁의 시간이 걸릴 수 있다.곧, 방문할 도시 수가 많은 경우엔 무차별 대입 전략은 사용하기 부적절하다.무차별 대입전략을 적용하기 어려운 경우에 대해(도시 수를 크게 늘려서),탐욕 알고리듬을 적용해서 총 여정 경로 최소가 되는 투어 경로 찾아보자.탐욕 알고리듬# 그리디 알고리즘 def greedy_algorithm(cities, start=None) : c = start or first(cities) # 여정 시작 도시 # 여정 tour = [c] # 방문 안 한 곳 unvisited = set(cities - {c}) while unvisited : # 방문 안 한 곳이 남아 있는 한 c = nearest_neighbor(c, unvisited) # 가장 가까운 도시 tour.append(c) # 여정 생성 unvisited = unvisited - {c} # 방문안 한 곳 리스트에서 이번에 방문한 도시 제거 return tour def first(cities) : return next(iter(cities)) def nearest_neighbor(start, cities) : return min(cities, key= lambda c : distance_point(c, start))탐욕 알고리듬으로 문제해결 실행; 5000개 도시 있을 때 최단 경로 찾기# 도시 수 : 5000개 tsp(greedy_algorithm, generate_cities(5000))무차별 대입 전략 : 4921 cities =&gt; tour length : 24055 (in 2.7062 sec)매 순간 최적 선택지(거리 가장 가까운 도시) 선택하는 탐욕 알고리듬은 단 2.7초 만에 최단 투어 경로 찾아냈다.탐욕 알고리듬이 더 많은 도시 개수에도 불구하고, 도시 10개 밖에 안 되는데 10초 넘게 걸렸던 무차별 대입전략 보다 약 5배 빨랐다.다만, 탐욕 알고리듬은 근사 알고리듬이기 때문에, 이 알고리듬이 찾은 정답은 전역 최적해가 아닐 수 있다. 즉, 거시적 관점에서 전체 도시와 경로를 보면 탐욕 알고리듬이 찾은 경로가 최단 경로가 아닐 수 있다." }, { "title": "[알고리즘] 알고리듬 정의 부터 알고리듬 검증까지 기초 이론", "url": "/bioinfo.github.io/posts/algorithm_theory/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-22 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 알고리듬 기초 이론을 공부. 복습하고나서, 공부한 내용을 내 언어로 바꾸어 기록한다.알고리듬(Algorithm)정의특정 입력을 받아서, 가장 효율적 방식으로 출력 도출하는. 논리흐름.또는문제에 대한 수학적 해결책.알고리듬 로직 표현하는 방법1. 의사코드구조화된 방식으로 알고리듬 로직을 표현한다.2. 스니펫프로그래밍 언어로 표현한 알고리듬.3. 실행계획각 작업 별로 알고리듬을 쪼개서 그 로직 표현한다.각 작업 블록을 ‘스테이지’라고 한다.스니펫 만으로는 알고리듬 로직 표현이 어려울 때(알고리듬이 매우 복잡한 경우) 주로 사용한다.알고리듬 분류1) 문제 특성에 따른 알고리듬 분류1. 데이터 집약적 알고리듬대규모 데이터 처리하는 알고리듬.2. 연산 집약적 알고리듬대규모 연산 수행하는 알고리듬.3. 연산/데이터 집약적 알고리듬대규모 데이터에 적용되며, 대규모 연산 수행하는 알고리듬2) 출력 결과에 따른 알고리듬 분류1. 결정론적 알고리듬특정한 입력에 대해 항상 같은 출력 결과 제공하는 알고리듬.2. 비결정론적 알고리듬난수가 개입되어, 특정한 입력에 대해 항상 다른 결과 나올 수 있는 알고리듬.3) 복잡도 낮추기 위해 정확도 희생 여부에 따른 분류1. 최적 알고리듬정확도 희생 안 한다. 문제에 대한 정확한 해결책 찾아내는 알고리듬.2. 근사 알고리듬복잡도 줄이기 위해 정확도 다소 희생한 알고리듬.알고리듬 성능 분석하기알고리듬 복잡도(알고리듬 성능 측정 지표) 알고리듬 공간복잡도 분석: 알고리듬 실행이 얼마만큼 메모리 필요로 하는가. 알고리듬 시간복잡도 분석: 알고리듬 실행에 얼마만큼 시간이 소요되는가.알고리듬 복잡도 줄이기(알고리듬 성능 향상하기)알고리듬 복잡도를 줄이기 위해서는 정확도를 희생해야 한다.알고리듬 성능 $\\Rightarrow$ 복잡도 와 정확도 사이 줄다리기.알고리듬 설계정의주어진 자원과 제약조건 내에서, 문제의 기능적. 비기능적 요구사항 최대로 충족시킬 방법 찾기.1) 사전과정문제의 기능적, 비기능적 요구사항 파악하기.문제의 기능적, 비기능적 요구사항 문제의 기능적 요구사항: 문제의 입력과 출력 파악하기. 문제의 비기능적 요구사항: 알고리듬 성능, 보안 기대치 파악하기.2) 과정 중 고려해야 할 특성들 알고리듬 정확성: 특정한 입력에 대해 ‘정확한’ 출력 내놔야 한다. 알고리듬 최적성: 현재 알고리듬이 최적 알고리듬인가 판단. 알고리듬 확장성: 이 알고리듬을 더 큰 데이터셋에도 적용할 수 있는가.알고리듬 검증1. 알고리듬 정확성 검증에 필요한 거 특정 입력에 대한 ‘정답’ 값. 알고리듬 정확성 측정 지표2. 알고리듬 최적성 검증에 필요한 거 문제의 복잡도 파악하기3. 알고리듬 확장성 검증에 필요한 거 데이터 크기와 알고리듬 공간. 시간복잡도 사이 관계 파악하기데이터 크기 증가 $\\Rightarrow$ 알고리듬 공간복잡도 크게 증가: 알고리듬 확장성 떨어진다.데이터 크기 증가 $\\Rightarrow$ 알고리듬 시간복잡도 크게 증가: 알고리듬 확장성 떨어진다.vice versa." }, { "title": "[알고리즘/검색 알고리즘] 선형검색, 이진검색 알고리즘", "url": "/bioinfo.github.io/posts/search_algorithm/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-21 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 선형, 이진검색 알고리즘을 공부. 복습하고나서, 알고리즘을 구현하기 위해 문제를 정의내리고 해결책을 구상한 과정. 사고흐름. 구현 결과를 기록한다.선형 검색(Linear search)정의 및 특징배열에서, 선형으로 데이터 하나하나 조회하기.장점검색하기 위해서 사전에 배열을 정렬할 필요, 없다.단점느리다.구상 0번 인덱스에서부터 시작한다. 찾았는지 여부는 처음에 false 로 둔다. 반복조건: &lt;리스트 마지막 요소까지 반복&gt; + &lt;일치하는 값 찾으면 정지(=일치하는 값 찾을 때 까지 반복한다 = 아직 못 찼았는 동안 반복한다)&gt; 만약 이번 인덱스가 일치하면: 찾았는지 여부 = true 로 변경한다 인덱스가 일치하지 않으면: 다음 인덱스로 이동한다. 최종으로, 찾았는지 여부를 return 한다(true or false)while 문 사용해서 구현# 선형검색 def linear_search(x, item) : current_index = 0 # 현재 인덱스 found = False # 찾았는지 여부 while (current_index &lt; len(x)) and (found == False) : if x[current_index] == item : found = True else : current_index += 1 return found 테스트x = [12, 33, 11, 99, 22, 55, 90]print(linear_search(x, 12))print(linear_search(x, 91))TrueFalsefor 문 사용해서 구현# 선형검색 -2 def linear_search_2(x, item) : found = False for cont in x : if cont == item : found = True break return found 테스트print(linear_search_2(x, 12))print(linear_search_2(x, 91))TrueFalse테스트 -2import numpy as np x2 = np.random.sample(100)sample = x2[3]print(linear_search_2(x2, sample))print(linear_search_2(x2, 33))TrueFalse이진 검색(Binary search)왜 이진(binary) 검색인가?배열을 중간값 기준으로 왼쪽 오른쪽 끊임없이 둘로 나누면서 검색하기 때문에 이진검색 이라 부른다.사용 전제조건데이터가 이미 정렬되어 있어야 한다.검색 과정아래 과정 반복한다. 배열에서 중간값 찾는다. 중간값과 찾으려는 값 크기 비교한다. 중간값 = 찾으려는 값 이면: 검색 종료한다. 중간값 &lt; 찾으려는 값 이면: 배열에서 중간값 기준 오른쪽 배열로 이동 중간값 &gt; 찾으려는 값 이면: 배열에서 중간값 기준 왼쪽 배열로 이동1차 구상 배열에서 가장 중앙에 위치한 값 찾는다. 중앙값과 찾으려는 값 비교해서, 값이 중앙값보다 크면 오른쪽 배열. 작으면 왼쪽 배열 따로 떼어낸다. 만약 중간값과 찾으려는 값 같으면 ‘찾았음’ 1과 2 과정, (원하는 값 못 찾았고) and (배열 크기가 1 이상일 때) 까지 반복한다.$\\Rightarrow$2차 구상while (원하는 값 못 찾았고) and (배열 크기가 1 이상 일 때) : &lt;반복 지속조건&gt;1 배열 가장 중간값 찾는다.2만약 중간값 == 찾으려는 값 이면: $\\Rightarrow$ ‘찾았음’그렇지 않은 모든 경우에 대해서,만약 중간값 &lt; 찾으려는 값 이면: x = x[ 중간값+1: ]만약 중간값 &gt; 찾으려는 값 이면: x = x[ :중간값 ]그 외 모든 경우에: break구현# 이진검색 def binary_search(x, item) : found = False # item을 찾았는가 여부 while (found is False) and (len(x) &gt;= 1) : # 반복 지속조건 mid_point = len(x)//2 # 중간값 인덱스 지정 if x[mid_point] == item : # 검사: 중간값이 내가 찾으려는 item 값과 같은가? found = True # 같다면 true(반복문도 종료) else : # item과 중간값이 다른 경우 if x[mid_point] &lt; item : # item이 더 크면 중간값 기준 오른쪽 리스트로 이동 x = x[mid_point+1:] elif x[mid_point] &gt; item : # item이 더 작으면 중간값 기준 왼쪽 리스트로 이동 x = x[:mid_point] return found # item 찾았는가 여부 반환. true 또는 false 일 것이다. 테스트test = [12, 33, 11, 99, 22, 55, 90]# 이진검색은 데이터가 사전에 이미 정렬되어 있어야 한다. # 따라서 test 리스트 정렬 위해 버블정렬 사용했다. # 버블정렬 정의def bubble_sort(x) : for pas in range(len(x)-1) : # 패스 n-1 번 반복 for i in range(len(x)-1) : if x[i] &gt; x[i+1] : x[i], x[i+1] = x[i+1], x[i] # 교환 return x # 결과 출력 print(binary_search(bubble_sort(test), 33332))print(binary_search(bubble_sort(test), 91))FalseFalse" }, { "title": "[알고리즘/정렬 알고리즘] 버블정렬, 삽입정렬, 병합정렬, 셸 정렬, 선택정렬 알고리즘", "url": "/bioinfo.github.io/posts/algorithms/", "categories": "computer science, algorithm, study", "tags": "computer science, algorithm, study", "date": "2022-07-20 00:00:00 +0900", "snippet": "‘프로그래머가 알아야 할 알고리즘 40’(임란 아마드 지음, 길벗 출판사) 을 통해 정렬 알고리즘을 공부. 복습하고나서, 알고리즘을 구현하기 위해 문제를 정의내리고 해결책을 구상한 과정. 사고흐름. 구현 결과를 2022년 7월 20일 최초 기록한다.버블정렬정의가장 큰 값을 가장 오른쪽으로 보내기방법이웃한 값 비교해서 교환(패스) 패스 N-1 번 반복스니펫 구상# 버블정렬 구상 for end in range(len(list), 0, -1) : for i in range(0, end-1) : # 1. 2개 비교 # 2. 만약 둘 중에 앞 값이 더 크면: 서로 자리 교체 # --&gt; if list[i] &gt; list[i+1] : list[i], list[i+1] = list[i+1], list[i]구현# 버블정렬 구현 def bubble_sort(x) : for end in range(len(x)-1, 0, -1) : for i in range(0,end) : if x[i] &gt; x[i+1] : x[i], x[i+1] = x[i+1], x[i] return x테스트x = [25, 21, 22, 24, 23, 27, 26]bubble_sort(x)[21, 22, 23, 24, 25, 26, 27]삽입정렬구상 N-1번 중 이번회차에 대해서 이번 회사체 정렬해야 할 원소 위치: j 이번 회차에 정렬해야 할 원소의 값: temp while(j-1 &gt;= 0) and (list[ j ] &lt; list[ j-1 ]) : list[ j ] = list[ j-1 ], j-=1 while 반복이 끝나면: list[ j ] = temp스니펫# 삽입정렬 스니펫 for n in range(1, len(x)) : j = n temp = x[j] while (j-1 &gt;= 0) and (temp &lt; list[j-1]&gt;) : list[j] = list[j-1] j-= 1 list[j] = temp 구현# 삽입정렬 구현 def insert_sort(x) : for n in range(1, len(x)) : j = n # 정렬 해야 할 가장 왼쪽 위치 temp = x[j] while (j-1 &gt;= 0) and (temp&lt;x[j-1]) : x[j] = x[j-1] j -= 1 x[j] = temp return x테스트import numpy as np import matplotlib.pyplot as plt x = [25, 26, 22, 24, 27, 23, 21]insert_sort(x)x2 = list(np.random.sample(100))plt.bar(range(100), insert_sort(x2))병합정렬구상전체 과정은 분리 $\\Rightarrow$ 병합.&lt;분리&gt; 분리조건: 리스트 크기 $&gt; 1$ 일 때; 리스트 크기 1 되면 분리 정지(=크기 1될 때 까지 분리) 분리 기준점 설정 분리 기준점 기준 왼쪽으로 분리 분리 기준점 기준 오른쪽으로 분리왼쪽에 대해 다시 분리(+병합) 적용오른쪽에 대해 다시 분리(+병합) 적용&lt;병합&gt; 왼쪽 오른쪽 크기 비교해서, 오름차순으로 원본리스트에 결합*분리된 상태 = 정렬된 상태.a = 0 , 왼쪽 인덱스b = 0 , 오른쪽 인덱스c = 0 , 전체 인덱스while (a &lt; len(left)) and (b &lt; len(right)) :if left[ a ] &gt; right[ b ] : list[ c ] = right[ b ], b+= 1else: list[ c ] = left[ a ], a+= 1c += 1while (a &lt; len(left)) : list[ c ] = left[ a ], a += 1, c+= 1while (b &lt; len(right)) : list[ c ] = right[ b ], b+= 1, c+= 1return list, 정렬 결과 출력구현# 병합 정렬 구현def merge_sort(x) : # 분리 if len(x) &gt; 1 : # 분리 조건 separate_criterion = len(x)//2 left = x[:separate_criterion] right = x[separate_criterion:] merge_sort(left) merge_sort(right) # 병합 a = 0 b = 0 c = 0 while (a &lt; len(left)) and (b &lt; len(right)) : if left[a] &gt; right[b] : x[c] = right[b] b += 1 else : x[c] = left[a] a += 1 c += 1 while (a &lt; len(left)) : x[c] = left[a] a += 1 c += 1 while (b &lt; len(right)) : x[c] = right[b] b += 1 c += 1 return x 테스트list3 = [44, 16, 83, 7, 67, 21, 34, 45, 10]merge_sort(list3)[7, 10, 16, 21, 34, 44, 45, 67, 83]테스트 2test = list(np.random.sample(100))plt.figure(figsize=(100,50))plt.subplot(1,2,1)plt.bar(range(100), test)plt.subplot(1,2,2)plt.bar(range(100), merge_sort(test))셸 정렬삽입정렬 보완판.구상 거리 설정한다. 정렬해야 할 원소 j와 j-distance 사이 값 비교한다. j &lt; j-distance 이면, j와 j-distance 값 위치 교환 , j = j-distance 로 새로 할당 3의 과정을 j-distance &gt;=0 일 때 까지 반복한다.구현# 셸 정렬 구현def shell_sort(x) : distance = len(x)//2 # 거리 지정 while distance &gt; 0 : # 부분 리스트 정렬 하는 코드 블럭 for i in range(distance, len(x)) : j = i # 부분리스트 1개에 대해 정렬하는 코드 블럭 while (j-distance &gt;= 0) and (x[j] &lt; x[j-distance]) : x[j], x[j-distance] = x[j-distance], x[j] j = j - distance distance = distance // 2 # 다 끝났으면 거리 조정 return x 테스트x = list(np.random.sample(100))plt.figure(figsize=(10,5))plt.subplot(1,2,1)plt.bar(range(100), x)plt.subplot(1,2,2)plt.bar(range(100), shell_sort(x))plt.show()선택정렬구상 정렬 안 된 부분에서 가장 큰 값 찾아서, 정렬 안 된 부분 가장 오른쪽 원소와 바꾼다. 정렬 안 된 부분 가장 오른쪽 위치는 교환 발생할 때 마다, 1씩 줄어든다.$\\Rightarrow$&lt;다시 정리&gt;교환 정리 안 된 부분에서 가장 큰 값 찾는다. 가장 큰 값과, 정렬 안 된 부분 가장 오른쪽 원소 맞바꾼다.+ 교환 발생할 때 마다 ‘정렬 안 된 부분 가장 오른쪽 위치’가 1씩 줄어든다. 교환은 총 n-1번 발생한다.스니펫for r in range(len(x)-1, 0, -1) : # 가장 오른쪽 요소의 인덱스 # n-1번 교환 발생 #&lt;가장 큰 값 찾기&gt; max_index = 0 for i in range(1, r+1) : if x[max_index] &lt; x[i] : max_index = i # 이제 가장 큰 값(그것의 인덱스) 찾았다. 교환한다. # &lt;교환&gt; x[max_index], x[r] = x[r], x[max_index]구현# 선택정렬 복습 &amp; 구현 def selection_sort(x) : for r in range(len(x)-1, 0, -1) : # 가장 오른쪽 요소의 인덱스 (1씩 감소) # 가장 큰 값 찾기 max_index = 0 for i in range(1, r+1) : if x[max_index] &lt; x[i] : max_index = i # 교환 x[max_index], x[r] = x[r], x[max_index] return x 테스트x = np.random.sample(500) plt.figure(figsize=(10,5))plt.subplot(1,2,1)plt.bar(range(500), x)plt.subplot(1,2,2)plt.bar(range(500), selection_sort(x))" }, { "title": "[분자생물학] 항원결정기(Epitope)", "url": "/bioinfo.github.io/posts/epitope/", "categories": "Molecular biology, Protein structure, Bioinformatics", "tags": "molecular biology, protein structure, bioinformatics", "date": "2022-07-12 00:00:00 +0900", "snippet": "항원결정기(epitope)정의항체와 결합하는 항원의 특정 부분 항원결정기와 결합하는 항체 쪽 카운터파트를 paratope(항원결합부) 라고 한다.항원결정기 종류1. 구조적(3차원적) 항원결정기(conformational epitope)단백질 3차원 접힘 과정에서, 불연속적 아미노산 배열이 형성하게 되는3차원 구조. 90% 가량의 항원결정기가 여기 속한다. 단백질이 접힘 상태일 때만, 항체가 구조적 항원결정기 인식할 수 있다. 단백질이 변성 되면서 접힘 풀리면 항체가 항원결정기 인식할 수 없다. 구조적 항원결정기는 항상 단백질 구조 표면(exterior)에 존재한다.2. 선형 항원결정기(linear epitope)연속적 아미노산 배열이 형성하는 3차원 구조. 단백질 변성 여부 상관없이, 항체가 선형 항원결정기 인식할 수 있다. 선형 항원결정기는 단백질 구조 표면 뿐 아니라, 3차원 구조 내부(interior)에 존재할 수도 있다. 이 경우엔 단백질을 변성 시켜 접힘을 풀어야 항체가 항원결정기 인식할 수 있다.*구조적 항원결정기와 선형 항원결정기 모두 3차원 구조를 띄고 있다. (3차원 구조라 부르기 어려운 아미노산 잔기 하나, 작은 폴리펩티드 조각 일 수도 있다)*선형 항원결정기의 3차원 구조는 기본적으론 항원결정기 부분 구성하는 아미노산 시퀀스가 결정(1차구조)하는데, 항원결정기 부분에 속하지 않는 나머지 전체 아미노산 배열도 선형 항원결정기 3차원 구조 형성에 영향 미친다.*항원결정기(epitope) 마다 생긴 구조가 다르기 때문에, 항체의 항원 결합부(paratope)는 이 구조에 마치 퍼즐처럼 들어맞아야 둘이 결합된다. (결합 $\\Rightarrow$ host의 생체 내에서 항원 제거)항원결정기 표현한 그림항원결정기에 항체가 결합선형 항원결정기와 구조적 항원결정기 표현한 그림[ 이미지 출처: https://microbeonline.com/epitope/ ]" }, { "title": "[분자생물학] 단백질 구조", "url": "/bioinfo.github.io/posts/protein-structure/", "categories": "Molecular biology, Protein structure, Bioinformatics", "tags": "molecular biology, protein structure, bioinformatics", "date": "2022-07-10 00:00:00 +0900", "snippet": "단백질 구조2022년 7월 4일 - 2022년 7월 10일까지 ‘왓슨 분자생물학 7판(옮긴이: 양재섭 외 14인, 출판사: (주)바이오사이언스출판), 2014’ 을 기반으로 공부한, 단백질 구조 공부 내용을 내 언어로 바꾸어 2022년 7월 10일 기록한다.학습 및 기록 목표는 논문 ‘Highly accurate protein structure prediction with AlphaFold’ 을 더 잘 이해하고, 앞으로 단백질 데이터 분석에 필요한, 단백질 관련 생물학 도메인 기본 지식을 쌓는 것 이다.아미노산정의단백질 구성 기본 단위.아미노산 분자구조$\\alpha$ 탄소, 작용기(카복실기 아미노기), 곁사슬 로 구성되어 있다.[ 이미지 출처: https://ko.wikipedia.org/wiki/아미노산#/media/파일:AminoAcidball001.svg ] 맨 중앙 알파탄소 왼쪽 NH2 가 아미노기, 알파탄소 오른쪽 CO2H가 카복실기, R은 곁사슬 이다. 카복실기: CO2H 또는 COOH 로 표기한다. 탄소, 산소, 수소 원자로 구성된다. 중간에 탄소 원자에 산소원자 2개가 붙어있고 1개 수소원자가 산소원자 하나에 붙어있다. 카복실기는 수소이온을 내놓기 때문에 산성이다. 아미노기: NH2로 표기한다. 질소원자 1, 수소원자 2 결합한 형태다. 염기성이다. R기: 곁사슬. 곁사슬 종류 = 아미노산 종류 다. 곁사슬은 극성 갖는데, 곁사슬 극성이 아미노산의 물에 대한 용해도(친수성 vs 소수성) 결정짓는다. 펩타이드 결합정의두 아미노산 사이 아미노기와 카복실기가 서로 반응, 물을 내놓으면서 둘이 서로 결합하는 것.&lt;이미지 출처: https://onsaem9134.tistory.com/21&gt;단백질은 이 펩타이드 결합의 연속이다. 따라서 단백질을 ‘펩타이드 중합체’ 라고도 한다.폴리펩티드정의아미노산 여러 개가 펩타이드 결합한 것. 폴리(Poly-) 는 ‘중합된’ 이란 뜻 갖고 있다. 즉 폴리펩티드는 ‘펩티드 중합체’ 말한다. ‘단백질’ 그 자체를 지칭하기도 한다. 하지만 일반적으로는, 일반적 단백질보다 적은 갯수 아미노산 분자로 엮여진 물질 말한다. 즉 폴리펩티드는 사이즈 좀 작은 펩타이드 중합체다.잔기(Residue)정의아미노산.$\\Rightarrow$ 단백질 아미노산 서열(1차구조) 에 속한 아미노산 하나하나. 즉 단백질 기본 단위.구조(Conformation)정의화학결합된 원자들의 3차원 정렬 단백질 접힘 구조(folded structure) = 단백질 구성하는 원자들의 3차원 정렬. 즉, 단백질 구조.단백질정의펩타이드 중합체. 아미노산 펩타이드 결합의 연속.아미노산 분자량이 적으면, 폴리펩티드. 분자량 크면, 단백질 이라고 한다.단백질 구조 (Protein structure)단백질 접힘 구조(folded structure) 라고도 한다.단백질은 3차원 구조를 갖는다. 이 3차원 구조는 3차원 적으로 ‘접힌’ 형태 띄고 있다.그래서 단백질 구조를 ‘단백질 접힘 구조’ 라고 표현한다.이 단백질 구조를 ‘표현’ 하는 4가지 단계가 있다.단백질 구조 표현 4단계1차구조정의: 아미노산 시퀀스 1차원 선(line) 이다. 예:ABCDEFG…XZ2차구조정의: 1차구조에 기반해서 만들어지는, 3차원 폴리펩타이드 사슬 중 규칙적인 형태갖는 일부분. 알파나선(Alpha helix), 베타병풍(Beta sheet 또는 Beta strand) 두 가지 종류 있다. 두 2차구조는 ‘안정적’이다. 알파나선(Alpha helix)정의: 단백질 2차구조 중 하나로, 폴리펩타이드 사슬이 용수철 모양으로 꼬여있는 것 말한다.[ 이미지 출처: https://statnmath.tistory.com/7 ]베타병풍(Beta sheet)정의: 단백질 2차구조 중 하나로, 폴리펩타이드 사슬이 접혀있는 병풍 형상 띄고 있다.[ 이미지 출처: https://statnmath.tistory.com/7 ]3차구조정의: 2차구조 집합 이자 전체 폴리펩티드 사슬이 3차원 구조로 접혀 있는 것. 보통 1개 기능 온전히 수행하는 단백질이 3차구조다.4차구조정의: 2개 이상 3차구조 집합. 4차구조 구성하는 각 3차구조를 소단위(subunit) 또는 기본단위(protomer) 라고 한다.1차구조부터 4차구조 까지 그림으로 정리[ 이미지 출처 https://pendingissue.tistory.com/103 ]1차구조는 아미노산들 연속적 나열 이다. 구슬 꿴 목걸이 같이 생긴 것이 1개 단백질이다.2차구조는 알파나선과 베타병풍 두 가지, 있다. 둘 모두 3차원 형상이다.3차구조는 2차구조 집합이자 전체 폴리펩티드 사슬이 3차원에서 접힌 것 이다.4차구조는 2개 이상 3차구조 집합이자 복합체다. 4차구조 이루는 각 3차구조를 ‘소단위(subunit)’ 이라 한다.단백질의 변성(denaturation)정의접힘구조 풀림 (unfolded) ‘접힌(folded)’ 단백질이 ‘풀림(unfolded)’ 단백질이 2차구조, 3차구조, 4차구조 상실하는 과정 단백질 변성은 1차구조는 손상시키지 않는다.[ 이미지 출처: https://ko.wikipedia.org/wiki/파일:Process_of_Denaturation.svg ]1) 단백질 4차구조가 있었다. 2) 열이 가해져서 단백질 내 분자 결합이 변한다 3) 전체 펩타이드 중합체가 ‘풀렸다’.만약 온도변화, ph변화, 방사선 등으로 인해 단백질 변성이 일어날 경우:단백질 접힘구조가 풀리게 되고, 단백질은 원래 제 기능 수행 능력 잃어버린다.이는 곧, 단백질 3차원 접힘구조가 단백질 기능 결정짓는다는 사실 의미한다.하지만 변성은 단백질 1차구조에 영향 미치지 않기 때문에, 변성제 제거하면 다시 원래 접힘구조로 접힌다. 가역적이다.$\\Rightarrow$ 아미노산 서열(1차구조)이 단백질 3차원 접힘구조 지정한다.단백질 도메인정의3차구조이면서, 독립적으로 진화하고 기능하는 덩어리 안정된 부분이다. 일반적으로 단백질은 1개 이상 도메인으로 구성된다.1개 도메인은 약 50~300개 아미노산으로 구성되어 있다. 약 300개 넘으면 서로 다른 도메인(덩어리)으로 분리된다.단백질 구조 연구 기본지식 단백질 구조는 매듭 형성하지 않는다. 한쪽 끝을 잡고 당기면 전체가 직선으로 열린다. 이 직선이 3차원 구조로 ‘접혀있기’ 때문에 ‘단백질 접힘 구조’ 라고 하는 것이다. 접힘구조 밝혀진 단백질은 아직 몇 없다. 대부분 소수성 곁사슬은 내부로 묻힌다. 친수성 곁사슬은 외부로 노출된다.단백질 접힘단백질 아미노산 서열이 단백질의 고유한 접힘구조 지정한다. 따라서 아미노산 서열 이용해 단백질 3차원 접힘구조 알아낼 수 있다.$\\Rightarrow$ 단백질 아미노산 서열에 어떤 아미노산이 어떻게 배열되었느냐에 따라, 단백질 접힘 구조가 바뀐다.단백질 접힘 문제정의아미노산 서열만 이용해 단백질 3차원 접힘 구조 예측하는 문제.문제점이게 매우 어렵다. 온전히 아미노산 서열만 이용해서 단백질 3차원 구조 에측하기란 하늘에 별따기. 아직 크기 크고 구조가 복잡한 단백질에 대해서는 시도할 엄두도 못 내고 있다.2021년 7월 등장한 구글 알파폴드는 바로 이 부분, ‘아미노산 서열만 가지고 단백질 3차원 접힘 구조 예측하기’를 매우 우수한 성능으로 해내서 주목받은 거다.DNA 염기서열에서 단백질 3차원 구조까지DNA 염기서열은 단백질 기능 및 구조를 결정짓는다[ 출처: https://ko.wikipedia.org/wiki/염기서열 ]DNA 염기서열에 따라 아미노산 서열 결정(지정) $\\Rightarrow$아미노산 서열에 따라 단백질 3차원 접힘 구조 형성 $\\Rightarrow$단백질 3차원 접힘 구조에 따라 단백질 기능 달라짐.$\\Rightarrow$ 결론: DNA 염기서열은 1. 아미노산 서열 결정, 2. 단백질 3차원 구조 및 단백질 기능 형성단백질의 구조적 변화단백질이 처한 환경이 변하면, 가장 안정한 단백질 접힘 구조도 변할 수 있다.예컨대 변성(접힘구조 풀림)도 단백질 구조적 변화의 한 종류다.다른 분자(효소기질과 같은 저분자 또는 단백질과 같은 고분자)와 상호작용 발생하는; 변성보다 더 약한 환경변화도 단백질 구조적 변화 가져올 수 있다.예컨대 리간드 결합을 단백질 구조적 변화 가져오는, 약한 환경변화로 들 수 있다.리간드정의표적단백질의 특정부위에 결합하는 분자. 표적단백질에 리간드가 결합하면; 표적단백질 3차원 접힘구조가 변화한다. 즉, 단백질 기능이 바뀐다. 표적단백질은 주로 효소나 수용체다.*수용체(recepter): 신호전달을 목적으로 하며 세포막. 세포질. 세포핵에 들어가는 단백질이다.리간드가 표적단백질에 결합하면 단백질 접힘구조를 변화시킨다. 이를 통해 단백질 기능 활성화 시킬 수 있다; 리간드가 activator 로서 작용 단백질 기능 약화 또는 비활성화 시킬 수 있다; 리간드가 inactivator 로서 작용*리간드 결합은 단백질 접힘 구조만 변경시킬 뿐, 1차구조 아미노산 서열은 변화시키지 않는다.효소정의생체 촉매 자신은 변화하지 않으면서, 화학반응 속도를 더 빠르게 해주는, 생물체 내 촉매를 특별히 ‘효소’ 라고 한다.생체 촉매 역할을 하는 것들, 즉 효소는 대부분 단백질이다.RNA 중에서도 생체 촉매 역할 하는 것들(효소)이 있는데, RNA 이면서 효소인 이것들을 ‘리보자임’ 이라고 한다.PDBProtein Data Bank단백질 이루는 원자들 3차원 좌표 데이터 X 선이나 마이크로웨이브파와 같은 빛, 분광장비 사용해 얻는다." }, { "title": "[딥러닝 연구주제 탐색] Image segmentation", "url": "/bioinfo.github.io/posts/image_segmentation/", "categories": "Research Topic, Machine Learning, Deep Learning", "tags": "Research Topic, Machine Learning, Deep Learning", "date": "2022-04-26 00:00:00 +0900", "snippet": "*아래는 관심있는 딥러닝-컴퓨터비전 분야인 Image segmentation 에 대해 알아보고, 내용을 간략히 기록한 글이다. 완성된 문서가 아니며, 계속 add-up 해 나가기 위해 작성했다.Image segmentation정의이미지 구성하는 단일 픽셀 하나하나를 특정 클래스로 분류하는 작업.종류1. Semantic segmentation단일 픽셀 하나하나를 특정 클래스로 분류한다. 대신, 동일한 객체 끼리는 구분 못한다. (이미지에 서로 다른 고양이 2마리 있으면 둘 다 똑같은 고양이로 분류한다.)2. Instance segmentationSemantic segmentation 처럼 단일 픽셀 하나하나를 특정 클래스로 분류하되, 이미지에 나타난 모든 객체를 구분해서 분류한다. (고양이 1, 고양이 2, 고양이 3)Image segmentation 적용 가능 분야 Handwriting Recognition: 손글씨 인식 할 수 있다. Portrait mode photo: 인물모드 촬영 YouTube stories: 유튜브 스토리 촬영 중 배경 마음대로 바꿀 수 있음 Virtual make-up Virtual try-on: 이미지에 가상으로 옷 착용 해볼 수 있다. Visual Image Search: 사용자가 업로드한 이미지에서 특정 객체만 뽑아내서, 비슷한 객체 가진 이미지들 웹에서 찾아준다. Self-driving cars: 자율주행 기술은 주변 사물에 대해 단일 픽셀 레벨에서 완벽한 이해 필요하다. Image segmentation 이 이미지(프레임)에서 각 객체 완벽하게 구분.분할 해 내기 위해 사용된다.https://nanonets.com/blog/semantic-image-segmentation-2020/예전에는 SVM, Random Forest, K-means Clustering 등이 image segmentation 하기 위해 사용됬다.하지만 이제 딥러닝이 그 자리 완전히 대체했다.Fully Convolutional Network정의완전연결 분류기 없이 전체가 합성곱 층으로 구성된 네트워크. 1*1 합성곱 층 역할 = 완전연결 분류기 역할 로 봤다.네트워크가 input down sampling과 up sampling 부분으로 이루어져 있다.Down sampling 파트를 인코더,Up sampling 파트를 디코더 라고 한다.인코더는 input 받아서 size 줄이고,디코더는 인코더 output 받아서 size 늘린다.참고: https://nanonets.com/blog/semantic-image-segmentation-2020/Up sampling정의저해상도 출력 결과에 픽셀 추가해서 고해상도 출력으로 변환하는 과정. 모델에서 Up sampling 파트를 디코더 라고도 부른다. (*Down sampling 파트는 인코더 라고 부른다.)방법 Bilinear interpolation: 2차원 이미지에 픽셀 (추정해서) 삽입 Backwards Convolution: 원래 down sampling 하는 convolution 과정을 역으로 수행하는 방법. FCN 에서는 두 가지 함께 사용한다.FCN이 Image segmentation 수행하는 과정 FCN은 사전학습된 이미지 분류 모델(예:VGG16)에서 완전연결 분류기를 떼고, 1*1 합성곱 층을 넣어서 사용한다. 이는 벡터 꼴 dense 층 출력이 픽셀 위치 정보를 잃어버리기 때문이다. 1*1 합성곱 층 출력 결과는 rough 한 heatmap 이다. 픽셀 별 위치 정보는 담고 있지만, segmentation 하기엔 이미지가 coarse 하다. 따라서 이 출력결과에 픽셀 추가할 필요 있다(해상도 높여야 한다). FCN은 픽셀 추정해서 삽입하는 Bilinear Interpolation 과 backwards convolution 을 함께 사용한다. 이 과정을 up sampling 이라 하고, 디코더 라고도 부른다. 디코딩 결과도 segmentation에는 부적합하다. 여전히 segmentation 결과가 rough 하기 때문이다. 이를 보완하기 위해 Skip architecture 를 사용한다. Skip architecture는 곡선, 직선, 엣지 등 local 정보를 담고 있는 신경망 얕은 층 정보와, 추상화. 의미단위 정보 담고 있는 깊은 층 정보를 결합해서 출력하는 신경망 구조를 말한다. Local 정보와 global 정보 결합해서 출력하는 Skip architecture는 보다 정교한 segmentation 결과 출력한다.참고: https://medium.com/@msmapark2/fcn-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-fully-convolutional-networks-for-semantic-segmentation-81f016d76204Semantic Image Segmentation with DeepLab in TensorFlowCutting-edge semantic image segmentation model: DeepLab-v3+(2018 기준) 텐서플로 기반 모델이다. CNN backbone 모델 위에 DeepLab-v3+ 얹은 형태다. 구글은 PascalVOC 2012 &amp; Cityscapes 데이터에 대해 사전훈련된 모델 제공한다. 방법론, 하드웨어, 데이터셋 발전으로 최근 semantic image segmentation system 들 성능 비약적 향상 되었다.‘딥 라벨링’은 신경망 사용해 각 픽셀마다 분류 예측값을 할당하는 방식으로 동작한다.https://ai.googleblog.com/2018/03/semantic-image-segmentation-with.html" }, { "title": "[논문 읽기] Distilling the Knowledge in a Neural Network", "url": "/bioinfo.github.io/posts/knowledge_distillation/", "categories": "ML, Deep learning", "tags": "ML, Deep learning", "date": "2022-04-25 00:00:00 +0900", "snippet": "Distilling the Knowledge in a Neural NetworkAuthors: Geoffrey Hinton, Oriol Vinyals, Jeff Deanhttps://arxiv.org/abs/1503.02531Knowledge Distillation 지식 증류정의: Teacher 모델에서 정보를 ‘증류’해서, Student 모델에 ‘전수’ 시키는 작업덩치 큰 딥러닝 네트워크(히든 층 갯수가 많다거나, 히든유닛 수가 많다거나…)는 분류 정확도는 높을 수 있지만, 알고리듬이 ‘무거워서’ 일반 사용자 대상으로 배포하기에는 적합하지 않다.99% 정확도 자랑하지만 분류 수행에 3시간 걸리는 모델 vs 90% 정확도지만 분류하는 데 3분이면 되는 모델$\\Rightarrow$ 오른쪽이 일반 사용자에겐 더 적합할 수 있다. 기업 관점에서 생각해도, 왼쪽 모델은 KPI 충족하지 못할 수 있다.$\\Rightarrow$ 배포에 적합하도록 알고리듬 경량화 하되, 성능은 최대한 원래 무거운 모델처럼 확보하기 위한 방법으로 Knowledge Distillation 이 등장했다.논문에 따르면, 실제로큰 모델 훈련 후 지식 증류 해서 작은 모델 훈련시키기 $&gt;$ 큰 모델 훈련시킨 데이터로 작은 모델 훈련시키기왼쪽이 더 효과적인 모델 훈련법이다.Knowledge Distillation 수행Soft target: Teacher 모델 소프트맥스 함수에 온도 항($T$) 추가해서 식 변형 후, $T$ 값 증가시키면서 얻어낸, $T=1$ 일 때 보다 엔트로피 커진 결과값 분포$Adjusted$ $softmax$: $q_{i} = \\frac{\\exp{(z_{i}/T)}}{\\sum_{j}\\exp{(z_{j}/T)}}$ T를 온도(Temperature) 라고 한다. T 증가할 수록 소프트맥스 출력 분포 엔트로피는 커진다. T 기본값은 $1$ 이다.거대 모델 증류한 온도 T 값을 small model 훈련할 때도 똑같이 소프트맥스 함수에 적용한다.small model은 위 상태에서, soft target을 잘 맞추도록 훈련된다.$\\Rightarrow$ 지식 증류 과정 정리 거대 모델을 Original dataset 으로 훈련시킬 때, 소프트맥스 층에 온도 항 $T$ 추가한다. 온도 계속 높여서 출력 분포를 보다 soft 하게 만든다. 이렇게 얻어낸 soft target을 small model 훈련 타겟으로 설정한다. small model 을 transfer set이나 original dataset으로 훈련시킨다. 매 훈련 case 마다, soft target을 target으로 설정하고, small 모델 softmax 층 출력과 비교한다. 이때, small 모델 에도 거대 모델과 같은 T 값 적용한다. small 모델 소프트맥스 출력과 soft target 사이 크로스 엔트로피, 그러니까 훈련과정 전체의 로그손실을 목적함수로 삼아 모델 최적화 하고, 훈련 다 끝나면 T값은 1로 되돌린다.Small 모델 성능 더 향상시키는 방법$\\Rightarrow$ 만약 transfer set 정답 값 알 경우, 목적함수 바꿔서 small 모델 성능 더 향상시킬 수 있다. small 모델 소프트맥스 출력 결과와 soft target 사이 로그 손실 small 모델 소프트맥스 출력 결과와(온도 항 적용 안함) transfer set 정답 값 사이 로그 손실위 두 로그 손실 가중평균으로 새 목적함수 찾고, 최적화 한다.논문에 따르면, 최적 결과는 두번째 로그 손실에 첫번째 보다 훨씬 낮은 가중치 줬을 때 얻을 수 있었다.MNIST 숫자 이미지 데이터로 예비 실험 수행 결과지식 증류 &amp; 전수 전거대 모델 2개 은닉 층, 총 1,200개 히든 유닛.으로 구성했다. 총 60,000개 데이터로 구성된 훈련 셋으로 훈련시켰다. 드롭아웃 층 추가하는 등, 과대적합 방지하기 위해 강력히 규제했다. 이미지 증식 사용, 훈련 데이터 부풀림으로써 모델 학습이 충분히 이루어질 수 있도록 했다.$\\Rightarrow$ 거대 모델은 테스트 셋에서 전체 중 67개 분류 오류만 기록했다.small model 2개 은닉 층, 총 800개 히든유닛, 규제 없음.$\\Rightarrow$ 지식 증류해서 전수하기 전, 테스트셋에서 총 146개 틀렸다.지식 증류 &amp; 전수 후 거대 모델 증류해서 얻어낸 soft target 으로 small model 훈련시켰을 때: 테스트셋에서 74개만 틀렸다. 오답 갯수 절반수준으로 감소했다! small model 각 층 히든 유닛 수를 300개 정도로 줄였을 때, 온도가 8 이상이기만 하면 히든유닛 총 800개 일 때랑 꽤 비슷한 결과 나왔다. 만약 히든유닛 수를 극단적으로 줄일 경우(1층 당 30개 히든유닛), T 값을 $2.5~4$ 범위로 유지하는 게 $2.5$ 미만 또는 $4$ 초과보다 더 나은 분류결과 가져왔다.한편$\\Rightarrow$ 지식 증류 &amp; 전수 과정은 그대로 유지하면서, small model 훈련시키는 transfer set 에서 3을 아예 빼고 훈련시켜봤다.따라서 모델은 한번도 3을 본적 없다.그럼에도 모델은 3이 1010개 포함된 test set에서 단지 206개만 틀렸다! 이 중 133개만 3을 틀린 것이다.$\\Rightarrow$ 거대 모델이 갖고 있는 지식이 small model 로 성공적 전수 되었다고 볼 수 있다.심지어 transfer set에 오직 7과 8만 넣어서 small model 훈련했을 때도 오답률은 $47.3%$ 로, 절반을 넘기지 않았다!" }, { "title": "[Keras/딥러닝 공부] 합성곱 신경망(CNN) 이론", "url": "/bioinfo.github.io/posts/cnn/", "categories": "Data Science, python, Keras, deep learning", "tags": "ML, Deep learning, python, Keras, data science", "date": "2022-02-28 00:00:00 +0900", "snippet": "아래 내용은 ‘케라스 창시자에게 배우는 딥러닝 (프랑소와 슐레 저, 박해선 옮김, 길벗 출판사)’ 을 공부한 뒤, 배운 내용을 제 언어로 정리.기록한 것 입니다.합성곱 신경망기본합성곱 층과 풀링 층 교차해서 쌓는 게 합성곱 신경망 기본 구조다.[이미지 출처: http://taewan.kim/post/cnn/]완전 연결 층(Dense) 과 차이완전 연결 층은 입력 이미지 전역패턴 학습하지만, 합성곱 층은 입력 이미지 지역 패턴 학습한다.특징 평행이동 불변성: 평행이동 된 지역 패턴은 같은 패턴으로 인식한다. 이는 합성곱 신경망이 효율적으로 지역 패턴 학습하게 한다. 또, 인간 두뇌가 객체 인식하는 방법과 같다. 객체를 계층적 인식: 컨브넷은 객체를 계층적으로 인식한다. 각 위치 에지, 질감에서 시작해서 귀, 코, 눈 등 더 상위 개념을 순차.계층적으로 인식해간다. 두뇌가 객체 인식하는 방법과 같다.합성곱 연산합성곱 층은 입력 이미지 받아 합성곱 연산 수행하고, 결과 출력한다.합성곱 연산은 입력 이미지 모든 위치에서 지역 패턴들 추출한다. 지역패턴에는 에지(Edge), 질감(Texture) 등 포함된다.합성곱 연산 과정 입력 이미지 위를 3 $\\times$ 3 또는 5 $\\times$ 5 크기 윈도우가 슬라이딩(Sliding) 하며 3 $\\times$ 3 또는 5 $\\times$ 5 크기 패치(Patch:작은 조각) 추출한다. (윈도우 사이즈 크기 패치 추출한다) 각 패치와. 에지, 질감 등 지역 특징 담고있는 필터(또는 커널)를 요소별 텐서 곱 연산 한다. 텐서 곱 연산 결과 모두 합한다. 곧, 2 과정은 패치 각 요소를 가중합 한 것과 같다. 3 결과를 특성 맵(Feature Map) 또는 응답 맵(Responsse Map) 이라고 한다. 입력 이미지 각 위치에 그 필터 패턴이 나타나 있었는지 확인.응답한 결과다. 입력 이미지 각 채널(예: RGB 3개) 별로 각각 다른 필터 적용된다. 1개 합성곱 층에서 입력 이미지에 대해 여러 개 필터 적용한다(예: 32개, 64개, 128개…). 보통 1개 합성곱 층 필터 개수는 하위 층에서 상위 층 갈 수록 2 제곱 수로 점차 증가시켜 간다. 일반 경우, 합성곱 하위 층에서 상위 층(더 깊은 층) 갈 수록, 각 층의 출력 특성 맵 크기는 줄어든다.위 과정 그림으로 그리면 아래와 같다.입력 이미지와 필터입력 이미지 위를 윈도우가 슬라이딩 하면서 패치 추출, 패치와 필터 합성곱 3개 채널 합성곱 결과 행렬을 요소별로 합 한게 필터 1개에 대한 최종 출력 특성 맵 이다. 이게 필터 수 만큼의 차원을 이룬다.패딩(Padding)Zero Padding입력 특성 맵과 출력 특성 맵 크기를 같게 하고 싶으면 입력 특성 맵에 패딩(Padding) 추가하면 된다.입력 특성 맵 가장자리에 적절한 개수 행과 열 추가하는 걸 패딩이라 한다.패딩 자리에 보통 0 넣기 때문에, 제로 패딩 이라고도 한다.빈 부분이 패딩 자리다.위 행렬에 대해 합성곱 하면 출력 특성 맵 크기가 입력 특성 맵과 같아진다 $(5*5)$케라스에서 패딩 사용하기 Conv2D 층에서 padding 파라미터 설정하면 된다. ‘valid’ 는 패딩 사용 안함, ‘same’은 패딩 사용함 이다. 기본 파라미터는 valid (패딩 사용 안함) 이다.스트라이드(Stride)보폭.정의연속한 두 윈도우 사이 거리를 스트라이드 라고 한다. 스트라이드 값 기본은 $1$ 이다.예) 스트라이드 = 2 인 경우출력 특성 맵 크기 $(4 \\times 4)$ 가 입력 특성 맵 크기 $(5 \\times 5)$ 보다 작아졌다(다운샘플링).최대 풀링 연산합성 곱 층 출력 특성맵 받아 다운샘플링 하는 연산이다.$2*2$ 윈도우와 스트라이드 $2$ 사용해서, 패치 별로 최댓값만 추출한다. 평균 풀링 연산 사용할 수도 있다. 패치 영역 내 평균을 추출한다.최대 풀링 연산 목적 입력을 다운샘플링 해서, 특성 맵 가중치 개수를 줄인다. 모델이 공간적 계층 구조 학습하는 걸 돕는다.최대 풀링 연산 예시간단한 컨브넷 만들기MNIST 이미지 분류하는 간단한 컨브넷 만들기from keras import layers from keras import models # 간단한 컨브넷 작성 # 이미지 특징 추출 층(합성곱 기반 층)model = models.Sequential() model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1))) # 필터 수, 패치 사이즈(3X3), 요소별 적용할 활성화 함수, 입력 특성 맵 사이즈 model.add(layers.MaxPooling2D((2,2))) model.add(layers.Conv2D(64, (3,3), activation='relu')) # activation='relu': 음수, 0은 모두 0으로 만들고. 양수 값만 남긴다. model.add(layers.MaxPooling2D((2,2)))model.add(layers.Conv2D(64, (3,3), activation='relu'))model.add(layers.Flatten()) # 특성공학 결과물 1차원 텐서(벡터)로 변환하는 층 # 완전 연결 분류기 model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(10, activation='softmax')) # 출력층: 최상위층, 분류 결과물 확률 꼴로 변환.# 모델 설계 결과 요약 model.summary() 합성곱 층과 최대 풀링 층 교차해서 쌓은. 전형적인 컨브넷 구조다. 합성곱 층 파라미터 별 의미: 입력 특성 맵에 적용할 필터 수(32), 윈도우 크기(3 $\\times$ 3), 활성화 함수(렐루함수), 입력 특성 맵 크기. 최대 풀링 층 파라미터 의미: 윈도우 크기(2 $\\times$ 2) Flatten() 층: 특성공학 결과를 1차원 텐서(벡터)로 변환하는 층. Dense 층에 넣기 위함이다.MNIST 숫자 이미지 합성곱 신경망으로 분류# MNIST 숫자 이미지 합성곱 신경망으로 분류 from keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() train_images = train_images.reshape((60000, 28, 28, 1)) # 6만개 배치, 높이 28, 너비 28, 채널 1 사이즈로 크기 조정 train_images = train_images.astype('float32') / 255test_images = test_images.reshape((10000, 28, 28, 1)) # 1만개 배치, 높이 28, 너비 28, 채널 1 사이즈로 크기 조정 test_images = test_images.astype('float32') / 255 # 전부 부동소수점 실수로 변환 + 1/255 로 스케일 조정 train_labels = to_categorical(train_labels) # train_label 들을 모두 원핫 인코딩 벡터로 변환 # 분류 결과와 크로스엔트로피 비교하기 위함 test_labels = to_categorical(test_labels) # 모델 컴파일 model.compile( optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])# 모델 학습 model.fit( train_images, train_labels, epochs = 5, batch_size=64, validation_data = (test_images, test_labels))test_loss, test_acc = model.evaluate(test_images, test_labels) ; print(test_acc)# 98% 정도 정확도 기록함. 간단한 컨브넷 밑바닥 부터 훈련시키기개 vs 고양이 분류 컨브넷 정의# 네트워크 구성 from keras import layers from keras import models model = models.Sequential() model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3))) # 입력 특성 맵에 적용 할 필터 수: 32, 윈도우 사이즈, 활성화함수, 입력 데이터 규격: 150*150, RGB 3 채널 model.add(layers.MaxPooling2D((2,2))) # 최대 풀링 연산 적용할 윈도우 사이즈 - 다운샘플링(크기 축소)model.add(layers.Conv2D(64, (3,3), activation='relu')) # 입력 특성 맵에 적용할 필터 수:64, 윈도우 사이즈, 활성화 함수 model.add(layers.MaxPooling2D((2,2))) # 윈도우 사이즈 model.add(layers.Conv2D(128, (3,3), activation='relu')) # 필터 수: 128개, 윈도우 사이즈 model.add(layers.MaxPooling2D((2,2))) # 윈도우 사이즈 model.add(layers.Conv2D(128, (3,3), activation='relu')) # 필터 수: 128개, 윈도우 사이즈 model.add(layers.MaxPooling2D(2,2)) # 윈도우 사이즈 # 여기까지 합성곱 기반 층(지역 패턴 추출 층)# 여기서부터 완전 연결 층(전역 패턴 추출, 분류기)model.add(layers.Flatten()) # 1차원 텐서(벡터)로 변환model.add(layers.Dense(512, activation='relu')) # 512차원 벡터공간에 투영 model.add(layers.Dense(1, activation='sigmoid'))model.summary()# 1. 150*150 입력 이미지에서 3*3 윈도우 슬라이딩하면서 3*3 패치 추출 -&gt; 32개 필터에 대해 합성곱 -&gt; 148*148*32 # 2. 2*2 윈도우 1의 출력 특성 맵에 적용해서 패치 구역 별 최댓값만 추출 -&gt; 출력 특성 맵 크기 절반으로 줄어든다 -&gt; 74*74*32 # 3. 2의 출력 특성 맵에서 다시 3*3 패치 추출 -&gt; 64개 필터에 대해 합성곱 -&gt; 72*72*64 # 4. 2 처럼 최대 풀링 연산 3 출력에 적용 -&gt; 출력 특성 맵 크기 절반으로 줄어든다 -&gt; 36*36*64 # 5. 3*3 패치, 128개 필터에 대해 합성곱 -&gt; 34*34*128 # 6. 최대 풀링 연산 적용 -&gt; 17*17*128 # 7. 3*3 패치, 128개 필터에 대해 합성곱 -&gt; 15*15*128 # 8. 최대 풀링 연산 적용 -&gt; 7*7*128 # 9. 완전 연결 분류기 주입 위해 1차원 텐서(벡터)로 변환하는 층 # 10. 512차원 벡터공간에 투영 # 11. 1차원 벡터공간으로 차원축소 후 시그모이드 함수 적용 모델 컴파일# 모델 컴파일 from keras import optimizers model.compile( loss = 'binary_crossentropy', optimizer = optimizers.adam_v2.Adam(learning_rate=0.001), metrics=['acc'])데이터 전처리# 데이터 전처리 from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator(rescale=1./255) # 스케일 1/255 로 조정 , 부동소수점 형태로 변환 test_datagen = ImageDataGenerator(rescale=1./255) # 스케일 조정 train_generator = train_datagen.flow_from_directory( '/Users/kibeomkim/Desktop/cats_and_dogs_small/train', target_size=(150, 150), # 네트워크 입력 규격에 맞게 크기 변환 batch_size=20, # 1에폭 동안 투입 할 데이터 묶음 class_mode = 'binary' # 데이터가 이진 레이블임. )valid_generator = test_datagen.flow_from_directory( '/Users/kibeomkim/Desktop/cats_and_dogs_small/test', target_size=(150,150), batch_size=20, class_mode='binary')# 모델 훈련 history = model.fit_generator( train_generator, steps_per_epoch= 100, # 20*100 = 총 훈련 데이터 갯수 epochs = 30 , validation_data = valid_generator, validation_steps = 50 )훈련 및 검증 정확도, 훈련 및 검증 손실 시각화acc = history.history['acc']val_acc = history.history['val_acc']loss = history.history['loss']val_loss = history.history['val_loss']epochs = range(1, len(acc) + 1)plt.figure(figsize=(10,5))plt.subplot(1,2,1)plt.plot(epochs, acc, 'bo', label='Training Accuracy')plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')plt.title('Training and Validation Accuracy')plt.legend() plt.subplot(1,2,2)plt.plot(epochs, loss, 'bo', label='Tranining Loss')plt.plot(epochs, val_loss, 'r', label='Validation Loss')plt.title('Training and Validation Loss')plt.legend()plt.suptitle('Accuracy &amp; Loss')plt.tight_layout()plt.show() 과대적합 억제하는 가장 좋은 방법 = 훈련 데이터 수 늘리는 거다.데이터 증식 사용해 과대적합 억제해보자.# 데이터 증식 datagen = ImageDataGenerator( rotation_range=30, # 회전을 몇 도 시킬 건가 width_shift_range=0.1, # 수평으로 평행이동 정도 height_shift_range=0.1, # 수직으로 평행이동 정도 shear_range=0.2, # y축 방향으로 각도 증가 zoom_range=0.5, # 확대/축소 범위 horizontal_flip=True, # 좌우 대칭시킨다 fill_mode='nearest' )# 데이터 증식 결과 시각화해서 살펴보기 from keras.preprocessing import image fnames = sorted([os.path.join('/Users/kibeomkim/Desktop/cats_and_dogs_small/train/cats', fname) for fname in os.listdir('/Users/kibeomkim/Desktop/cats_and_dogs_small/train/cats')])img_path = fnames[7]img = image.load_img(img_path, target_size = (150,150)) # 이미지 읽어오기, 크기 150*150으로 변환 x = image.img_to_array(img) # (150,150,3) 크기 넘파이 배열(텐서)로 변환 x = x.reshape((1,)+x.shape) # (1,150,150,3) 으로 변환 (배치 차원 추가)plt.figure(figsize=(5,5))i = 1for batch in datagen.flow(x, batch_size=1) : plt.subplot(2,2,i) # i번째 이미지 imgplot = plt.imshow(image.array_to_img(batch[0])) plt.xticks([]) plt.yticks([]) i += 1 if i == 5 : break plt.tight_layout()plt.show()데이터 증식 적용하더라도, 애초에 훈련 데이터 수가 적기 때문에 과대적합 억제하는 데 충분치 않을 수 있다.모델에 드롭아웃 추가해서 과대적합을 좀 더 억제해 보자.# 드롭아웃 포함한 새로운 컨브넷 정의 from keras import models from keras import layers from keras import optimizersmodel = models.Sequential() # 합성곱 기반 층model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))model.add(layers.MaxPooling2D((2,2))) model.add(layers.Conv2D(64, (3,3), activation='relu'))model.add(layers.MaxPooling2D((2,2)))model.add(layers.Conv2D(128, (3,3), activation='relu'))model.add(layers.MaxPooling2D((2,2)))model.add(layers.Conv2D(128, (3,3), activation='relu'))model.add(layers.MaxPooling2D((2,2)))model.add(layers.Flatten())model.add(layers.Dropout(0.5))# 완전 연결 분류기 model.add(layers.Dense(512, activation='relu'))model.add(layers.Dense(1, activation='sigmoid'))# 모델 컴파일 model.compile( loss = 'binary_crossentropy', metrics = ['acc'], optimizer = optimizers.adam_v2.Adam(lr = 0.001))# 데이터 증식 &amp; 전처리 train_datagen = ImageDataGenerator( rescale = 1./255, rotation_range = 40, width_shift_range= 0.1, height_shift_range=0.1, shear_range = 0.4, zoom_range= 0.5, horizontal_flip=True )test_datagen = ImageDataGenerator( rescale=1./255)train_generator = train_datagen.flow_from_directory( '/Users/kibeomkim/Desktop/cats_and_dogs_small/train', target_size=(150,150), batch_size= 20, class_mode='binary')valid_generator = test_datagen.flow_from_directory( '/Users/kibeomkim/Desktop/cats_and_dogs_small/test', target_size = (150,150), batch_size=20, class_mode = 'binary')# 모델 훈련 history = model.fit_generator( train_generator, steps_per_epoch=100, epochs = 100, validation_data = valid_generator, validation_steps = 50 )model.save('/Users/kibeomkim/Desktop/models_saved/dog_and_cant.h5')정확도 및 손실acc = history.history['acc']val_acc = history.history['val_acc']loss = history.history['loss']val_loss = history.history['val_loss']epochs = range(1, len(acc) + 1)plt.figure(figsize=(10,5))plt.subplot(1,2,1)plt.plot(epochs, acc, 'bo', label='Training Accuracy')plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')plt.title('Training and Validation Accuracy')plt.legend() plt.subplot(1,2,2)plt.plot(epochs, loss, 'bo', label='Tranining Loss')plt.plot(epochs, val_loss, 'r', label='Validation Loss')plt.title('Training and Validation Loss')plt.legend()plt.suptitle('Accuracy &amp; Loss')plt.tight_layout()plt.show() 컨브넷 학습 시각화활성화 시각화합성곱 층 출력에 요소 별로 활성화 함수 적용한 결과를 ‘활성화’ 라고 한다.이 활성화를 시각화 해서, 각 층의 의미 직접 눈으로 확인할 수 있다.from keras.models import load_model # 저장한 작은 컨브넷 로드 model2 = load_model('/Users/kibeomkim/Desktop/models_saved/dog_and_cant.h5')model2.summary()‘활성화’ 시각화# 합성곱 층, 풀링 층 출력 시각화 # '활성화' 시각화 img_path = '/Users/kibeomkim/Desktop/cc.png'from keras.preprocessing import image img = image.load_img(img_path, target_size=(150,150))img_tensor = image.img_to_array(img) # 텐서로 변환 img_tensor = np.expand_dims(img_tensor, axis=0) # 배치 축 추가 img_tensor /= 255. # 1/255로 스케일 조정 print(img_tensor.shape)(1, 150, 150, 3)# 원본 이미지 출력 plt.figure(figsize=(2,2))plt.imshow(img_tensor[0])plt.xticks([])plt.yticks([])plt.show()[고양이 이미지 출처: https://www.rd.com/list/black-cat-breeds/]# 상위 8개 레이어 출력만 추출 from keras import models layer_outputs = [layer.output for layer in model2.layers[:8]] # 상위 8개 레이어 출력 추출 # 특정 입력에 대한 출력 매핑하는 모형 activation_model = models.Model(inputs=model2.input, outputs=layer_outputs)# 하나 입력에 대해: 8개 출력 대응된다 (층 8개 출력 결과)# 예측모드로 모델 실행하기 activations = activation_model.predict(img_tensor) # img_tensor 1개 입력에 대해: 8개 층 각각에 통과시켜서 그 출력 반환 첫번째 합성곱 층 12번째 필터의 활성화 맵 시각화# 첫번째 합성곱 층 활성화 맵 시각화 first_layer_activation_result = activations[0]print(first_layer_activation_result.shape) # 합성곱 결과: 높이 148, 너비 148, 배치 1, 필터 적용한 응답 맵 32개 # 응답 맵 32개 중 12번째 응답 맵 시각화 plt.figure(figsize=(2,2))plt.matshow(first_layer_activation_result[0, :,:,21], cmap='viridis')plt.xticks([])plt.yticks([])plt.show()이 필터는 전체 에지를 감지하는 것 같다.first_layer_activation_result = activations[0]print(first_layer_activation_result.shape) # 합성곱 결과: 높이 148, 너비 148, 배치 1, 필터 적용한 응답 맵 32개 # 응답 맵 32개 중 2번째 활성화 맵 plt.figure(figsize=(2,2))plt.matshow(first_layer_activation_result[0, :,:,2], cmap='viridis')plt.xticks([])plt.yticks([])plt.show()첫번째 층 두번째 필터는 도드라진 엣지 감지하는 것 같다.(고양이 귀 끝 부분)네트워크 모든 활성화 시각화# 네트워크 모든 활성화 시각화 layer_names = []for layer in model2.layers[:8] : # 상위 8개 층 이름들 추출 (그림 이름으로 사용) layer_names.append(layer.name)print(layer_names)[‘conv2d_13’, ‘max_pooling2d_11’, ‘conv2d_14’, ‘max_pooling2d_12’, ‘conv2d_15’, ‘max_pooling2d_13’, ‘conv2d_16’, ‘max_pooling2d_14’]images_per_row = 16for layer_name, layer_activation in zip(layer_names, activations) : # 층 - 활성화 매핑 n_features = layer_activation.shape[-1] # 활성화 마다 채널 수 size = layer_activation.shape[1] # 높이와 너비 어차피 같다. n_cols = n_features // images_per_row display_grid = np.zeros((size*n_cols, images_per_row*size)) for col in range(n_cols) : for row in range(images_per_row) : channel_image = layer_activation[0, :, :, col*images_per_row+row] # 채널 이미지 스케일 조정 # 정규화 channel_image -= channel_image.mean() channel_image /= channel_image.std() channel_image*=64 channel_image += 128 channel_image = np.clip(channel_image, 0, 255).astype('uint8') display_grid[col*size : (col+1)*size, row*size:(row+1)*size] = channel_image scale = 1./size plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0])) plt.title(layer_name) plt.grid(False) plt.imshow(display_grid, aspect='auto', cmap='viridis') #plt.xticks([]) #plt.yticks([])plt.show()상위 층으로 갈 수록 활성화 맵 의미 시각적 파악 어려워진다.상위 층 갈 수록, 모델이 학습한 몇 가지 ‘고양이라면 갖고 있을 만한 주요 특징들’만 남게 된다.곧, 상위 층 각 필터는 ‘고양이의 특징’들이다.모델은 입력 이미지 위를 슬라이딩 하면서 자신이 학습한 ‘고양이 특징’들이 입력 이미지에 나타나 있는지 확인한다.위 마지막 이미지가 듬성듬성 빈 건, 입력 이미지가 모델이 학습한 고양이 특징들 중 일부를 안 갖고 있었다는 말이다. 곧, 필터에 응답 발생하지 않았다.결과로 나온 활성화 맵 하나하나가 추상화 된 고차원적 의미 담게 된다. 예컨대 고양이 귀, 입, 눈 등이다.CNN이 객체를 인식하는 방법은 인간 두뇌가 현실세계의 객체 인식하는 방법과 매우 유사하다.[오른쪽 고양이 사진 출처: https://petdoc.co.kr/ency/280] 기억에 의존해 그린 고양이 얼굴 / 실제 고양이 사진우리 인간은 객체를 주요 특징 몇 가지를 가지고 인식한다. 기억에 의존해 고양이 얼굴을 그릴 때 나는 머릿속으로 생각했다. 고양이는 뾰족한 귀가 있다. 고양이는 입, 코, 그리고 눈이 있다. 얼룩 고양이 였다. 고양이는 인중에 콧수염이 있다.고양이에 대한 추상화 된 몇 가지 특징들만 가지고 ‘이것은 고양이다’라고 인식했다.세부 디테일은 기억하지 않는다. 온전하게 기억할 수도 없다.세부 디테일은 가지치기 하고 주요 특징 만을 기억하고. 객체 인식한다.CNN 모델도 그러하다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 최소신장트리, Prim 알고리듬, Diijkstra 알고리듬(최단 경로 찾기) ", "url": "/bioinfo.github.io/posts/prim_algorithm/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, python, study, data science", "date": "2022-02-19 00:00:00 +0900", "snippet": "최소신장트리(Minimum Spanning Tree)정의간선 가중치 합 최소인 신장트리. 가중치 합 최소인. 싸이클 없이. 모든 정점이 최소 간선 수로 연결된. 그래프 최소 간선 수: 정점 수($N$) $-1$그래프에서 최소신장트리 찾는 알고리듬 Prim 알고리듬 Kruskal 알고리듬 Sollin 알고리듬모두 최적화 알고리듬인 그리디(Greedy) 알고리듬에 속한다.그리디 알고리듬은 매번 ‘욕심내서’ 지역 최저점을 찾고, 이를 반복하면서 전역 최저점에 수렴하는 최적화 방식이다.Prim 알고리듬무향 그래프에서 최소신장트리 찾는 알고리듬이다.연결성분과 정점 사이 간선 가중치 최소인 정점 찾아 연결성분과 연결한다.예시 싸이클이 있는 무향 그래프다.시작점 A로 임의 설정한다.A 에 인접한 정점 중 간선 가중치 최소인 정점과 A를 연결한다.A 인접 정점 B, C 중에 B가 간선 가중치 3으로 더 작다. 따라서 A와 B를 연결한다.A와 B 연결성분에 인접한 정점들 중 간선 가중치 최소인 정점과 연결성분 연결한다.B 인접 정점 C가 간선 가중치 1로 가장 작다. 따라서 A-B 연결성분과 정점 C 연결한다.A-B-C 연결성분과 인접한 정점 중 간선 가중치 최소인 정점 찾는다.B와 인접한 정점 D가 간선 가중치 6으로 가장 작다.A-B-C 연결성분과 정점 D 연결한다.A-B-C-D 연결성분과 인접한 정점 중 간선 가중치 최소인 정점 찾는다.E가 간선 가중치 7로 가장 작다. 따라서 A-B-C-D와 간선 E 연결한다.A-B-C-D-E 연결성분과 인접 정점 중 간선 가중치 최소인 정점 찾는다.D에서 F가 간선 가중치 13으로 가장 작다.정점 D와 F를 잇는다.A-B-C-D-E-F 연결성분과 인접한 정점 중 간선 가중치 최소인 정점 찾는다.F-I가 간선 가중치 12로 가장 작다. 따라서 F와 I를 잇는다.연결성분 A-B-C-D-E-F-I 와 인접한 정점 중 간선 가중치 가장 작은 정점과 연결성분 잇는다.I - H 가 간선 가중치 9로 가장 작다. 따라서 I와 H를 잇는다.연결성분과 인접한 정점 중 간선 가중치 최소인 정점 찾는다.H와 J가 간선 가중치 8로 가장 작다. 따라서 H와 J를 잇는다.연결성분과 마지막 남은 정점 G를 간선 가중치 최소인 정점으로 잇는다.H-G가 간선 가중치 10으로 가장 작다. 따라서 H와 G를 잇는다.위 결과를 모양을 트리처럼 그리면 아래와 같아질 것이다. 싸이클이 없는가?: 없다. 최소 간선 수인가?: 맞다. $10-1 = 9$ 모든 정점이 연결되어 있는가?: 연결되어 있다. 간선 가중치 합 최소인가?: 맞다. $69$.$\\Rightarrow$ Prim 알고리듬 실행 결과 최소신장트리 찾았다.Prim 알고리듬 구현Prim 알고리듬 구현하고, 위 예제를 넣어보자.# Prim's Algorithmfor i in range(N): # 모든 정점 한번씩 찍는다. 정점 수 만큼 반복. # 임시로 쓰는 값. 큰 의미 없다. m = np.random.randint(-5, -1) min_value = sys.maxsize for j in range(N): # 전체 정점 중에서 if not visited[j] and D[j] &lt; min_value : # 방문 안 했고, 인접한 거. min_value = D[j] # 최소 간선 가중치 m = j # 최소 간선 정점 visited[m] = True # 최소 간선 정점 방문 완료 # 방금 방문한 정점 m의 인접 정점과 가중치 for w, wt in g[m]: if not visited[w] : if (wt &lt; D[w]): # 간선 w 가중치 D에 추가 or D 업데이트 D[w] = wt previous[w] = m 메커니즘 어느 정점 연결하지? 전체 정점 중에 1) 방문 안 했고 2) 연결성분과 인접 3) 간선 가중치 최소 인 정점 찾는다 2번 정점과 연결 2번 정점의 인접 정점 찾고, 간선 가중치 조사한다.모든 정점 연결 될 때 까지 1~4 과정 반복한다.테스트 - 1# 위 별모양 그래프로 프림 알고리듬 테스트 start = 0 N = 10 g = [None for x in range(N)]g[0] = [(2,3),(3,5)]g[1] = [(2,6),(5, 13)]g[2] = [(0, 3), (1,6),(3,1),(5,14)]g[3] = [(0,5),(2,1),(4,7),(6,15)]g[4] = [(3,7),(6,16)]g[5] = [(1,13),(2,14),(8,12),(7,17)]g[6] = [(3,15),(4,16),(7,10),(9,11)]g[7] = [(5,17),(8,9),(6,10),(9,8)]g[8] = [(5,12),(7,9)]g[9] = [(7,8),(6,11)]visited = [False for x in range(N)]D = [sys.maxsize for x in range(N)]D[start] = 0 previous = [None for x in range(N)]previous[start] = None # 프림 알고리듬 for i in range(N): m = np.random.randint(-5, -1) min_value = sys.maxsize for j in range(N): # 전체 정점 중에서 if not visited[j] and D[j] &lt; min_value : # 방문 안 했고, 인접한 거. min_value = D[j] # 최소 간선 가중치 m = j # 최소 간선 정점 visited[m] = True # 최소 간선 정점 방문 완료 # 방금 방문한 정점 m의 인접 정점과 가중치 for w, wt in g[m]: if not visited[w] : if (wt &lt; D[w]): # 간선 w 가중치 D에 추가 or D 업데이트 D[w] = wt previous[w] = m # 결과 출력 print(f'최소신장트리(간선):', end='')mst_cost = 0 for i in range(N): print(f'({i}, {previous[i]})', end='') mst_cost += D[i]print(f'\\n최소신장트리 가중치 합:{mst_cost}')최소신장트리(간선):(0, None)(1, 2)(2, 0)(3, 2)(4, 3)(5, 1)(6, 7)(7, 8)(8, 5)(9, 7)최소신장트리 가중치 합:69예상대로 잘 나왔다.테스트 - 2이번엔 다음과 같은 그래프에서 최소신장트리를 찾아보자.# 시작 정점 start = 1 # 정점 수 N = 10 # 0~9 까지 각 정점의 인접 정점 리스트 g = [None for x in range(N)]# 각 정점의 (인접 정점, 그 사이 간선 가중치)g[0] = [(1, 7), (2, 6)]g[1] = [(0, 7), (2, 5), (6, 13), (3, 9)]g[2] = [(0, 6), (1, 5), (5, 8), (4, 2)]g[3] = [(1, 9)]g[4] = [(2, 2), (9, 1)]g[5] = [(2, 8)]g[6] = [(1, 13), (8, 11), (7, 10)]g[7] = [(6, 10)]g[8] = [(6, 11)]g[9] = [(4,1)]# 각 정점 방문 완료 여부 표시 visited = [False for x in range(N)]# 정점 i와 연결 성분 사이 간선 가중치(최소가 우선)D = [sys.maxsize for x in range(N)]# 시작 정점과 연결성분 사이엔 간선이 존재 안 한다. D[start] = 0 # 새로 발견된 정점의 그 이전 정점 (최소신장트리 간선 추출 위함)previous = [None for x in range(N)]previous[start] = None 프림 알고리듬 정의# 프림 알고리듬 정의 def prim(N, start): global g ; global visited ; global D ; global previous for i in range(N): m = np.random.randint(-5, -1) min_value = sys.maxsize for j in range(N): # 전체 정점 중에서 if not visited[j] and D[j] &lt; min_value : # 방문 안 했고, 인접한 거. min_value = D[j] # 최소 간선 가중치 m = j # 최소 간선 정점 visited[m] = True # 최소 간선 정점 방문 완료 # 방금 방문한 정점 m의 인접 정점과 가중치 for w, wt in g[m]: if not visited[w] : if (wt &lt; D[w]): # 간선 w 가중치 D에 추가 or D 업데이트 D[w] = wt previous[w] = m span = [] mst_cost = 0 for i in range(N) : span.append((i, previous[i])) mst_cost += D[i] return span , mst_costprim(10, 1)([(0, 2), (1, None), (2, 1), (3, 1), (4, 2), (5, 2), (6, 1), (7, 6), (8, 6), (9, 4)], 65)최단 경로(Shortest Path) 찾기가중치 그래프 출발점에서 어떤 정점 $w$ 까지 도달하는 최단 경로 찾기.Diijkstra(데이크스트라) 알고리듬가중치 그래프에서. 출발점~정점 $w$ 까지. 최단 경로 찾는 알고리듬. 전체적으로 Prim 알고리듬과 거의 똑같다.Prim 알고리듬과 차이점 Prim 알고리듬은 출발점 주어지지 않지만, Diijkstra 알고리듬은 출발점이 주어진다. Prim 알고리듬은 리스트 D에 연결성분과 정점 $w$ 사이 간선 가중치가 저장되는 데 반해, Diijkstra 알고리듬은 D에 출발점~정점 $w$ 사이 경로 길이가 저장된다.*경로 길이: 출발점~정점 $w$ 사이 간선들 가중치 합.Diijkstra 알고리듬 구현*가중치 중 음수 있으면 최단 경로 제대로 못 찾을 수 있다.# 데이크스트라 알고리듬 정의 import sys for k in range(N) : # 여기서 m과 min_value 는 임시 값. m = -1 min_value = sys.maxsize for i in range(N) : if not visited[i] and (D[i] &lt; min_value) : # 방문 안 했고, 출발점에서 경로 길이 가장 짧은 정점 j min_value = D[i] # 최소 경로 길이 , D[i] 는 출발점에서 정점 i 사이 간선들 가중치 합 m = i # 출발점에서 가장 가까운 정점 m visited[m] = True # 방문 완료: 최단 경로 확정. 갱신 더 이상 안 한다. for w, wt in g[m] : # 정점 m의 (인접 정점, 가중치) if not visited[w] : # 출발~정점 w 까지 최단거리 아직 확정 못 지었다면 # 최단경로 갱신(간선완화) if (D[m] + wt) &lt; D[w] : # 기존 경로보다 (D[m] + wt)가 더 최단 경로면 D[w] = D[m] + wt # 출발점~w까지 최단 거리 갱신. 간선완화 previous[w] = m 알고리듬 테스트 - 1아래 그래프에서 출발점을 정점 0 삼아 0에서 각 정점 i 까지 최단 경로를 찾아보자.# 테스트 # 정점 수 N = 10 # 출발점s = 0 # 정점 i의 (인접 정점, 간선 가중치) 리스트g = [None for x in range(N)]# 정점 w까지 최단 경로 확정 유무 visited = [False for x in range(N)]# 출발점부터 정점 w 까지 경로 길이 D = [sys.maxsize for x in range(N)]D[s] = 0 # 정점 w의 이전 정점 리스트 previous = [None for x in range(N)]previous[s] = None # 그래프 g[0] = [(2,3),(3,5)]g[1] = [(2,6),(5, 13)]g[2] = [(0, 3), (1,6),(3,1),(5,14)]g[3] = [(0,5),(2,1),(4,7),(6,15)]g[4] = [(3,7),(6,16)]g[5] = [(1,13),(2,14),(8,12),(7,17)]g[6] = [(3,15),(4,16),(7,10),(9,11)]g[7] = [(5,17),(8,9),(6,10),(9,8)]g[8] = [(5,12),(7,9)]g[9] = [(7,8),(6,11)]# 데이크스트라 알고리듬 정의 import sys for k in range(N) : m = -1 min_value = sys.maxsize for i in range(N) : if not visited[i] and (D[i] &lt; min_value) : min_value = D[i] # 최소 경로 길이 m = i # 출발점에서 가장 가까운 정점 m visited[m] = True # 방문 완료: 최단 경로 확정. 갱신 더 이상 안 한다. for w, wt in g[m] : # 정점 m의 (인접 정점, 가중치) if not visited[w] : # 출발~정점 w 까지 최단거리 아직 확정 못 지었다면 # 최단경로 갱신(간선완화) if (D[m] + wt) &lt; D[w] : # 기존 경로보다 최단 경로면 D[w] = D[m] + wt # 간선완화 previous[w] = m 출발점 0에서 정점 i 까지 최단 경로 길이시작점과 정점 i 사이 경로 없으면 $D[i]$ 는 $\\infty$ 로 그냥 둔다.# 최단 경로 길이print(f'출발점 {s} 로 부터 정점 i의 최단거리')for i in range(N) : if D[i] == sys.maxsize : # 시작점과 i 사이 경로 없는 경우 print(f'출발점 {s}와 정점 {i} 사이 경로 없음') else : print(f'[{s}, {i}] = {D[i]}') # 시작점과 정점 i 사이 최단 경로길이 출력출발점 0 로 부터 정점 i의 최단거리[0, 0] = 0[0, 1] = 9[0, 2] = 3[0, 3] = 4[0, 4] = 11[0, 5] = 17[0, 6] = 19[0, 7] = 29[0, 8] = 29[0, 9] = 30)출발점 0에서 정점 i 까지 최단 경로# 최단경로print(f'출발점 {s} 로 부터 정점 i 까지 최단경로')for i in range(N) : vertex = i # 현재 정점 i print(vertex, end='') while (vertex != s) : print(f'&lt;-{previous[vertex]}', end='') vertex = previous[vertex] print() 출발점 0 로 부터 정점 i 까지 최단경로01&lt;-2&lt;-02&lt;-03&lt;-2&lt;-04&lt;-3&lt;-2&lt;-05&lt;-2&lt;-06&lt;-3&lt;-2&lt;-07&lt;-6&lt;-3&lt;-2&lt;-08&lt;-5&lt;-2&lt;-09&lt;-6&lt;-3&lt;-2&lt;-0알고리듬 테스트 - 2이번엔 아래 그래프에서 시작점 0 삼아 각 정점까지 최단 경로 찾기를 해보자.# 테스트N = 10 s = 0 g = [None for x in range(N)]visited = [False for x in range(N)]D = [sys.maxsize for x in range(N)]D[s] = 0 previous = [None for x in range(N)]previous[s] = None g[0] = [(1, 7), (2, 6)]g[1] = [(0, 7), (2, 5), (6, 13), (3, 9)]g[2] = [(0, 6), (1, 5), (5, 8), (4, 2)]g[3] = [(1, 9)]g[4] = [(2, 2), (9, 1)]g[5] = [(2, 8)]g[6] = [(1, 13), (8, 11), (7, 10)]g[7] = [(6, 10)]g[8] = [(6, 11)]g[9] = [(4,1)]# 데이크스트라 알고리듬 정의 import sys for k in range(N) : m = -1 min_value = sys.maxsize for i in range(N) : if not visited[i] and (D[i] &lt; min_value) : min_value = D[i] # 최소 경로 길이 m = i # 출발점에서 가장 가까운 정점 m visited[m] = True # 방문 완료: 최단 경로 확정. 갱신 더 이상 안 한다. for w, wt in g[m] : # 정점 m의 (인접 정점, 가중치) if not visited[w] : # 출발~정점 w 까지 최단거리 아직 확정 못 지었다면 # 최단경로 갱신(간선완화) if (D[m] + wt) &lt; D[w] : # 기존 경로보다 최단 경로면 D[w] = D[m] + wt # 간선완화 previous[w] = m 출발점 0에서 정점 i 까지 최단 경로 길이시작점과 정점 i 사이 경로 없으면 $D[i]$ 는 $\\infty$ 로 그냥 둔다.# 최단 경로 길이 print(f'출발점 {s} 로 부터 정점 i의 최단거리')for i in range(N) : if D[i] == sys.maxsize : print(f'출발점 {s}와 정점 {i} 사이 경로 없음') else : print(f'[{s}, {i}] = {D[i]}')출발점 0 로 부터 정점 i의 최단거리[0, 0] = 0[0, 1] = 7[0, 2] = 6[0, 3] = 16[0, 4] = 8[0, 5] = 14[0, 6] = 20[0, 7] = 30[0, 8] = 31[0, 9] = 9출발점 0에서 정점 i 까지 최단 경로# 최단 경로 print(f'출발점 {s} 로 부터 정점 i 까지 최단경로')for i in range(N) : vertex = i # 현재 정점 i print(vertex, end='') while (vertex != s) : print(f'&lt;-{previous[vertex]}', end='') vertex = previous[vertex] print() 출발점 0 로 부터 정점 i 까지 최단경로01&lt;-02&lt;-03&lt;-1&lt;-04&lt;-2&lt;-05&lt;-2&lt;-06&lt;-1&lt;-07&lt;-6&lt;-1&lt;-08&lt;-6&lt;-1&lt;-09&lt;-4&lt;-2&lt;-0Diijkstra 알고리듬 성능$O(N^{2})$ 알고리듬 시작부에서. 출발점에서 가장 가까운 정점 찾기 위해. D에서 $N$개 정점 비교한다. $\\Rightarrow$ $O(N)$ 시간 소요 출발점에서 가장 가까운 정점 $m$ 의 인접 정접 $M(M\\leq N)$ 개를 검사해서, D의 원소 갱신한다. $\\Rightarrow$ 추가로 $O(M)$ 시간 소요$O(N+M) = O(N)$ 위 과정을 정점 갯수 $N$ 번 반복한다. $\\Rightarrow$ 총 수행시간: $O(N^{2})$" }, { "title": "[2021 인공지능전문가 교육과정 복습] 그래프 개념, 그래프 깊이우선탐색(DFS), 그래프 너비우선탐색(BFS) 알고리듬", "url": "/bioinfo.github.io/posts/graph_dfs/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, python, study, data science", "date": "2022-02-16 00:00:00 +0900", "snippet": "그래프(Graph)정의객체 간 관계 나타내는 자료구조.구성 그래프는 정점(Vertex)과 간선(Edge)으로 이루어져 있다. 1개 간선에는 정점 2개 연결한다.종류 무방향그래프: 간선에 방향 없는 그래프 방향그래프: 간선에 방향 있는 그래프 완전그래프: 간선 수 최대인 그래프.무방향그래프 경우 최대 간선 수: $\\frac{n(n-1)}{2}$방향그래프 경우 최대 간선 수: $n(n-1)$그래프 정점과 간선 정점 A,B 를 연결하는 방향없는 간선: $(A,B)$ 로 표기 정점 A,B 연결하는 방향 있는 간선: $&lt;A,B&gt;$ 로 표기 무방향그래프에서는 간선 방향이 없기 때문에 $(A,B)$ 와 $(B,A)$ 는 같다. 방향그래프는 간선 방향이 있다. 따라서 $&lt;A,B&gt;$ 와 $&lt;B,A&gt;$ 는 다르다.차수(Degree): 정점 1개에 부속된 간선 수 방향 그래프는 정점 차수가 진입차수(In-degree)와 진출차수(Out-degree) 로 구분된다. 진입차수: 정점에 들어오는 부속 간선 수 진출차수: 정점에서 나가는 부속 간선 수 왼쪽 무방향 그래프 정점 A의 차수는 3이다. B 차수는 2이다. 오른쪽 방향 그래프 정점 A의 진입차수는 2다. 진출차수는 1이다.(정점이) 인접무방향 그래프에서 두 정점 사이 간선이 있으면 두 정점이 서로 ‘인접하다’ 고 한다(간선이) 부속무방향 그래프에서 두 정점 사이 간선은 두 정점에 ‘부속된다’ 고 한다그래프 경로(Path)경로(Path)정의정점 시퀀스. $[A,B,C,D]$ : 정점 A부터 D까지 경로 경로 길이: 경로에 포함되는 간선 수. (시퀀스 원소 수 - 1)단순경로(Simple Path)정의시퀀스 내 원소가 모두 다른 경로싸이클(Cycle)정의단순경로인데, 시작 정점과 끝 정점 같다.예시$[A,B,C,D,A]$ 시작 정점과 끝 정점이 같은, 단순경로다. 곧, 싸이클(Cycle)이다. 경로 상 정점 수: 3 (B,C,D) 경로 길이: 4이 외 그래프 각종 용어연결성분그래프에서 정점이 서로 연결된 부분을 ‘연결성분’ 이라 한다.A,B 두 정점이 연결되어 있다A,B 두 정점 사이 경로(정점 시퀀스)가 있으면 두 정점은 ‘연결되어 있다’만약 A,B 두 정점 사이 간선 방향이 있어서 두 정점 왕복할 수 있는 ‘경로’가 있다면 두 정점은 ‘강연결 되어 있다’가중치 그래프(Weighted Graph)간선마다 가중치 부여된 그래프가중치는 두 정점 사이 거리, 간선 지나는 시간 등이 될 수 있다. 음수 가중치도 가능하다.부분그래프(Sub Graph)전체 그래프의 부분집합.트리(Tree)싸이클이 없는 그래프.신장트리(Spanning Tree)모든 정점이 연결되어 있는 트리그래프 정점과 간선 표현 방법그래프 G1V(G1) = $[A,B,C]$E(G1) = $[(A,C),(C,B),(A,B)]$그래프 G2V(G2) = $[E,F,G,H,I]$E(G2) = $[(E,G),(G,I),(H,I),(F,H),(E,F),(E,H),(E,I),(F,G),(F,I),(H,G)]$그래프 G3V(G3) = $[J, L, N, M]$E(G3) = $[&lt;J, L&gt;,&lt;L,N&gt;,&lt;L,M&gt;,&lt;M,L&gt;]$그래프 저장 방법인접행렬(Adjacency Matrix)그래프 정점 수가 $N$ 이면 $N\\times N$ 행렬에 그래프 저장(또는 표현)한다.$0,1,2,3,…N-1$ 번 행이 정점 $0,1,2,3,…N-1$ 이다.마찬가지로$0,1,2,3,…N-1$ 번 열이 정점 $0,1,2,3,…N-1$ 이다.두 정점 사이 간선 있으면 행렬 X의 a행 b열 원소를 1로 한다.두 정점 사이 간선 없으면 그 원소를 0으로 한다. 가중치 그래프라면, 1 대신 간선 가중치 저장한다.예시 - 1 완전그래프다.예시 - 2인접리스트(Adjacency List)각 정점마다 1개씩 연결리스트(또는 배열) 이용해서 그 인접 정점 저장하는 방법예시 - 1 배열 대신 연결리스트 쓴다면, 배열 각 원소를 연결리스트 각 노드에 저장하면 된다. 인접 정점 리스트 저장 우선순위: 다음 꺼(1) 갈 수 있었는 데 안 간거(2) 이전 꺼(3) 나머지(4)예시 - 2그래프 탐색정점 방문. (후 출력)종류 깊이우선탐색(DFS): 트리 전위순회를 그래프 탐색에 적용 너비우선탐색(BFS): 트리 레벨순회를 그래프 탐색에 적용깊이우선탐색(DFS)트리 전위순회 방식 그래프 탐색에 적용했다. 무조건 직진한다. 더 직진 할 데가 없을때만 후진해서 ‘갈 수 있었지만 가지 않은 곳’ 방문 한번 방문한 곳은 다시 방문하지 않는다.예시 및 구현 그래프가 2개 연결성분으로 되어 있다. 각 정점 방문 후 출력한다.# 깊이우선탐색 정의 def dfs(v) : global adj global visited # 방문완료 visited[v] = True # 출력 print(f'{v}', end=' ') # 인접 정점으로 for w in adj[v] : if not visited[w] : # 아직 방문 안 했다면 dfs(w) # 그 인접 정점에서 재귀호출 # 인접리스트로 표현한 그래프 adj = [ [2,1], [3,0], [3,0], [9,8,2,1], [5], [7,6,4], [7,5], [6,5], [3], [3]]# 그래프 정점 수 N = len(adj)# 정점 별 방문여부 visited = [False for x in range(N)]# 깊이우선탐색 실행 및 결과 출력 print(f'DFS 결과:', ' ',end='')for i in range(N) : if not visited[i] : dfs(i)DFS 결과: 0 2 3 9 8 1 4 5 7 6깊이우선 신장트리깊이우선탐색으로 만들어지는 트리를 ‘깊이우선 신장트리’라고 한다. 선이 있어서 가긴 갔는데 이미 방문한 정점인 경우, 두 정점 사이 깊이우선 신장트리에서 점선으로 표시한다.깊이우선탐색 성능$O(N+M)$ N은 정점 수 M은 간선 수N개 정점을 1번씩 만 방문한다.M개 간선을 1번씩 만 이용한다.미로 길 찾기 - 깊이우선탐색 메커니즘 이용 미로 탐색 중 ‘갈 수 있는 곳’은 모두 스택에 저장한다. 현재 위치 기준, 하 - 상 - 우 - 좌 순으로 다음 위치 먼저 간다. 계속 가다가 막히면 ‘이전에 갈 수 있었지만 가지 않은 곳’으로 간다. 길 찾을 미로 1# 미로 map = [ [1,1,1,1,1,1], ['e',0,0,0,0,1], [1,0,1,0,1,1], [1,1,1,0,1,1], [1,1,1,'x',1,1]] 1은 갈 수 없는 곳이다(벽) e가 입구 x가 출구 0이 길이다.길 찾기 정의# 미로 길 찾기 정의# 미로 시작점 start = (1,0)# 미로 크기maze_size = (5,6)# 현재 위치에서 갈 수 있는 곳 좌표 담을 스택 stack = []# 갈 수 있는 길인기, 갈 수 없는 길인지 검사 정의 def isValidPos(x,y) : if x &lt; 0 or y &lt; 0 or x &gt;= maze_size[0] or y &gt;= maze_size[1] : return False # 갈 수 없는 길이다. return map[x][y] == 0 or map[x][y] == 'x' # 1은 갈 수 없는 길이다. # DFS 정의 def DFS(start) : global stack ; global map stack.append(start) # 미로 시작 위치 while len(stack) != 0 : # 스택이 빌 때 까지 = 갈 수 있는 곳이 없을 떼 까지 here = stack.pop() # 현재위치 print(f'{here}-&gt;', end=' ') # 현재 진행상황 (x,y) = here if (map[x][y] == 'x') : # 현재 위치가 출구면 return True # 탈출 성공 else : # 탈출구 아니면 다음 갈 수 있는 위치 찾는다. map[x][y] = '.' # 한번. 이미. 방문한 곳 표시 (다시 가지 않기 위함) # 갈 수 있는 다음 위치 검사 if isValidPos(x, y-1) : stack.append((x, y-1)) # 좌 if isValidPos(x, y+1) : stack.append((x, y+1)) # 우 if isValidPos(x-1, y) : stack.append((x-1, y)) # 상 if isValidPos(x+1, y) : stack.append((x+1, y)) # 하 print(f'stack: {stack}') # 갈 수 있는 선택지들 return False # 사방이 막장이면 탈출 실패 길 찾기 실행DFS(start)(1, 0)-&gt; stack: [(1, 1)](1, 1)-&gt; stack: [(1, 2), (2, 1)](2, 1)-&gt; stack: [(1, 2)](1, 2)-&gt; stack: [(1, 3)](1, 3)-&gt; stack: [(1, 4), (2, 3)](2, 3)-&gt; stack: [(1, 4), (3, 3)](3, 3)-&gt; stack: [(1, 4), (4, 3)](4, 3)-&gt;True길 찾을 미로 2만약 미로에 출구가 없다면?# 미로 map = [ [1,1,1,1,1,1], ['e',0,0,0,0,1], [1,0,1,0,1,1], [1,1,1,0,1,1], [1,1,1,1,1,1]]길 찾기 실행DFS(start)(1, 0)-&gt; stack: [(1, 4), (1, 1)](1, 1)-&gt; stack: [(1, 4), (1, 2), (2, 1)](2, 1)-&gt; stack: [(1, 4), (1, 2)](1, 2)-&gt; stack: [(1, 4), (1, 3)](1, 3)-&gt; stack: [(1, 4), (1, 4), (2, 3)](2, 3)-&gt; stack: [(1, 4), (1, 4), (3, 3)](3, 3)-&gt; stack: [(1, 4), (1, 4)](1, 4)-&gt; stack: [(1, 4)](1, 4)-&gt; stack: []False길 찾기 실패했다.길 찾을 미로 3# 미로 map = [ [1,1,1,1,'x',1], [1,0,0,0,0,1], [1,0,1,0,1,1], [1,0,0,0,1,1], [1,1,1,'e',1,1]]길 찾기 실행start = (4, 3)DFS(start)(4, 3)-&gt; stack: [(3, 3)](3, 3)-&gt; stack: [(3, 2), (2, 3)](2, 3)-&gt; stack: [(3, 2), (1, 3)](1, 3)-&gt; stack: [(3, 2), (1, 2), (1, 4)](1, 4)-&gt; stack: [(3, 2), (1, 2), (0, 4)](0, 4)-&gt;True너비우선탐색(BFS)트리 레벨순회 메커니즘을 그래프 탐색에 적용했다. 계속 직진하면서 정점들 방문하는데, 인접 정점 있으면 거기 먼저 간다.(모양새가 레벨순회랑 비슷) 방문한 곳은 다시 안 들린다. 후진은 더 이상 갈 데 없을 때만 한다.구현에 FIFO 보장되는 큐 활용한다.예시 및 구현# 너비우선탐색 정의 # 큐에 삽입하는 건 그저 방문 순서대로 출력하기 위함이다. def BFS(i) : # 점점 i global visited ; global adj que = [] # 큐 정의 visited[i] = True # 정점 i 방문완료 que.append(i) while len(que) != 0 : # 방문한 곳이 없으면 멈춘다 v = que.pop(0) print(v, end=' ') for w in adj[v] : if not visited[w] : visited[w] = True # 정점 w 방문완료 que.append(w)실행# 주어진 그래프에서 너비우선탐색 실행 adj = [ [2,1], [3,0], [3,0], [9,8,2,1], [5], [7,6,4], [7,5], [6,5], [3], [3]]N = len(adj)visited = [False for x in range(N)]# BFS 테스트 for i in range(N) : if not visited[i] : BFS(i)0 2 1 3 9 8 4 5 7 6너비우선 신장트리그래프 너비우선탐색으로 만들어지는 트리를 ‘너비우선 신장트리’ 라고 한다.위 너비우선탐색 결과로 나오는 너비우선 신장트리는 아래와 같이 표현할 수 있다.너비우선탐색 성능$O(N+M)$ 소요모든 정점을 단 한번씩만 방문. 모든 간선 단 한번씩만 사용. N은 정점 수 M은 간선 수 깊이우선탐색(DFS) 과 정점 방문 순서 &amp; 간선 사용 순서만 다를 뿐이다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 퀵 정렬, 기수 정렬 알고리듬", "url": "/bioinfo.github.io/posts/quick_sort/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, python, study, data science", "date": "2022-02-10 00:00:00 +0900", "snippet": "퀵 정렬(Quick Sort)피벗(기준) 정렬.정의피벗값을 기준삼아. 피벗 왼쪽에는 피벗보다 작은 값들, 오른쪽에는 큰 값들 오도록 정렬하는 알고리듬.특징 피벗값은 아무거나 잡아도 되나, 기왕이면 중앙값 잡는 게 좋다. 그 값 중심으로 왼쪽 작은 부분과 오른쪽 큰 부분이 균등하게 나눠지도록 하기 위해서다. 양쪽이 균등하게 나눠 질 수록 정렬 수행 시간 빨라진다. 일반적으로 가장 빠른 정렬 알고리듬이다. 합병정렬이 정렬 과정에서 전체를 균등분할 했다면, 퀵 정렬은 대부분 경우 비균등분할한다.메커니즘 피벗값 잡는다. i, j 잡고 각각 오른쪽, 왼쪽 방향 이동하다가 각각 피벗보다 큰 값, 피벗보다 작은 값 만나면 멈춘다. i, j 위치의 값 서로 교환한다. 2~3 과정 반복. i = j(둘이 만나는 경우) 또는 j &lt; i(둘이 교차한 경우) 되면서 멈춘 경우 반복도 멈춘다. 피벗 왼쪽에는 피벗보다 작은 값만, 오른쪽에는 큰 값만 있어야 한다. 이 원칙에 기반해서 i, j 위치 값을 피벗과 비교한다. i, j 위치 값 중 원칙 어긋나는 값을 피벗과 교환한다. 이후 피벗 위치는 그 값의 최종위치다. 더 이상 정렬하지 않는다. 피벗 기준 왼쪽과 오른쪽 부분리스트에서 1~5 과정을 재귀호출 함으로써 과정 반복한다. 매 재귀호출 마다 피벗값들이 최종위치에 놓여지면서 정렬된다.예시 - 1가장 왼쪽 레코드를 피벗(pivot)으로 잡는 경우예시 - 2중간 레코드를 피벗으로 잡는 경우 1예시 - 3중간 레코드를 피벗으로 잡는 경우 2예시 - 4가장 오른쪽 레코드를 피벗으로 잡는 경우퀵 정렬 성능평균 경우: $O(N\\log_{2}{N})$최선 경우: 각 부분리스트가 균등분할 되는 경우이론상 가장 이상적 경우는 각 부분리스트가 모두 균등분할 되는 경우다. 재귀호출 수: $\\log_{2}{n}$입력의 원소 개수를 $2^{k}$ 개 라고 가정하자. $n = 2^{k}$.k가 3인 경우($n = 2^{3}$) 재귀호출 하면서 균등분할 한다고 했을 때.$2^{3} \\Rightarrow 2^{2} \\Rightarrow 2^{1} \\Rightarrow 2^{0}$ 으로 총 $3$번 재귀호출 하게 된다.곧, 재귀호출 수 $= k$ 가 된다.$n = 2^{k} \\Rightarrow k = \\log_{2}{n}$ 이므로 재귀호출 수는 $\\log_{2}{n}$ 이 된다. 각 재귀호출에서 레코드 간 비교 횟수: $n$ 이동횟수는 비교횟수에 비해 적어 무시가능총 비교 횟수 $\\Rightarrow n\\log_{2}{n}$따라서퀵 정렬 최선 경우 성능: $O(N\\log_{2}{N})$최악 경우: 극도로 불균등한 리스트로 분할되는 경우퀵 정렬은 리스트 분할이 불균등 할 수록 시간복잡도 증가한다.이미 정렬된 리스트 정렬의 예)[ 1,2,3,4,5,6,7,8 ] 이라는 이미 정렬된 리스트가 있다고 하자.가장 왼쪽 원소를 피벗 삼아 퀵 정렬 한다.이 경우 매 순환호출 마다 리스트가 오른쪽으로 전부 몰려서 분할된다. 왼쪽 부분리스트는 아예 없다. 총 비교횟수: $n+(n-1)+(n-2)+…+2+1 = \\frac{n(n+1)}{2}$ 이미 정렬되어 있기 때문에 이동은 없다.따라서퀵 정렬 최악 경우 성능: $O(N^{2})$퀵 정렬 구현퀵 정렬 정의(1) - pivot을 가운데 값으로 잡는 경우# pivot이 가운데 있는 경우 정의 def partition(a, low, high) : i = low j = high pivot = (high + low) // 2 while True : while (i &lt; high) and (a[i] &lt; a[pivot]) : i += 1 while (j &gt; low) and (a[j] &gt; a[pivot]) : j -= 1 if j &lt;= i : break # 계속 가다가 멈춘 사유가 j &lt;= i 이면 break. if (i == pivot) : a[i], a[j] = a[j], a[i] pivot = j # pivot은 포인터에 불과 i += 1 ; j -= 1 elif (j == pivot) : a[i], a[j] = a[j], a[i] pivot = i i += 1 ; j -= 1 else : a[i], a[j] = a[j], a[i] i += 1 ; j -= 1 if (a[j] &lt;= a[pivot]) and (j &gt;= pivot) : a[pivot], a[j] = a[j], a[pivot] return j elif (a[i] &gt;= a[pivot]) and (i &lt;= pivot) : a[pivot], a[i] = a[i], a[pivot] return i# 퀵 정렬 def qsort(a, low, high) : if (low &lt; high) : pivot = partition(a, low, high) qsort(a, low, pivot-1) qsort(a, pivot+1, high)알고리듬 테스트(1)# 정렬 알고리듬 테스트 a = [54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]print(f'정렬 전:{a}')qsort(a, 0, len(a)-1)print(f'정렬 후:{a}')정렬 전:[54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]정렬 후:[10, 11, 17, 17, 17, 20, 22, 26, 31, 44, 49, 54, 77, 77, 88, 93](2)# 정렬 알고리듬 테스트 random_list = list(np.random.randint(0,100,20))print(f'정렬 전:{random_list}')qsort(random_list, 0, len(random_list)-1)print(f'퀵 정렬 후:{random_list}')정렬 전:[5, 83, 59, 31, 86, 89, 25, 91, 41, 15, 77, 6, 55, 55, 46, 59, 91, 40, 50, 46]퀵 정렬 후:[5, 6, 15, 25, 31, 40, 41, 46, 46, 50, 55, 55, 59, 59, 77, 83, 86, 89, 91, 91](3)# 정렬 알고리듬 테스트 random_list = list(np.random.randint(0,1000,20))print(f'정렬 전:{random_list}')qsort(random_list, 0, len(random_list)-1)print(f'퀵 정렬 후:{random_list}')정렬 전:[831, 388, 62, 442, 111, 668, 838, 7, 869, 445, 635, 793, 169, 843, 586, 405, 346, 892, 665, 950]퀵 정렬 후:[7, 62, 111, 169, 346, 388, 405, 442, 445, 586, 635, 665, 668, 793, 831, 838, 843, 869, 892, 950]퀵 정렬 정의(2) - 가장 왼쪽 레코드가 pivot이 되는 경우# 가장 왼쪽이 pivot이 되는 경우 정의def partition_pl(a, pivot, high) : i = pivot + 1 j = high while True : while (i &lt; high) and (a[i] &lt; a[pivot]) : i += 1 while (j &gt; pivot) and (a[j] &gt; a[pivot]) : j -= 1 if j &lt;= i : break # i, j 만났거나 i, j 교차해서 멈춘 경우 a[i], a[j] = a[j], a[i] i += 1 ; j -= 1 # break 로 loop 깨진 경우 a[pivot], a[j] = a[j], a[pivot] return j # pivot 위치 반환 # 퀵 정렬 정의def qsort_pl(a, low, high) : if low &lt; high : pivot = partition_pl(a, low, high) qsort_pl(a, low, pivot-1) qsort_pl(a, pivot+1, high)알고리듬 테스트# 테스트 - qsort_plrandoms = np.random.randint(0, 1000, 20)print(f'정렬 전:{randoms}')qsort_pl(randoms, 0, len(randoms)-1)print(f'정렬 후:{randoms}')정렬 전:[468 69 341 122 406 909 912 904 327 811 448 80 379 333 960 478 652 48 913 386]정렬 후:[ 48 69 80 122 327 333 341 379 386 406 448 468 478 652 811 904 909 912 913 960]퀵 정렬 정의(3) - 가장 오른쪽 레코드가 pivot이 되는 경우# 가장 오른쪽이 pivot이 되는 경우 정의 def partition_pr(a, low, pivot) : i = low j = pivot - 1 while True : while (i &lt; pivot) and (a[i] &lt; a[pivot]) : i += 1 while (j &gt; low) and (a[j] &gt; a[pivot]) : j -= 1 if (j &lt;= i) : break a[i], a[j] = a[j], a[i] i += 1 ; j-= 1 a[pivot], a[i] = a[i], a[pivot] return i # pivot 위치 반환 # 퀵 정렬 정의def qsort_pr(a, low, high) : if low &lt; high : pivot = partition_pr(a, low, high) qsort_pr(a, low, pivot-1) qsort_pr(a, pivot+1, high)알고리듬 테스트# 테스트 - qsort_pr randoms = np.random.randint(5, 100, 20)print(f'정렬 전:{randoms}')qsort_pr(randoms, 0, len(randoms)-1)print(f'정렬 후:{randoms}')정렬 전:[78 78 8 38 33 31 12 71 95 78 99 54 29 65 65 15 28 33 10 58]정렬 후:[ 8 10 12 15 28 29 31 33 33 38 54 58 65 65 71 78 78 78 95 99]정렬 알고리듬 별 비교시간복잡도, 안정성, 추가메모리 필요 여부 비교기수 정렬(Radix Sort)자릿수(기수) 정렬.MSD / LSD 방법 중 LSD 방법(작은 자릿수 부터 정렬하는 방법)에 근거해 설명한다.정의각 레코드를 자릿수 별로 정렬하는 정렬 알고리듬.특징 비교연산 없이 정렬한다! 최선, 최악 경우 없이 매번 굉장히 빠른 정렬 알고리듬이다$O(N)$. 데이터 외 버킷(데이터 임시 저장 공간. 하나하나가 큐) 이 추가로 필요하다. 따라서 메모리 많이 잡아먹는다.메커니즘 10개 버킷 준비한다(0~9 의미) 각 레코드 1 자릿수 별로 버킷에 순서대로 넣는다. 버킷에서 순서대로 가져온다(1 자릿수에 대해 정렬완료) 10 자릿수, 100 자릿수… 에 대해 2~3 과정 반복한다.예시각 버킷은 큐(Queue)다. 선입선출(FIFO) 한다.1 자릿수 대로 정렬10 자릿수 대로 정렬100 자릿수 대로 정렬기수 정렬 성능시간복잡도항상 $O(N)$ 시간복잡도 보장된다.최선, 최악 경우 없이 항상 빠르다.위 경우 예로 들 때(데이터수: 11개) 1 자릿수 찾기 위해: 11번 탐색 10 자릿수 찾기 위해: 11번 탐색 100 자릿수 찾기 위해: 11번 탐색$\\Rightarrow$ $k \\times N$ 번 탐색 수행.$\\Rightarrow$ $O(N)$ 시간복잡도.정렬 알고리듬 안정성안정성 보장단점메모리 많이 잡아먹는다전체 데이터 저장공간 뿐 아니라, 버킷을 위한 메모리 공간도 필요하다.이것 자체로 메모리를 많이 먹는다. 그리고 버킷에 데이터 담고 빼는 과정이 많아 질 수록, 무시할 수 없을 만큼 시간도 많이 잡아먹는다.기수 정렬 구현기수 정렬 정의# 기수 정렬 정의 class Radix_sort : def __init__(self, num) : self.num = num # 정렬할 대상 def radix_sort(self) : max1 = max(self.num) # 최댓값 찾는다: 최소한 최댓값 자릿수만큼 충분히 정렬하기 위해서다 exp = 1 while (max1/exp) &gt; 0 : self.count_sort(self.num, exp) exp *= 10 # 1의 자리, 10의 자리, 100의 자리, ... 돌아가며 정렬한다 def count_sort(self, A, k) : B = [0]*len(A) # 정렬 결과 담을 임시 리스트 C = [0]*10 # 0~9. 0~9인 N 자릿수 갯수 담을 리스트 # 정렬 위해 C를 먼저 만든다. for i in range(0, len(A)) : C[(A[i]//k)%10] += 1 # C완성 # C를 누적 값 리스트로 바꾼다. for i in range(1, len(C)) : C[i] = C[i-1] + C[i] i = len(A) - 1 # 정렬 다 된 상태에서. 더 안 움직이기 위해 뒤에서 부터 돈다. while (i &gt;= 0) : B[C[(A[i]//k)%10]-1] = A[i] # 임시리스트에 정렬 C[(A[i]//k)%10] -= 1 i -= 1 # 임시리스트 결과 원본 리스트에 복사 for i in range(0, len(A)) : A[i] = B[i] 1 자리, 10 자리, 100자리, 1000자리, … 돌아가며 자릿수 별로 순서대로 정렬한다. 어떤 수 X의 k 자릿수 $= (X//k)\\%{10}$ (몫 - 나머지) 임시 배열 B 만들고 거기다 정렬한 뒤 원래 배열에 옮긴다. C는 N 자릿수가 0부터 9인 것들 갯수 저장된 배열이다. 배열 C 각 인덱스 위치는 0~9를 의미한다. C 배열 0번 인덱스에 2가 들어가 있다면. 1의 자리가 0인게 (정렬 안 된 채로) 2개 있다는 말이다. C를 만들고 나서. 0~9까지 갯수 누적값 저장한 배열로 바꾼다. B에 ‘정렬’ 할 때. 그 수가 반드시 있을 법한 자리에 집어넣는다. $\\Rightarrow$ 예컨대 1 자리가 2인 수를 B에 임시로 정렬하려 한다. 한편 C의 2번 인덱스가 3이라 가정한다. 이건 1 자리가 0, 1, 2인 원소 갯수가 총 3개라는 말이다. 우리는 내가 넣으려는 수가 이 3개 안에 반드시 포함되어 있다는 걸 알고 있다. 3개 중에서 적어도 마지막 3번째에는 어느 상황에서든 반드시 1 자리 2인 수가 포함되어 있을 것이다. 내가 넣으려는 수는 1 자리가 2다. 따라서 3개 중 마지막 3번째에 해당하는 B의 2번 인덱스에 내가 넣으려는 수를 집어넣는다. 맨 마지막 while 루프 안에 B[C[(A[i]//k)%10]-1] = A[i] 코드는 그래서 나온 것이다. 이후 1자리 2인 원소 1개가 정렬되었으므로, 정렬되지 않은 것들 개수 누적 리스트 C의 2번 인덱스 원소에서 1을 줄인다. 그 다음 줄 C[(A[i]//k)%10] -= 1 코드가 그 역할 한다.알고리듬 테스트 - 1# 테스트 test = [5,2,8,4,9,1,11,33,22,12]rd = Radix_sort(test)rd.radix_sort()rd.num[1, 2, 4, 5, 8, 9, 11, 12, 22, 33]알고리듬 테스트 - 2# 테스트 number = [170, 45, 75, 90, 802, 24, 2, 66]print(f'정렬 전:{number}')radix = Radix_sort(number)radix.radix_sort() print(f'정렬 후:{radix.num}')정렬 전:[170, 45, 75, 90, 802, 24, 2, 66]정렬 후:[2, 24, 45, 66, 75, 90, 170, 802]기수 정렬(LSD) 문자열 정렬에 응용LSD 알고리듬 정의 - 1# 1def lsd_sort(a) : width = 3 n = len(a) r = 128 temp = [None]*n for d in reversed(range(width)) : count = [0]*(r+1) for i in range(n) : count[ord(a[i][d])+1] += 1 for j in range(1, r) : count[j] += count[j-1] for i in range(n) : p = ord(a[i][d]) temp[count[p]] = a[i] count[p] += 1 for i in range(n) : a[i] = temp[i] print(f'{d}번째 문자:', end='') for x in a : print(x, '', end=' ') print()참고ord() 함수ord() 함수는 어떤 문자열의 아스키코드 값을 반환 해준다.# ord()print(ord('A'))print(ord('a'))6597chr() 함수chr() 함수에 아스키코드 값 넣으면 그 아스키코드에 할당된 문자열 반환해준다.곧, ord() 함수와 정 반대다.# chr() print(chr(65))print(chr(97))‘A’‘a’알고리듬 테스트 - 1a = ['ICN', 'SFO', 'LAX', 'FRA', 'SIN', 'ROM', 'HKG', 'TLV', 'SYD', 'MEX', 'LHR', 'NRT', 'JFK', 'PEK', 'BER', 'MOW']print(f'정렬 전:{a}')lsd_sort(a)정렬 전:[‘ICN’, ‘SFO’, ‘LAX’, ‘FRA’, ‘SIN’, ‘ROM’, ‘HKG’, ‘TLV’, ‘SYD’, ‘MEX’, ‘LHR’, ‘NRT’, ‘JFK’, ‘PEK’, ‘BER’, ‘MOW’]2번째 문자:FRA SYD HKG JFK PEK ROM ICN SIN SFO LHR BER NRT TLV MOW LAX MEX1번째 문자:LAX ICN PEK BER MEX JFK SFO LHR SIN HKG TLV ROM MOW FRA NRT SYD0번째 문자:BER FRA HKG ICN JFK LAX LHR MEX MOW NRT PEK ROM SFO SIN SYD TLVLSD 알고리듬 정의 - 2# 2def lsd_sort(a) : width = 3 n = len(a) r = 128 temp = [None]*n for d in reversed(range(width)) : count = [0]*r for i in range(n) : count[ord(a[i][d])] += 1 for j in range(1, r) : count[j] += count[j-1] for i in range(n) : p = ord(a[i][d]) temp[count[p]-1] = a[i] count[p] -= 1 for i in range(n) : a[i] = temp[i] print(f'{d}번째 문자:', end='') for x in a : print(x, '', end=' ') print()알고리듬 테스트 - 2a = ['ICN', 'SFO', 'LAX', 'FRA', 'SIN', 'ROM', 'HKG', 'TLV', 'SYD', 'MEX', 'LHR', 'NRT', 'JFK', 'PEK', 'BER', 'MOW']print(f'정렬 전:{a}')lsd_sort(a)정렬 전:[‘ICN’, ‘SFO’, ‘LAX’, ‘FRA’, ‘SIN’, ‘ROM’, ‘HKG’, ‘TLV’, ‘SYD’, ‘MEX’, ‘LHR’, ‘NRT’, ‘JFK’, ‘PEK’, ‘BER’, ‘MOW’]2번째 문자:FRA SYD HKG PEK JFK ROM SIN ICN SFO BER LHR NRT TLV MOW MEX LAX1번째 문자:LAX ICN MEX BER PEK SFO JFK LHR SIN HKG TLV MOW ROM NRT FRA SYD0번째 문자:BER FRA HKG ICN JFK LHR LAX MOW MEX NRT PEK ROM SYD SIN SFO TLVLSD 알고리듬 정의 - 3# 3def lsd(a) : width = 3 # 문자열 크기 n = len(a) # 입력 크기 asch = 128 # 아스키코드 총 수 128 for d in reversed(range(width)): # 2,1,0 count = [0]*asch # 0~127 for i in range(n) : count[ord(a[i][d])] += 1 # aschii 코드 집계 for i in range(1, len(count)) : count[i] = count[i-1] + count[i] # count를 누적 값들로 변환 temp = [None] * n # 정렬 결과 담을 임시 리스트 for i in range(0, len(a)) : temp[count[ord(a[i][d])] - 1] = a[i] # temp에 정렬 count[ord(a[i][d])] -= 1 # 정렬 할 게 하나 줄었다: -1 for i in range(0, len(a)) : a[i] = temp[i] print(f'{d}번째 알파벳: {a}')알고리듬 테스트 - 3a = ['ICN', 'SFO', 'LAX', 'FRA', 'SIN', 'ROM', 'HKG', 'TLV', 'SYD', 'MEX', 'LHR', 'NRT', 'JFK', 'PEK', 'BER', 'MOW']print(f'정렬 전:{a}')print()lsd(a)정렬 전:[‘ICN’, ‘SFO’, ‘LAX’, ‘FRA’, ‘SIN’, ‘ROM’, ‘HKG’, ‘TLV’, ‘SYD’, ‘MEX’, ‘LHR’, ‘NRT’, ‘JFK’, ‘PEK’, ‘BER’, ‘MOW’]2번째 알파벳: [‘FRA’, ‘SYD’, ‘HKG’, ‘PEK’, ‘JFK’, ‘ROM’, ‘SIN’, ‘ICN’, ‘SFO’, ‘BER’, ‘LHR’, ‘NRT’, ‘TLV’, ‘MOW’, ‘MEX’, ‘LAX’]1번째 알파벳: [‘LAX’, ‘ICN’, ‘MEX’, ‘BER’, ‘PEK’, ‘SFO’, ‘JFK’, ‘LHR’, ‘SIN’, ‘HKG’, ‘TLV’, ‘MOW’, ‘ROM’, ‘NRT’, ‘FRA’, ‘SYD’]0번째 알파벳: [‘BER’, ‘FRA’, ‘HKG’, ‘ICN’, ‘JFK’, ‘LHR’, ‘LAX’, ‘MOW’, ‘MEX’, ‘NRT’, ‘PEK’, ‘ROM’, ‘SYD’, ‘SIN’, ‘SFO’, ‘TLV’]" }, { "title": "[2021 인공지능전문가 교육과정 복습] (이진)힙 정렬, 합병 정렬 알고리듬", "url": "/bioinfo.github.io/posts/heap_merge_sort/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, python, study, data science", "date": "2022-02-07 00:00:00 +0900", "snippet": "힙 정렬(Heap Sort)정의이진 힙 삭제연산 메커니즘을 배열에 적용해서 정렬하는 알고리듬. 삭제된 걸 받아서 배열 -1 쪽 부터 정렬한다.절차오름차순 정렬을 위해서는 최대힙 사용. 내림차순 정렬 위해서는 최소힙 사용.아래 과정은 오름차순 정렬을 예시로 든 것이다. 배열에 저장된 데이터들의 키를 우선순위로 삼아 최대 힙 구성 힙 가장 마지막 원소와 루트 R 교환. 힙 크기 1 감소(루트 R은 배열 가장 마지막에 정렬된 걸로 간주. 힙에서는 제외한다) 최대 힙 속성 유지 위해 루트R부터 다운힙 2~3 과정을 힙 크기 0 될때 까지 반복예시 배열에 90, 80, … 이 값들을 각 데이터 키로 생각하자. 맨 처음 임의의 어떤 입력이 들어왔을 것이다. 그 입력을 최대힙 상태로 바꾼게 가장 왼쪽 첫 번째 그림이다. 맨 마지막 노드 90과 루트 40 교환 뒤. 90은 배열에는 남아있지만 힙에서는 삭제된 걸로 간주한다. 따라서 힙 크기 1 줄인다. 최대힙 속성 유지 위해 다운힙 한다. 40의 자식 60과 80 중 자식 승자는 80이다. 80과 40 교환한다. 최대힙 속성 유지 될 때 까지 40이 내려가면서 반복한다. 위 그림은 1회전 예다. 힙 크기가 0 될때 까지 위 과정을 반복한다.힙 정렬 성능시간복잡도항상 $O(N\\log{N})$ 걸린다. 입력에 전혀 영향 받지 않는다.항상 효율적인 편이다. 초기 힙(최대힙/최소힙) 생성: $O(N)$ 시간 루트와 맨 마지막 노드 교환하고, 다운힙: $O(\\log{N})$ $\\Leftarrow$ 이진 힙 삭제연산 시간복잡도 위 두번째 과정(이진 힙 삭제연산) 총 $N-1$ 번 반복따라서$N + (N-1)*\\log{N} = O(N\\log{N})$정렬 알고리듬 안정성(Stability)안정성 보장하지 않는다.곧, 정렬하고 나면 키값 같은 원소들의 상대적 위치 바뀔 수 있다.힙 정렬 쓸모 입력에서 최댓값 또는 최솟값 뽑아 낼 때 유용하게 쓸 수 있다. 한편 힙 정렬은 메모리 많이 먹는다. 따라서 대용량 입력에는 비효율적이다. 힙 정렬 구현힙 정렬 정의# 다운힙 정의 def downheap(i, hsize) : # 현재노드, 이진 힙 크기 # 다운힙 하기 위한 조건 : 왼쪽 자식이 있을 때 while (2*i &lt;= hsize) : k = 2*i # 왼쪽 자식 / 자식 승자 if k &lt; hsize and a[k] &lt; a[k+1] : # 오른쪽 자식이 있고 + 오른쪽 자식이 왼쪽 자식보다 크다면 k += 1 # 자식승자 (오른쪽 자식) if a[i] &gt;= a[k] : break # 다운힙 그만한다 a[i], a[k] = a[k], a[i] # 루트와 자식승자 교환 i = k # 자식승자 자리가 다시 루트이자 현재노드가 된다. # 초기 힙 생성 정의 def create_heap(a) : hsize = len(a) - 1 for i in reversed(range(1, (hsize//2)+1)) : # 가장 아래 서브트리 루트~루트R 까지 다운 힙 downheap(i, hsize)# 힙 정렬 정의def heap_sort(a) : N = len(a) - 1 # 맨 마지막 노드 이면서 동시에 이진 힙 크기 for i in range(N) : a[1], a[N] = a[N], a[1] # 루트R과 제일 마지막 노드 교환 downheap(1, N-1) N -= 1 힙 정렬 알고리듬 테스트# 힙 정렬 알고리듬 테스트 a = [None,54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]print('정렬 전:\\t', end='')print(a)create_heap(a) # 최대 힙 생성 print(f'최대힙: {a}')heap_sort(a)print(f'힙 정렬 후(오름차순): {a}')정렬 전: [None, 54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]최대힙: [None, 93, 88, 77, 26, 77, 31, 49, 20, 17, 54, 11, 17, 22, 44, 17, 10]힙 정렬 후(오름차순): [None, 10, 11, 17, 17, 17, 20, 22, 26, 31, 44, 49, 54, 77, 77, 88, 93]heapq 활용한 힙 정렬힙 정렬은 이진 힙 삭제연산을 배열에 적용한 것과 같다.단지 삭제된 값을 받아서 배열에 다시 저장하는 것 뿐이다.heapq.heappop()은 최소힙에서 삭제연산 구현해준다.곧, 최솟값(루트R) 삭제 - 최소힙 속성 위해 다운힙 하는 알고리듬을 수행한다.최소힙 속성 위해 다운힙 하면 다시 그 다음 최솟값이 루트 R에 올라올 것이다. 과정을 반복한다.한편 매 삭제 과정에서 이진 힙에서 삭제된 루트R 값을 리스트에 append 함수로 추가해준다.그러면 리스트 0번부터 -1까지 최솟값 ~ 최댓값 순으로 오름차순 정렬 될 것이다.아래 코드는 위 생각을 코드로 구현한 것이다.구현# heapq 활용한 힙 정렬 import heapqa = [54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]print(f'정렬 전: {a}')heapq.heapify(a) # 배열을 최소힙으로 만드는 함수. 최대힙은 heapq._heapify_max('a')print(f'힙: {a}')정렬 전: [54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]힙: [10, 11, 17, 17, 54, 17, 44, 20, 88, 77, 93, 31, 22, 77, 49, 26]힙 정렬# 힙 정렬 s = []while a : s.append(heapq.heappop(a)) 힙 정렬 결과 출력# 힙 정렬 결과 출력print(f'heapq - 힙 정렬 이용해 오름차순 정렬 결과: {s}')heapq - 힙 정렬 이용해 오름차순 정렬 결과: [10, 11, 17, 17, 17, 20, 22, 26, 31, 44, 49, 54, 77, 77, 88, 93]합병 정렬(Merge Sort)정의배열을 균일한 두 등분으로 나눈 뒤. 정렬하면서 합병하는 알고리듬 이러한 문제 해결 방식을 분할 정복 방법 이라고도 한다.과정 배열을 더 이상 쪼갤 수 없을 때 까지 쪼갠다(크기 = 1) 크기 같은 것(또는 비슷한 것)들 끼리 서로 정렬하면서 합병한다유의점 정렬은 합병할 때 함께 일어난다. 정렬 &amp; 합병은 임시 리스트에서 일어난다. 정렬 &amp; 합병 끝나면 결과를 원본 리스트에 덮어쓴다. 임시 리스트는 입력이 배열(Array) 일 때만 사용된다. 입력이 연결리스트일 때는 임시 리스트 사용 안 한다.예시 가장 마지막 2개 부분리스트 정렬 &amp; 합병 하는 과정만 좀 더 상세히 나타냈다. 두번째 그림 맨 아래 임시리스트를 원본 리스트에 덮어쓴다.합병 정렬 구현합병 정렬 정의# 합병정렬 정의 def merge_sort(a, b, low, high) : if low &gt;= high : return # 재귀중지, low=high:크기 1이라서 정렬 안한다, low &gt; high: 정렬 할 게 없다 mid = low + (high-low)//2 merge_sort(a,b, low, mid) merge_sort(a, b, mid+1, high) merge(a,b,low, mid, high) # 재귀 결과, 정렬 &amp; 합병 동시에 이루어진다.# 합병 정의# mid 와 high는 고정되어 있다. def merge(a,b, low, mid, high) : i = low # 앞쪽 리스트에서 포인터 현재위치 j = mid + 1 # 뒤쪽 리스트에서 포인터 현재위치 for k in range(low, high+1) : # k는 임시리스트 B 안에서 현재 위치 if (i &gt; mid) : # 앞쪽 리스트 소진된 경우 b[k] = a[j] j += 1 elif (j &gt; high) : # 뒤쪽 리스트 소진된 경우 b[k] = a[i] i += 1 elif (a[i] &gt; a[j]) : b[k] = a[j] j += 1 else : b[k] = a[i] i += 1 for k in range(low, high+1) : # 임시배열에 저장된 정렬 결과 원래 배열에 덮어쓴다 a[k] = b[k]합병 정렬 알고리듬 테스트# 알고리듬 테스트 - 1a = [2,3,1,6,7,5,4,9]b = [None]*len(a)print(f'정렬 전:{a}')merge_sort(a,b, 0, len(a)-1)print(f'정렬 후:{a}')정렬 전:[2, 3, 1, 6, 7, 5, 4, 9]정렬 후:[1, 2, 3, 4, 5, 6, 7, 9]재귀호출 과정을 정리하면 아래와 같다. merge_sort(a,b, low=0, high=7) mid = 3 merge_sort(a,b, low=0, mid=3) # 앞 mid = 1 merge_sort(a,b, low=0, mid = 1) mid = 0 merge_sort(a, b, low=0, mid=0) # 정렬 x. 크기 1짜리다 return merge_sort(a,b, mid+1=1, high=1) # 정렬 x. 크기 1짜리다 return merge(a,b, low=0, mid=0, high=1) $\\Rightarrow$ 합병정렬. (0,1)위치 두 개 합병 merge_sort(a,b, mid+1=2, high=3) mid = 2 merge_sort(a,b, low=2, mid=2) # 정렬 x. 크기 1짜리다 return merge_sort(a,b, mid+1=3, high=3) # 정렬 x. 크기 1짜리다 return merge(a,b, low=2, mid=2, high=3) $\\Rightarrow$ 합병정렬. (2,3)위치 두 개 합병 merge(a,b, low=0, mid=1, high=3) $\\Rightarrow$ 합병정렬. (0,1,2,3) 위치 정렬 &amp; 합병 완료 merge_sort(a, b, mid+1=4, high=7) # 뒤 mid=5 merge_sort(a,b, low=4, mid=5) mid=4 merge_sort(a,b, low=4, mid=4) # 정렬 x. 크기 1짜리다 return merge_sort(a,b, mid+1=5, high=5) # 정렬 x. 크기 1짜리다 return merge(a,b, low=4, mid=4, high=5) $\\Rightarrow$ 합병정렬. (4,5)위치 두 개 합병 merge_sort(a,b, mid+1=6, high=7) mid=6 merge_sort(a,b, low=6, mid=6) # 정렬 x. 크기 1짜리다 return merge_sort(a,b, mid+1=7, high=7) # 정렬 x. 크기 1짜리다 return merge(a, b, low=6, mid=6, high=7) $\\Rightarrow$ 합병정렬. (6,7)위치 두 개 합병 merge(a,b, low=4, mid=5, high=7) $\\Rightarrow$ 합병정렬. (4,5,6,7)위치 정렬 &amp; 합병 완료 merge(a,b, low=0, mid=3, high=7) $\\Rightarrow$ 합병정렬. 전체 정렬 &amp; 합병 완료. # 알고리듬 테스트 -2a = [54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]b = [None]*len(a) # 임시배열 print(f'정렬 전:{a}')merge_sort(a, b, 0, len(a)-1)print(f'정렬 후:{a}')정렬 전:[54, 88, 77, 26, 93, 17, 49, 10, 17, 77, 11, 31, 22, 44, 17, 20]정렬 후:[10, 11, 17, 17, 17, 20, 22, 26, 31, 44, 49, 54, 77, 77, 88, 93]합병 정렬 성능시간복잡도항상 $O(N\\log{N})$ 시간복잡도 걸린다. 입력의 상태(데이터 분산 정도)에 영향 안 받는다. 입력 크기 $N$ 일 때. 합병 정렬이 비교연산에 쓰는 시간은 $O(N)$ 이다. 외부정렬 알고리듬이다. 전체 데이터는 하드에 저장되어 있고, 램에 일부만 불러온다. 램에 불러온 일부를 정렬한 뒤 하드에 저장하는 과정 반복한다. 결과로 하드에는 여러 개의 정렬된 블록이 들어있다. 이 블록들 병합은 하드 내에서 이루어진다. 곧, 전체 데이터의 정렬은 하드 내에서 이루어지는 셈이다. 속도가 느리다.입력 크기보통 $2^{k}$ 크기 입력을 받아 합병 정렬한다.정렬 알고리듬 안정성: 보장" }, { "title": "[Keras/딥러닝 공부] 머신러닝 기법 분류, 데이터셋 분리 기법, 데이터 전처리 기법, 규제 기법, 머신러닝 작업 흐름", "url": "/bioinfo.github.io/posts/machine_learning_basic/", "categories": "Data Science, python, Keras, deep learning", "tags": "data science, python, keras, deep learning", "date": "2022-02-04 00:00:00 +0900", "snippet": "아래 내용은 ‘케라스 창시자에게 배우는 딥러닝 (프랑소와 슐레 저, 박해선 옮김, 길벗 출판사)’ 을 공부한 뒤, 배운 내용을 제 언어로 정리.기록한 것 입니다.머신러닝 네 가지 분류지도 학습정의사람이 정답 주고, 모델이 주어진 정답 잘 맞추도록 학습시키는 기법종류 분류 회귀 시퀀스 생성 구문 트리 예측 물체 감지 이미지 분할비지도 학습정의데이터 자체의 특성 파악. 추출하도록 학습시키는 기법종류 차원 축소 군집(Clustering)자기 지도 학습정의사람이 개입하지 않는 지도학습 모형이 경험적 알고리듬(heuristic algorithm) 사용해 입력 데이터로부터 레이블 생성한다.종류 오토인코더(autoencoder) 시간에 따른 지도 학습강화학습정의모형이 주어진 상황에서 보상 강화하는 출력을 선택하도록 학습시키는 기법 아직 현장에서는 잘 사용되지 않고, 연구 영역에 있다. 하지만 발전 가능성, 비전 있는 머신러닝 분야다.예게임에서 강화학습 게임 속 전장 상황이 주어지면, 모형이 게임 점수 최대화 할 수 있는 게임 내 행동을 출력머신러닝 모델 평가‘일반화 할 수 있는 모델 평가’$\\Rightarrow$ 새 데이터셋에서 모델 성능 평가 모델 성능 평가 위해 ‘신뢰할 수 있는 모델 성능 측정 방법’이 필요하다.데이터셋을 훈련용, 검증용, 테스트용 셋으로 나누기모델 훈련시키고 성능 평가하는 과정 훈련용 셋에서 모델을 훈련시킨다. 검증용 셋으로 새 데이터셋에서 모델 성능 평가한다. 검증용 셋 결과 가지고. 신경망 각 층의 히든유닛 수, 층 수 등 하이퍼파라미터 ‘튜닝’한다. 모델 성능 올리기 위한 작업이다. 튜닝된 모델을 다시 훈련용 셋으로 훈련시키고, 성능 검증하고, 튜닝한다. 튜닝 모두 끝나면 테스트용 셋으로 딱 한 번 모델 성능 평가한다.테스트용 셋 따로 두는 이유과정 중 하이퍼파라미터 튜닝 반복하면서 모델이 검증용 셋에 과적합 되는 경향 나타난다.따라서 튜닝 반복하다 보면 검증용 셋에서 성능이 갈수록 올라갈 수 밖에 없다.모델 일반화 성능 제대로 평가하기 위해 완전히 새로운 데이터가 필요하고, 그 역할 하는 게 테스트 셋이다.데이터셋 나누는 기법단순 홀드아웃 검증Hold out: 남겨두다정의전체 셋에서 검증용 셋 따로 떼어두는 방법 테스트용 셋은 검증용 셋 분리 전에 따로 떼 두었다고 가정 훈련용 셋으로 모델 훈련시킨다 검증 셋으로 모델 성능 검증하고, 하이퍼파라미터 튜닝한다장점단순하다. 복잡한 작업 필요 없다.단점데이터 적으면 훈련용 셋과 검증용 셋의 전체 데이터에 대한 통계적 대표성 떨어진다.$\\Rightarrow$ 데이터 수 적을 때는 적용할 수 없다.K-겹 교차검증데이터 수 작을 때 특히 유용한 방법이다.정의전체 데이터셋 k개 분할로 나눠 그 중 하나는 검증용 셋, 나머지는 훈련용 셋으로 삼는 방법 모델 훈련 - 검증 과정 k번 반복한다. k개 성능 점수 평균을 최종 성능 점수로 삼는다.셔플링 사용한 반복 K-겹 교차검증데이터 수 작을 때 특히 유용한 방법이다.정의P번 반복해서 K-겹 교차검증 수행 K-겹 교차검증 수행 하기 전 매번 데이터셋 무작위로 섞는다(셔플) P번의 K-겹 교차검증 점수 평균이 최종 점수 된다.단점시간 많이 걸린다.이외 기억해야 할 점 데이터셋을 훈련용 셋, 검증용 셋, 테스트 셋으로 나누기 전에 되도록 데이터셋 한번 섞자(셔플).# 셔플 np.random.shuffle(data) 데이터에 시간 순서가 나타나면 절대 섞으면 안 된다. 훈련용 셋은 상대적으로 과거 데이터, 테스트 셋은 상대적으로 미래 데이터로 구성되도록 분리하자. 데이터셋에 중복된 데이터(레코드)가 있으면 제거하는 것이 좋다. 데이터 전처리데이터 전처리 기법들은 입력 데이터 종류별로 특화되어 있다. 예컨대 이미지, 텍스트 데이터 전처리 방법이 다르다.신경망 위한 데이터 전처리 일반론벡터화(데이터 벡터화)정의입력 데이터를 부동 소수점 실수 또는 정수로 구성된 텐서로 변환하는 작업. 신경망 모든 입력은 텐서여야 하므로, 데이터 전처리 할 때 반드시 거치는 과정이다.정규화정의각 데이터를 0과 1 사이(또는 작은 값) 로 변환하고, 특성값들 간 스케일 맞춰주는 작업이다. 신경망의 원활한 학습 위해 반드시 거쳐야 할 과정이다.보다 엄격한 정규화(수학적 정규화)정의각 특성 별 데이터를 평균이 0, 표준편차가 1로 만드는 작업.누락된 값(Null/NA) 값 다루기전체 평균에 영향 미치지 않는 값으로 누락된 값 채운다.Null 자리에 뭘 넣는가 일반적으로 0 넣는다. 평균값을 넣기도 한다. 중앙값을 넣기도 한다.만약 훈련용 셋 누락 값을 그 평균. 중앙값으로 대체하기로 했다면,테스트 셋 누락 값도 훈련용 셋 평균. 중앙값으로 대체해야 한다.교차검증 할 때도 검증용 셋 누락 값은 훈련용 셋 평균. 중앙값으로 채워야 한다.만약 훈련용 셋에 누락 값 없는데 테스트셋에 있다면?모델이 훈련 받을 때 누락 값 처리 방법을 학습하지 못했으므로, 문제 발생한다.따라서 전체 데이터셋에서 누락 값 있는 샘플(레코드 or 행벡터) 수가 적다면, 테스트셋 떼어놓기 전 이 레코드들 제외한다. 누락된 값 있는 특성이 별로 안 중요하면, 이 특성을 통째로 제외하고 테스트셋 떼어 놓는다.특성 공학정의원본 데이터에서 특성만 추출해서 데이터 변환하는 작업. 문제에 대한 명료한 정의를 내릴 수 있어야 한다.예시시계 사진(이미지) 에 나타난 시간 정보 출력하는 모형 만들고 싶다. 시계 사진 그대로 써서 정보 추출하기에는 보다 복잡한 모형, 높은 컴퓨팅 파워 필요하다.한편 시계 사진 데이터에 특성 공학 적용하면 아래와 같아진다.내가 추출하고 싶은 정보는 ‘시간 정보’다.그러면 굳이 원본 데이터 전체가 필요 없다. 시간 정보만 있으면 된다.$\\Rightarrow$ 원본 데이터에서 시간 정보 나타내는 특성만 추출한다.여기서 ‘시간’에 대한 정의가 필요하다.시간 정의: 초침과 분침이 가리키는 지점.$\\Rightarrow$ 원본 데이터에서 초침과 분침이 가리키는 지점 정보만 추출한다.또는시간 정의: 초침과 분침이 이루는 각도.$\\Rightarrow$ 원본 데이터에서 초침과 분침이 이루는 각도 정보만 추출한다.결과로2차원 벡터공간 상의 특정 지점(point)또는원점과 2차원 직교좌표계를 중심으로 한 어떤 각도 값들로구성된 1차원 텐서(벡터)가 나올 것이다.이 벡터가 원본 이미지 데이터가 ‘변환된’ 데이터 이고, 이렇게 원본 데이터 변환하는 작업을 ‘특성 공학’ 이라 한다.쓰임 특성 공학은 전통적 머신러닝 기법들 사용할 때 아주 중요하게 쓰인다. 딥러닝 기법 사용할 때는 특성 공학 필요 없다.그럼에도 특성 공학 사용하면. 딥러닝 모델 썼을 때 보다. 특정 문제를 더 적은 자원 &amp; 훨씬 효율적으로 해결할 수 있다. 위 시계 문제가 예다. 데이터 수 적어서 딥러닝 모델 적용할 수 없을 때. 특성 공학 사용하면 적은 데이터로 문제 효과적으로 해결할 수 있다.과대적합과 과소적합머신러닝 근본 이슈는 ‘일반화’와 ‘최적화’ 사이 줄다리기최적화는 ‘훈련 데이터’에서 모델 성능 최대화 하기 위해 최적 파라미터 찾는 작업 말한다.일반화는 ‘새 데이터’에서 모델 성능이 잘 나오도록 하는 걸 말한다.최적화가 과도하면 과대적합 나타난다. 모델 일반화 성능은 떨어진다.반면 최적화 부족하면 과소적합 나타난다. 모델 일반화 성능 더 끌어올릴 여지 남아있다.과대적합(Overfitting)모든 머신러닝 문제에서 과대적합은 종종.자주. 마주치는 문제다.따라서 머신러닝에서는 과대적합 잘 제어하는 것이 중요하다.정의모델이 학습 데이터에 특화된 패턴을 학습하기 시작한 상태.$\\Rightarrow$ 모델이 학습 데이터와 레이블을 ‘외워버리기 시작한’ 상태.과대적합 있을 때 모델 성능과대적합이 나타나면 검증용 셋에서 모델 성능은 떨어지기 시작한다.테스트 셋에서도 모델 성능이 낮게 나온다. 곧, 과대적합 나타나면 모델 일반화 성능 떨어진다.과소적합(Underfitting)모델 훈련 초기에 나타난다.정의모델이 훈련 데이터에 나타난 특징들을 아직 충분히(모두) 학습하지 못한 상태.과소적합 있을 때 모델 성능과소적합 있을 때, 모델 성능은 훈련용 셋과 검증용 셋 모두에서 함께 증가한다.과소적합 있을 때는 모델 성능이 아직 더 향상될 여지가 남아있다. 과소적합 상태 끝나고나면 곧이어 과대적합 나타나기 시작한다.규제(Regularization)정의모델에 과대적합 발생 억제하는 과정 모델에 과대적합 발생하면 모델 일반화 성능(모델 개발 목표)이 떨어진다. 그래서 규제 통해 과대적합 발생 억제한다.종류더 많은 훈련 데이터 모으기과대적합 억제하는 가장 좋은 방법이다. 훈련 데이터가 많으면 많을 수록. 과대적합 발생 억제되고, 모델 일반화 성능도 올라간다.네트워크 크기 축소(모델 학습 파라미터 수 줄이기)*학습 파라미터 수 = 모델 크기 = 모델 용량모델 학습 파라미터 수를 줄인다는 건. 모델이 제한적 정보만 저장할 수 있도록 한다는 거다.모델이 제한적 정보만 저장하게 되면. 보다 중요한 패턴에 집중하게 된다.이렇게 해서 모델 일반화 성능을 끌어올릴 수 있다.(딥러닝 모델은 항상 과대적합 쪽으로 흘려가려는 경향이 있다. 즉, 놔두면 과도한 최적화 쪽으로 알아서 흘러간다는 거다. 따라서 우리의 관심사는 ‘일반화’다)다만 유념해야 할 것은. 모델 학습 파라미터 수 너무 줄이면 과소적합 발생한다는 거다.따라서 과대적합 피하기 위해 학습 파라미터 수를 줄이되, 적정한 정도로 줄이는 것이 좋다.학습 파라미터 수는 층 수 또는 각 층 히든유닛 수 줄이면 감소된다.가중치 규제 추가가중치 ‘크기’ 규제.정의: 가중치가 작은 값만 갖도록 규제하는 작업이다.방법: 손실함수에 가중치 크기만큼 손실(비용) 추가한다.가중치 규제 종류:L1규제: 가중치 벡터 요소들의 절댓값에 비례하는 비용을 손실함수에 추가한다(가중치 L1 놈(norm))$\\Rightarrow$ 손실함수 + 비용(상숫값)L2규제: 가중치 벡터 놈 제곱을 손실함수에 추가한다(가중치 L2 놈(norm)). 가중치 감쇠(weight decay) 라고도 한다.$\\Rightarrow$ 손실함수 + 가중치 크기(상숫값) 케라스에서 모형에 가중치 규제 적용하려면 각 층 kernel_regularizer 매개변수에 가중치 규제 객체 전달하면 된다.# 모델에 가중치 규제 적용 예 from keras import regularizers model = models.Sequential() model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))model.add(layers.Dense(1, activation='sigmoid')) l2(0.001)은 가중치 행렬 요소 제곱 합 값에 0.001 곱한 결과값을 손실함수에 더한다는 뜻이다. 이 결과값 항을 ‘패널티 항’ 이라고도 한다. 패널티 항은 훈련할 때만 손실함수에 추가된다. 훈련할 때 손실함수에 패널티 항이 추가되면서. 훈련 손실은 추가 전보다 높아질 것이다. 한편 손실함수 최적화 하면서 가중치 크기도 자연스레 함께 줄어들 것이다. 가중치 크기 작아지면 과대적합 완화할 수 있다. 훈련 완료된 모델은 과대적합에 잘 견딜 것이다. 따라서 모델을 검증용 데이터로 성능 테스트하면. 검증 손실 그래프 기울기가 훨씬 완만하게 증가할 것이다. 곧, 모델 일반화 성능도 보다 높일 수 있다.l2 규제 이외 l1규제 또는 l1, l2규제 동시 적용 위해 아래 코드를 적용할 수 있다.# l1규제, l1,l2규제 동시 적용 from keras import regularizersregularizers.l1(0.001) # l1규제 regularizers.l1_l2(l1=0.001, l2=0.001) # l1, l2규제 동시 적용 드롭아웃 추가드롭아웃 정의훈련 동안. 층의 출력 특성 중 일부를. 무작위로. 0 만드는 규제기법.특징 각 층에 적용한다. 가장 효과적이고 널리 사용되는 규제기법이다. 훈련 동안만 적용한다.드롭아웃 비율층 출력의 요소 중 몇% 를 0으로 만들지 나타내는 비율이다.예컨대 드롭아웃 비율이 0.5 면 층 출력 요소 중 절반을 랜덤하게 0 만든다.층 출력이 $[0.5, 0.2, 0.4, 0.6]^{T}$ 이라고 하면. 0.5 비율로 드롭아웃 적용했을 때 $[0, 0.2, 0.4, 0]^{T}$ 으로 바뀌는 식이다. 테스트 단계에서는 드롭아웃 적용하지 않는다. 대신, 각 층 출력의 요소들을 드롭아웃 비율만큼 스케일 다운 해야 한다. 예컨대 드롭아웃 비율이 0.5 였으면, 테스트 단계 각 층 출력 요소들에 0.5씩 곱해서 스케일을 절반으로 줄인다. 테스트 단계 층 출력이 $[1,2,3,4]^{T}$ 면, 각 요소에 0.5 씩 곱해서 $[0.5, 1, 1.5, 2]^{T}$ 로 스케일 낮추는 식이다.테스트 단계 출력 스케일 유지하는 다른 방법훈련 단계 층 출력에 드롭아웃 적용하고, 출력 각 요소들을 드롭아웃 비율만큼 역으로 스케일 업 시킨다.예컨대 드롭아웃 비율이 $0.5$ 였으면. 층 출력 각 요소들 스케일 $2$ 배로 키운다.$[1,2,3,4]^{T} \\Rightarrow [2,4,6,8]^{T}$이러면 테스트 단계 층 출력은 스케일 변화시킬 필요 없다.드롭아웃 규제기법이 과대적합 감소시키는 원리층 출력에 노이즈 추가($0$) 해서. 훈련 데이터에 특화된 지엽적 패턴을 깨뜨린다.결과로 훈련 동안 모델이 지엽적 패턴을 학습하지 못하게 되고, 훈련 데이터의 주요 패턴(특성)만 집중적으로 학습하게 될 것이다. 이는 과대적합 회피로 이어진다.케라스에서 드롭아웃 적용각 층 바로 다음에 드롭아웃 층을 배치하는 방식으로 각 층에 드롭아웃 적용할 수 있다.# 모델 각 층에 드롭아웃 적용 model = models.Sequential() model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))model.add(layers.Dropout(0.5)) # 드롭아웃 비율 = 0.5model.add(layers.Dense(16, activation='relu'))model.add(layers.Dropout(0.5)) # 드롭아웃 비율 = 0.5model.add(layers.Dense(1, activation='sigmoid'))보편적 머신러닝 작업 흐름1. 문제 정의 &amp; 모델 학습시킬 데이터 수집내가 지금 해결하려는 문제가 이진 분류인지, 다중 분류인지, 회귀인지 파악해야 한다.동시에 지금 문제 해결을 위해 필요한 데이터는 무엇인지, 그 데이터를 구할 수 있는지 등도 따져봐야 한다.2. 모델 성능 측정 지표 설정하기 &amp; 손실함수 선택하기모델 성능 측정 지표가 손실함수 선택 기준이 된다.3. 모델 성능 검증 방법 설정하기(데이터셋 나누기)단순 홀드아웃 검증, K-겹 교차검증, 반복 K-겹 교차검증 중 한 방법을 선택해 전체 데이터셋을 훈련용 셋과 검증용 셋으로 분리한다.단순 홀드아웃 검증 - 전체 데이터셋을 훈련용 셋과 검증용 셋으로 나눈 뒤 검증용 셋으로 일반화 성능 검증한다.K-겹 교차검증 - 전체 셋을 K개로 나눈 뒤 그 중 하나는 검증용 셋, 나머지는 훈련용 셋으로 사용한다. K번 과정 반복한다.반복 K-겹 교차검증 - K-겹 교차검증을 P번 반복한다. 단, K-겹 교차검증 매번 시행하기 전에. 셔플(Shuffle) 통해 데이터셋을 함 섞는다.대부분 경우 단순 홀드아웃 검증이면 충분하다. 데이터가 충분할 것이기 때문이다.하지만 데이터가 부족한 경우엔 K-겹 교차검증 또는 반복 K-겹 교차검증이 유용한 대안이다.4. 데이터 전처리 신경망의 입력은 텐서다. 텐서는 넘파이 다차원 배열을 일컫는다. 따라서 신경망에 데이터 주입 전, 모든 데이터를 부동 소수점 실수 또는 정수 텐서로 바꿔줘야 한다. 각 특성값들은 모두 스케일이 비슷해지도록 조정해야 한다. 대표적 방법으로 정규화가 있다. 데이터 수가 적어서 신경망 적용이 어렵거나, 굳이 신경망 안 써도 될 문제라면 특성 공학 써서 보다 효율적으로 해결할 수도 있다. 5. 크기 작은 모델로 시작하기과소적합이 있는 모델. 또는 과도한 일반화 쪽에 가까운 모델.층 수 또는 히든유닛 수 작은 모델로 적합한 모델 찾는 과정 시작한다.이런 모델을 통계적 검정력이 확보된 모델이라고도 한다.모델 만들 때 세 가지 요소를 선택한다. 마지막 층 활성화 함수: 신경망 출력 값에 필요한 제한을 가한다. 이진분류 예로 들면, 마지막 출력 층 활성화 함수로 시그모이드 함수가 들어가 출력 값을 0과 1 사이로 제한해준다. 손실함수: 풀려는 문제에 적합한 손실함수를 선택한다. 예컨대 회귀문제라면 손실함수로 $mse$ 를 선택할 것이고, 이진분류 문제라면 binary crossentropy (로그손실) 를 사용할 것이다. 최적화 알고리듬 설정: 옵티마이저와 학습률 선택한다. 일반적으로 확률적 경사 하강법(rmsprop)과 기본 학습률 사용한다. 6. 모델 몸집 키우기: 과대적합 모델 구축통계적 검정력이 확보된 모델은 크기가 작아서 과소적합 여지가 있다.곧, 성능이 더 향상될 여지가 남아있다.머신러닝을 한줄로 정의히자면 ‘일반화와 최적화 사이 줄다리기’ 로 정의할 수 있다.현재 모델 상태는 ‘과도한 일반화’ 쪽에 가깝다. 최적화 쪽으로 옮겨서 둘 사이의 균형점에 도달해야 한다.하지만 실제로 과소적합과 과대적합 사이 적절한 균형점이 어디인지는 알 수 없다.따라서 균형점에 도달하기 위해 일단 균형점을 지나 과도한 최적화(과대적합) 쪽으로 움직인다.이를 위해 기존 모델 크기를 키운다. 곧, 과대적합 모델을 구축한다. 모델에 층 추가한다. 층 크기를 키운다(히든유닛 수 증가). 더 많은 에포크 동안 훈련한다. 크기 많이 키울 수록 매우 빠르게 과대적합 도달할 것이다.모델 검증 손실이 증가하기 시작하는 지점부터 과대적합에 도달한 것이다.이제 모델 규제와 하이퍼파라미터 튜닝 통해 과대적합을 억제하면서. 과소적합과 과대적합 사이 균형점을 찾을 것이다.7. 모델 규제와 하이퍼파라미터 튜닝반복적으로 모델을 ‘수정’ 하고 ‘훈련’하고 검증데이터에서 ‘평가’한다. 좋은 모델을 얻을 때 까지 반복한다.위에서 모델 규제 방법들을 열거했다. 훈련 데이터 수 증가시키기 네트워크 크기 축소(학습 파라미터 수 줄이기) 가중치 크기 규제(가중치 크기가 작도록) 드롭아웃 추가한편 층 수, 히든유닛 수, 옵티마이저 학습률 등을 조정하는 걸 하이퍼파라미터 튜닝 이라고 정의했다.과대적합된 모델의 검증 결과를 바탕으로 위 규제와 튜닝을 적용한다. 그리고 모델을 훈련데이터로 다시 훈련시킨다.훈련된 모델을 검증 데이터로 다시 검증하고, 그 결과를 통해 다시 규제하고 튜닝한다. 주의점: 모델 수정을 반복할 때 마다 모델이 서서히 검증 데이터에 익숙해진다. 검증 데이터로 모델을 학습시키지도 않았지만 모델이 검증 데이터에 ‘과대적합’ 될 수 있다. 따라서 모델 튜닝을 너무 많이 반복하는 건 검증 데이터 신뢰성을 떨어뜨린다.과정을 반복하면서 만족할 만 한 모델을 얻었다면, 훈련용 데이터와 검증용 데이터를 합친 전체 데이터셋으로 모델을 훈련시킨다. 그 후 테스트 데이터셋으로 모델 일반화 성능을 검증한다.만약 테스트 데이터셋에 나타난 모델 일반화 성능이 검증에서 나타난 일반화 성능보다 많이 나쁘다면. 이는 검증 데이터셋 자체가 애초에 신뢰성이 없었거나(편향 등) 모델이 수정 반복하면서 검증용 셋에 과대적합 된 결과일 수 있다.어찌됬건 둘 다 검증용 셋이 신뢰성을 잃어버린 경우다. 따라서 기존 모델 파기하고, 새 모델에 대해 반복 K-겹 교차검증 등을 써서 검증함으로써 검증 과정 신뢰성을 확보해야 한다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 삽입 정렬, 버블 정렬, 쉘 정렬 알고리듬", "url": "/bioinfo.github.io/posts/sort_series/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, python, study, data science", "date": "2022-02-03 00:00:00 +0900", "snippet": "삽입 정렬(Insertion Sort) 알고리듬정의정렬 안 된 부분 가장 왼쪽 원소를 정렬 된 부분에 ‘삽입’하는 정렬 알고리듬 정렬 후 정렬 된 부분 원소 수 1 증가 정렬 후 정렬 안 된 부분 원소 수 1 감소메커니즘정렬 안 된 부분 가장 왼쪽 원소. 정렬된 부분 원소와 비교한 뒤. 자기 자리 찾아 삽입. 정렬 안 된 부분 가장 왼쪽 원소에 대해. (비교 - 이동 - 삽입) 반복. 정렬 안 된 부분 원소 다 사라질 때 까지 반복알고리듬 적용 예삽입 정렬 성능삽입 정렬 성능은 입력에 민감하게 반응한다(Input Sensitive)입력: 이미 정렬된 배열 최선 경우 수행: 비교연산만 $N-1$ 번 수행$\\Rightarrow O(N)$ 시간복잡도입력: 역으로 정렬된 배열 최악 경우 수행: 비교, 이동, 삽입 이동횟수 $= 1+2+…+(N-2)+(N-1) = \\frac{N(N-1)}{2}$$\\Rightarrow O(N^{2})$ 시간복잡도입력: 랜덤으로 배열된 데이터들 평균 경우 수행: 비교, 이동, 삽입 이동횟수 $= \\frac{1}{2} \\times \\frac{N(N-1)}{2} = \\frac{N(N-1)}{4}$$\\Rightarrow O(N^{2})$ 시간복잡도$\\Rightarrow$ 삽입 정렬은 일반적으로 $O(N^{2})$ 시간복잡도가 걸리고, 최선 경우에만 $O(N)$ 시간복잡도 걸린다. 효율성 떨어지는 정렬 알고리듬이다.삽입 정렬 특징아래 경우 삽입 정렬은 효율적이다. 이미 정렬된 배열에 소량의 데이터만 추가해서 다시 정렬할 때 애초에 입력 크기가 작을 때높은 알고리듬 단순성, but 입력 크기 클 수록 비효율적 알고리듬 자체도 단순하고, 재귀호출도 사용 안 한다. 입력 크기 클 수록 많은 이동 발생한다. 따라서 비효율적이다.합병 정렬, 퀵 정렬 성능 향상에 도움 준다. 합병, 퀵 정렬 알고리듬과 함께 사용되어서, 두 알고리듬의 실질적 성능 향상에 기여한다. 단, 이론적 성능보다 실제 성능이 더 잘 나오는 거다. 이론적 성능은 향상되지 않는다.정렬 알고리듬 안정성이 보장된다. 정렬 후. 키 값 같은 원소들 사이 상대적 위치가 유지된다.삽입 정렬 알고리듬 구현삽입 정렬 알고리듬 정의# 삽입정렬 알고리듬 정의 def insertion_sort(A) : n = len(A) for i in range(1, n) : key = A[i] # 정렬 안 된 부분 가장 왼쪽 원소 j = i-1 # 비교 - 이동 조건 만족하는 한 반복 while j &gt;= 0 and A[j] &gt; key : # 비교 A[j+1] = A[j] j = j-1 A[j+1] = key # 삽입 printStep(A, i)정렬 결과 출력 정의# i번째 루프. 정렬 결과 출력 정의def printStep(arr, loop) : print(f'{loop}번째 루프. 정렬 결과:', end=' ') print(arr)알고리듬 테스트# 알고리듬 테스트 data = [5,3,8,4,9,1,6,2,7] # 정렬 전print('정렬 전:', data)insertion_sort(data)print('삽입 정렬 종료 결과:', data)정렬 전: [5, 3, 8, 4, 9, 1, 6, 2, 7]1번째 루프. 정렬 결과: [3, 5, 8, 4, 9, 1, 6, 2, 7]2번째 루프. 정렬 결과: [3, 5, 8, 4, 9, 1, 6, 2, 7]3번째 루프. 정렬 결과: [3, 4, 5, 8, 9, 1, 6, 2, 7]4번째 루프. 정렬 결과: [3, 4, 5, 8, 9, 1, 6, 2, 7]5번째 루프. 정렬 결과: [1, 3, 4, 5, 8, 9, 6, 2, 7]6번째 루프. 정렬 결과: [1, 3, 4, 5, 6, 8, 9, 2, 7]7번째 루프. 정렬 결과: [1, 2, 3, 4, 5, 6, 8, 9, 7]8번째 루프. 정렬 결과: [1, 2, 3, 4, 5, 6, 7, 8, 9]삽입 정렬 종료 결과: [1, 2, 3, 4, 5, 6, 7, 8, 9]버블 정렬(Bubble Sort) 알고리듬정의인접한 2개 원소 비교해서. 순서대로 되어있지 않으면 서로 교환하는 정렬 알고리듬. 비교 &amp; 교환 과정을 리스트 왼쪽 끝에서 오른쪽 끝 까지 반복 리스트 전체가 정렬 될 때 까지 정렬 루프 반복한다. 루프 1회 끝날 때 마다. 최댓값 원소가 리스트 오른쪽 끝에 배치되고. 비교 대상에서 제외된다. 루프 최대 횟수는 $n-1$버블 정렬 예시버블 정렬 성능비교횟수항상 $\\frac{n(n-1)}{2}$.따라서 비교연산 시간복잡도도 항상 $O(n^{2})$이동횟수 최악 경우(입력이 역순으로 정렬된 경우): 3 $\\times$ 비교횟수 $\\Rightarrow O(n^{2})$ 최선 경우(입력이 이미 정렬된 경우): 이동 없다. 비교연산만 한다. 평균 경우: $O(n^{2})$$\\Rightarrow$ 버블정렬은 일반적 경우. 비교, 이동 모두 각각 $O(n^{2})$ 시간복잡도 걸린다.비효율적이다.버블 정렬 특징 알고리듬 단순하다. 구현도 쉽다. 최악 경우(가장 큰 값이 왼쪽 끝에 있을 때), 원소가 왼쪽 끝에서 오른쪽 끝으로 이동하기 위해 모든 원소와 교환 일어나야 한다. 특정 요소가 이미 최종 정렬 위치에 놓여 있더라도 교환 발생한다.단순한 알고리듬에도 불구하고, 거의 사용하지 않는다.버블 정렬 구현버블 정렬 정의# 버블 정렬 알고리듬 정의 def bubble_sort(A) : n = len(A) # 정렬 안 된거 개수 # 버블정렬 반복 루프(최대 n-1 번 반복) for i in range(n-1, 0, -1) : change_happened = False for j in range(i) : if A[j] &gt; A[j+1] : # 비교 A[j], A[j+1] = A[j+1], A[j] # 교환 change_happened = True if not change_happened : break # 버블정렬 루프에서 유의미한 정렬 발생 안 했으면 루프 종료 (이미 정렬 완료됨) printStep(A, n-i) # 이번 루프 정렬 결과 출력 루프 정렬 결과 출력 정의# 루프 정렬 결과 출력 정의 def printStep(arr, loop) : print(f'{loop}번째 루프:', end='') print(arr)알고리듬 테스트 -1# 알고리듬 테스트 #1data = [5,3,8,1,2,7]print('정렬 전:', data)bubble_sort(data)print('정렬 후:', data)정렬 전: [5, 3, 8, 1, 2, 7]1번째 루프:[3, 5, 1, 2, 7, 8]2번째 루프:[3, 1, 2, 5, 7, 8]3번째 루프:[1, 2, 3, 5, 7, 8]정렬 후: [1, 2, 3, 5, 7, 8]알고리듬 테스트 -2# 알고리듬 테스트 # 2data = [5,3,8,4,9,1,6,2,7]print('정렬 전:', data)bubble_sort(data)print('정렬 후:', data)정렬 전: [5, 3, 8, 4, 9, 1, 6, 2, 7]1번째 루프:[3, 5, 4, 8, 1, 6, 2, 7, 9]2번째 루프:[3, 4, 5, 1, 6, 2, 7, 8, 9]3번째 루프:[3, 4, 1, 5, 2, 6, 7, 8, 9]4번째 루프:[3, 1, 4, 2, 5, 6, 7, 8, 9]5번째 루프:[1, 3, 2, 4, 5, 6, 7, 8, 9]6번째 루프:[1, 2, 3, 4, 5, 6, 7, 8, 9]정렬 후: [1, 2, 3, 4, 5, 6, 7, 8, 9]쉘 정렬(Shell Sort) 알고리듬정의효율 높인 삽입 정렬.메커니즘 h만큼 간격 떨어진 원소들 모아 여러 개 부분 리스트 만든다. 각 부분리스트 내에서 삽입정렬 수행 부분리스트 합친다. 1~3 과정을 h 줄여가며 반복한다. h가 1일때가 마지막이다. 일반적으로 각 루프마다 h를 절반씩 줄인다. h를 줄일 때 마다 각 부분리스트 원소 수는 증가한다.예시쉘 정렬 성능초기 간격(h) 어떻게 설정하느냐에 성능 영향 받는다. 초기 간격 크다: h가 작아질 수록 성능 올라간다. 초기 간격 작다: 쉘 정렬이 삽입정렬보다 나은 이점 제대로 활용 못한다. 성능 낮다.평균 경우 시간 복잡도: $O(N^{1.5})$최악 경우 시간 복잡도: $O(N^{2})$ 예컨대 역으로 정렬된 배열에 h = 1 에서 쉘 정렬 적용한다고 가정하자. 이는 삽입 정렬 최악 경우와 같다. 이때 시간복잡도는 $O(N^{2})$ 걸린다.일반적으로 입력 크기가 그리 크지 않을 때. 쉘 정렬 높은 성능 보인다. 전체 입력 크기가 크지 않다면. 여러 개 부분 리스트로 나누었을 때. 삽입 정렬 속도가 더 빨라질 것이다.쉘 정렬 특징 자료와 자료가 원거리 이동하면서, 전체 이동 횟수는 단순히 삽입 정렬 적용했을 때 보다 줄어들 수 있다. 각 부분 리스트는 다소 정렬된 상태다. h가 감소할 수록. 각 부분 리스트는 점차 정렬된 상태가 되어간다. 따라서 h가 감소할 수록 부분 리스트 내 삽입 정렬 속도도 빨라진다. 알고리듬이 단순하다. 임베디드 시스템에 주로 사용된다. (효율적) 쉘 정렬 구현쉘 정렬 정의# 쉘 정렬 정의def shell_sort(A): h = 3 # 간격 while h &gt;= 1 : for i in range(h, len(A)) : # 부분리스트 정렬 j = i # 부분리스트에서 정렬 안 된 부분 가장 왼쪽 원소 while (j-h &gt;= 0) and (A[j]&lt;A[j-h]) : # 비교-이동-삽입 반복 # j 앞에 어떤 값 있고 and 그 값이 오름차순 만족 안 하면 A[j], A[j-h] = A[j-h], A[j] j = j-h printStep(A,h) # h에서 정렬 결과 출력 h = h//2 # 간격 조정 쉘 정렬 결과 출력 정의# 결과 출력 정의 def printStep(arr, h): print(f'간격 {h} 일 때 쉘 정렬 결과: {arr}')쉘 정렬 알고리듬 테스트# 알고리듬 테스트 data = [5,3,8,4,9,1,6,2,7]print(f'쉘 정렬 전: {data}')shell_sort(data)print(f'쉘 정렬 후: {data}')쉘 정렬 전: [5, 3, 8, 4, 9, 1, 6, 2, 7]간격 3 일 때 쉘 정렬 결과: [4, 2, 1, 5, 3, 7, 6, 9, 8]간격 1 일 때 쉘 정렬 결과: [1, 2, 3, 4, 5, 6, 7, 8, 9]쉘 정렬 후: [1, 2, 3, 4, 5, 6, 7, 8, 9]" }, { "title": "[2021 인공지능전문가 교육과정 복습] 정렬 개념, 선택 정렬 알고리듬", "url": "/bioinfo.github.io/posts/sort/", "categories": "Data Science, python, data structure", "tags": "data structure, python, computer science, study, data science", "date": "2022-02-01 00:00:00 +0900", "snippet": "정렬정의데이터를 ‘순서대로 배열’ 하는 일.목적탐색 편하게 하기 위해 정렬한다.전제‘순서’가 있어야 한다.순서 정의비교가능한 모든 속성.$\\Rightarrow$ 데이터 사이 ‘비교가능한 속성’ 있어야 정렬할 수 있다.순서 예시 오름차순 내림차순데이터셋 관점에서 본 정렬예컨대 다음과 같은 데이터셋이 있다고 하자.# 사이킷런 보스턴 집값 데이터셋from sklearn.datasets import load_bostondata = load_boston()datadf = pd.DataFrame( data['data'], columns=data.feature_names)df 각 열: 레코드 각 행: 필드(field) 정렬 키(sort key): 정렬 기준이 되는 필드정렬은 키 값 순서대로 레코드를 배열하는 것이다. 곧, 정렬 대상은 ‘레코드’다.예컨대 정렬 키를 AGE 로 삼아 정렬한다고 가정하자.그러면 AGE 값의 순서(예: 오름차순) 대로 각 행도 순서가 재배열 될 것이다.정렬 알고리듬 분류, 평가 기준상황별로 최적 정렬 알고리듬이 다르다. 상황에 따라 적합한 정렬 알고리듬 골라 사용하는 게 필요하다.레코드 수 많고 적음, 레코드 크기 크고 작음, key 특성(문자, 정수, 실수 등) 등에 맞춰서 정렬 알고리듬을 선정한다.정렬 알고리듬 분류 기준1. 정렬 장소 내부 정렬: 모든 데이터가 주기억장치에 저장되어 있고, 정렬도 거기서 일어난다. 외부 정렬: 대부분 데이터가 외부기억장치, 일부가 주기억장치에 저장. 정렬이 외부기억장치에서 일어난다.2. 효율성 단순하지만 낮은 효율성: 삽입, 선택, 버블정렬 등 복잡하지만 높은 효율성: 퀵, 힙, 병합, 기수정렬, 팀 등3. 정렬 알고리듬의 안정성(Stability) 보장 유무 안정성 보장된 알고리듬: 정렬해도 키 값 같은 데이터들 사이 상대적 위치(들어온 순서)는 변치 않는다. 안정성 없는 알고리듬: 정렬하면 키 값 같은 데이터들 사이에도 상대적 위치 변한다(들어온 순서 유지 안 된다).안정성 없는 알고리듬 예) 같은 키 값(10) 갖는 세 레코드가 정렬 후 순서가 뒤엉켰다. 안정성 보장된 알고리듬이었다면, 세 레코드의 들어온 순서가 정렬 후에도 유지되었을 것이다.정렬 알고리듬 성능 평가 기준1. 비교횟수2. 이동횟수선택 정렬(Selection Sort) 알고리듬정의배열의 정렬되지 않은 원소들 중 최솟값을 ‘선택’ 해서 정렬된 부분 바로 오른쪽 원소와 ‘교환’하는 정렬 알고리듬.과정1. 리스트 정렬된 부분과 정렬 안 된 부분 맨 처음에는 정렬된 부분 없음. 모두 정렬 안 된 상태다.2. 정렬 안 된 부분에서 최솟값 선택, 정렬 안 된 부분 첫번째 원소와 교환 정렬 된 부분 크기 1 증가한다. 정렬 안 된 부분 크기 1 감소한다.3. 정렬 안 된 부분 원소가 모두 사라지면 정렬 완료선택 정렬 수행 예선택 정렬 성능비교연산 시간복잡도매 루프 마다 배열의 정렬 안 된 부분에서 최솟값 찾는다. 맨 처음 루프에서 최솟값 찾기 위해 값들 간 비교 횟수: $N-1$ 두번째 루프에서 최솟값 찾기 위해 값들 간 비교 횟수: $N-2$ 마지막 루프에서 최솟값 찾기 위해 값들 간 비교 횟수: $1$ (2개 값 비교해서 1개 최솟값 찾는다)$\\Rightarrow$ 총 비교 횟수 $=$ $(N-1)+(N-2)+(N-3)+…+2+1 = \\frac{N(N-1)}{2}$$\\Rightarrow$ 비교연산 시간복잡도 $= O(N^{2})$따라서 선택 정렬 총 시간복잡도는 $O(N^{2})$선택 정렬 특징 항상 $O(N^{2})$ 시간복잡도가 보장된다. 선택 정렬 할 때 i값 - 최솟값 사이 총 교환 횟수는 $N-1$ 이다. 모든 정렬 알고리듬 중 가장 적은 원소 교환 횟수다. 정렬 알고리듬 안정성 보장하지 않는다. 곧, 정렬하면. 같은 키 값 갖는 원소들 사이 들어온 순서. 유지되지 않는다.효율성 떨어진다. 거의 이용하지 않는다 ($O(N^{2})$).선택 정렬 알고리듬 구현# 선택 정렬 알고리듬 정의 def selection_sort(A) : n = len(A) #정렬 안 된 원소 개수 for i in range(n-1) : # 오른쪽 리스트 첫번째 값 minimum = i for j in range(i+1, n) : if A[j] &lt; A[minimum] : minimum = j A[i], A[minimum] = A[minimum], A[i] # 오른쪽 리스트 첫번째 값 - 최솟값 교환 printStep(A, i+1) # 정렬 결과 출력 # 몇 번째 선택 정렬 루프인가. 그리고 그 루프 정렬 결과 출력 정의def printStep(arranged, loop) : print(f'{loop}번째 루프 정렬 결과 =', end=' ') print(arranged)리스트 예data = [5,3,8,4,9,1,6,2,7]위 리스트를 정의된 선택 정렬 알고리듬으로 정렬시키기print('정렬 전:', data)selection_sort(data)print()print('선택정렬 후', data)정렬 전: [5, 3, 8, 4, 9, 1, 6, 2, 7]1번째 루프 정렬 결과 = [1, 3, 8, 4, 9, 5, 6, 2, 7]2번째 루프 정렬 결과 = [1, 2, 8, 4, 9, 5, 6, 3, 7]3번째 루프 정렬 결과 = [1, 2, 3, 4, 9, 5, 6, 8, 7]4번째 루프 정렬 결과 = [1, 2, 3, 4, 9, 5, 6, 8, 7]5번째 루프 정렬 결과 = [1, 2, 3, 4, 5, 9, 6, 8, 7]6번째 루프 정렬 결과 = [1, 2, 3, 4, 5, 6, 9, 8, 7]7번째 루프 정렬 결과 = [1, 2, 3, 4, 5, 6, 7, 8, 9]8번째 루프 정렬 결과 = [1, 2, 3, 4, 5, 6, 7, 8, 9]선택정렬 후 [1, 2, 3, 4, 5, 6, 7, 8, 9]" }, { "title": "[2021 인공지능전문가 교육과정 복습] AVL 트리 개념, 연산, 구현", "url": "/bioinfo.github.io/posts/AVL_tree/", "categories": "Data Science, python, data structure", "tags": "data structure, python, computer science, study, data science", "date": "2022-01-29 00:00:00 +0900", "snippet": "AVL 트리균형 이진탐색트리.정의루트노드 R의 왼쪽. 오른쪽 서브트리 높이 차가 1 이내인 ‘이진탐색트리’. 언제나 높이 균형이 유지된다.특징높은 시간 효율성.$\\Rightarrow$ 항상 $O(\\log_{2}{n})$ 시간복잡도 보장. 따라서 $O(n)$ 시간복잡도(최악경우) 걸릴 일 없다.예시회전연산균형유지 연산.정의AVL 트리에 데이터 삽입. 삭제 후 균형 맞추기 위해 ‘서브트리가 회전’하는 연산.기반rotate_right()AVL트리에서 루트 왼쪽 서브트리가 오른쪽 보다 더 높아 불균형 발생할 경우.서브트리가 오른쪽으로 회전.rotate_left()AVL트리에서 루트 오른쪽 서브트리가 왼쪽 보다 더 높아 불균형 발생할 경우.서브트리가 왼쪽으로 회전.아래는 rotate_right(), roate_left()를 기반으로 한.각 상황 별 회전연산이다.‘상황 - 회전’LL- 회전rotate_right() 사용조건(루트 왼쪽 서브트리 높이 $-$ 오른쪽 서브트리 높이) $&gt; 1$$+$ 그 왼쪽 서브트리 안에서 $&gt;$ (왼쪽 서브트리 높이 $-$ 오른쪽 서브트리 높이) $&gt; 0$RR - 회전rotate_left() 사용조건(루트 왼쪽 서브트리 높이 $-$ 오른쪽 서브트리 높이) $&lt; -1$$+$ 그 오른쪽 서브트리 안에서 $&gt;$ (왼쪽 서브트리 높이 $-$ 오른쪽 서브트리 높이) $&lt; 0$LR - 회전1. 루트 왼쪽 서브트리에서 rotate_left()2. 루트에서 rotate_right()조건(루트 왼쪽 서브트리 높이 - 오른쪽 서브트리 높이) $&gt; 1$$+$ 그 왼쪽 서브트리 안에서 $&gt;$ (왼쪽 서브트리 높이 - 오른쪽 서브트리 높이) $&lt; 0$RL - 회전1. 루트 오른쪽 서브트리에서 rotate_right()2. 루트에서 rotate_left()조건(루트 왼쪽 서브트리 높이 - 오른쪽 서브트리 높이) $&lt; -1$$+$ 그 오른쪽 서브트리 안에서 $&gt;$ (왼쪽 서브트리 높이 - 오른쪽 서브트리 높이) $&gt; 0$LL, RR, RL, LR 회전연산 공통점 시간복잡도 모두 $O(1)$: 변경된 노드 레퍼런스 수가 $O(1)$ 개 이기 때문이다. 회전 후 트리 형상. 모두 동일하다.4종류 회전연산 정의 트리에서는 항상 연산 후 루트R 반환한다.LL - 회전# LL - 회전 정의 ## LL def rotate_LL(A) : B = A.left A.left = B.right B.right = A return B 노드 레퍼런스가 3번 변경되었다.RR - 회전# RR - 회전 정의 ## RRdef rotate_RR(A) : B = A.right A.right = B.left B.left = A return B RL - 회전# RL - 회전 정의 # RLdef rotate_RL(A) : B = A.right A.right = rotate_LL(B) return rotate_RR(A)LR - 회전# LR - 회전 정의 # LRdef rotate_LR(A) : B = A.left A.left = rotate_RR(B) return rotate_LL(A)AVL 트리 노드, 재균형 연산 정의AVL 트리 노드 이진탐색트리 노드에 height(노드 높이) 속성이 추가되었다.# AVL 트리 노드 정의 class Node : def __init__(self, key, value, height, left=None, right=None) : self.key = key self.value = value self.left = left self.right = right self.height = height # 추가된 속성 서브트리 높이 차 정의 루트 왼쪽 서브트리 높이 - 루트 오른쪽 서브트리 높이 루트 왼쪽 자식 노드 height 속성 값 - 루트 오른쪽 자식 노드 height 속성 값# 서브트리 높이 차 정의 def height_diff(n) : return height(n.left) - height(n.right) # 왼쪽 서브트리 높이 - 오른쪽 서브트리 높이트리 높이 정의 높이 구하려는 트리 루트노드의 height 값 루트노드가 비어있으면 높이는 0# 서브트리 높이 정의 def height(n) : if n == None : # 공트리면 높이 0 return 0 return n.height 재균형 연산 정의 왼쪽이 더 높고, 왼쪽이 더 높으면 LL - 회전 왼쪽이 더 높고, 오른쪽이 더 높으면 LR - 회전 오른쪽이 더 높고, 왼쪽이 더 높으면 RL - 회전 오른쪽이 더 높고, 오른쪽이 더 높으면 RR - 회전# 재균형 연산 정의 def rebalance(parent) : if height_diff(parent) &gt; 1 : # 왼쪽 서브트리가 오른쪽 서브트리 보다 2 이상 높을 때 if height_diff(parent.left) &gt; 0 : # 왼쪽 안에서 왼쪽이 더 큰 경우 parent = rotate_LL(parent) elif height_diff(parent.left) &lt; 0 : # 왼쪽 안에서 오른쪽이 더 큰 경우 parent = rotate_LR(parent) elif height_diff(parent) &lt; -1 : # 오른쪽 서브트리가 왼쪽보다 절댓값 2 이상 높을 때 if height_diff(parent.right) &gt; 0 : parent = rotate_RL(parent) elif height_diff(parent.right) &lt; 0 : parent = rotate_RR(parent) return parent 노드 삽입연산노드 삽입 + 재균형 작업 한 세트다. 노드 삽입은 이진탐색트리와 같은 방법으로 이루어진다. (탐색 - 탐색 실패하면 그 자리 노드 삽입) 삽입한 노드부터 루트R로 거슬러 올라가며 각 서브트리 단위에서 재균형 작업 수행한다.# 노드 삽입연산 정의 def insert(parent, node) : # 키 비교할 노드, 삽입할 노드 if (parent.key &gt; node.key) : if parent.left == None : parent.left = node else : parent.left = insert(parent.left, node) return rebalance(parent) # 균형유지 후 루트 반환 elif (parent.key &lt; node.key) : if parent.right == None : parent.right = node else : parent.right = insert(parent.right, node) return rebalance(parent) else : print('중복된 키 에러. 삽입실패') # 탐색 실패 노드 삽입연산 예10, 20, 30, 5, 3, 25, 28, 50, 40 을 AVL 트리에 순서대로 삽입하는 경우노드 삭제연산노드 삭제 + 재균형 작업 한 세트다. 노드 삭제는 이진탐색트리와 같은 방법으로 이루어진다. (탐색 - 키 찾으면 그 노드 삭제. 자식 0개냐, 1개냐, 2개냐에 따라 삭제방법 다름) 노드 삭제된 자리부터 루트R로 거슬러 올라가며 각 서브트리 단위에서 재균형 작업 수행한다.# 노드 삭제연산 정의 def del_node(self, n, key) : if n == None : return None # 삭제할 노드가 트리 안에 없음 if (n.key &gt; key) : n.left = self.del_node(n.left, key) elif (n.key &lt; key) : n.right = self.del_node(n.right, key) else : # 삭제할 노드 찾은 경우 if n.right == None : # 0, 1 return n.left elif n.left == None : return n.right # 1 else : # 2 target = n n = self.minimum(target.right) # 중위후속자 = 오른쪽 서브트리 가장 왼쪽 값(최솟값) n.right = self.del_min(target.right) n.left = target.left n.height = max(self.height(n.left), self.height(n.right)) + 1 # n의 높이 조정 return self.balance(n)AVL 트리 성능연산(탐색, 삽입, 삭제) 시간복잡도가 항상 $O(\\log{n})$ 보장된다. AVL 트리 높이에 비례한다AVL 트리 구현AVL 트리 노드 정의# 노드 정의class Node : def __init__(self, key, value, height, left=None, right=None) : self.key = key self.value = value self.height = height self.left = left self.right = right AVL 트리 객체 정의# AVL트리 클래스class AVL : def __init__(self) : self.root = None # 노드 높이 정의 def height(self, n) : if n == None : return 0 return n.height # 삽입연산 정의 def put(self, key, value) : self.root = self.put_item(self.root, key, value) def put_item(self, n, key, value) : if n == None : return Node(key, value, 1) if (n.key &gt; key) : n.left = self.put_item(n.left, key, value) elif (n.key &lt; key) : n.right = self.put_item(n.right, key, value) else : n.value = value # 키는 일치. 현재 노드 값 갱신 n.height = max(self.height(n.left), self.height(n.right)) + 1 # 루트 높이 갱신 return self.balance(n) # 루트 반환 # 불균형 처리 정의 def balance(self, n) : if self.bf(n) &gt; 1 : # 왼쪽 서브트리가 오른쪽 보다 높은 경우 if self.bf(n.left) &lt; 0 : # LR n.left = self.rotate_left(n.left) n = self.rotate_right(n) # LL elif self.bf(n) &lt; -1 : # 오른쪽 서브트리가 왼쪽보다 높은 경우 if self.bf(n.right) &gt; 0 : # RL n.right = self.rotate_right(n.right) n = self.rotate_left(n) # RR return n # 서브트리 높이 비교 정의 def bf(self, n) : return self.height(n.left) - self.height(n.right) # 오른쪽으로 회전 정의 def rotate_right(self, n) : x = n.left n.left = x.right x.right = n n.height = max(self.height(n.left), self.height(n.right)) + 1 x.height = max(self.height(x.left), self.height(x.right)) + 1 return x # 왼쪽으로 회전 정의 def rotate_left(self, n) : x = n.right n.right = x.left x.left = n n.height = max(self.height(n.left), self.height(n.right)) + 1 x.height = max(self.height(x.left), self.height(x.right)) + 1 return x # 노드 삭제 연산 정의 def delete(self, key) : self.root = self.del_node(self.root, key) def del_node(self, n, key) : if n == None : return None # 삭제할 노드가 트리 안에 없음 if (n.key &gt; key) : n.left = self.del_node(n.left, key) elif (n.key &lt; key) : n.right = self.del_node(n.right, key) else : # 삭제할 노드 찾은 경우 if n.right == None : # 0, 1 return n.left elif n.left == None : return n.right # 1 else : # 2 target = n n = self.minimum(target.right) # 중위후속자 = 오른쪽 서브트리 가장 왼쪽 값(최솟값) n.right = self.del_min(target.right) n.left = target.left n.height = max(self.height(n.left), self.height(n.right)) + 1 # n의 높이 조정 return self.balance(n) # 최솟값(가장 왼쪽 노드) 삭제 정의 def delete_min(self) : if self.root == None : print(f'트리가 비어 있음') self.root = self.del_min(self.root) def del_min(self, n) : if n.left == None : return n.right n.left = self.del_min(n.left) n.height = max(self.height(n.left), self.height(n.right)) + 1 # 높이 갱신 return self.balance(n) # 최솟값 찾기 정의 def min(self) : if self.root == None : # 공트리면 return None return self.minimum(self.root) def minimum(self, n) : if n.left == None : return n # 최소 키 가진 노드 return self.minimum(n.left) # 전위순회 def preorder(self, n) : if n != None : print(str(n.key), end=' ') if n.left : self.preorder(n.left) if n.right : self.preorder(n.right) # 중위순회 def inorder(self, n) : if n != None : if n.left != None : self.inorder(n.left) print(str(n.key), end=' ') if n.right != None : self.inorder(n.right)AVL 트리 객체가 잘 동작하는 지 테스트노드 삽입# 삽입연산if __name__ == '__main__' : t = AVL() # 데이터 삽입 t.put(75, 'apple') t.put(80, 'grape') t.put(85, 'lime') t.put(20, 'mango') t.put(10, 'strawberry') t.put(50, 'banana') t.put(30, 'cherry') t.put(40, 'orange') t.put(70, 'melon') t.put(90, 'plum')전위순회# 전위순회if __name__ == '__main__' : print(f'전위순회:\\t', end=' ') t.preorder(t.root)전위순회:\t 75 40 20 10 30 50 70 85 80 90중위순회# 중위순회 if __name__ == '__main__' : print(f'중위순회:\\t', end=' ') t.inorder(t.root)중위순회:\t 10 20 30 40 50 70 75 80 85 9075와 85 삭제# 삭제연산if __name__ == '__main__' : t.delete(75) t.delete(85)삭제 후 전위순회# 전위순회 if __name__ == '__main__' : t.preorder(t.root)40 20 10 30 80 50 70 90삭제 후 중위순회# 중위순회 if __name__ == '__main__' : t.inorder(t.root)10 20 30 40 50 70 80 9080 삭제# 삭제연산 t.delete(80)80 삭제 후 전위순회# 전위순회 t.preorder(t.root)40 20 10 30 70 50 9080 삭제 후 중위순회# 중위순회 t.inorder(t.root)10 20 30 40 50 70 90위 과정이 제대로 이루어진 건지 알아보기 위해, 직접 손으로 그려가며 검증해 보았다.75, 80, 85, 20, 10, 50 삽입30, 40, 70, 90 삽입전위순회)75, 40, 20, 10, 30, 50, 70, 85, 80, 90중위순회)10, 20, 30, 40, 50, 70, 75, 80, 85, 9075와 85 삭제 후)75 삭제 &gt;원래 트리가 이랬다.75 삭제는 자식 2개인 노드를 삭제하는 거다.따라서 중위순회 후속자를 찾아서 75 자리를 대체해줘야 한다.위 중위순회 결과를 보면 80이 75의 중위순회 후속자다.80을 75 자리에 대체하면 트리가 아래와 같아진다.이후 80이 지워진 자리부터 루트 방향으로 올라가면서 불균형 여부를 검사했다.85 $\\Rightarrow$ 불균형 없음80 $\\Rightarrow$ 불균형 없음85 삭제 &gt;85는 오른쪽 자식 1개 있는 노드다. 이진탐색트리 노드 삭제 규칙에 따라, 85가 지워진 자리에 그 오른쪽 자식 90이 채워진다.따라서 결과는 아래와 같다.90부터 루트로 올라가면서 불균형 여부를 검사한다.80 $\\Rightarrow$ 불균형 있음. 왼쪽 서브트리가 더 높다.왼쪽 서브트리가 더 높아 불균형 발생했으므로, 오른쪽으로 회전시켜야 한다.$\\Rightarrow$ rotate_right()서브트리가 모두 오른쪽으로 회전하고, 결과는 아래와 같다.전위순회)40 20 10 30 80 50 70 90중위순회)10 20 30 40 50 70 80 9080 삭제)80은 자식이 2개 있는 노드다. 위 중위순회 결과를 보면 80의 중위 후속자는 90 이다.90으로 80 자리 대체한다.90부터 루트로 올라가며 불균형 여부 검사한다.90 $\\Rightarrow$ 불균형 있다. 왼쪽 서브트리가 더 높고, 왼쪽 안에서는 오른쪽 서브트리가 더 높다.$\\Rightarrow$ LR - 회전LR - 회전 과정과 결과는 아래와 같다.전위순회)40 20 10 30 70 50 90중위순회)10 20 30 40 50 70 90AVL 트리 객체가 잘 정의, 구현되었음을 확인할 수 있었다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 이진탐색트리 개념, 연산, 구현", "url": "/bioinfo.github.io/posts/binary_search_tree/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, study, data science, python", "date": "2022-01-27 00:00:00 +0900", "snippet": "이진탐색트리정의탐색을 위한 이진트리.이진탐색트리 연산 시간복잡도$O(\\log{n})$ 트리 높이이진트리가 이진탐색트리가 되기 위한 조건 원소들이 서로 다른. 유일한 키를 갖고 있다. 왼쪽 서브트리 원소들의 키는 루트보다 작다. 오른쪽 서브트리 원소들의 키는 루트보다 크다. 왼쪽 서브트리와 오른쪽 서브트리도 이진탐색트리 조건 만족한다.이진탐색트리 예이진탐색트리 노드구조(키, 값) 쌍 형태. 키, 값, 왼쪽자식, 오른쪽 자식# 이진탐색트리 노드 정의# (키, 값) 쌍 class Node : def __init__(self, key, value, left=None, right=None) : self.key = key self.value = value self.left = left self.right = right 이진탐색트리 탐색 연산1. 루트에서 시작한다.2. 탐색할 키를 루트 노드 키 값과 비교한다. 키 $=$ 루트노드 키: 탐색연산 성공 키 $&lt;$ 루트노드 키: 왼쪽 서브트리로 가서 탐색 연산 수행 키 $&gt;$ 루트노드 키: 오른쪽 서브트리로 가서 탐색 연산 수행3. 서브트리에 대해 재귀적으로 탐색 연산 반복탐색 연산 메소드 구현# 탐색 연산 정의def get_item(n, k) : # 현재노드, 찾으려는 키 if n == None : return None if n.key &gt; k : return get_item(n.left, k) if n.key &lt; k : return get_item(n.right, k) else : return n.value 이진탐색트리 노드 삽입 연산정의탐색 하다가 탐색 실패한 위치에 노드 삽입. 탐색 성공 시 삽입하지 않는다. (중복값 허용 X)키가 16인 노드를 이진탐색트리 삽입하는 예과정 20과 비교: 왼쪽 서브트리로 간다. 10과 비교: 오른쪽 서브트리로 간다. 15와 비교: 오른쪽 서브트리로 간다. 15의 오른쪽 서브트리에서 탐색 실패. 탐색 실패한 자리에 16을 넣는다.노드 삽입 연산 메소드 구현# 노드삽입연산 정의def add_item(r,n) : if r.key &gt; n.key : if r.left == None : r.left = n return True # 삽입성공 else : return add_item(r.left, n) if r.key &lt; n.key : if r.right == None : r.right = n return True else : return add_item(r.right, n) else : # 탐색 성공한 경우 return False # 삽입실패이진탐색트리 노드 삭제 연산삭제하려는 노드 자식 수. 몇 개냐에 따라. 연산 방법. 다르다. 삭제하려는 노드 자식 수 0개인 경우(단말노드) 삭제하려는 노드 자식 수 1개인 경우 삭제하려는 노드 자식 수 2개인 경우연산 정의할 땐. 노드 간 관계 입체적으로 보는 게. 중요하다.연산 수행하고 나면 항상 전체 트리의 루트R을 반환한다.삭제하려는 노드 자식 수가 0개(단말노드)정의그 부모의. 자식 자리에 None을 할당한다.# 단말노드 삭제연산 정의def delete_zero(parent, node, root) : if parent == None : root = None else : if node == parent.left : parent.left = None else : parent.right = None return root 삭제하려는 노드 자식 수가 1개삭제 대상 노드가 왼쪽이든 오른쪽이든. 자식 1개 있을 때.정의그 부모의 자식 자리에 삭제 대상 노드 외자식을 새로 할당한다.# 외자식 갖는 노드 삭제연산 정의 # 노드삭제연산 정의 - 자식 수 1개인 노드 삭제 def delete_one(parent, node, root) : if node.left != None : target = node.left else : target = node.right if node == root : root = target else : if parent.left == node : parent.left = target else : parent.right = target return root 삭제하려는 노드 자식 수가 2개정의노드의 중위순회 후속자 찾아서, 그 부모의 자식 자리에 새로 할당한다. 중위순회 후속자는 ‘노드의 오른쪽 서브트리 안에서 가장 왼쪽 노드’가 된다.# 서브트리 2개 갖는 노드 삭제연산 정의 def delete_two(parent, node, root) : target_parent = node target = node.right while target.left != None : target_parent = target target = target.left if (target_parent.left == target) : target_parent.left = target.right else : target_parent.right = target.right node.key = target.key node.value = target.value return root 노드 삭제 연산 종합 구현case 별 3 가지 삭제연산 종합해서 ‘삭제연산’ 구현# 노드 삭제 연산 3가지 종합해서 구현 def delete(root, key) : if root == None : # 공트리면 return None #탐색 parent = None # 현재 노드의 부모 node = root # 현재 노드 while node != None and key != node.key : # 공트리 아니고. 원하는 키 찾을 때 까지 if (node.key &gt; key) : parent = node node = node.left else : parent = node node = node.right # 원하는 키가 트리에 없으면 if node == None : return None #-------------------삭제하려는 키에 도착했을 때-------------------------- if node.right == None and node.left == None : # 현재 노드 단말노드면 root = delete_zero(parent, node, root) elif node.right == None or node.left == None : # 자식 1개면 root = delete_one(parent, node, root) else : # 자식 2개면 root = delete_two(parent, node, root) return root 최대키, 최소키 갖는 노드 탐색 연산 최대키 갖는 노드: 오른쪽 라인 타고 내려가다가 오른쪽 자식이 $None$ 인 노드. 최소키 갖는 노드: 왼쪽 라인 타고 내려가다가 왼쪽 자식이 $None$ 인 노드.최대키 갖는 노드 탐색 연산# 최대키 갖는 노드 탐색 연산 정의def search_max_key(node) : while node != None and node.right != None : node = node.right return node 최소키 갖는 노드 탐색 연산# 최소키 갖는 노드 탐색 연산 정의 def search_min_key(node) : while node != None and node.left != None : node = node.left return node 이진탐색트리 연산 시간복잡도연산의 범위: 삭제, 삽입, 탐색트리 높이 만큼 시간복잡도 소요된다. $O(\\log_{2}{n})$~$O(n)$ 최선경우(완전이진트리일 때): $O(\\log_{2}{n})$ 최악경우(편향이진트리일 때): $O(n)$이진탐색트리 구현위에서 정의한 노드와 메소드를 종합해서. 이진탐색트리를 코드로 정의하겠다.노드# 이진탐색트리 노드 정의 class Node : def __init__(self, key, value, left=None, right=None) : self.key = key self.value = value self.left = left self.right = right 이진탐색트리 클래스# 이진탐색트리 객체 정의class BST : def __init__(self) : self.root = None # 탐색연산 def get(self, k) : # k=찾으려는 키 return self.get_item(self.root, k) def get_item(self, n, k) : if n == None : return None # 키 가진게 트리 안에 없을 때 # 탐색 if n.key &gt; k : # 왼쪽 서브트리 return self.get_item(n.left, k) elif n.key &lt; k : # 오른쪽 서브트리 return self.get_item(n.right, k) # 탐색 성공했을 때 else : return n.value # 삽입연산 def put(self, key, value) : self.root = self.put_items(self.root, key, value) def put_items(self, n, key, value) : # 탐색 실패 했을 때 if n == None : return Node(key, value) # 탐색하고 실패하면 삽입 if n.key &gt; key : # 왼쪽 서브트리로 고 n.left = self.put_items(n.left, key, value) elif n.key &lt; key : # 오른쪽 서브트리로 고 n.right = self.put_items(n.right, key, value) # 탐색 성공했을 때 else : n.value = value return n # 루트노드 반환 # 최솟값 삭제 연산 def delete_min(self) : # 정의: 트리가 공 트리인 경우 if self.root == None : return None else: self.root = self.del_min(self.root) def del_min(self, n) : if n.left is None : return n.right n.left = self.del_min(n.left) return n # 특정 키 노드 삭제 연산 정의 : def delete(self, k) : self.root = self.del_node(self.root, k) def del_node(self, n, k) : # 재귀중지 if n == None : return None # 재귀호출 if (n.key &gt; k) : # 왼쪽 서브트리 n.left = self.del_node(n.left, k) elif (n.key &lt; k) : # 오른쪽 서브트리 n.right = self.del_node(n.right, k) #부모의 자식 자리(왼쪽,오른쪽)에 새 n의 결과 넣는다. else : #(n.key == k) # k노드가 단말노드 | k노드가 오른쪽 자식 1개만 있을 때 if (n.left== None) : return n.right # k노드가 왼쪽 자식 1개만 있을 때 elif (n.right == None) : return n.left else : target = n # target = 현재노드 n = self.minimum(target.right) # target 오른쪽 서브트리에서 최솟값 찾아라 n.right = self.del_min(target.right) # 최솟값 지운 오른쪽 서브트리를 오른쪽에 새로 할당 n.left = target.left # 왼쪽 서브트리는 그대로 return n # 최솟값 가진 노드 찾기. 정의. def min(self) : # 트리가 빈 경우 if self.root == None : return None return self.minimum(self.root) def minimum(self, n) : # 재귀중지 if n.left == None : return n return self.minimum(n.left) # 전위순회 def preorder(self, n) : if n != None : print(n.key, end=' ') # 루트 출력 if n.left : self.preorder(n.left) # 왼쪽 서브트리 전위순회 if n.right : self.preorder(n.right) # 오른쪽 서브트리 전위순회 # 중위순회 def inorder(self, n) : if n.left : self.inorder(n.left) # 왼쪽 서브트리 중위순회 print(n.key, end=' ') if n.right : self.inorder(n.right) # 오른쪽 서브트리 중위순회 # 후위순회 def postorder(self, n) : if n.left : self.postorder(n.left) # 왼쪽 서브트리 후위순회 if n.right : self.postorder(n.right) # 오른쪽 서브트리 후위순회 print(n.key, end=' ') # 레벨순회 def levelorder(self, n) : que = [] que.append(n) while len(que) != 0 : # 큐가 빌 때 까지 e = que.pop(0) print(e.key, end=' ') if e.left != None : que.append(e.left) if e.right != None : que.append(e.right) 대부분 연산을 함수 재귀호출 사용해 구현했다.함수 재귀호출 사용했을 때. 메소드가 어떻게 동작하는 지 깔끔한 이해가 어려울 땐. 종이에 직접 재귀호출 과정 기록하면서 따라가니 이해에 큰 도움 되었다.이진탐색트리 객체가 잘 동작하는 지 테스트데이터 삽입# 이진탐색트리 테스트 # 빈 이진탐색트리에 노드 삽입if __name__ is '__main__' : t = BST() # 이진탐색트리 t.put(500, 'apple');t.put(600, 'banana') t.put(200, 'melon');t.put(100, 'orange') t.put(400, 'lime');t.put(250, 'kiwi') t.put(150, 'grape');t.put(800, 'peach') t.put(700, 'cherry');t.put(50, 'pear') t.put(350, 'lemon');t.put(10, 'plum')위 삽입 결과를 직관적으로 시각화 하면 아래와 같을 것이다.전위순회# 전위순회print('전위순회:\\t', end=' ');t.preorder(t.root)전위순회:\t 500 200 100 50 10 150 400 250 350 600 800 700중위순회# 중위순회 print(f'중위순회:\\t', end=' ');t.inorder(t.root)중위순회:\t 10 50 100 150 200 250 350 400 500 600 700 800탐색연산: 250# 탐색연산 : 250 print('\\n250: ', t.get(250))250: kiwi삭제연산# 삭제연산 t.delete(200)삭제 후 전위순회print('삭제후:\\t', end=' ')# 전위순회 print('전위순회:\\t', end=' ');t.preorder(t.root)삭제후:\t 전위순회:\t 500 250 100 50 10 150 400 350 600 800 700삭제 후 중위순회# 삭제 후 중위순회 print('\\n중위순회:\\t', end=' ')t.inorder(t.root)중위순회:\t 10 50 100 150 250 350 400 500 600 700 800최솟값 삭제: 10# 최솟값 삭제 t.delete_min()최솟값 삭제 후 중위순회# 최솟값 삭제 후 중위순회t.inorder(t.root)50 100 150 250 350 400 500 600 700 800최솟값 삭제 후 후위순회# 최솟값 삭제 후 후위순회t.postorder(t.root)50 150 100 350 400 250 700 800 600 500최솟값 삭제 후 레벨순회# 최솟값 삭제 후 레벨순회 t.levelorder(t.root)500 250 600 100 400 800 50 150 350 700" }, { "title": "[Keras/딥러닝 공부] 신경망 기본 구성, 이진분류, 다중분류, 회귀문제", "url": "/bioinfo.github.io/posts/keras_problems/", "categories": "Data Science, python, Keras, deep learning", "tags": "ML, Deep learning, python, Keras, data science", "date": "2022-01-24 00:00:00 +0900", "snippet": "아래 내용은 ‘케라스 창시자에게 배우는 딥러닝 (프랑소와 슐레 저, 박해선 옮김, 길벗 출판사)’ 을 공부한 뒤, 배운 내용을 제 언어로 정리.기록한 것 입니다.신경망 구조신경망 구성.훈련에 관련된 요소들 층: 모델 기본 구성 단위. 입력값과 정답값(타겟.레이블) 최적화 대상인. 손실함수 최적화 방식. 옵티마이저층(Layer)함수. 필터 가중치를 갖는다. 가중치는 학습 결과이자 저장된 정보.입력 데이터에 따른 층 구분층 종류 별로 다른 입력 받는다. Dense 층(밀집 층): 벡터, 행렬(2차원 텐서) 순환 층: 3차원 텐서 2차원 합성곱 층: 4차원 텐서(이미지)층 호환성층들 출력과 입력 사이 연결성.1층에서 1000 차원 벡터를 입력받아 32차원 벡터 출력했다고 가정하자.그러면 2층은 32차원 벡터를 입력으로 받을 수 있어야 ‘층 호환성’이 보장된다. 케라스에서는 자동으로 층 호환성 보장해준다.예시from keras import models from keras import layers model = models.Sequential() model.add(layers.Dense(32, input_shape=(784,)))model.add(layers.Dense(10))1층이 784 차원 벡터를 입력받아 32차원 벡터를 출력한다.그러면 2층은 32차원 벡터 입력받을 수 있어야 ‘층 호환성’ 이 보장된 것이다.케라스에서는 이걸 자동 조정 해주기 때문에, 위 예시에서는 2층에 input_shape를 따로 지정하지 않았다.손실함수, 옵티마이저손실함수(목적함수)최적화 대상.손실함수 최솟점 잘 찾을 수록, 모형 성능은 올라간다. 이진분류: 이진 크로스엔트로피 (로그손실) 다중분류: 카테고리 크로스엔트로피 (로그손실) 기댓값 예측(회귀): 평균제곱오차(MSE)옵티마이저최적화 방법(알고리듬)손실함수 위 특정 점에서 다른 점으로 어떻게 이동할 지 결정한다.영화 리뷰 이진분류 예제데이터셋 총 데이터 수: 5만 훈련 데이터 수: 2만 5천 개 검증 데이터 수: 2만 5천 개 훈련,검증 모두에서 긍정 리뷰, 부정리뷰 50:50 비율로 구성됨 이미 전처리 되어있음. 각 리뷰는 숫자(사전 값) 리스트 상태로 변환되어 있다.데이터셋 로드from keras.datasets import imdb(train_data, train_labels),(test_data, test_labels) = imdb.load_data(num_words=10000) num_words=10000 은 훈련데이터에서 가장 자주 나타나는 1만개 단어만 쓰겠다는 뜻이다.숮자 리스트로 된 1개 리뷰는 원래 아래와 같은 데이터였다.word_index = imdb.get_word_index() # 사전 reversed_word_index = dict([(value, key) for (key, value) in word_index.items()])decoded_review = [reversed_word_index.get(i-3, '?') for i in train_data[0]]for i in decoded_review : print(i, end=' ')print() ? 는 사전에 없는 단어라서 ?가 된거다.데이터 전처리신경망에 데이터 넣으려면 데이터를 원핫 인코딩 벡터 꼴로 바꿔야 한다.그리고 변환된 원핫 인코딩 벡터를 Dense 층에 넣는다.입력 데이터(벡터) 모두 원핫 인코딩 벡터 꼴로 변환# 입력데이터의 원핫인코딩 행렬 구한다. import numpy as npdef vectorize_sequence(sequence, dimension=10000) : zero_matrix = np.zeros((len(sequence), dimension)) # (25000, 10000) 영행렬 for i, sq in enumerate(sequence) : zero_matrix[i, sq] = 1. # 영벡터에서 sq 위치 전부 1로 바꾼다. -&gt; 원핫 인코딩 벡터 25000개로 구성된 행렬이 된다. return zero_matrix x_train = vectorize_sequence(train_data); x_test = vectorize_sequence(test_data) # 변환된 원핫 인코딩 '행렬' 2개. (리뷰 수, 10000) 크기 영행렬 만든다. 이 행렬은 이제 행은 각 리뷰, 열은 사전 인덱스 0~10000의 각 단어가 문장(리뷰)에 있고 없고를 나타낼 것이다. 각 리뷰에서, 문장 안에 단어(열)가 있으면 1, 아니면 0을 코딩한다. 최종 결과는 ‘원핫 인코딩 행렬’ 이 나온다.위 방법으로 훈련용, 검증용 입력 데이터 모두 원핫 인코딩 벡터로 바꾼다.정답값(타겟값) 모두 원핫 인코딩 벡터 꼴로 변환타겟값은 숫자 리스트지만, 그 내용물은 모두 1 또는 0이다. 따라서 넘파이 배열로만 변환해주면 된다.y_train = np.asarray(train_labels).astype('float32')y_test = np.asarray(test_labels).astype('float32') # 정답값도 전부 ndarray 꼴로 변환한다. 데이터를 ‘모델에 넣기 적합한 상태’로 만들었다.이제 모델을 정의하자.신경망 모델 정의# GPU 확인import tensorflow as tfprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))Num GPUs Available: 1# 모델 정의 from keras import models from keras import layersmodel = models.Sequential()# 1층 model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))# 2층 model.add(layers.Dense(16, activation='relu'))# 3층 (출력 층)model.add(layers.Dense(1, activation='sigmoid'))1층의 매개변숫값 16은 은닉유닛 갯수를 말한다.1층에 (10000,1) 크기 벡터를 입력데이터로 넣으면, 가중치 $w$와 벡터를 내적하면서 입력 데이터가 16차원 공간으로 투영된다.곧, 벡터의 차원축소가 일어난다. 벡터를 차원축소 함으로써 원본 벡터에서 노이즈를 모두 날리고, 핵심 특징 부분만 남게 된다(16차원 공간의 기저벡터 선형조합).차원축소된 벡터에 편향벡터를 더하고, relu 함수를 요소별로 적용한다. 은닉유닛 늘리면 벡터가 더 고차원 공간에 투영되면서, 신경망이 더 복잡한 표현을 학습하게 된다. 다만 계산시간 늘어나게 된다. 또 내가 학습시키고자 하는 패턴 이외 다른 패턴 학습할 수도 있다. 다른 패턴까지 학습하게 되면 훈련데이터는 정말 잘 맞추게 되지만, 검증 데이터에서는 오히려 성능 떨어질 수 있다.모델 컴파일# 모델 컴파일 model.compile( optimizer='rmsprop', loss = 'binary_crossentropy', metrics=['accuracy']) 최적화 방법(옵티마이저)은 확률적 경사하강법 알고리듬을 선택했다. 예측 손실(오차)은 이진 크로스엔트로피 사용해 계산할 것이다. 모델 성능은 정확하게 분류한 비율 사용해 측정하겠다.크로스엔트로피쿨백-라이블러 발산값은 두 분포 모양 서로 다른 정도 나타낸다.쿨백 라이블러 발산과 크로스엔트로피 사이 관계는 아래 식으로 나타낼 수 있다.$KL(p\\vert\\vert{q}) = H[p,q] - H[p]$위 이진분류 문제에서 정답 분포는 0 또는 1 하나 값 확률이 1인 베르누이 분포다.곧, 정답값의 분포는 엔트로피가 0이다.$H[p] = 0$따라서 위 식은 아래와 같아진다.$KL(p\\vert\\vert{q}) = H[p,q]$예측분포와 정답분포의 쿨백-라이블러 발산 값(두 분포 모양 다른 정도) 는 두 분포 크로스엔트로피 값과 같다.곧, 이 문제에서 두 분포의 크로스엔트로피는 두 분포 모양 다른 정도를 나타낸다.두 분포 모양 다른 정도는 곧 모델의 예측 손실을 의미한다.모형에 입력 데이터를 배치 사이즈에 맞춰 넣으면(예:128개 1묶음), 각 개별 데이터 별 크로스엔트로피 값(손실값)이 나올 것이다.이 손실값들 평균 낸 것을 로그손실($Log loss$) 이라고 한다.이 로그손실은 현재 가중치에서 손실이고, 모형의 손실함수로 사용된다.새 데이터셋에서 모델 성능 얼마나 나오는지 측정 위한 검증용 셋 만들기원본 훈련데이터에서 10,000개 표본을 떼어서 검증용 셋으로 만들겠다.# 모델 성능 검증 위한 테스트셋 만들기 x_val = x_train[:10000]partial_x_train = x_train[10000:]y_val = y_train[:10000]partial_y_train = y_train[10000:]모델 훈련시키기# 모델 훈련 hs = model.fit( partial_x_train, partial_y_train, epochs = 20, batch_size=512, validation_data=(x_val, y_val))검증용 셋 만들고 남은 훈련용 데이터 partial_x_train 과 partial_y_train(타겟) 이용해 모형을 학습시켰다.데이터는 512개를 한 묶음으로 삼아 훈련시켰다. 곧, 512개를 예측하도록 하고 512개 다 하면 그때 정답 확인해서 손실 계산. 가중치 수정했다.전체 데이터셋에 대해 에포크는 20번 반복했다.종합하면 에포크 1회 당 전체 데이터셋 데이터를 512개씩 묶음으로 가중치를 수정한다. 이 과정을 20번 반복한다.그리고 1회 에포크를 마치면 x_val, y_val 검증용 데이터셋을 이용해 로그손실 값과 정확하게 분류한 비율을 계산한다.*책에서는 위 훈련과정이 20초 이상 걸릴 것이라 했지만, GPU를 사용해서 그런지 전 과정에 10초도 걸리지 않았다.훈련 마친 후 - 에포크 별 손실, 정확도 출력model.fit() 객체의 history 속성은 훈련하면서 발생한 에포크 별 손실, 정확도를 딕셔너리 형태로 담고 있다.history_dict = hs.historyhistory_dict.keys()dict_keys([‘loss’, ‘accuracy’, ‘val_loss’, ‘val_accuracy’])import pandas as pdpd.DataFrame(history_dict)왼쪽부터 순서대로 i번 에포크에서 훈련 손실, 훈련 정확도, 검증 손실, 검증 정확도 나타낸다.위 데이터프레임을 그래프로 옮기면 내용을 시각적으로 한눈에 볼 수 있을 것이다.# 훈련, 검증 손실 그래프로 그리기 import matplotlib.pyplot as pltloss = history_dict['loss']val_loss = history_dict['val_loss']epochs = range(1, len(loss)+1) # 1~20plt.plot(epochs, loss, 'bo', label='loss while training')plt.plot(epochs, val_loss, 'b', label='loss while validation')plt.title('Training and Validation loss')plt.xlabel(f'Epochs')plt.ylabel(f'Loss')plt.legend()plt.show()그래프 해석 및 추측약 3번째 ~ 4번째 반복부터 과적합이 발생 한 것 같다. 그래프를 보면 훈련용 셋에서 손실은 계속 줄어들어 0에 수렴하지만, 검증용 셋에서 약 4번째 에포크 후 부터는 점차 손실이 증가하는 걸 관찰할 수 있다.훈련용 셋에 오버피팅 발생했기 때문에, 새 데이터를 모델에 넣으면 제대로 성능이 안 나올 것이다.한편 아래는 훈련용, 검증용 셋에서 정확도 그래프다.# 훈련, 검증 정확도 그래프로 그리기 plt.clf() # 그래프 초기화 acc = history_dict['accuracy']val_acc = history_dict['val_accuracy']plt.plot(epochs, acc, 'ro', label='Training accuracy')plt.plot(epochs, val_acc, 'r', label='Validation accuracy')plt.title(f'Training and Validation Accuracy')plt.xlabel('Epochs')plt.ylabel('Accuracy')plt.legend()plt.show()정확도 그래프에서도 과적합 발생이 짐작되는 형태가 나왔다.약 4번째 에포크 넘어가면 과적합 발생했다. 그러면 모델을 새로 정의하고, 4번만 반복해서 과적합을 완화시켜 보자.# 20번 반복하면서 과적합 발생했다. # 4번만 반복해서 과적합을 완화해보자. model = models.Sequential()model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))model.add(layers.Dense(16, activation='relu'))model.add(layers.Dense(1, activation='sigmoid'))# 모델 컴파일 model.compile( optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])model.fit(x_train, y_train, epochs=4, batch_size=512)result = model.evaluate(x_test, y_test)result[0.2950170338153839, 0.8840000629425049]에포크 4번만 반복했을 때는 약 88% 정확도가 나왔다.이번에도 에포크 별 손실과 정확도를 그래프로 나타내면 아래와 같았다.train_loss = hd.history['loss']test_loss = hd.history['val_loss']train_acc = hd.history['accuracy']test_acc = hd.history['val_accuracy']epochs = range(1, len(hd.history['accuracy'])+1)plt.subplot(1,2,1)plt.plot(epochs, train_loss, 'bo', label='Training loss')plt.plot(epochs, test_loss, 'b', label='Test loss')plt.xlabel('Epochs')plt.ylabel('Loss')plt.title(f'Training loss and Test loss')plt.legend()plt.subplot(1,2,2)plt.plot(epochs, train_acc, 'ro', label='Training Accuracy')plt.plot(epochs, test_acc, 'r', label='Test Accuracy')plt.xlabel('Epochs')plt.ylabel('Accuracy')plt.title(f'Training and Test Accuracy')plt.legend()plt.tight_layout()plt.show()모델에 새 데이터 넣어서 예측하기위에서 훈련시킨 모델에 새 데이터를 넣어서 분류해보자. predict() 메소드를 사용하면 모델에 예측 명령 내릴 수 있다.# 훈련된 모델이(가중치가) 새 데이터를 어떻게 분류하는 지 관찰하자. r = model.predict(x_test)# 예측 결과 r출력 벡터의 각 스칼라 값들은 해당 데이터(리뷰)가 긍정리뷰(1)일 확률이다.추가실험은닉 유닛을 늘렸을 때 검증 정확도 변화는? 은닉 유닛 기존 16개에서 32개로 늘렸을 때 정확도 변화# 은닉 유닛을 더 늘렸을 때 model3 = models.Sequential()model3.add(layers.Dense(32, activation='relu', input_shape=(10000,)))model3.add(layers.Dense(32, activation='relu'))model3.add(layers.Dense(1, activation='sigmoid'))model3.compile( optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])result = model3.fit(partial_x_train, partial_y_train, batch_size=512, epochs=20, validation_data= (x_val, y_val))plt.figure(figsize=(10,5))plt.plot(range(1, 21), result.history['accuracy'], 'go', label='training accuracy')plt.plot(range(1, 21), result.history['val_accuracy'], 'g', label='validation accuracy')plt.legend()plt.show()은닉 유닛 32개일 때, 16개 일 때 보다 과적합이 더 빨리 나타났다.16개 일 때는 4번째 에포크 쯤에서 과적합 나타났다.하지만 32개일 때는 3번째 에포크 이후부터 과적합 관찰됬다.또 16개 은닉유닛일 때는 에포크 반복 초반에는 일단 검증 셋 정확도가 조금씩 증가하는 양상이었다면, 32개 일 때 는 정확도가 일단 감소하면서 시작됬다. 은닉 유닛 64개로 늘렸을 때 모델 검증 정확도 변화# 은닉 유닛 64개이면? model4 = models.Sequential() model4.add(layers.Dense(64, activation='relu', input_shape=(10000,)))model4.add(layers.Dense(64, activation='relu'))model4.add(layers.Dense(1, activation='sigmoid'))model4.compile( optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])result = model4.fit(partial_x_train, partial_y_train, batch_size=512, epochs=20, validation_data=(x_val, y_val))plt.plot(range(1, 21), result.history['accuracy'], 'bo', label='training accuracy')plt.plot(range(1, 21), result.history['val_accuracy'], 'b', label='Validation accuracy')plt.legend()plt.show()은닉유닛 64개일 때는 약 2번째 에포크 쯤 부터 검증 정확도가 떨어지기 시작했다.반면 훈련용 데이터셋에서 정확도는 같은 구간에서 계속 증가한다.$\\Rightarrow$ 은닉유닛을 너무 많이 추가하면 과적합이 더 빨리 나타났다.뉴스 기사 다중 분류 문제다중 분류 문제 정의: 데이터가 2개 이상 클래스(여러 카테고리값)로 분류되는 문제로이터 데이터셋from keras.datasets import reuters(train_data, train_label), (test_data, test_label) = reuters.load_data(num_words=10000) 46개 토픽(46개 레이블), 각 레이블값은 0과 45 사이 정수다. 8,982개 훈련용 데이터, 2,246개 검증용 데이터 각 표본은 숫자로 된 리스트다. 위 이진분류 문제 때와 같다.예) 0번째 데이터는 원래 아래와 같았다.# 0번째 데이터 디코딩word_index = reuters.get_word_index()reversed_word_index = dict([(value, key) for (key, value) in word_index.items()])decoded_news = ' '.join([reversed_word_index.get(i-3, '?') for i in train_data[0]])decoded_news’? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3’ 사전을 만들고, 1개 샘플에서 각 단어를 사전 숫자값으로 바꾼 뒤 그걸 리스트에 담은 거다.데이터셋을 원핫 인코딩 벡터로 변환입력데이터 원핫 인코딩 벡터로 변환원핫 인코딩 벡터 꼴로 변화된 각 데이터를 벡터, 행렬 입력 받는 신경망 Dense층에 넣을 것이다.벡터 변환 방법은 위 이진분류 문제와 같다.# 데이터 전처리 - 각 데이터(문장) 원핫 인코딩 벡터 꼴로 변환 import numpy as np def vectorize_sequence(sequence, dimension=10000) : matrix = np.zeros((len(sequence), dimension)) for i, sq in enumerate(sequence) : matrix[i, sq] = 1. return matrixx_train = vectorize_sequence(train_data)x_test = vectorize_sequence(test_data)레이블 값 원핫 인코딩 벡터로 변환여기서는 이진분류 문제와 달리 레이블 값이 0과 45 사이 정수다.레이블 값들도 모두 원핫 인코딩 벡터로 바꿔준다.$\\Rightarrow$ 원핫 인코딩 벡터를 행으로 쌓은 행렬이 나올 것이다.# 레이블 원핫 인코딩 벡터로 변환 def invert_one_hot(sequence, dimension=46) : matrix = np.zeros((len(sequence), dimension)) for i, sq in enumerate(sequence) : matrix[i, sq] = 1. return matrix one_hot_train_label = invert_one_hot(train_label)one_hot_test_label = invert_one_hot(test_label)모델 정의층을 순서대로 쌓아올린 Sequential() 모델을 정의하겠다.# 모델 정의model = models.Sequential() model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(46, activation='softmax')) 다중분류를 하는 게 목적임으로, 맨 마지막 출력층 활성화 함수를 소프트맥스 함수로 지정한다. 소프트맥스 함수는 46차원 출력벡터 각 요소를 확률 꼴로 바꿔준다. 소프트맥스 함수 거친 모델의 최종 출력벡터는 데이터 1개가 각 0~45 범줏값일 확률 나타낸다.모델 컴파일# 모델 컴파일 model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) 손실계산 방법에 카테고리 크로스엔트로피 사용했다. 소프트맥스 함수 거친 출력의 확률분포와 정답값의 카테고리 확률분포 모양이 서로 다른 정도 나타낸다. 이때 손실함수는 카테고리 로그 손실($Categorycal log loss$) 가 된다.훈련용 셋에서 검증용 셋 따로 떼어내기모델 훈련시키고, 성능 검증하기 위해 검증용 셋 1,000개를 따로 떼어냈다.x_val = x_train[:1000]partial_x_train = x_train[1000:]y_val = one_hot_train_label[:1000]partial_y_train = one_hot_train_label[1000:]모델 훈련에포크는 20번, 배치 사이즈는 512로 지정하고 모델을 훈련시켰다.# 모델 훈련 training_result = model.fit(partial_x_train, partial_y_train, batch_size=512, epochs=20, validation_data=(x_val, y_val))#plt.figure(figsize=(10,5))plt.subplot(1,2,1)epochs = range(1,21)plt.plot(epochs, training_result.history['accuracy'], 'bo', label='Traning Accuracy')plt.plot(epochs, training_result.history['val_accuracy'], 'b', label='Validation Accuracy')plt.xlabel('Epochs')plt.ylabel('Accuracy')plt.title('Training &amp; Validation Accuracy')plt.legend()plt.subplot(1,2,2)plt.plot(epochs, training_result.history['loss'], 'ro', label='Traning Loss')plt.plot(epochs, training_result.history['val_loss'], 'r', label='Validation Loss')plt.xlabel('Epochs')plt.ylabel('Loss')plt.title('Training &amp; Validation Loss')plt.legend()plt.tight_layout()plt.show()20번 에포크를 돌았는데, 한 9번째 에포크 부터 과적합 나타나는 것 같다.과적합 완화하기 위해 에포크를 9로 조정하고 다시 모델 학습시키자.# 에포크 9번으로 조정하고 모델 새로 훈련시키기 # 모델 정의model = models.Sequential()model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(46, activation='softmax'))# 모델 컴파일 model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])# 모델 훈련 model.fit(x_train, one_hot_train_label, epochs=9, batch_size=512)result2 = model.evaluate(x_test, one_hot_test_label)result2[0.9699822664260864, 0.7947462201118469]검증용 데이터셋에서 약 79% 정확도가 나왔다.새로운 데이터 예측하기학습된 모델에 새 데이터를 넣어서, 분류하도록 해보자.predictions = model.predict(x_test)# 0번째 데이터 예측 결과predictions[0] # 소프트맥스함수 통과한 확률꼴 값들 0번째 데이터가 0~45로 각각 분류될 확률을 나타낸다. 확률 꼴 값들이므로, 전체 총합도 1이다.sum(predictions[0])1.0000001185512701위 벡터가 담고있는 확률값들을 시각화 해보자.sns.barplot(np.arange(0, 46, 1), predictions[0])plt.tight_layout()plt.title('Topic prediction result: 3')plt.show()모델은 0번째 데이터를 3으로 분류했다.실제 정답은 뭐였는지 확인해보자.train_label[:10][0] # 실제 정답 3모델을 정의할 때, 충분히 큰 중간층 두어야 한다.중간층 히든유닛이 출력 벡터 차원보다 작은 경우.그 층에서 ‘정보의 병목현상’이 발생한다.위 경우. 입력 데이터를 저차원 공간으로 투영하게 되는데, 너무 저차원 공간으로 투영해버리면서 분류에 필요한 핵심 특성들이 층을 다 통과하지 못하게 된다.결국 중간층 히든유닛이 너무 작으면, 모델 분류성능도 떨어지게 된다.위에서 모델 정의할 땐 중간층 히든유닛을 64개로 지정했다.만약 히든유닛을 32개로 지정하면 어떻게 될까.이 경우 히든유닛 갯수는 내가 분류하고자 하는 카테고리 수 46보다 작다.아마 모델의 분류 성능이 다소 떨어지게 될 것 같다.# 추가 실험 # 중간 층 유닛크기를 32로 해보자. # 모델 정의model = models.Sequential()model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))model.add(layers.Dense(32, activation='relu'))model.add(layers.Dense(46, activation='softmax'))# 모델 컴파일model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])# 모델 학습 result = model.fit(x_train, one_hot_train_label, batch_size=512, epochs=9, validation_data=(x_test, one_hot_test_label))plt.figure(figsize=(10,5))plt.plot(range(1,10), result.history['accuracy'], 'bo', label='Traning Accuracy')plt.plot(range(1,10), result.history['val_accuracy'], 'b', label='Validation Accuracy')plt.legend()plt.show()검증 데이터셋에서 최고 정확도가 78.76 정도 나왔다. 유닛크기를 64로 했을 때 검증 셋 정확도가 79.47 정도였다.아주 큰 정도는 아니지만 모델 성능이 살짝 떨어진 것을 관찰할 수 있었다.유닛크기를 더 줄여보자 $\\Rightarrow$ 10# 유닛 크기를 더 줄여보자. --&gt; 10 def training_model(unit_num): global x_train global one_hot_train_label global x_test global one_hot_test_label model = models.Sequential() model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) model.add(layers.Dense(int(unit_num), activation='relu')) model.add(layers.Dense(46, activation='softmax')) # 모델 컴파일 model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'] ) # 모델 학습 result = model.fit(x_train, one_hot_train_label, batch_size=512, epochs=9, validation_data=(x_test, one_hot_test_label)) plt.clf() plt.figure(figsize=(10,5)) plt.plot(range(1,10), result.history['accuracy'], 'bo', label='Traning Accuracy') plt.plot(range(1,10), result.history['val_accuracy'], 'b', label='Validation Accuracy') plt.legend() plt.show()training_model(10)중간층 히든유닛 갯수를 10개로 줄이니 검증셋 정확도가 78%에서 74% 까지 4% 정도 떨어졌다.데이터가 너무 저차원으로 차원축소 되면서 분류에 필요한 정보가 제대로 걸러지지 않았고, 결과로 제대로 분류가 안 됬다고 추측할 수 있다.은닉유닛 수를 64보다 증가시켰을 때def training_model(unit_num, layer_added_num): global x_train global one_hot_train_label global x_test global one_hot_test_label model = models.Sequential() model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) for i in range(layer_added_num) : model.add(layers.Dense(int(unit_num), activation='relu')) model.add(layers.Dense(46, activation='softmax')) # 모델 컴파일 model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'] ) # 모델 학습 result = model.fit(x_train, one_hot_train_label, batch_size=512, epochs=9, validation_data=(x_test, one_hot_test_label)) plt.clf() plt.figure(figsize=(10,5)) plt.plot(range(1,10), result.history['accuracy'], 'bo', label='Traning Accuracy') plt.plot(range(1,10), result.history['val_accuracy'], 'b', label='Validation Accuracy') plt.legend() plt.show()# 유닛 수 = 64 일 때 training_model(64, 1)검증 셋 최고 정확도: 0.7988# 유닛 수 = 128 일 때 training_model(128,1)검증 셋 최고 정확도: 0.8032# 유닛 수 = 512 일 때 training_model(512,1)검증 셋 최고 정확도: 0.7934처음예상: 은닉유닛 수를 46차원보다 너무 크게 올리면(128, 512) 처음 (10000,1) 벡터가 차원축소하면서 너무 많은 노이즈가 벡터에 남게 될 것이다.노이즈가 많이 남아도 제대로 분류하기 어려울 것이다.$\\Rightarrow$ 은닉유닛 수를 너무 크게 올려도 제대로 분류가 안 될 것이다.결과: 은닉유닛 수 128, 512 일 때 대체로 정확도가 64일때 보다 낮게 나왔지만, 항상 그렇지는 않았다.회귀문제에 신경망 적용하기신경망 써서 기댓값 예측하기.보스턴 주택 가격 데이터셋from keras.datasets import boston_housing(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data() 총 샘플 수 506개 (훈련용:404개, 테스트용:102개) 입력 데이터에 있는 각 특성은 스케일(값의 범위)이 서로 다르다. 데이터셋이 13개 속성 갖는다. 타깃값: 주택의 중간 가격데이터 준비이 데이터셋은 각 속성값들 스케일이 모두 다르다.이런 경우 값들 간 스케일이 비슷해지도록 맞춰줘야 한다.정규화(표준화)$\\frac{X_{i}-mean}{s}$각 값들을 정규화 함으로써 스케일을 맞춰줄 수 있다.각 속성(열)의 평균과 표준편차를 구한 뒤 정규화 하면 된다. 주의) 테스트 셋도 훈련용 셋의 평균과 표준편차로 정규화 한다.정규화 하면 각 속성값들은 모두 평균이 0이 되고 표준편차는 1이 된다.$\\Rightarrow$ 모든 값들이 대략 0~1 사이로 몰리게 된다.# 훈련용 데이터 정규화 mean = train_data.mean(axis=0) # axis=0: 행 방향 train_data -= meanstd = train_data.std(axis=0)train_data /= std# 검증용 데이터 정규화 test_data -= mean test_data /=std모델 정의데이터 수가 작을 때는 은닉 층 수 작은 모델 쓰는게 과적합 방지할 수 있다.# 모델 구성 def build_model() : # 모델 정의 model = models.Sequential() model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],))) model.add(layers.Dense(64, activation='relu')) model.add(layers.Dense(1)) # 선형 층 # 기댓값 에측치만 모든 범위에서 내놓을 것이다. # 모델 컴파일 model.compile( optimizer='rmsprop', loss = 'mse', metrics=['mae'] ) return model 이 모델 마지막 층은 활성화 함수가 없다. 이런 층을 선형 층 이라고 한다. 함수에 비유하면 $y = W\\cdot{X} + b$ 이런 꼴 일거다. $W$ 는 가중치 행렬, $b$ 는 편향 벡터다. 앞에서 처럼 활성화 함수로 시그모이드 함수를 적용하면 위 함수 결과값을 0과 1 사이에서 나오도록 제한한다. 반면 여기서는 활성화 함수가 없으므로, 위 선형함수 형상처럼 출력값 $y$ 가 전 구간에서 나올 수 있게 된다. 회귀문제의 손실함수로 평균 제곱 오차($mse$) 를 적용했다. 이 값은 예측값(기댓값 예측치)과 타깃(기댓값) 사이 잔차의 제곱을 평균낸 것이다. 모형의 성능 측정 지표로 평균 절대 오차($mae$) 를 적용했다. 이 값은 예측값과 타깃값 사이 잔차 절댓값을 평균 낸 것이다.K-fold 교차검증으로 모델 성능 측정데이터 수 적을 때 유용한 방법보스턴 집값 데이터셋은 표본 수가 적다. 이렇게 데이터 수가 적을 때는 K-fold 교차검증을 사용하면 모델 성능을 신뢰성 있게 측정할 수 있다.방법K-fold 교차검증은 전체 데이터셋을 K 개로 분할하고. 그 중 1개를 검증용 셋, 나머지 K-1개를 훈련용 셋으로 써서 모델 훈련. 검증한다. 이 과정을 검증용 셋을 바꿔가며 K번 반복한다.결과로 K개 검증점수(MAE 값)가 나온다. 이 K개 검증점수 평균내서 모델의 최종 검증점수로 삼는 방법이다.에포크 = 100일 때 수행에포크를 100번으로 설정했다. Fold 수는 4이다.아래 코드의 흐름은 다음과 같다. 검증용 셋 / 훈련용 셋 분할 훈련용 셋으로 모델 학습 검증용 셋에서 모델 성능 평가# k겹 교차검증 import numpy as np k = 4num_val_samples = len(train_data)//knum_epochs = 100 all_scores = [] for i in range(k) : print(f'처리 중인 폴드: {i}') val_data = train_data[i*num_val_samples:(i+1)*num_val_samples] val_targets = train_targets[i*num_val_samples:(i+1)*num_val_samples] partial_train_data = np.concatenate([ train_data[:i*num_val_samples], train_data[(i+1)*num_val_samples:] ], axis=0) partial_train_targets = np.concatenate([ train_targets[:i*num_val_samples], train_targets[(i+1)*num_val_samples:] ], axis=0) model = build_model() model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose='0') val_mse, val_mae = model.evaluate(val_data, val_targets, verbose='0') all_scores.append(val_mae)Fold 가 4개 이므로 4개의 모델 성능 평가 점수가 나온다.Fold 별 검증 점수의 평균을 내서 모델의 최종 검증 점수 구한다.np.mean(all_scores) # 최종 검증점수 2.3305585384368896최종 MAE 값이 2.33 나왔다.모델의 기댓값 예측이 빗나가는 정도(크기)가 예측값에서 $\\pm{2300}$ 달러 정도 날 수 있다는 뜻이다.에포크 = 500 일 때 수행에포크를 100에서 500으로 늘리고 같은 방법으로 모델 다시 학습시켰다.num_epochs = 500 all_mae_histories = []num_val_samples = len(train_data) // kfor i in range(k) : print(f'처리 중인 폴드:{i}') # 데이터 val_data = train_data[i*num_val_samples:(i+1)*num_val_samples] val_label = train_targets[i*num_val_samples:(i+1)*num_val_samples] partial_train_data = np.concatenate([ train_data[:i*num_val_samples], train_data[(i+1)*num_val_samples:] ], axis=0) partial_train_label = np.concatenate([ train_targets[:i*num_val_samples], train_targets[(i+1)*num_val_samples:] ], axis=0) # 모델 model = build_model() history = model.fit(partial_train_data, partial_train_label, epochs=num_epochs, batch_size=1, validation_data=(val_data, val_label), verbose='0') all_mae_histories.append(history.history['val_mae'])k_fold_score_per_epoch = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]# mae plotplt.plot(range(1, num_epochs+1), k_fold_score_per_epoch)plt.xlabel('The number of Epochs')plt.ylabel('Validation MAEs')plt.title('Validation MAE per Epoch')plt.show()흐름 훈련용 셋 / 검증용 셋으로 나눈다. 훈련용 셋으로 모델 학습시킨다. batch_size=1 이고 에포크가 500 이므로, 에포크 1번 당 훈련용 데이터 갯수만큼 가중치를 조정할 것이다. 이 과정을 총 500번 반복한다. 에포크 1번이 끝나면 학습된 모델에 검증용 셋 적용한다. 여기서 MAE 구한다. 에포크가 총 500번이므로, MAE 값도 에포크 당 1개씩 해서 총 500개 나온다. K번 검증용 셋을 바꿔가며 위 과정을 실시하면, MAE 값 500개가 들은 리스트가 총 K개 나온다. 이 경우 4개다. 결과로 all_mae_histories는 크기가 (4, 500) 이다. 마지막으로 에포크 당 모델 성능점수를 구한다. 곧, 에포크 별로 K개 분할에서 MAE 점수 평균을 구한다. 총 500개가 나온다.에포크 별 모델 성능 최종점수를 그래프로 나타내면 아래와 같다.그래프에서 좀 더 쓸만한 정보를 얻고자 데이터를 아래와 같이 변형하자. 에포크 횟수가 늘 수록 모델이 훈련되면서 검증용 셋에서도 잔차 크기가 줄어들 것이다. 위 그래프의 0 근처 초반 구간에서 나타나는 현상(MAE가 급격히 감소)은 대체로 예상가능하고 당연한 결과다. 이 부분을 없애자. 또한 이 부분은 그래프 나머지 부분과 스케일이 너무 많이 차이난다. 제외한다. 각 값들을 이전 포인트의 지수 이동 평균으로 대체함으로써, 값들 크기를 조정한다.# mae 값들 지수이동평균으로 크기 변환 # 지수이동평균으로 변환 과정 정의def smooth_curve(points, factor=0.9) : smooth_points = [] for i in points : if smooth_points : previous = smooth_points[-1] smooth_points.append(previous*factor + i*(1-factor)) else : smooth_points.append(i) return smooth_points smooth_mae_history = smooth_curve(k_fold_score_per_epoch[10:]) # mae 값 모두 크기 변환plt.figure(figsize=(10,5))plt.plot(range(10, num_epochs), smooth_mae_history)plt.xlabel('Epochs')plt.ylabel('Validation MAE')plt.title('Validation MAE per Epochs')plt.plot(80, 2.35, 'ro')plt.show()변환된 값들의 그래프에서 빨간 점에 주목하자.약 80번째 에포크를 기점으로 감소하던 MAE 값이 다시 증가한다.80번째 에포크 이후부터 모델에 과적합이 발생했다고 추측할 수 있다.$\\Rightarrow$ 새 데이터에서 모델 예측 성능을 끌어올리기 위해 에포크 횟수를 80으로 조정한다.에포크 횟수에 대한 최적 매개변수를 찾았다. 이제 최적 파라미터와 전체 훈련용 데이터를 사용해서 모델 훈련하고, 검증용 셋으로 모델 성능 검증해보자.model = build_model() model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose='0')test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)test_mae_score # MAE 약 2.55 기록했다. 2.550393581390381 최적 에포크 횟수 적용했음에도 MAE 값이 크게 줄진 않았다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 이진 힙 개념, Downheap과 Upheap, 이진 힙 구현", "url": "/bioinfo.github.io/posts/binary_heap/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, study, data science, python", "date": "2022-01-22 00:00:00 +0900", "snippet": "이진 힙(Binary Heap)정의데이터 간 우선순위 있는 완전이진트리 우선순위: 부모노드 &gt; 자식노드종류 최대힙: 부모노드 키 값이 자식노드 보다 같거나 큰 값 갖는 이진 힙 최소힙: 부모노드 키 값이 자식노드 보다 같거나 작은 값 갖는 이진 힙특징 반 정렬 상태다. 중복 값 허용한다.응용 우선순위 큐 구현이진 힙 연산 (최소힙 기준)삭제연산(Downheap)루트로부터 아래로 ‘내려가면서’ 정렬(엄밀히 말해 정렬은 아니지만)이 진행된다. 그래서 Downheap 이라 부른다.결과루트의 키가 삭제된다. 그리고 힙 속성 유지 위해 정렬한다.과정 힙의 가장 마지막 노드를 루트 자리에 갖다 놓는다. 그 과정에서 루트는 삭제된다. 힙 크기를 1 감소시킨다. 새 루트의 왼쪽 / 오른쪽 자식 중 크기 더 작은 것 찾는다. 더 작은 자식과 새 루트 키 크기 비교해서, 루트가 더 작으면 가만히 있는다. 자식이 더 작으면 루트와 그 자식 자리를 바꾼다. 최소힙 속성 만족할 때 까지 3~4 과정 반복하며 이파리 방향으로 진행한다.시간복잡도$O(log{n})$삽입연산(Upheap)이파리부터 위로 올라가면서 정렬이 진행된다. 그래서 Upheap 이라 부른다.결과이진 힙 마지막 노드로 데이터를 삽입한다. 그리고 힙 속성 유지 위해 정렬한다.과정 힙 마지막 노드로 데이터 삽입한다. 데이터 삽입한 노드와 그 부모의 키를 비교해서, 부모가 더 크면 자식과 부모 노드를 맞교환한다. 2번 과정 반복하며 루트 향해 올라간다.시간복잡도$O(log{n})$이진 힙 구현 - 배열 리스트 이용 1완전 이진트리에서, [ 왼쪽 $\\Rightarrow$ 오른쪽 방향 ] 으로 노드 별 번호를 붙인다.노드 별 번호를 배열 리스트의 인덱스로 삼는다. 번호는 1번부터 시작한다. 따라서 리스트 0번 인덱스 자리도 비운다.최대힙# 배열 리스트 이용해 최대힙 구현 class Maxheap : def __init__(self) : self.heap = [] self.heap.append(0) # 힙 크기 정의 def size(self) : return len(self.heap) -1 # 힙이 비었다'의 정의 def isEmpty(self) : return len(self.heap) == 0 # i번째 노드의 부모 노드 def parent(self, i) : return self.heap[i//2] # i번째 노드의 왼쪽 자식 노드 def left(self, i) : return self.heap[2*i] # i번째 노드의 오른쪽 자식 노드 def right(self, i) : return self.heap[2*i+1] # 힙 출력 정의 def print_heap(self) : print(self.heap[1:]) # 최대힙 삽입연산 정의 def insert(self, n) : self.heap.append(n) # 삽입한 데이터 현재위치 i = self.size() # 정렬 while i != 1 and n &gt; self.parent(i) : # 정렬 일어나는 조건 정의: 루트가 아니면서, 자식이 부모보다 클 때 # 정렬은 어떻게 발생하는가?의 정의 self.heap[i] = self.parent(i) # 자식의 위치로 부모가 이동 i = i // 2 # 자식이 부모 위치로 이동 self.heap[i] = n # 최대힙 삭제연산 정의 def delete(self) : parent = 1 child = 2 if not self.isEmpty() : # 힙이 비어있지 않을 때 heaproot = self.heap[1] last = self.heap[self.size()] # 정렬 while child &lt;= self.size() : # self.size() 이하 인덱스. 모든 노드에 대해 반복. 특정조건 나오면 서라. if (child &lt; self.size()) and (self.left(parent) &lt; self.right(parent)) : # 1. 왼쪽.오른쪽 자식 비교해서 더 큰 놈 가려낸다. child += 1 if last &gt; self.heap[child] : break # 2. 자식과 부모 비교 -&gt; 속성 만족하면 선다. # 속성 만족 안 하면 정렬한다. self.heap[parent] = self.heap[child] # 원래 부모가 있던 자리에 자식이 간다. parent = child # 원래 자식이 있던 자리는 또 다른 부모의 자리다. child = 2*parent # 새 부모자리의 왼쪽 자식(인덱스) self.heap[parent] = last self.heap.pop(-1) return heaproot 최대힙이 잘 작동하는 지 테스트if __name__ == '__main__' : m = Maxheap() m.insert([90, 'watermelon']);m.insert([80, 'pear']) m.insert([70, 'melon']);m.insert([50, 'lime']) m.insert([60, 'mango']);m.insert([20, 'cherry']) m.insert([30, 'grape']);m.insert([35, 'orange']) m.insert([10, 'app']);m.insert([15, 'banana']) m.insert([45, 'lemon']);m.insert([40, 'kiwi'])if __name__=='__main__' : print(f'최대 힙:', end='') m.print_heap() print() print(f'최댓값 삭제 후:', end='') m.delete() m.print_heap() print() m.insert([5, 'apple']) print(f'5 삽입 후:', end='') m.print_heap() print()최대 힙:[[90, ‘watermelon’], [80, ‘pear’], [70, ‘melon’], [50, ‘lime’], [60, ‘mango’], [40, ‘kiwi’], [30, ‘grape’], [35, ‘orange’], [10, ‘app’], [15, ‘banana’], [45, ‘lemon’], [20, ‘cherry’]]최댓값 삭제 후:[[80, ‘pear’], [60, ‘mango’], [70, ‘melon’], [50, ‘lime’], [45, ‘lemon’], [40, ‘kiwi’], [30, ‘grape’], [35, ‘orange’], [10, ‘app’], [15, ‘banana’], [20, ‘cherry’]]5 삽입 후:[[80, ‘pear’], [60, ‘mango’], [70, ‘melon’], [50, ‘lime’], [45, ‘lemon’], [40, ‘kiwi’], [30, ‘grape’], [35, ‘orange’], [10, ‘app’], [15, ‘banana’], [20, ‘cherry’], [5, ‘apple’]]이진 힙 구현 - 배열 리스트 이용 2좀 더 직관적인 방식이다.downheap, upheap 의 정의를 삽입. 삭제 정의 내부에 두지 않고, 따로 빼서 정의했다.결과로, 삽입. 삭제 연산 정의할 때는 정의된 downheap, upheap을 갖다 쓰기만 하면 된다.최소힙# 이진힙 구현 - 2# 좀 더 직관적 방식class BinaryHeap : def __init__(self, base) : self.heap = base # 리스트 self.n = len(base) - 1 # 최초 힙 생성(초기정렬) def create_heap(self) : for i in range(self.n//2, 0, -1) : self.downheap(i) # 삽입연산 정의 def insert(self, n) : self.heap.append(n)# 삽입 self.n += 1 # 힙 크기 + 1 self.upheap(self.n)# 정렬 # 삭제연산 정의 def delete_minimum(self) : if self.n != 0 : # 이진힙 비어있지 않을 때 minimum = self.heap[1] # 루트노드 self.heap[1], self.heap[-1] = self.heap[-1], self.heap[1] # 루트와 맨 마지막 노드 서로 바꾼다 self.heap.pop(-1) self.n -= 1 self.downheap(1) # 루트노드1 부터 정렬 return minimum # downheap 정렬 def downheap(self, i) : # i는 현재노드 while (2*i &lt;= self.n) : k = 2*i if (k &lt; self.n) and (self.heap[k][0] &gt; self.heap[k+1][0]) : # i의 왼쪽 자식 vs 오른쪽 자식 중 더 작은 것. k = k+1 if self.heap[i][0] &lt;= self.heap[k][0] : break # 최소힙 속성 만족하는 지 검사 self.heap[i], self.heap[k] = self.heap[k], self.heap[i] # 정렬 i = k # upheap 정렬 def upheap(self, j) : # j는 현재노드 while (j &gt; 1) and (self.heap[j//2][0] &gt; self.heap[j][0]) : # 현재노드가 루트가 아닐 때 &amp; 부모가 자식보다 클 때 self.heap[j//2], self.heap[j] = self.heap[j], self.heap[j//2] # 부모-자식 교환 j = j//2 # 힙 출력 def print_heap(self) : for i in range(1, self.n+1) : print(f'[{self.heap[i][0]}, {self.heap[i][1]}]', end='') print() print(f'힙 크기: {self.n}')참고)create_heap() 은 ‘최소힙 상태로 초기정렬 하는’ 메소드다. 완전이진트리에서 각 단위 서브트리 돌면서 downheap downheap(맨 마지막 노드의 부모~ 루트)구현된 최소힙이 잘 작동하는 지 테스트# 위 스크립트를 모듈로 만들고, 저장했다. # 따라서 먼저 모듈을 호출한다. import sys import ossys.path.append('/Users/kibeomkim/Desktop/datascience/DIY_modules')os.listdir('/Users/kibeomkim/Desktop/datascience/DIY_modules')# 이진힙 클래스 호출 from binary_heap import BinaryHeapif __name__ == '__main__' : a = [None] a.append([90, 'watermellon']); a.append([80, 'pear']) a.append([70, 'melon']); a.append([50, 'lime']) a.append([60, 'mango']);a.append([20, 'cherry']) a.append([30, 'grape']);a.append([35, 'orange']) a.append([10, 'apricot']);a.append([15, 'banana']) a.append([45, 'lemon']);a.append([40,'kiwi']) bh = BinaryHeap(a)if __name__ == '__main__' : print(f'힙 만들기 전:', end='') bh.print_heap() bh.create_heap() print(f'최소힙:', end='') bh.print_heap() print(f'최솟값 삭제 후:', end='') print(bh.delete_minimum()) bh.print_heap() bh.insert([5, 'apple']) print(f'5 삽입 후:', end='') bh.print_heap()힙 만들기 전:[90, watermellon][80, pear][70, melon][50, lime][60, mango][20, cherry][30, grape][35, orange][10, apricot][15, banana][45, lemon][40, kiwi]힙 크기: 12최소힙:[10, apricot][15, banana][20, cherry][35, orange][45, lemon][40, kiwi][30, grape][80, pear][50, lime][60, mango][90, watermellon][70, melon]힙 크기: 12최솟값 삭제 후:[10, ‘apricot’][15, banana][35, orange][20, cherry][50, lime][45, lemon][40, kiwi][30, grape][80, pear][70, melon][60, mango][90, watermellon]힙 크기: 115 삽입 후:[5, apple][35, orange][15, banana][50, lime][45, lemon][20, cherry][30, grape][80, pear][70, melon][60, mango][90, watermellon][40, kiwi]힙 크기: 12" }, { "title": "[2021 인공지능전문가 교육과정 복습] 트리, 이진트리, 이진트리 순회", "url": "/bioinfo.github.io/posts/tree_series/", "categories": "Data Science, python, data structure", "tags": "data structure, python, computer science, study, data science", "date": "2022-01-20 00:00:00 +0900", "snippet": "트리(Tree)비선형자료구조.정의계층.또는 부모/자식/형제.특징 계층구조 표현에 적합하다. (조직계층구조, OS 파일시스템 등) 일반트리와 이진트리로 구분된다. Empty 이거나 루트노드R 과 서브트리 집합으로 구성된다. 단, 서브트리 집합은 공집합일 수 있다. 각 서브트리 루트노드는 루트노드R 의 자식노드다.응용탐색트리, 힙, 구문트리 등트리 용어 루트노드 R: 트리 최상단 1개 노드. 부모가 없다. 단말노드(이파리): 끝노드. 자식이 없다. 내부노드: 단말노드 아닌 모든 노드 링크(가지): 각 노드 연결 형제: 같은 부모에서 나온 노드들 노드 크기: 자기자신 &amp; 그 자손노드 갯수 노드 깊이: 루트노드R에서 특정노드까지 가기 위해 거치는 가지 수 노드레벨: 특정 노드 깊이 갖는 노드들의 집합 노드 차수: 각 노드가 가진 가지 수 트리 차수: $max($ 노드 차수 $)$ 트리 높이: 노드레벨 수 서브트리: 루트노드R 에 달려있는 모든 하위 트리 조상: 어떤 노드에서 루트R 까지 경로에 있는 모든 상위노드 자손: 특정 노드 아래 매달린 모든 노드일반트리 표현방법왼쪽 자식-오른쪽 형제 표현부모/자식/형제 표현 가능하다. 노드 왼쪽 링크필드에 가장 왼쪽 자식노드, 오른쪽 링크필드에 오른쪽 형제노드 넣는다. 링크필드 메모리 아낄 수 있다.왼쪽 자식-오른쪽 형제 표현법을 써서 일반트리 나타내면 비어있는(None) 링크필드를 최대한 줄일 수 있을 것이다. 위 오른쪽 그림에서는 ‘.’ 이 없는 링크가 None 이 들어간 링크다.N-링크 표현법모든 노드가 트리차수 N 만큼 링크필드 갖는 방법이다. None 링크필드가 너무 많이 생긴다. 메모리 비효율적 활용 한다. 예컨대, 트리차수 N 인데 자식노드 수 N-3인 부모노드가 있다고 하자. 3개의 None 저장된 링크필드 생긴다. 이 3개만큼 메모리 낭비다. 트리차수 N 커질 수록, 메모리 낭비 더 심해진다. 따라서 이 방법은 비효율적 방법이다.이진트리(Binary Tree)정의각 노드 자식 수가 2 이하 $(0,1,2)$ 인 트리종류포화 이진 트리(Full binary tree): 각 레벨에 노드가 꽉 찬 이진트리완전 이진 트리(Complete binary tree): 단말노드가 꽉 차거나 비는 이진트리 포화 이진 트리는 완전 이진 트리의 한 종류다. 하지만 반대는 성립 안 한다.편향 이진 트리(Skewed binary tree): 모든 노드 한쪽방향으로 치우친 이진트리. 트리높이가 높아질 수록 메모리 낭비 심해진다. None이 들어간 링크필드가 많아져서 그렇다.규칙 노드 개수가 $n$ 개 이면 가지 갯수는 $n-1$예) 노드 7개, 가지 6개 트리높이가 $h$ 이면 노드 갯수는 $h$~ $2^{h}-1$예) 트리높이 3, 노드 3~7 $n$ 개 노드 갖는 이진트리 높이는 $[\\log_{2}{(n+1)}]$~$n$예) 3개 노드 갖는 이진트리 높이: $[\\log_{2}{(4)}]$~$3$예) 7개 노드 갖는 이진트리 높이: $[\\log_{2}{(8)}]$~$7$이진트리 표현방법배열 리스트로 이진트리 표현하는 방법 리스트 0번 인덱스는 비운다. 1번 인덱스에 루트노드R 넣는다. 짝수노드 i의 부모노드 인덱스: i/2 홀수노드 i의 부모노드 인덱스: i/2-0.5 노드 i 왼쪽자식 노드의 인덱스: 2i 노드 i 오른쪽 자식 노드의 인덱스: 2i+1$\\Rightarrow$ 부모/자식/형제 표현 가능하다.포화 이진트리 배열 리스트로 표현한 예편향 이진트리 배열 리스트로 표현한 예연결리스트로 이진트리 표현하는 방법왼쪽 자식-오른쪽 자식 표현 사용 노드 왼쪽 링크필드에는 왼쪽 자식, 오른쪽 링크필드에는 오른쪽 자식 할당한다. None 들어가는 링크필드 최대한 줄일 수 있다. 따라서 메모리 효율적 사용 가능하다.class Node : def __init__(self, item, left=None, right=None) : self.item = item # 노드가 담고 있는 데이터 self.left = left # 왼쪽 링크 필드에 왼쪽 자식 self.right = right # 오른쪽 링크 필드에 오른쪽 자식순회이진트리가 연산(데이터 저장, 삭제, 출력)하는 방법이다.정의모든 노드 한번씩 다 ‘방문’하는 것. 노드 그냥 지나가는 것과 ‘방문’ 하는 건 다르다.종류 전위순회: NLR 중위순회: LNR 후위순회: LRN이진트리 순회하면서 데이터 출력 예시이진트리가 아래와 같은 포화 이진트리 일 때, 전위순회 결과: A B C D E F G 중위순회 결과: C B D A F E G 후위순회 결과: C D B F G E A그 외 레벨순회: 레벨 순서로 순회, 왼쪽에서 오른쪽으로. 레벨순회 결과: A B E C D F G이진트리 순회 구현함수 재귀호출 사용해 이진트리 순회(전위, 중위, 후위) 구현한다. 레벨순회는 재귀호출 대신 큐를 이용해 구현한다.전위순회 구현# 전위순회 구현 class BinaryTree : def __init__(self) : self.root = None # 이진트리 empty 상태 # 전위순회 def preorder(self, n) : if n != None : # 트리가 empty 상태가 아닐 때 print(f'{str(n.item)}', end=' ') if n.left: self.preorder(n.left) if n.right: self.preorder(n.right)중위순회 구현# 중위순회 구현 class BinaryTree : def __init__(self) : self.root = None # 이진트리 empty 상태 # 중위순회 def inorder(self, n) : if n != None : if n.left: self.inorder(n.left) print(f'{str(n.item)}', end=' ') if n.right: self.inorder(n.right)후위순회 구현# 후위순회 구현 class BinaryTree : def __init__(self) : self.root = None # 이진트리 empty 상태 # 후위순회 def postorder(self, n) : if n != None : if n.left: self.postorder(n.left) if n.right: self.postorder(n.right) print(f'{str(n.item)}', end='')레벨순회 구현 함수 재귀호출 사용 안 하고 큐로 구현한다.# 레벨순회 구현 class BinaryTree : def __init__(self) : self.root = None # 이진트리 empty 상태 # 레벨순회 def levelorder(self, root) : if root != None : # 트리가 empty 가 아닐 때 q = [] q.append(root) while len(q) != 0 : result = q.pop(0) ;print(f'{result.item}', end=' ') if result.left: q.append(result.left) if result.right: q.append(result.right)이진트리 노드 수, 트리 높이, 그리고 동일성 여부 계산 알고리듬노드 수 계산이진트리 노드 수 = 1 + (루트노드R 왼쪽 서브트리 노드 수) + (루트노드R 오른쪽 서브트리 노드 수)파이썬으로 알고리듬 표현# 노드 수 계산 class BinaryTree : # 이진트리 생성자 def __init__(self) : self.root = None # 트리가 empty 상태 # 트리 노드 수 계산 def size(self, n) : if n == None : return 0 return 1 + self.size(n.left) + self.size(n.right)size() 재귀호출의 이해함수 재귀호출 사용해서 노드 수 계산 알고리듬을 표현했다.위 알고리듬에서 함수 재귀호출이 어떻게 동작하는지, 아래와 같은 순서로 이해할 수 있다.예를 들어 아래와 같은 완전 이진트리가 있다고 하자. self.size(A.left) self.size(B.left) self.size(D.left) size(None) $\\Rightarrow$ 0 self.size(D.right) size(None) $\\Rightarrow$ 0 1 + 0 + 0 $\\Rightarrow$ 1 self.size(B.right) self.size(E.left) size(None) $\\Rightarrow$ 0 self.size(E.right) size(None) $\\Rightarrow$ 0 1 + 0 + 0 $\\Rightarrow$ 1 1 + 1 + 1 $\\Rightarrow$ 3 self.size(A.right) self.size(C.left) size(None) $\\Rightarrow$ 0 self.size(C.right) size(None) $\\Rightarrow$ 0 1 + 0 + 0 $\\Rightarrow$ 1 1 + 3 + 1 $\\Rightarrow$ 5트리 높이 계산이진트리 트리 높이 = 1 + $max($ 루트R의 왼쪽 서브트리 높이, 루트R 오른쪽 서브트리 높이 $)$파이썬으로 알고리듬 표현# 트리 높이 계산 class BinaryTree : # 이진트리 생성자 def __init__(self) : self.root = None # 트리가 empty 상태 # 트리 높이 계산 def height(self, n) : if n == None : return 0 # 트리가 empty 상태면 높이 = 0 return 1 + max(self.height(n.left), self.height(n.right))height() 재귀호출의 이해함수 재귀호출 사용해서 트리 높이 계산 알고리듬을 표현했다.위 알고리듬에서 함수 재귀호출이 어떻게 동작하는지, 아래와 같은 순서로 이해할 수 있다.예를 들어 아래와 같은 완전 이진트리가 있다고 하자. self.height(A.left) self.height(B.left) self.height(D.left) height(None) $\\Rightarrow$ 0 self.height(D.right) height(None) $\\Rightarrow$ 0 max(0, 0) + 1 self.height(B.right) self.height(E.left) height(None) $\\Rightarrow$ 0 self.height(E.right) height(None) $\\Rightarrow$ 0 max(0, 0) + 1 $\\Rightarrow$ 1 max(1, 1) + 1 $\\Rightarrow$ 2 self.height(A.right) self.height(C.left) height(None) $\\Rightarrow$ 0 self.height(C.right) height(None) $\\Rightarrow$ 0 max(0, 0) + 1 $\\Rightarrow$ 1 max(2, 1) + 1 $\\Rightarrow$ 3트리 동일성 여부 계산비교하려는 두 트리 루트노드R 부터 시작해서 각 노드 메소드 인자로 전달하며 하나씩 같은지 검사파이썬으로 알고리듬 표현class BinaryTree : # 이진트리 생성자 def __init__(self) : self.root = None # 트리가 empty 상태 # 트리 동일성 검사 def is_equal(self, n, m) : if n is None or m == None : return n == m # n, m 둘 다 None 인 경우도 여기 걸린다. if n.item != m.item : return False # 내용물이 다른 경우 else : # n,m 둘 다 none 아니고 내용물도 같은 경우 return (self.is_equal(n.left, m.left) and self.is_equal(n.right, m.right)) # 둘 다 True 일 때만 True 반환한다. is_equal() 재귀호출의 이해함수 재귀호출 사용해서 트리 동일성 여부 계산 알고리듬을 표현했다.위 알고리듬에서 함수 재귀호출이 어떻게 동작하는지, 아래와 같은 순서로 이해할 수 있다.트리 동일성 검사 - 1 self.isequal(A.left, A.left) self.isequal(B.left, B.left) self.isequal(D.left, D.left) isequal(None, None) $\\Rightarrow$ True self.isequal(D.right, D.right) isequal(None, None) $\\Rightarrow$ True True and True $\\Rightarrow$ True self.isequal(B.right, B.right) self.isequal(E.left, E.left) isequal(None, None) $\\Rightarrow$ True self.isequal(E.right, E.right) isequal(None, None) $\\Rightarrow$ True True and True $\\Rightarrow$ True True and True $\\Rightarrow$ True self.isequal(A.right, A.right) self.isequal(C.left, C.left) isequal(None, None) $\\Rightarrow$ True self.isequal(C.right, C.right) isequal(None, None) $\\Rightarrow$ True True and True $\\Rightarrow$ True True and True $\\Rightarrow$ True트리 동일성 검사 - 2 self.isequal(A.left, A.left) self.isequal(B.left, B.left) self.isequal(D.left, D.left) isequal(None, None) $\\Rightarrow$ True self.isequal(D.right, D.right) isequal(None, None) $\\Rightarrow$ True self.isequal(B.right, B.right) isequal(E, None) $\\Rightarrow$ False True and False $\\Rightarrow$ False self.isequal(A.right, A.right) self.isequal(C.left, C.left) isequal(None, None) $\\Rightarrow$ True self.isequal(C.right, C.right) isequal(None, None) $\\Rightarrow$ True True and True $\\Rightarrow$ True False and True $\\Rightarrow$ False트리 동일성 검사 - 3 self.isequal(A.left, A.left) isequal(E, X) $\\Rightarrow$ False self.isequal(A.right, A.right) isequal(G, Z) $\\Rightarrow$ False False and False $\\Rightarrow$ False트리 동일성 검사 - 4 self.isequal(A.left, A.left) self.isequal(B.left, B.left) isequal(None, E) $\\Rightarrow$ False self.isequal(A.right, A.right) isequal(G, T) $\\Rightarrow$ False False and False $\\Rightarrow$ False+ 트리 복제이파리 노드 부터 복제시작한다. 결과값으로 (아래로 서브트리를 달고 있는) 복제된 루트노드R을 반환한다.파이썬으로 알고리듬 표현class Node : def __init__(self, item, left=None, right=None) : # 왼쪽자식-오른쪽자식 표현 self.item = item self.left = left # 왼쪽자식 self.right = right # 오른쪽 자식 # 트리 복제 def duplicate_tree(self, n) : if n is None : return None else: left = self.duplicate_tree(n.left) right = self.duplicate_tree(n.right) return Node(n.item, left=left, right=right) # 새 루트 노드 생성(복제본)duplicate_tree() 재귀호출의 이해함수 재귀호출 사용해서 트리 복제 알고리듬을 표현했다.위 알고리듬에서 함수 재귀호출이 어떻게 동작하는지, 아래와 같은 순서로 이해할 수 있다.예를 들어 아래와 같은 완전 이진트리가 있다고 하자. self.duplicate_tree(A.left) self.duplicate_tree(B.left) self.duplicate_tree(D.left) duplicate_tree(None) $\\Rightarrow$ None self.duplicate_tree(D.right) duplicate_tree(None) $\\Rightarrow$ None Node(D.item, None, None) 생성 self.duplicate_tree(B.right) self.duplicate_tree(E.left) duplicate_tree(None) $\\Rightarrow$ None self.duplicate_tree(E.right) duplicate_tree(None) $\\Rightarrow$ None Node(E.item, None, None) 생성 Node(B.item, Node(D, None, None), Node(E, None, None)) 생성 self.duplicate_tree(A.right) self.duplicate_tree(C.left) duplicate_tree(None) $\\Rightarrow$ None self.duplicate_tree(C.right) duplicate_tree(None) $\\Rightarrow$ None Node(C.item, None, None) 생성 Node(A, 14번 노드, 20번 노드) 생성연결리스트로 이진트리 구현왼쪽 자식-오른쪽 자식 표현 사용# 연결리스트로 이진트리 구현 # 노드 정의class Node : def __init__(self, item, left=None, right=None) : # 왼쪽자식-오른쪽자식 표현 self.item = item self.left = left # 왼쪽자식 self.right = right # 오른쪽 자식# 이진트리 정의 class BinaryTree : # 이진트리 생성자 def __init__(self) : self.root = None # 트리가 empty 상태 # 전위순회 def preorder(self, n) : if n != None : # 트리가 empty 상태가 아닐 때 print(f'{str(n.item)}', end=' ') if n.left: self.preorder(n.left) if n.right: self.preorder(n.right) # 중위순회 def inorder(self, n) : if n != None : if n.left: self.inorder(n.left) print(f'{str(n.item)}', end=' ') if n.right: self.inorder(n.right) # 후위순회 def postorder(self, n) : if n != None : if n.left: self.postorder(n.left) if n.right: self.postorder(n.right) print(f'{str(n.item)}', end='') # 레벨순회 def levelorder(self, root) : if root != None : # 트리가 empty 가 아닐 때 q = [] q.append(root) while len(q) != 0 : result = q.pop(0) ;print(f'{result.item}', end=' ') if result.left: q.append(result.left) if result.right: q.append(result.right) # 트리 높이 계산 def height(self, n) : if n == None : return 0 # 트리가 empty 상태면 높이 = 0 return 1 + max(self.height(n.left), self.height(n.right)) # 트리 노드 수 계산 def size(self, n) : if n == None : return 0 return 1 + self.size(n.left) + self.size(n.right) # 트리 복제 def duplicate_tree(self, n) : if n is None : return None else: left = self.duplicate_tree(n.left) right = self.duplicate_tree(n.right) return Node(n.item, left=left, right=right) # 새 루트 노드 생성(복제본) # 트리 동일성 검사 def is_equal(self, n, m) : if n is None or m == None : return n == m if n.item != m.item : return False else : return (self.is_equal(n.left, m.left) and self.is_equal(n.right, m.right))연결리스트로 구현된 이진트리 잘 작동하는지 테스트# 위에서 작성한 파이썬 스크립트를 모듈화 시켜서 따로 저장해뒀다. # sys 함수 이용해 파이썬 스크립트 저장해둔 경로를 시스템 경로에 추가한다. import syssys.path.append('/Users/kibeomkim/Desktop')from binary_tree import Node, BinaryTree#print(__name__) # __main__ 이다. if __name__ == '__main__' : # 현재 실행환경이 메인 스크립트이므로 항상 True 일 것이다. 한편 모듈 불러온 뒤 모듈 내에 있던 __name__ 을 출력하면 그 모듈 이름이 출력된다. t = BinaryTree() # 이진트리 객체 생성 n1 = Node(100);n2 = Node(200) n3 = Node(300);n4 = Node(400) n5 = Node(500);n6 = Node(600) n7 = Node(700);n8 = Node(800) # 100부터 800까지 값 넣은 8개 노드 생성 (연결 전) n1.left = n2 # n1 노드 왼쪽자식 = n2 n1.right = n3 # n1 노드 오른쪽자식 = n3 n2.left = n4 # n2 노드 왼쪽자식 = n4 n2.right = n5 # n2 노드 오른쪽자식 = n5 n3.left = n6 # n3 노드 왼쪽자식 = n6 n3.right = n7 # n3 노드 오른쪽자식 = n7 n4.left = n8 # n4 노드 왼쪽자식 = n8 t.root = n1 # n1을 이진트리 루트노드 R로 설정. print(f'트리높이: {t.height(t.root)}') print(f'전위순회:', end='') t.preorder(t.root) print('\\n중위순회:', end='') t.inorder(t.root) print('\\n후위순회:', end='') t.postorder(t.root) print('\\n레벨순회:', end='') t.levelorder(t.root) print() print(f'트리 노드 수: {t.size(t.root)}') new_root = t.duplicate_tree(t.root) # 트리 복제 t2 = BinaryTree() # 새 이진트리 객체 호출 (empty 상태) t2.root = new_root # 새 이진트리 루트노드 R에 기존 트리 t의 루트노드 할당 (이제 t2는 복제된 이진트리) print('두 트리가 같은가?: ', end='') print(t.is_equal(t.root, t2.root)) # 두 트리 (t, t2) 동질성 검사: 둘은 같은 트리인가? print() # 두 트리가 같다. 트리높이: 4전위순회:100 200 400 800 500 300 600 700중위순회:800 400 200 500 100 600 300 700후위순회:800 400 500 200 600 700 300 100레벨순회:100 200 300 400 500 600 700 800트리 노드 수: 8두 트리가 같은가?: True" }, { "title": "[Keras/딥러닝 공부] 신경망 기본 개념, 텐서, MNIST 데이터 분류하기", "url": "/bioinfo.github.io/posts/keras_with_mnist/", "categories": "Data Science, python, Keras, deep learning", "tags": "data science, python, keras, deep learning", "date": "2022-01-18 00:00:00 +0900", "snippet": "아래 내용은 ‘케라스 창시자에게 배우는 딥러닝 (프랑소와 슐레 저, 박해선 옮김, 길벗 출판사)’ 을 공부한 뒤, 배운 내용을 제 언어로 정리.기록한 것 입니다.신경망 기본 개념신경망은 여러 겹의 ‘층(Layer)’ 으로 이루어져 있다.각 층은 데이터 특징 추출 ‘필터’ 이다. 각 층은 함수로 생각할 수도 있다.신경망은 여러 겹 필터로 구성된 ‘여과기’ 이다.텐서(tensor)머신러닝 기본 입력 데이터는 ‘텐서’다.텐서정의: 넘파이 다차원 배열텐서 종류스칼라(0차원 텐서)숫자 하나 하나가 스칼라다. 스칼라는 0차원 텐서다.# 스칼라 예 s = np.array(3)s.ndim0벡터(1차원 텐서)스칼라의 모임, 벡터가 1차원 텐서다.# 벡터 (1차원 텐서) 예v = np.array([1,2,3])# or v = np.array([[1],[2],[3]])위 두 방식 모두 3차원 열벡터 나타내고, 동시에 1차원 텐서다.행렬(2차원 텐서)열벡터를 행벡터로 쌓은, 벡터의 모임. 행렬이 2차원 텐서다.# 행렬(2차원 텐서) 예 np.array([ [1,2,3], [4,5,6], [7,8,9]])3차원 텐서 및 고차원 텐서행렬을 3차원으로 여러 개 쌓으면 3차원 텐서가 된다.그리고 3차원 텐서 여러 개를 다시 여러 개 묶으면 4차원 텐서가 된다.그 이상 차원을 가진 텐서도 가능하다.보통 이미지 1개가 RGB 3개 채널(행렬)로 이루어진 3차원 텐서다.$\\Rightarrow$ 여러 이미지 묶음은 4차원 텐서가 될 것이다.$\\Rightarrow$ 1개 비디오는 여러 이미지 묶음(여러 프레임의 연속) 이므로 4차원 텐서가 된다. 여러 비디오를 묶어놓은 데이터셋은 5차원 텐서가 된다.배치(batch) 데이터1개 배치(batch) 는 여러 개 개별 데이터로 구성된 데이터 묶음이다.예를 들어 배치 크기(batch size) 가 128 이라면, 1개 배치(묶음)에 128개 개별 데이터가 들어가 있다는 소리다.벡터 브로드캐스팅벡터 - 스칼라 연산을 할 때 스칼라를 1벡터 이용해 ‘브로드캐스팅’ 할 수 있었다. 그리고 그 결과, 벡터 - 스칼라 연산을 수행할 수 있었다.한편 행렬 - 벡터 사이 벡터 브로드캐스팅도 가능하다.예컨대 행렬 AA = np.array([ [1,2,3], [4,5,6], [7,8,9]])와 벡터 BB = np.array([ [1], [2], [3]])이 있다고 하자.$A+B$ 연산을 수행하고 싶다.이때, 벡터 B를 아래와 같이 브로드캐스팅 할 수 있다.# 벡터 B를 브로드캐스팅해 만든 행렬 B = np.array([ [1,2,3], [1,2,3], [1,2,3]])이후 행렬 $A$ 와 $B$ 를 요소별 연산 $A+B$ 하면 된다.# 요소별 연산 결과 result = np.array([ [2,4,6], [5,7,9], [8,10,12]])케라스 Sequential() 모델 이용해 MNIST 데이터 분류하기데이터셋 로드# mnist 데이터셋 로드 from keras.datasets import mnist 데이터셋을 훈련용 데이터셋과 검정용 데이터셋으로 분리(train_images, train_labels), (test_images, test_labels) = mnist.load_data()print(train_images.shape)(60000, 28, 28)train_images 는 3차원 텐서 데이터다.6만개 28*28 행렬(2차원 텐서)로 구성되어 있다.# GPU 확인import tensorflow as tfprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))Num GPUs Available: 1print(test_images.shape);print(len(test_labels));print(test_labels)(10000, 28, 28)10000[7 2 1 … 4 5 6] 검정용 test_images 데이터는 1만 개 28*28 행렬로 구성된 3차원 텐서다. test_labels 레이블 데이터(정답값)는 1만개 값으로 되어 있다. 각 값은 0~9 이다.모델 로드# 신경망 구조 from keras import models from keras import layersnetwork = models.Sequential() # sequantial 모델 객체 network.add(layers.Dense(512, activation='relu', input_shape=(28*28,))) # 이미지 특징 추출 층 network.add(layers.Dense(10, activation='softmax')) # 1번 레이어에서 추출된 특징 소프트맥스 함수 이용해 확률 꼴로 바꾸는 층 모델 로드하고 2개 층을 구성했다. 1층은 렐루함수 이용해 이미지 특징 추출하는 층. 2층은 소프트맥스 함수 이용해 1층에서 나온 결과값들을 0과 1 사이, 총합 1 되는 ‘확률 꼴’ 로 바꾸는 층이다. 벡터로 출력된다.모델 컴파일(훈련준비)모델 훈련준비 시키는 과정을 ‘모델 컴파일’ 이라고 한다.# 모델 컴파일(훈련준비)network.compile(optimizer='rmsprop',# 최적화 방법loss='categorical_crossentropy', # 손실함수(성능함수)metrics=['accuracy']) # 모델 정확도 측정 방법 최적화 방법으로 rmsprop 방법을 적용했다. 손실함수(손실) 계산 방법으로 범주형 크로스엔트로피를 적용했다. 정답값(레이블)을 0과 1만으로 구성된 원핫 인코딩 벡터 꼴로 변환해 줄 것이다. 특정 이미지를 신경망에 통과시키고 나서 나오는 소프트맥스 함수 출력값들은 각 카테고리값에 대한 확률 꼴일 것이다. 소프트맥스 함수 출력값과 레이블의 원핫인코딩 벡터를 각각 확률분포라 생각할 수 있다. 이때 정답값 분포와 소프트맥스 함수 출력값 분포 사이 크로스엔트로피 값은 두 분포가 다른 정도를 나타내는 쿨백-라이블러 발산값과 같아진다. 여기서 쿨백-라이블러 발산값 또는 ‘두 분포가 다른 정도’가 예측 오차 또는 손실이 될 것이다. 모델 정확도 측정 방법으로 accuracy rate 를 적용했다. 곧, 정확하게 분류한 비율을 뜻한다.입력 데이터 전처리이미지 데이터는 일반적으로 신경망에 넣을 때 0과 1사이 값으로 크기 변환해서 넣는다.train_images = train_images.reshape((60000, 28 * 28))train_images = train_images.astype('float32')/255 # train 데이터 자료형을 실수형으로 바꾸고, 255로 나눠서 크기 조정 (0과 1사이 값들로 크기 조정)test_images = test_images.reshape((10000, 28*28))test_images = test_images.astype('float32')/255 # test 데이터 자료형을 실수형으로 변경 하고 255로 나눠서 크기 조정 (0과 1사이 값)# 보통 신경망에 이미지 넣을 때는 0과 1사이 값으로 바꿔서 넣는다. 3차원 텐서였던 train_images 데이터셋(훈련용 데이터셋)을 $(60000,784)$ 크기 행렬로 변환한다. 여기서 주목할 점은, 개별 이미지는 $(1,784)$ 크기 행벡터가 되어 행렬을 구성하게 되었다는 점이다. 이후 행렬 각 원소를 부동소수점 실수 자료형인 float32 타입으로 바꾸고, 모든 값을 255로 나눠서 크기가 0과 1사이가 되게 조정했다. 한편 역시 3차원 텐서였던 test_images 데이터셋(검정용 데이터셋)을 $(10000, 784)$ 크기 행렬로 변환한다. 역시 개별 이미지는 $(1,784)$ 크기 행벡터가 되었다. 행렬 각 원소를 float32 타입으로 변환하고, 255로 나눠 크기를 0과 1사이로 조정한다.# 레이블값 (정답 값) 모두 원핫인코딩 벡터 꼴로 변환 import keras.utils train_labels = tf.keras.utils.to_categorical(train_labels) # 훈련용 데이터 정답값test_labels = tf.keras.utils.to_categorical(test_labels) # 테스트 데이터 정답값 한편, 훈련용 데이터셋과 검정용 데이터셋의 레이블 데이터를 모두 원핫인코딩 벡터 꼴로 바꾼다.변환 방법은 위와 같다.변환 후 0~9 사이 각 레이블값들은 모두 0과 1로만 구성된 원핫 인코딩 벡터로 바뀌었다.이렇게 입력데이터 전처리를 마친다.# 전처리된 입력 데이터 크기 확인 train_images.shape(60000, 784)train_labels.shape(60000, 10)모델 훈련시키기# 컴파일 된 모델 훈련데이터로 지도학습 하기 network.fit(train_images, train_labels, epochs=5, batch_size=128) # batch_size: 한번에 몇 개씩 예측.평가해서 가중치 업데이트 할 건가. M1 맥의 GPU를 이용했다.에포크는 5번, 배치 크기는 128을 설정했다. 모델을 훈련(학습) 시키는 작업 = 최적의 가중치(파라미터)를 찾는 작업 으로 정의할 수 있다. 모델 가중치는 학습 결과이자 모델에 저장된 정보다.모델 성능 교차검증하기# 모델에 테스트셋 넣어서 성증 교차검증 하기 test_loss, test_acc = network.evaluate(test_images, test_labels)0.9801 정도 정확도가 나왔다.# 모형 성능평가 결과값 print(f'test_loss:{test_loss}');print(f'test_acc:{test_acc}')test_loss:0.06420930474996567test_acc:0.9801000356674194학습된 모형에 이미지 넣어보기데이터셋 로드 - 훈련데이터 vs 검증데이터 나누기 - 모델 로드 - 모델 컴파일 - 데이터셋 전처리 - 모델 학습 - 성능검증위 과정을 통해 학습된 모델을 얻었다.이 모델에 임의의 MNIST 데이터 하나를 넣어서, 어떻게 분류해내는지 한번 보자.# 임의의 MNIST 데이터 first_image = train_images[3].reshape((1,28*28))훈련용 셋에서 3번째 이미지 데이터를 빼냈다. 그리고 이걸 행벡터 형태로 변환했다.그 후 모형의 predict() 메소드에 넣어서 3번째 이미지를 분류하도록 했다.result = network.predict(first_image)[0]result # 소프트맥스 함수 출력값결과:array([2.3608993e-09, 9.9996030e-01, 1.2336987e-05, 8.0996138e-08, 1.6119817e-06, 1.2742596e-08, 2.0098611e-08, 1.7875993e-05, 7.7193372e-06, 4.1783554e-09], dtype=float32)결과는 소프트맥스 함수 출력값. 즉 확률 꼴 값이다. 각 값들은 0과 1사이 값이고, 총합은 1이다.이 경우 result 값은 10차원 벡터로 나오고, 각 값들은 모형에 예측하도록 시킨 3번째 이미지가 각 카테고리값일 확률을 나타낸다.위 출력값을 좀 더 이해하기 쉽게 시각화했다.import seaborn as snsimport matplotlib.pyplot as pltplt.figure(figsize=(5,2))sns.barplot(list(range(0,10)), result)plt.title('prediction result')plt.show()seaborn을 이용해 막대그래프로 각 카테고리값 별 확률을 나타냈다.모델은 3번째 이미지를 ‘1’ 로 예측했음을 볼 수 있다.그러면 1로 분류된 3번째 이미지가 실제로 어떤 형상이었는지, 직접 육안으로 확인하자.plt.figure(figsize=(1,1))plt.imshow(train_images[3].reshape(28,28))plt.axis('off')plt.show() # 모델이 1로 분류해냈다. 사람인 내가 봐도 이 숫자는 1인것 같다.모델이 제대로 잘 분류해냈음을 관찰할 수 있었다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 스택 활용, 덱 활용 (괄호검사, 후위표기변경, 후위표기 계산, 그리고 회문분석)", "url": "/bioinfo.github.io/posts/stack_deque_utilization/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, study, data science", "date": "2022-01-17 00:00:00 +0900", "snippet": "스택 활용 - 괄호검사문제 정의: 괄호 짝 모두 pair 맞는지 검사 하고자 함. ’(‘ 나 ‘{‘ 여는 괄호면 무조건 스택에 집어넣는다. ’)’, ‘}’ 닫는 괄호면 스택 제일 위에서 하나 꺼내 짝이 맞는지 검사한다. 괄호 짝 맞으면 True. 괄호 짝 하나라도 안 맞으면 모두 False.1차원 리스트로 스택 구현해서 검사하겠다.# 스택 활용 - 괄호검사 a = ['(', ')', '{', '{', ')', ')', '}', '}', '(', '(']stack = [] # 스택 n = len(a)for i in range(n) : if a[i] == '(' or a[i] == '{' : stack.append(a[i]) else : # 닫힌 게 나오면 괄호검사 if len(stack) != 0 : top = stack.pop() if a[i] == ')' and top != '(' : result = False break elif a[i] == '}' and top != '{' : result = False break else : result = False break if len(stack) == 0 and result == True : print(f'{True}')else : print('False')False함수로 묶기# 함수로 만들어 사용 def check(a) : s = [] n = len(a) result = True for i in range(n) : if a[i] == '(' or a[i] == '{' : s.append(a[i]) else : # 닫힌 게 나오면 괄호검사 if len(s) != 0 : top = s.pop() if a[i] == ')' and top != '(' : result = False break elif a[i] == '}' and top != '{' : result = False break else : result = False break if len(s) == 0 and result == True : return True else : return Falsecheck(a)Falsea = ['(', '(', '{', '}', '(', ')', ')', '{', '{', '}', '(', ')', '}', ')']check(a)True스택 활용 - 중위표기를 후위표기로 변경하기중위표기 예: $A+B-C*(D+E)$후위표기 예: $AB+CDE+*-$중위표기 후위표기로 변경 방법 연산우선순위에 따라 괄호로 묶는다. 괄호 안 연산자를 괄호 오른쪽 밖으로 이동시킨다. 괄호 제거한다.스택을 활용해서 중위표기 후위표기로 변경하기문제 정의: 문자열(숫자)는 바로 출력 ’(‘ 여는 괄호는 스택에 넣는다. ’)’ 닫는 괄호 나오면 스택에서 ‘(‘ 직전까지 모두 순서대로 빼서 출력한다. ‘(‘는 스택에서 빼서 버린다. 사칙연산 연산자는 나오면 스택에 넣는다. 자기자신보다 우선순위 낮은 연산자가 스택에 들어올 때 스택에서 빠져나와 출력된다.1차원 리스트로 스택 구현해서 문제 해결첫번째 시도# 스택 구현stack = []# 삽입연산def push(item) : global stack stack.append(item)# 삭제연산 def pop() : global stack if len(stack) != 0 : return stack.pop(-1)# 조회 def peek() : if len(stack) != 0 : return stack[-1] # -----------------------#시도 1. 중위표기를 후위표기로 변경 def infix_to_postfix(expr) : result = [] p = {} p['*'] = 3 p['/'] = 3 p['+'] = 2 p['-'] = 2 p['('] = 1 input_expr = expr.split() for i in input_expr : if (i in 'ABCDEFGHIJKLMNOPQRSTUWXYZ') or (i in '0123456789') : result.append(i) elif i == '(' : push(i) elif i == ')' : while True : popped = pop() if popped != '(' : result.append(popped) elif popped == '(' : break else : while (len(stack) != 0) and (p[i] &lt;= p[peek()]) : result.append(pop()) push(i) # 마지막까지 스택에 남은거 전부방출 while len(stack) != 0 : result.append(pop()) return ' '.join(result)infix_to_postfix('( A + B ) * C - ( D - E ) * ( F + G )')‘A B + C * D E - F G + * -‘print(infix_to_postfix('A * B + C * D'))A B * C D * +print(infix_to_postfix('A + B * C / ( D - E )'))A B C * D E - / +중위표기 - 후위표기 변경 함수 바꾼 뒤 두번째 시도# 2. 중위표기를 후위표기로 변경 def infix_to_postfix(expr) : result = [] p = {} p['*'] = 3 p['/'] = 3 p['+'] = 2 p['-'] = 2 p['('] = 1 input_expr = expr.split() for i in input_expr : if (i in 'ABCDEFGHIJKLMNOPQRSTUWXYZ') or (i in '0123456789') : result.append(i) elif i == '(' : push(i) elif i == ')' : top = pop() while top != '(' : result.append(top) top = pop() else : while (len(stack) != 0) and (p[i] &lt;= p[peek()]) : result.append(pop()) push(i) # 스택에 남은거 전부방출 while len(stack) != 0 : result.append(pop()) return ' '.join(result)infix_to_postfix('( A + B ) * C - ( D - E ) * ( F + G )')‘A B + C * D E - F G + * -‘print(infix_to_postfix('A * B + C * D'))A B * C D * +print(infix_to_postfix('A + B * C / ( D - E )'))A B C * D E - / +스택 활용 - 후위표기 계산하기위에서 중위표기를 후위표기로 바꿨다. 이제 후위표기를 직접 계산한다.문제 정의: 숫자는 무조건 스택에 집어넣는다. 사칙연산 연산자가 나오면 스택에서 2개 꺼내 그 연산자로 연산한다. 2번 연산 결과를 다시 스택에 집어넣는다. 스택에 마지막 최후의 1값 남을 때 까지 1~3 과정 반복한다.1차원 리스트로 스택 구현해서 문제 해결# 후위표기 계산 stack = [] # 스택 def push(item) : stack.append(item)def pop() : if len(stack) != 0 : return stack.pop(-1) def peek() : if len(stack) != 0 : return stack[-1]def compute(operator, operand1, operand2) : if operator == '*' : return (operand1 * operand2) elif operator == '/' : return (operand1 / operand2) elif operator == '+' : return (operand1 + operand2) else : return (operand1 - operand2)# 계산 def calculation(input_expression) : expr = input_expression.split() for token in expr : if token in '0123456789' : push(int(token)) else : op2 = pop() op1 = pop() push(compute(token, op1, op2)) if len(stack) == 1 : return stack.pop(-1)calculation('7 8 + 3 2 + /')3calculation('2 3 5 * 6 4 - / +')9.5덱 활용 - 영단어가 회문인지 아닌지 검사하기회문이란, 가운데 중심으로 알파벳이 좌우대칭되는 영단어 말한다.문제 정의: 영단어를 알파벳 단위로 분리해서 덱에 넣는다. 덱 전단과 후단에서 원소 빼서 같은지 검사한다. 2번 덱에 알파벳 1개 또는 0개 남을 때 까지 반복한다. 그 후 검사종료. 2번 반복 중 불일치 발생하면 곧바로 검사종료, 회문 아니다.1차원 리스트로 덱 구현해서 문제 해결def check_palindrome(word) : flag = True words = list(word) while len(words) &gt; 1 : front = words.pop(0) rear = words.pop(-1) if front != rear : flag = False break return flag check_palindrome('racecar')Truecheck_palindrome('tesesta')Falsecheck_palindrome('raddar')Truecheck_palindrome('wasitacatisaw')True" }, { "title": "[2021 인공지능전문가 교육과정 복습] 스택, 큐, 덱, 우선순위 큐", "url": "/bioinfo.github.io/posts/stack_que_deck/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, study, data science", "date": "2022-01-12 00:00:00 +0900", "snippet": "스택(Stack)쌓기나무.선형자료구조다.추상자료형속성 데이터 접근 방식: 후입선출(Last In First Out) 0개 이상 유한개 원소를 포함한다. 각 원소는 순서(인덱스)를 갖는다.연산 push(): 스택 맨 위에 새 데이터 삽입한다. pop(): 스택 맨 위 데이터를 사용자에게 한번 보여주고 삭제한다. peek(): 스택 맨 위 데이터가 뭔지 확인한다. isEmpty(): 스택이 비어있는지 확인한다. size(): 스택 내 원소 수를 확인한다.스택 구현 방법 파이썬 기본 리스트 단순연결리스트파이썬 기본 리스트 후단을 top 으로 삼아 거기서만 데이터 삽입, 삭제 가능케 하면 스택으로 쓸 수 있다.스택 구현 - 파이썬 기본 리스트 이용하는 방법1. pythonds 클래스 사용pythonds 클래스는 파이썬 기본 리스트 이용해서 스택을 미리 구현해놓은 클래스다.곧, 클래스 호출만으로 스택 자료구조를 바로 쓸 수 있다.pythonds 에서 구현해놓은 스택 연산은 push(): 삽입 pop(): 반환 후 삭제 peek(): 조회 isEmpty(): 비었는지 확인 size(): 원소 갯수 확인 items(): 들어있는 모든 요소 리스트 형식으로 출력from pythonds.basic import Stack # 스택 클래스 호출 st = Stack() # 스택 객체 st 생성 print(st.isEmpty()) # 스택이 비어있는지 확인: 아무것도 안 넣었으니까 Truest.push(3);st.push(4);st.push(5);st.push('A') # 스택에 차례로 3,4,5,'A' 삽입print(st.items) # 스택에 넣은 요소들 리스트 형태로 출력 st.peek() # 맨 위에 있는 데이터 조회: 'A'while st.size() != 0 : # 스택이 빌 때 까지 print(st.pop()) # 후입선출로 하나씩 꺼내서 반환하고 삭제. A-5-4-3 순으로 나올 것이다. print(st.isEmpty())# 스택이 비어있는지 확인. pop()으로 다 꺼냈다. True2. 파이썬 기본 리스트 사용해서 직접 스택 클래스 짜기파이썬 기본 리스트 사용해서 직접 스택 클래스를 쓰고, 스택 자료구조 객체를 직접 생성할 수 있다.# 스택 클래스 생성 - 1class Stack : # 객체 생성 할 때 자동 호출 def __init__(self): self.items = [] # push() 연산 구현 def push(self, value): self.items.append(value) # 리스트 후단에 데이터 추가 # pop() 연산 구현 def pop(self): print(self.items[-1]) del self.items[-1] # peek() 연산 구현 def peek(self): print(self.items[-1]) # isEmpty() 연산 구현 def isEmpty(self): if len(self.items) == 0 : return True else : return False # size() 연산 구현 def size(self): return len(self.items)st2 = Stack() # 스택 객체 생성 하지만 위 방법은 스택이 비어 있을 때 pop(), peek() 연산에서 에러를 발생시킨다는 단점이 있다.더 나은 방법# 스택 클래스 생성 - 2class Stack : def __init__(self) : self.items = [] # push() def push(self, item) : self.items.append(item) # pop() : 스택이 비어 있을 때는 아무 동작도 하지 않는다. def pop(self) : if not self.isEmpty() : self.items.pop() # peek() : 스택이 비어 있을 때는 아무 동작도 하지 않는다. def peek(self) : if not self.isEmpty() : return self.items[len(self.items)-1] # isEmpty() def isEmpty(self) : return self.items == [] # size() def size(self) : return len(self.items)st2 = Stack()스택 구현 - 단순연결리스트 이용하는 방법단순연결리스트 이용 push 연산할 때 마다 매번 노드 생성 새 노드 생성되면 곧바로 헤드포인터 부여연결리스트에 데이터 추가 절차 (push) 노드 생성 데이터 투입 링크 설정 헤드포인터 지정연결리스트에서 데이터 빼는 절차 (pop) 헤드포인터만 이동시키면 끝난다. 원래 top에 뭐가 들어있었는지 보여준다.# 단순연결리스트로 스택 구현하기 # 노드 정의 class Node : def __init__(self, data, link) : self.item = data # 데이터 필드 self.next = link # 링크 필드 # 빈 단순연결리스트의 헤드포인터 top = None# 빈 단순연결리스트 사이즈 size = 0# push(): 삽입 def push(data) : global top # 전역변수 top 가져와서 쓸 것이다 global size # 전역변수 size 가져와서 쓸 것이다 # 새 노드 생성, 데이터 삽입, 링크 지정, 그리고 헤드포인터 지정 top = Node(data, top) # 데이터 1 추가할 때. 연결리스트 크기 1 증가 size += 1 # pop(): 삭제 def pop() : global top global size if size != 0 : # 스택이 차 있을 때 만 top_item = top.item # 연결리스트에서 삭제: 헤드포인터만 다음 노드로 옮겨간다 top = top.next # 연결리스트 노드 수 -1 size -= 1 return top_item # 연결리스트에서 뺀 노드에 뭑가 들어있었는지 반환 # peek(): 조회def peek() : global top if size != 0 : # 스택이 차 있을 때 만 return top.item# print_stack(): 스택 내용물 전체 출력 def print_stack() : global top global size print('top -&gt;', end='') p = top # 현재 노드 while p : if p.next != None : # 후단 노드가 아닐 때 print(f'{p.item} -&gt;', end='') else : # 후단에 도달 했을 때 print(p.item, end='') p = p.next # 다음 노드로 이동 print()# 스택 내용물 모두 제거 def stack_clear() : global top global size # 연결리스트 헤드포인터를 None에 지정하면 된다. # 맨 처음 빈 연결리스트 상태로 돌아간다. top = None size = 0스택이 잘 생성되었는지 테스트# 스택이 잘 생성되었는지 테스트 push('apple')push('orange')push('cherry')print('사과, 오렌지, 체리 스택에 push 후:', end='')print_stack() # 스택 출력 print('top 항목: ', end='')print(peek())push('pear')print(f'배 push 후: ', end='')print_stack()pop()push('grape')print('pop(), 포도 push 후:', end='')print_stack()큐(Queue)줄서기.선형자료구조다.데이터 삭제는 큐 전단에서, 삽입은 큐 후단에서 일어난다.추상자료형속성 데이터 접근 방식: 선입선출(First In First Out) 0개 이상 유한개 원소 포함한다. 각 원소는 순서(인덱스)를 갖는다.연산 enqueue(): 큐 후단에 데이터 삽입한다. dequeue(): 큐 전단에서 데이터 꺼내 반환하고 삭제한다. peek(): 큐 전단에 데이터 조회한다. isEmpty(): 큐가 비어있는지 확인한다. size(): 큐 안에 데이터가 몇개 들었는지 확인한다.큐 구현 방법 파이썬 내장 queue 모듈의 Queue 클래스 파이썬 기본 리스트 단순연결리스트큐 구현 - 파이썬 내장 queue 모듈의 Queue 클래스Queue 클래스queue 모듈의 Queue 클래스를 사용하면, 별도의 클래스 정의나 함수 정의 없이 큐 자료구조를 바로 활용 가능하다.Queue 클래스에서 구현해 놓은 큐 연산은 enqueue: 삽입(put(item)) dequeue: 삭제(get())# queue 모듈 Queue 클래스 활용해서 큐 자료구조 사용하기 from queue import Queueque = Queue()que.put(3)que.put(4)que.put(5)que.put(8)que.put(10)for i in range(5) : print(que.get(), end=',')print()결과: 3,4,5,8,10,큐 구현 - 파이썬 기본 리스트 이용하는 방법데이터 저장은 파이썬 기본 리스트에 하되, 특별함수 만들어서 데이터 삽입과 삭제를 큐 처럼 하는 방법이다.# 파이썬 기본 리스트로 큐 구현 que = [] # 큐# 데이터 삽입def enqueue(item) : global que que.append(item) # 데이터 삽입은 리스트 후단에서만 일어나도록 # 데이터 삭제 def dequeue() : global que if len(que) != 0 : item = que.pop(0) # 데이터 삭제는 리스트 전단에서만 일어나도록 return item # 삭제 한 항목 반환큐 구현 - 단순연결리스트 이용하는 방법단순연결리스트로 큐 생성 전 명심해야 할 것 큐는 전단과 후단이 있다. 새로 만든 노드는 항상 큐의 가장 후단이다. 노드 생성은 데이터 삽입 할 때 마다 발생한다.# 단순연결리스트로 큐 구현 시도 1 # 빈 큐top = Nonesize = 0pre_node = None# 노드 정의class Node : def __init__(self, data, link) : self.item = data # 데이터 필드 self.next = link # 링크 필드 # 삽입 def enqueue(item) : global top global size global pre_node if size == 0 : # 큐에 처음으로 뭘 넣을 때 # 헤드포인터 노드 생성 top = Node(item, None) size += 1 pre_node = top else : # 그게 아닌 모든 경우 # 새 노드 생성 new_node = Node(item, None) size += 1 # 새 노드를 이전 노드 링크와 연결 pre_node.next = new_node pre_node = new_node# 삭제 : 헤드포인터만 이동하면 된다. def dequeue() : global top global size if size != 0 : deleted_one = top.item top = top.next # 헤드포인터 변경 : 삭제 끝 size -= 1 return deleted_one # 조회 : 헤드포인터 노드에 담긴 데이터 확인한다. def peek() : global top global size if size != 0 : return top.item # 큐가 비어있는지 확인 def isEmpty() : global size return size == 0 # 큐의 자료 수 확인 def que_size() : global size return size def clear() : global top global size top = None size = 0def print_q() : global top global size if size != 0 : n = top print(f'front -&gt;', end='') for i in range(size) : print(f'{n.item}', end=' ') n = n.next print()삽입 연산 enqueue() 가 필요이상으로 번잡하다.큐에 대한 개념(concept) 및 이해를 좀 더 명료하게 해야 할 필요가 있었다. 큐에 처음으로 데이터 삽입하면 그 큐는 전단이면서 동시에 후단이다. 이후, 큐에 데이터 삽입하는 ‘작업’은 ‘큐 후단에 새 노드를 갖다 붙이는 작업’이다. 새 노드는 항상 큐의 후단이 된다.# 단순연결리스트로 큐 구현 시도 - 2 # 빈 큐front = Nonerear = Nonesize = 0 # 노드 정의 class Node : def __init__(self, item, link) : self.item = item self.next = link # 삽입 def enqueue(item) : global front global rear global size p = Node(item, None) if size == 0 : # 첫 번째면 front = p else : # 그 외에 rear.next = p rear = p size += 1 # 삭제 def dequeue() : global front global rear global size if size != 0 : deleted = front.item # 삭제된 항목 front = front.next size -= 1 if size == 0 : rear = None return deleted # 조회 def peek() : global front return front.item # 삭제 def clear() : global front global rear global size front = None rear = None size = 0 # 내용물 출력 def print_que() : global front global rear global size p = front print(f'front -&gt;', end=' ') while p : # 큐 끝까지 돌아라 print(f'{p.item}', end=' ') p = p.next # 다음 노드로 가라 print() 큐 구현 - 선형 큐의 문제점선형 큐 삽입 연산은 큐를 어떻게 구현하든 $O(1)$ 만큼 시간복잡도만 걸린다. 효율적이다.반면 삭제 연산 할 때 선형 큐는 시간 또는 공간을 비효율적으로 사용한다.높은 시간복잡도 $O(n)$ - 배열 리스트로 구현된 선형 큐삭제연산을 하면 배열에서 0번 인덱스가 삭제되고, 1번 인덱스부터 n번까지가 모두 한 칸씩 앞으로 물리적 이동을 한다. 당연히 시간복잡도는 $O(n)$ 이다.매 삭제연산마다 $O(n)$ 만큼 시간복잡도가 걸린다는 건 매우 비효율적이다.비효율적 공간 사용 - 단순연결리스트로 구현된 선형 큐삭제연산 하면 큐의 전단(front) 을 나타내는 헤드포인터가 한 칸 뒤로 이동한다.그러면 원래 데이터가 있었던 공간을 큐가 사용할 수 없게 된다.원형 큐 - 선형 큐 문제점 해결1차원 배열 리스트(파이썬 기본 리스트) 를 ‘원형’으로 ‘사용’해서 원형 큐 구현한다.특징Front 포인터와 Rear 포인터 둘 다 이동한다. 삽입연산: Rear 포인터 이동 삭제연산: Front 포인터 이동두 포인터는 시계방향으로 이동한다.Front 포인터 위치(노드)는 항상 비워둔다.개념 정의1. 원형 큐가 비었다front 포인터 위치 == rear 포인터 위치2. 원형 큐가 포화상태다(rear+1)%MAX_SIZE = front3. 삽입연산(enqueue)front 포인터 고정. 새 rear 포인터 위치: rear = (rear+1)%MAX_SIZE 새 위치로 rear 포인터 이동 새 rear 포인터 위치에 데이터 삽입만약 새 rear 포인터 위치가 (rear+1)%MAX_SIZE == front 이면 큐가 포화상태, 삽입연산 수행하지 않는다.4. 삭제연산(dequeue)rear 포인터 고정. 새 front 포인터 위치: front = (front+1)%MAX_SIZE 새 위치로 front 포인터 이동 새 front 포인터 위치의 데이터 삭제만약 front 포인터 위치 == rear 포인터 위치 이면 원형 큐가 공백 상태다. 삭제연산 수행하지 않는다.원형 큐 구현구현방법파이썬 기본 리스트 자료구조 이용개념 정의 원형 큐가 비었다 $=$ front 포인터와 rear 포인터 위치가 같다. 원형 큐에 데이터 삽입한다 $=$ front 포인터 고정, rear 포인터만 새 위치로 이동 후 그 위치에 데이터 삽입 원형 큐에서 데이터 삭제한다 $=$ rear 포인터 고정, front 포인터만 새 위치로 이동, 원래 그 위치에 있던 데이터 반환 원형 큐가 포화상태다 $=$ (rear+1)%MAX_SIZE = front 원형 큐 front 포인터와 rear 포인터는 두 가지 상황만 갖는다. rear 가 front 앞에 있던지. 혹은 뒤에 있던지. front 포인터 위치는 항상 비어있다.# 1차원 배열 리스트로 원형 큐 구현 class Circularque : def __init__(self) : self.MAX_SIZE = 5 # 큐 최대 사이즈 5로 지정 self.front = 0 # front 포인터 시작점 self.rear = 0 # rear 포인터 시작점 self.q = [None]*self.MAX_SIZE # 포화상태 정의 def isFull(self) : return (self.rear+1)%self.MAX_SIZE == self.front # 공백상태 정의 def isEmpty(self) : return self.front == self.rear # 삽입연산 def enqueue(self, item) : if not self.isFull() : # 포화상태가 아닐 때 self.rear = (self.rear+1)%self.MAX_SIZE # 다음 리어 포인터 위치 self.q[self.rear] = item # 삭제연산 def dequeue(self) : if not self.isEmpty() : # 공백상태가 아닐 때 self.front = (self.front+1)%self.MAX_SIZE # 다음 프론트 포인터 위치 deleted = self.q[self.front] return deleted # 뭐가 삭제됬는지 반환 # 원형 큐 출력 연산 def print_cq(self) : if not self.isEmpty(): out = [] # 리어 포인터가 프론트 포인터보다 앞에 있는 경우 if self.front &lt; self.rear : out = self.q[self.front+1:self.rear+1] # 리어 포인터가 프론트보다 뒤에 있는 경우 else : out = self.q[self.front+1:self.MAX_SIZE+1]+self.q[0:self.rear+1] print(f'front:{self.front}, rear:{self.rear}', out) def size(self) : return (self.rear-self.front+self.MAX_SIZE)%self.MAX_SIZE # 원형 큐 비우기 def clear(self) : self.front = self.rear # 원형 큐 가장 전단에 있는 항목 조회 def peek(self) : if not self.isEmpty() : return self.q[(self.front+1)%self.MAX_SIZE] # 현재 front 포인터 하나 뒤 위치의 항목 속성과 연산을 정의. 구현한 원형 큐가 잘 동작하는 지 보자.# 원형 큐 호출 cq = Circularque() # 원형 큐 테스트 print(cq.isEmpty())for i in range(1,4) : cq.enqueue(i)cq.print_cq()for _ in range(2) : cq.dequeue()cq.print_cq()for i in range(4,7) : cq.enqueue(i)cq.print_cq()print(cq.isFull())덱(Deque)Double Ended QUEue큐의 일종.추상자료형속성 전단과 후단 모두에서 접근가능한 항목들의 모임연산큐의 연산 enqueueRear(): 큐 후단에 데이터 삽입한다. (enqueue) dequeueFront(): 큐 전단에서 데이터 꺼내 반환하고 삭제한다. (dequeue) isEmpty(): 큐가 비어있는지 확인한다. size(): 큐 안에 데이터가 몇개 들었는지 확인한다. isFull(): 큐가 비어있는지 화인한다.추가 enqueueFront(): 큐 전단에 데이터 삽입한다. dequeueRear(): 큐 전단에서 데이터 꺼내 반환하고 삭제한다.덱 구현 방법 파이썬 내장 collections 모듈의 deque 클래스 (1차원 배열 리스트로 구현된) 원형 큐에 덱 연산 추가덱 구현 - Collections 모듈의 deque 클래스deque 클래스덱 연산이 이미 구현되어 있는 클래스다. 갖다 쓰기만 하면 된다.덱 구현에 1차원 배열 리스트를 사용한다. 리스트를 ‘덱 처럼’ 이용한다.덱 객체 생성 시 클래스에 반복가능자를 받는다. 반복가능자 각 요소가 덱의 요소가 된다. 반복가능자 안 넣으면 빈 덱을 생성한다.deque 클래스에서 구현해 놓은 덱 연산은 enqueueRear: 큐 후단에 데이터 삽입 (append(item)) enqueueFront: 큐 전단에 데이터 삽입 (appendleft(item)) dequeueRear: 큐 후단에서 데이터 삭제 (pop()) dequeueFront: 큐 전단에서 데이터 삭제 (popleft())# collections 모듈 deque 클래스로 덱 구현하기 # 덱을 직관적. 간단하게 사용할 수 있다. from collections import dequedq = deque([88,22,11]);print(dq)dq.append(3);print(dq)dq.appendleft(76);print(dq)dq.pop();print(dq)dq.popleft();print(dq)# deque 클래스 활용 from collections import dequedq = deque('data')for elem in dq : print(elem.upper(), end='')DATAprint() dq.append('r')dq.appendleft('k')print(dq) deque([‘k’, ‘d’, ‘a’, ‘t’, ‘a’, ‘r’])dq.pop() dq.popleft() print(dq[-1])aprint('x' in dq)# 소속검사: 문자열 'x'가 dq에 소속되어 있나? Falsedq.extend('structure') # 문자열 'structure' 각 요소 하나하나를 후단에서 덱에 추가 print(dq)deque([‘d’, ‘a’, ‘t’, ‘a’, ‘s’, ‘t’, ‘r’, ‘u’, ‘c’, ‘t’, ‘u’, ‘r’, ‘e’])dq.extendleft(reversed('python')) # 문자열 'python' 문자열 순서를 반대로 뒤집고, 요소 하나하나를 차례로 덱 전단에 추가 print(dq)deque([‘p’, ‘y’, ‘t’, ‘h’, ‘o’, ‘n’, ‘d’, ‘a’, ‘t’, ‘a’, ‘s’, ‘t’, ‘r’, ‘u’, ‘c’, ‘t’, ‘u’, ‘r’, ‘e’])덱 구현 - 원형 큐에 덱 연산 추가덱은 큐의 일종이다.원형 큐에 ‘전단에서 데이터 삽입’, ‘후단에서 데이터 삭제’ 연산을 가능하게 만들면 덱이 된다.원형 큐 클래스에 ‘전단 삽입’, ‘후단 삭제’ 연산을 추가하자.# 원형 큐에 연산 추가해서 덱 구현 class Deque : def __init__(self) : self.MAX_SIZE = 5 self.front = 0 self.rear = 0 self.q = [None]*self.MAX_SIZE # 추가된 덱 연산 # 전단 삽입 def enqueueFront(self, item) : if not self.isFull() : # 포화상태가 아닐 때 # 1. front 포인터 위치에 데이터 삽입 self.q[self.front] = item # 2. front 포인터 이동 self.front = self.front -1 if self.front &lt; 0 : self.front = self.MAX_SIZE -1 # 후단 삭제 def dequeueRear(self) : if not self.isEmpty() : # 공백상태가 아닐 때 # 리어 포인터 이동 = 큐에서 제외(삭제) deleted = self.q[self.rear] # 현재 리어에 담겨 있는 거. self.rear = self.rear - 1 # 삭제: 리어 포인터 이동 if self.rear &lt; 0 : self.rear = self.MAX_SIZE - 1 return deleted # 후단 항목 조회 def peekRear(self) : return self.q[self.rear] # --------------------------- 원형 큐 연산과 동일----------------------- # 포화상태 정의 def isFull(self) : return (self.rear+1)%self.MAX_SIZE == self.front # 공백상태 정의 def isEmpty(self) : return self.front == self.rear # 삽입연산 def enqueueRear(self, item) : if not self.isFull() : # 포화상태가 아닐 때 self.rear = (self.rear+1)%self.MAX_SIZE # 다음 리어 포인터 위치 self.q[self.rear] = item # 삭제연산 def dequeueFront(self) : if not self.isEmpty() : # 공백상태가 아닐 때 self.front = (self.front+1)%self.MAX_SIZE # 다음 프론트 포인터 위치 deleted = self.q[self.front] return deleted # 뭐가 삭제됬는지 반환 # 원형 큐 출력 연산 def print_cq(self) : if not self.isEmpty(): out = [] # 리어 포인터가 프론트 포인터보다 앞에 있는 경우 if self.front &lt; self.rear : out = self.q[self.front+1:self.rear+1] # 리어 포인터가 프론트보다 뒤에 있는 경우 else : out = self.q[self.front+1:self.MAX_SIZE+1]+self.q[0:self.rear+1] print(f'front:{self.front}, rear:{self.rear}', out) def size(self) : return (self.rear-self.front+self.MAX_SIZE)%self.MAX_SIZE # 원형 큐 비우기 def clear(self) : self.front = self.rear # 원형 큐 가장 전단에 있는 항목 조회 def peek(self) : if not self.isEmpty() : return self.q[(self.front+1)%self.MAX_SIZE] # 현재 front 포인터 하나 뒤 위치의 항목 원형 큐로 구현된 덱이 잘 작동하는지 테스트# 덱 테스트 dq = Deque() for i in range(1,4) : if i%2 == 0 : # i가 짝수면 dq.enqueueRear(i) # 덱 후단에 추가 else : # 홀수면 dq.enqueueFront(i) # 덱 전단에 추가 dq.print_cq()front:3, rear:1 [3, 1, 2]for i in range(2) : dq.dequeueFront()dq.print_cq() front:0, rear:1 [2]for i in range(3) : dq.dequeueRear()dq.print_cq() for i in range(5,7) : dq.enqueueFront(i) dq.print_cq() front:3, rear:0 [6, 5]우선순위 큐(Priority Queue)큐의 일종.출력(삭제) 우선순위가 있다. 입력 순서는 중요치 않다.추상자료형속성 출력 우선순위가 있는 항목들의 모임연산 enqueue(): 데이터와 출력 우선순위 함께 큐에 삽입한다. dequeue(): 우선순위 대로 큐에서 데이터 삭제한다.우선순위 큐 구현 방법 파이썬 내장 queue 모듈의 PriorityQueue 클래스 리스트 단순연결리스트 힙트리우선순위 큐 구현 - 파이썬 내장 PriorityQueue 클래스 로 우선순위 큐 구현우선순위 큐가 이미 구현되어 있는 클래스다. 갖다 쓰기만 하면 된다. 기본 출력 우선순위는 오름차순 이다. 내가 출력 우선순위 부여하려면 (우선순위, 데이터) 튜플 형식으로 데이터 우선순위 큐에 넣으면 된다.구현되어 있는 연산 put(): 우선순위 큐에 데이터 삽입 get(): 우선순위 큐에서 우선순위 대로 데이터 삭제# 파이썬 내장 PriorityQueue 클래스로 우선순위 큐 구현 from queue import PriorityQueueque = PriorityQueue(maxsize=8) # 우선순위 큐 객체 # 큐에 데이터 삽입# 별도 출력우선순위 부여 안 했다 = 출력시키면 오름차순으로 출력된다. que.put(2);que.put(8)que.put(3);que.put(5)que.put(4);que.put(55)# 출력for _ in range(que.qsize()) : print(que.get(), end=',')print()2,3,4,5,8,55,오름차순으로 낮은 것 부터 출력된 걸 볼 수 있다.que.qsize()0PriorityQueue 에 데이터 넣을 때 사용자 정의 우선순위 부여하기# 사용자 정의 우선순위 부여해서 데이터 삽입하기 # (우선순위, 데이터) 튜플 형식으로 큐에 삽입 que.put((1,'가'));que.put((2,1))que.put((3,'s'));que.put((4,'나'))que.put((5,2))# 데이터 우선순위대로 삭제 for _ in range(que.qsize()) : print(que.get(), end=',')print()(1, ‘가’),(2, 1),(3, ‘s’),(4, ‘나’),(5, 2),뒤에 어떤 데이터가 있던 아랑곳하지 않고, 우선순위대로 삭제된 걸 볼 수 있다.우선순위 큐 구현 - 파이썬 기본 리스트로 우선순위 큐 구현우선순위 큐에서 중요한 것: 오직 출력 순위.# 파이썬 기본 리스트로 우선순위 큐 구현 class priorityque : def __init__(self) : self.items = [] # 우선순위큐가 비어있는지 확인하는 메소드 def isEmpty(self) : return len(self.items) == 0 # 비어있다'의 정의= 들어있는 아이템이 0개다. # 우선순위큐에 들어있는 항목 갯수 확인하는 메소드 def size(self) : return len(self.items) # 우선순위 큐 비우는 메소드 def clear(self) : self.items = [] # 삽입 메소드 def enqueue(self, item) : self.items.append(item) # 넣는 건 아무렇게나 넣어도 상관없다. 출력이 matter. # 최우선순위 항목 찾는 알고리즘 def find_top_priority(self) : if self.isEmpty() : return None # 비어있다면, 최우선순위는 없다. else : top_priority = 0 # 전체 항목에 대하여: 2개씩 비교해서 최우선순위항목 나올때 까지 가린다. for i in range(1, self.size()) : if self.items[i] &lt; self.items[top_priority] : # 새로운 도전자가 기존 것 보다 작을때 우선순위 부여 top_priority = i # 갱신된 최우선순위 return top_priority #(도출된 최우선순위) # 삭제 메소드: 삭제 우선순위만 지키면 된다. def dequeue(self) : # 삭제우선순위 top_priority = self.find_top_priority() if top_priority is not None : return self.items.pop(top_priority) # 최우선순위 항목 미리보기 def peek(self) : # 삭제우선순위 top_priority = self.find_top_priority() if top_priority != None : return self.items[top_priority]우선순위 큐가 잘 작동하는지 테스트# 우선순위 큐 테스트 pq = priorityque() pq.enqueue(34)pq.enqueue(18)pq.enqueue(27)pq.enqueue(45)pq.enqueue(15) # 작은 것 부터 우선순위 부여 받았으니 15,18,27,34,45 순으로 삭제될 것이라 예상. print(f'p_que:',pq.items) p_que: [34, 18, 27, 45, 15]while not pq.isEmpty() : print(f'삭제된항목:{pq.dequeue()}')삭제된항목:15삭제된항목:18삭제된항목:27삭제된항목:34삭제된항목:45우선순위 큐 구현 - 이진 힙 이용해 구현heapq파이썬 내장 모듈 중 heapq 는 파이썬 기본 리스트를 우선순위 큐로 쓸 수 있게 해준다.데이터 간 출력 우선순위 부여를 이진 힙 사용해서 한다.heapq 에 이미 선언되어 있는 메소드아래 메소드들은 동작하며 최소힙 속성 유지 한다. heappush(heap, item): 삽입연산 heappop(heap): 삭제연산 heappushpop(heap, item): item 삽입 후 삭제 수행 heapreplace(heap, item): 삭제 수행 후 item 삽입heapq로 우선순위 큐 구현# heapq - 이진 힙 이용해 우선순위 큐 구현from heapq import heappush, heappop, heappushpop, heapreplaceheap = [] # 파이썬 리스트를 우선순위 큐 처럼 사용heappush(heap, 3);heappush(heap, 8);heappush(heap, 1);heappush(heap, 0);heappush(heap,99);heappush(heap, 4);heappush(heap, 2)heap[0, 1, 2, 8, 99, 4, 3]for i in range(len(heap)) : print(heappop(heap))01234899heappushpop(heap, 5);print(heap) # 5 삽입하고 0 삭제 [1, 5, 2, 8, 99, 4, 3]heappushpop(heap, 4);print(heap) # 4 넣고 1 삭제 [2, 5, 3, 8, 99, 4, 4]heapreplace(heap, 11) # 2삭제하고 11 삽입 2print(heap)[3, 5, 4, 8, 99, 4, 11]heapreplace(heap, 17);print(heap) # 3나오고 17 삽입 [4, 5, 4, 8, 99, 17, 11]자료구조 별 삽입, 삭제연산 시간복잡도 비교설명파이썬 리스트로 구현한 스택은 리스트 후단에 삽입연산 한번이면 된다. $O(1)$ 리스트 후단에서 삭제연산 한번이면 된다. $O(1)$연결리스트로 구현한 스택은 새 노드 만들고 헤드포인터 지정하면 전단에서 삽입된다. $O(1)$ 헤드포인터 다음 노드로 옮기면 연결리스트에서 삭제된다. $O(1)$파이썬 리스트로 구현한 큐(원형 큐)는 리어 포인터에서 삽입연산 한번이면 된다. $O(1)$ 프론트 포인터에서 삭제연산 한번이면 된다. $O(1)$원형 연결리스트로 구현한 큐(원형 큐)는 리어 포인터에서 삽입연산 한번이면 된다. $O(1)$ 프론트 포인터에서 삭제연산 한번이면 된다. $O(1)$파이썬 리스트로 구현한 덱(원형 큐로 구현한 덱)은 리어 포인터든, 프론트 포인터든 삽입연산 한번이면 된다. $O(1)$ 리어 포인터든, 프론트 포인터든 삭제연산 한번이면 된다. $O(1)$원형 연결리스트로 구현한 덱(원형 큐로 구현한 덱)은 리어 포인터든, 프론트 포인터든 삽입연산 한번이면 된다. $O(1)$ 리어 포인터든, 프론트 포인터든 삭제연산 한번이면 된다. $O(1)$순서없는 파이썬 리스트로 구현된 우선순위 큐는 append 연산으로 파이썬 리스트 후단에 계속 집어넣으면 된다. 삽입연산 $O(1)$ 막 넣었기 때문에 삭제할 때는 항목들 비교해서 최우선순위 항목 찾아야 된다. n개 항목을 서로 비교하면 최대 시간복잡도 $O(n)$ 만큼 걸릴 것이다.순서없는 연결리스트로 구현된 우선순위 큐는 새 노드 만들고 기존 최후단 노드랑 링크로 연결하면 삽입에 $O(1)$ 만큼 시간복잡도 걸린다. 각 노드에 담겨 있는 데이터 필드를 서로 비교해서 최우선순위 항목 찾아야 된다. 연결리스트이므로 헤드포인터 붙은 0번 항목부터 순차 접근해가면서 항목들 우선순위 비교해야만 한다. 따라서 시간상한은 최대 $O(n)$ 까지 걸릴 수 있다.정렬된 파이썬 리스트로 구현된 우선순위 큐는 삽입할 때 항목별 우선순위에 맞춰서 넣어야 한다. 만약 0번 인덱스에 뭔가 넣어야 된다면, 기존 항목들이 뒤로 1칸씩 물리적 이동하면서 삽입에 최대 $O(n)$ 만큼 시간 복잡도 걸릴 것이다. 이미 모든 항목이 우선순위대로 정렬되어 있다. 따라서 삭제할 때는 이동하고 자시고 할 것 없이. 가장 앞 0번 인덱스부터 순서대로 삭제하면 된다. $O(1)$정렬된 연결리스트로 구현된 우선순위 큐는 삽입할 때 우선순위 지켜서 넣어야 한다. 따라서 뭔가 항목을 넣으려면 연결리스트의 0번 노드에서 시작해서 n번 노드까지 접근하면서 새 항목과 기존 항목 간 우선순위 비교해야만 한다. $O(n)$ 모든 항목이 우선순위대로 정렬되어 있다. 헤드포인터 한칸씩 뒤로 이동하면서 전단노드부터 연결리스트에서 빼면 된다. $O(1)$힙으로 구현된 우선순위큐는 힙 자료구조를 좀 더 공부한 뒤 다시 정리하겠다." }, { "title": "[통계학개론 복습] 회귀분석 개념, 종류, 단순선형회귀분석, 다중선형회귀분석", "url": "/bioinfo.github.io/posts/regression/", "categories": "Statistics, R, Data Science", "tags": "Statistics, R, Data Science", "date": "2022-01-11 00:00:00 +0900", "snippet": "회귀분석(Regression Analysis)통계적 모형 중 회귀함수를 찾는 분석이다.통계적(확률론적) 모형입력과 출력 사이 관계가 일정하게 대응되지 않는 모형. 항상 오차를 수반한다.$Y = f(x_{1}, x_{2}, x_{3}, … x_{n}) + \\epsilon$$\\epsilon$ 이 오차항이며, $N(0, \\sigma^{2})$ 을 따르는 확률변숫값이다. 따라서 출력 $Y$ 도 확률변숫값이다.수학적(결정론적) 모형입력과 출력 사이 일정한 대응관계 성립하는 모형. 수학적 함수다. 오차를 수반하지 않는다.$Y = f(x_{1}, x_{2}, x_{3}, … x_{n})$회귀모형은 통계적 모형이다.회귀모형(Regression Model)회귀모형은 회귀함수 $f(x_{i})$ 와 오차항 $\\epsilon$ 으로 구성된다.$Y = f(x_{1}, x_{2}, x_{3}, … x_{n}) + \\epsilon$회귀분석은 위 모형에서 회귀함수 $f(x_{1}, x_{2}, x_{3}, … x_{n})$ 를 찾는 분석이다. $Y:$ 반응변수, 종속변수 $x_{1}, x_{2}, … x_{n}:$ 설명변수, 독립변수 $\\epsilon:$ 오차항 $f(x_{1}, x_{2}, x_{3}, … x_{n}):$ 회귀함수회귀모형 종류회귀모형 = 회귀함수 + 오차회귀함수 종류에 따라 회귀모형을 구분한다.모수회귀모형정의: 회귀함수 형태가 고정된 회귀모형 회귀분석 할 때는 형태 고정된 어떤 회귀함수로 모회귀모형을 설정하고, 그 모회귀모형의 추정모형(적합모형) 을 찾는다.모수회귀모형 종류 단순선형회귀모형: $f(X) = \\beta_{0}+\\beta_{1}X$. 회귀함수가 1차원 선형함수다. 다중선형회귀모형: $f(X) = \\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}…+\\beta_{n}X_{n}$. 회귀함수가 회귀계수와 설명변수 벡터의 선형조합 형태다. 비선형회귀모형: $f(X) = \\frac{\\beta_{0}X}{\\beta_{1}+X}$. 회귀함수는 $\\beta$ 와 설명변수 $X$의 비선형결합 형태다. $k-$차 다항회귀모형: $f(X) = \\beta_{0}+\\beta_{1}X + \\beta_{2}X^{2}+\\beta_{3}X^{3}…+\\beta_{k}X^{k}$. 회귀함수가 회귀계수와 설명변수 $X$ $k$차 항의 선형조합 형태다. 로지스틱 회귀모형: 반응변수 $Y$ 가 이항분포(n번 중 성공 횟수)를 따를 때 로그선형모형: 반응변수 $Y$가 포아송분포를 따를 때비모수회귀모형정의: 회귀함수 $f(X)$ 형태가 고정되어 있지 않은 회귀모형 회귀함수는 특정 가정만 만족하면 된다. 예) 3번 미분 가능한 함수회귀분석의 논리 흐름아래와 같이 실현된 데이터를 내가 갖고 있다고 가정해보자.이 데이터는 본래 어떤 형태 모형에서 실현되었을까? 알 수 없다. 데이터를 실현시킨 본래 ‘참모형(True model)’ 을 아는 건 신의 영역이다. 인간은 알 수 없다.$\\Rightarrow$ 데이터를 발생시킨 본래 모형을 ‘참모형(True model)’ 이라고 한다.따라서 참 모형을 알아내는 건 우리 관심사가 아니다. 무슨 노력을 해도 알 수 없다. 미지의 영역이고, 신의 영역이다.따라서 우리 인간은 참 모형의 대안으로, 실현된 데이터를 가장 잘 설명해 줄 수 있을 것 같은 임의의 모형을 ‘설정’ 한다. 이 모형을 ‘설정모형’ 이라고 한다.위 산점도를 보니 데이터가 양의 선형 상관관계 있어 보인다. 데이터가 선형으로, 오른쪽 위를 향하고 있으므로 오른쪽 위를 향하는 ‘직선’으로 이 데이터를 잘 설명할 수 있을 걸로 보인다.직선 형태 회귀함수 갖는 회귀모형은 단순선형회귀모형이 있다. 단순선형회귀모형을 설정모형으로 선택한다.$\\Rightarrow$ 설정모형: $Y = \\beta_{0}+\\beta_{1}X + \\epsilon$이 설정모형의 회귀함수 $Y =\\beta_{0}+\\beta_{1}X$는 $Y \\vert{X}$ 분포의 기댓값들을 연결한 것과 같다. 이 회귀함수를 모회귀함수(모회귀선) 라고 한다.[이미지 출처: http://www.aistudy.com/math/regression_lee.htm ]하지만 $Y \\vert{X}$ 분포 기댓값들은 인간이 알 수 없는 미지의 값이다. 즉, 모회귀선은 알 수 없는 어떤 모수라고 생각할 수 있다. 미지의 모수를 추정하려면 실현된 데이터를 이용해서 추정치를 찾는다. 여기서도 마찬가지로, 실현된 데이터를 이용해서 모회귀선의 추정치를 찾는다.회귀선과 실현된 데이터 사이 차이를 ‘잔차’라고 하는데, 이 잔차 제곱합(총 잔차 크기)이 최소가 되는 회귀선을 모회귀선 추정치로 삼는다.$\\Rightarrow$ 이 추정치를 ‘표본회귀선’ 이라 부른다. 표본회귀선은 $Y \\vert{X}$ 분포 기댓값 추정치를 연결한 선이다. 한편 정규분포 기댓값 모수는 하나인데 기댓값 모수 추정치(표본평균)은 표본 얻을 때 마다 달라지는 것 처럼, 표본회귀선도 표본 얻을 때 마다 달라진다. 곧, 1개 표본회귀선은 모회귀선에 대한 여러 추정치중 하나에 불과하다.[이미지 출처: http://www.aistudy.com/math/regression_lee.htm ]표본회귀선을 회귀함수로 삼은 회귀모형을 표본회귀함수 또는 적합모형(fitted model) 이라고 한다.적합모형 = 표본회귀선(회귀함수) + $\\epsilon$적합모형은 모회귀모형 또는 설정모형에 대한 추정모형이다.회귀분석의 최종목표는 주어진 데이터에 대해 적합모형의 회귀함수. 표본회귀선을 찾는 것이다.모수회귀모형 - 단순선형회귀모형정의: 회귀함수가 $f(X) = \\beta_{0}+\\beta_{1}X$ 선형 형태로 고정된 회귀모형특징: 설명변수 $X$ 가 1개다.형태:$Y = \\beta_{0} + \\beta_{1}X + \\epsilon$ $Y:$ 반응변수 $\\beta_{0}, \\beta_{1}:$ 회귀계수 $X:$ 설명변수 $\\epsilon:$ 잔차두 회귀계수는 확률변숫값이다. 확률변수 내부에 확률분포를 내포한다. $\\beta_{0}, \\beta_{1}$ 은 확률분포의 기댓값 모수다. 정확하게 알 수 없다. 즉, 추정의 대상이다.$\\beta_{0}, \\beta_{1}$ 이 기댓값 모수이므로, $\\beta_{0} + \\beta_{1}X$ 의미를 ‘$X$ 에서 $Y$ 기댓값’ 이라고 해석할 수 있다. 이 $Y$ 기댓값에서 잔차 $\\epsilon$ 을 더하면 실현된 반응변수 $Y$ 값이 나온다.기댓값은 모수이므로 정확하게 알 수 없다. 따라서 $\\beta_{0} + \\beta_{1}X$ 도 정확하게 알 수 없다. 추정 대상이다. $\\beta_{0} + \\beta_{1}X$ 를 추정하기 위해 $\\beta_{0}$ 와 $\\beta_{1}$ 기댓값 모수 추정치를 각각 구한다. 그 점 추정치는 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 이라고 하며, 최소제곱추정(최소자승법) 을 이용해서 구한다.기댓값 모수 점 추정치 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 로 구성된 회귀함수 $\\hat{\\beta_{0}} + \\hat{\\beta_{1}}X$ 를 표본회귀함수 라고 하고, $\\beta_{0} + \\beta_{1}X$ 의 추정치로 삼는다. 표본회귀함수는 $Y$ 기댓값 추정치다.단순선형회귀모형의 목표는 $Y$ 기댓값 추정치, 그러니까 표본회귀함수 $\\hat{\\beta_{0}} + \\hat{\\beta_{1}}X$ 를 찾는 것이다.한편, 잔차 $\\epsilon$ 은 정규분포 $N(0, \\sigma^{2})$ 을 따른다고 알려져 있다. $\\sigma^{2}$ 은 알 수 없는 모수 값이다. $\\sigma^{2}$ 또는 $\\sigma$ 를 알면 회귀모형의 대략적인 잔차 크기를 알 수 있다. $\\epsilon$ 의 표준편차 $\\sigma$ 는 $\\epsilon$ 값들이 기댓값 $0$ 에서 대략적으로 떨어진 정도를 의미한다. 즉, $\\epsilon$ 의 대략적 크기다. 이 때문에 $\\sigma$ 를 알면 회귀모형의 대략적 잔차 크기를 알 수 있는 것이다.회귀모형의 대략적 잔차 크기를 알면 그 회귀모형이 실현된 데이터를 잘 설명하는지(잘 적합 되었는지) 알 수 있다. 대략적 잔차 크기가 작을 수록, 모형이 주어진 데이터를 잘 설명한다(잘 적합되었다). 모형이 실현된 데이터를 잘 설명하는지 판단. 확인하는 것은 모형 선택에서 중요한 절차다. 모형이 주어진 데이터 잘 설명 못하면 데이터를 더 모으거나, 설정모형을 바꿔야 할 것이다. 따라서 잔차 $\\epsilon$ 의 분산모수 $\\sigma^{2}$ 또는 표준편차 모수 $\\sigma$ 를 아는 것도 중요하다. 종합하면 단순선형회귀모형의 최종 목표는 $\\beta_{0}, \\beta_{1}, \\sigma^{2}$ 을 추정하는 것이다.단순선형회귀모형 목표 $\\Rightarrow$ 3개 모수 $\\beta_{0}, \\beta_{1}, \\sigma^{2}$ 추정모수추정을 위해. 언제나 그랬듯이, 데이터(표본)를 관측한다. 관측된 표본들과 최소제곱추정(최소자승법) 을 사용해서 모수 추정치를 찾는다.최소제곱추정(LSE: Least Squares Estimation)정의: 모형의 잔차 제곱합(총 잔차 크기)을 최소화 시키는 $\\beta_{0}, \\beta_{1}$ 점 추정치를 찾는 방법$argmin_{\\beta_{0}, \\beta_{1}} \\sum{(Y_{i}-\\hat{Y_{i}})^{2}} = argmin_{\\beta_{0}, \\beta_{1}} \\sum{(Y_{i}-(\\hat{\\beta_{0}}+\\hat{\\beta_{1}}X_{i}))^{2}}$목적함수 $\\sum{(Y_{i}-(\\hat{\\beta_{0}}+\\hat{\\beta_{1}}X_{i}))^{2}}$ 에 대한 최적화 필요조건은 ‘$\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 으로 각각 편미분한 1차 도함수가 최적값에서 0이 되어야 한다’ 이다.1차 도함수를 0 만드는 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 이 최적해(최소해) 이며, 각각 $\\beta_{0}, \\beta_{1}$ 의 점 추정치다.목적함수를 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 으로 편미분 한 결과는 아래와 같다.목적함수를 $D$ 라고 칭하겠다.편미분 결과$\\frac{\\partial{D}}{\\partial{\\hat{\\beta_{0}}}} = -2\\sum{(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})} = 0$$\\frac{\\partial{D}}{\\partial{\\hat{\\beta_{1}}}} = -2\\sum{X_{i}(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})} = 0$여기서 $\\sum{(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})} = 0$ 와 $\\sum{X_{i}(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})} = 0$ 를 ‘정규방정식’ 이라고 한다.정규방정식 $\\sum{(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})} = 0$ $\\sum{X_{i}(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})} = 0$편미분 결과 1차 도함수를 $0$ 되게 만드는 $\\hat{\\beta_{0}}$ 과 $\\hat{\\beta_{1}}$ 을 구하면 아래와 같다.$\\beta_{0}$ 점 추정치(최소제곱추정치) $\\hat{\\beta_{0}} = \\bar{Y}-\\hat{\\beta_{1}}\\bar{X}$$\\beta_{1}$ 점 추정치(최소제곱추정치) $\\hat{\\beta_{1}} = \\frac{\\sum{(X_{i}-\\bar{X})(Y_{i}-\\bar{Y})}}{\\sum{(X_{i}-\\bar{X})^{2}}} = \\frac{S_{XY}}{S_{XX}}$ $\\hat{\\beta_{0}}$ 과 $\\hat{\\beta_{1}}$ 을 사용해서 만든 회귀함수 $\\hat{\\beta_{0}}+\\hat{\\beta_{1}}X$ 가 표본회귀함수(표본회귀선) 이고 $\\hat{\\beta_{0}}+\\hat{\\beta_{1}}X$ 를 회귀함수로 사용한 회귀모형이 적합모형(fitted model) 이다.$\\epsilon$ 분산모수 $\\sigma^{2}$ 추정과 $\\beta_{0}, \\beta_{1}$ 구간추정 및 가설검정앞에서는 $\\beta_{0}, \\beta_{1}$ 를 점 추정 했다. 하지만 모수의 점 추정치는 표본 얻을 때 마다 다르며, 여러 개 존재한다. 따라서 점 추정치 이용해서 모수 구간추정 해야 할 필요가 있다.$\\epsilon$ 분산모수 $\\sigma^{2}$ 추정$\\epsilon_{i} = Y_{i}-\\hat{Y_{i}} = Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i}$$\\epsilon \\sim N(0, \\sigma^{2})$ 이다.$\\epsilon$ 표본 값들의 비편향 표본분산이 분산모수 $\\sigma^{2}$ 의 비편향 추정치가 될 수 있다.$s^{2} = \\frac{1}{(n-2)}\\sum{(\\epsilon_{i} - 0)^{2}} = \\frac{1}{(n-2)}\\sum{\\epsilon_{i}^{2}} = \\frac{1}{(n-2)}\\sum{(Y_{i}-\\hat{\\beta_{0}}-\\hat{\\beta_{1}}X_{i})^{2}}$ $s^{2}$ 을 구하기 위해서는 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 두 값을 알아야만 한다. 즉, $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 는 제약조건이다. $s^{2}$ 을 구하는 데 필요한 표본 수 $n - $ 제약조건 $2$ 개 $=$ 자유도 $(n-2)$ 이다. 그래서 $s^{2}$ 구할 때 $(n-2)$ 로 나누는 것이다.$\\epsilon$ 분산모수 $\\sigma^{2}$ 점 추정치 = $s^{2} = \\frac{1}{(n-2)}\\sum{\\epsilon_{i}^{2}}$$\\beta_{1}$ 구간추정$95$% 신뢰구간을 구하고 싶다면 점 추정치 $\\hat{\\beta_{1}}$ 이 따르는 분포에서 면적 $0.95$ 에 해당하는 구간을 찾으면 된다.분포의 면적을 좀 더 쉽게 구하기 위해 $\\hat{\\beta_{1}}$ 을 표준화 시킨다.$E[\\hat{\\beta_{0}}] = \\beta_{1}$$V[\\hat{\\beta_{1}}] = \\frac{s^{2}}{S_{XX}}$$\\frac{\\hat{\\beta_{1}} - \\beta_{1}}{\\frac{s}{\\sqrt{S_{XX}}}} \\sim t(n-2)$ t분포(통계량)는 $s$ 때문에 자유도가 $(n-2)$ 다.$\\beta_{0}$ 의 $95$% 신뢰구간$\\hat{\\beta_{1}} \\pm t_{\\alpha/2}\\frac{s}{\\sqrt{S_{XX}}}$$\\beta_{0}$ 구간추정$\\beta_{0}$ 에 대해서도 $\\beta_{1}$ 구간추정과 같은 메커니즘을 적용한다.$E[\\hat{\\beta_{0}}] = \\beta_{0}$$V[\\hat{\\beta_{0}}] = s^{2}(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{S_{XX}})$$\\frac{\\hat{\\beta_{0}} - \\beta_{0}}{s\\sqrt{\\frac{1}{n}+\\frac{\\bar{x}^{2}}{S_{XX}}}} \\sim t(n-2)$ t분포(통계량)는 $s$ 때문에 자유도가 $(n-2)$ 다.$\\beta_{0}$ 의 $95$% 신뢰구간$\\hat{\\beta_{0}}\\pm t_{\\alpha/2}s\\sqrt{\\frac{1}{n}+\\frac{\\bar{x}^{2}}{S_{XX}}}$$\\beta_{0}, \\beta_{1}$ 가설검정$H_{0}: \\beta_{i} = \\beta_{criterion}$$H_{a}: \\beta_{i} (\\ne or &gt; or &lt;) \\beta_{criterion}$ $\\beta_{criterion}$ 은 기준값 상수$\\beta_{0}$ 과 $\\beta_{1}$ 검정통계량은 두 값의 점 추정치가 된다. $\\beta_{0}$ 검정통계량: $\\frac{\\hat{\\beta_{0}} - \\beta_{0}}{s\\sqrt{\\frac{1}{n}+\\frac{\\bar{x}^{2}}{S_{XX}}}}$ $\\beta_{0}$ 검정통계량 분포: $t(n-2)$ $\\beta_{1}$ 검정통계량: $\\frac{\\hat{\\beta_{1}} - \\beta_{1}}{\\frac{s}{\\sqrt{S_{XX}}}}$ $\\beta_{1}$ 검정통계량 분포: $t(n-2)$ 이제 유의수준 $\\alpha$ 를 적절한 값으로 설정하고, $\\beta_{0}, \\beta_{1}$ 의 유의확률(p-value) 를 구해서유의확률이 유의수준보다 작으면 귀무가설 기각, 대립가설 채택.유의확률이 유의수준보다 크면 귀무가설 기각할 수 없음. 으로 결론 지으면 된다.회귀모형의 적합도정의: 회귀모형 $\\hat{Y}$ 이 $\\bar{Y}$ 에 비해 더 나은 정도$\\Rightarrow$ 회귀모형이 제공하는 설명력이 $\\bar{Y}$ 보다 나은 정도$\\Rightarrow$ 회귀모형이 제공하는 설명력의 정도회귀모형 적합도는 결정계수 $R^{2}$(또는 $r^{2}$) 로 나타낸다.$R^{2}$ 결정계수정의: 회귀모형의 데이터에 대한 적합도(설명력)를 나타내는 값$R^{2} = \\frac{SST}{SST} = 1-\\frac{SSE}{SST}$, $(0 &lt; R^{2} &lt; 1)$ $SST$: 총 제곱합 $\\sum{(Y_{i}-\\bar{Y}})^{2}$ $SSR$: 회귀 제곱합 $\\sum{(\\hat{Y_{i}}-\\bar{Y})^{2}}$ $SSE$: 잔차 제곱합 $\\sum{(Y_{i}-\\hat{Y_{i}})^{2}}$ 결정계숫값이 0에 가까울 수록 회귀모형이 X,Y 사이 관계를 제대로 설명 못한다는 말이다. 결정계숫값이 1에 가까울 수록 회귀모형이 X,Y 사이 관계를 잘 설명한다는 말이다. 단순선형회귀에서는 표본상관계수(피어슨 상관계수) $r$ 값을 제곱하면 결정계숫값과 같아진다.SST, SSR, SSE 사이 관계와 분산분석 표(ANOVA Table)회귀모형의 3개 제곱합, SST, SSR, SSE 사이 관계는 아래와 같이 유도할 수 있다.$Y_{i} - \\bar{Y} = \\hat{Y_{i}}-\\bar{Y} + Y_{i}-\\hat{Y}_{i}$양변을 제곱하면$(Y_{i} - \\bar{Y})^{2} = (\\hat{Y_{i}}-\\bar{Y})^{2} + (Y_{i}-\\hat{Y_{i}})^{2} + 2(\\hat{Y_{i}}-\\bar{Y})(Y_{i}-\\hat{Y_{i}})$$\\sum{(Y_{i} - \\bar{Y})^{2}} = \\sum{(\\hat{Y_{i}}-\\bar{Y})^{2}} + \\sum{(Y_{i}-\\hat{Y_{i}})^{2}} + \\sum{2(\\hat{Y_{i}}-\\bar{Y})(Y_{i}-\\hat{Y_{i}})}$여기서 $\\sum{2(\\hat{Y_{i}}-\\bar{Y})(Y_{i}-\\hat{Y_{i})}}$ 은 $0$ 이 된다.정규방정식으로 cross product term $= 0$ 증명$\\sum{2(\\hat{Y_{i}}-\\bar{Y})(Y_{i}-\\hat{Y_{i}})}$ 에서 $(Y_{i}-\\hat{Y_{i}})$ 를 앞으로 분배한다.$\\Rightarrow 2\\sum{\\hat{Y_{i}}(Y_{i}-\\hat{Y_{i}})} - 2\\sum{\\bar{Y}(Y_{i}-\\hat{Y}_{i})}$정규방정식 1번은 $\\sum{(Y_{i}-\\hat{Y_{i}})} = 0$ 이었다.두 번째 항 $2\\sum{\\bar{Y}(Y_{i}-\\hat{Y_{i}})}$ 은 정규방정식 1번에 의해 0 된다.$2\\bar{Y}\\sum{(Y_{i}-\\hat{Y_{i}})} = 0$그러면 첫번째 항 $2\\sum{\\hat{Y_{i}}(Y_{i}-\\hat{Y_{i}})}$ 만 남는다.$\\hat{Y_{i}} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}x_{i}$ 를 이용해서 $2\\sum{\\hat{Y_{i}}(Y_{i}-\\hat{Y_{i}})}$ 를 변형시키자.$\\Rightarrow$ $2\\sum{(\\hat{\\beta_{0}}+\\hat{\\beta_{1}}x_{i})(Y_{i}-\\hat{Y_{i}})}$$(Y_{i}-\\hat{Y_{i}})$ 를 앞으로 분배하자.$\\Rightarrow 2\\sum{\\hat{\\beta_{0}}(Y_{i}-\\hat{Y_{i}})+2\\sum{\\hat{\\beta_{1}}x_{i}(Y_{i}-\\hat{Y_{i}})}}$위 식에서 첫 번째 항 $2\\sum{\\hat{\\beta_{0}}(Y_{i}-\\hat{Y_{i}})}$ 은 앞에서 사용한 정규방정식 1번에 의해 $0$ 된다.$2\\hat{\\beta_{0}}\\sum{(Y_{i}-\\hat{Y_{i}})} = 0$정규방정식 2번은 $\\sum{x_{i}(Y_{i}-\\hat{Y_{i}})} = 0$ 이었다.위 식에서 두 번째 항 $2\\sum{\\hat{\\beta_{1}}x_{i}(Y_{i}-\\hat{Y_{i}})}$ 은 정규방정식 2번에 의해 $0$ 된다.$2\\hat{\\beta_{1}}\\sum{x_{i}(Y_{i}-\\hat{Y_{i}})} = 0$결국 $0+0 = 0$ 된다.SST, SSR, SSE 사이 관계$\\Rightarrow \\sum{(Y_{i} - \\bar{Y})^{2}} = \\sum{(\\hat{Y_{i}}-\\bar{Y})^{2}} + \\sum{(Y_{i}-\\hat{Y}_{i})^{2}}$ $\\sum{(Y_{i} - \\bar{Y})^{2}}:$ 총 제곱합(Total Sum of Squares) $\\sum{(\\hat{Y_{i}}-\\bar{Y})^{2}}:$ 회귀 제곱합(Regression Sum of Squares) $\\sum{(Y_{i}-\\hat{Y}_{i})^{2}}:$ 잔차 제곱합(Error Sum of Squares) 총 제곱합은 $X$ 에 상관없이 고정된 값이다. 총 제곱합이 고정되어 있으므로, 회귀제곱합과 잔차제곱합은 반대로 움직인다. 회귀모형 적합도가 높아지면 회귀제곱합이 커지고 잔차 제곱합이 작아진다. 반대도 성립한다.각 제곱합의 자유도 총 제곱합: $\\bar{Y}$ 때문에 제약조건이 1개 있다. 따라서 $n-1$ 잔차 제곱합: $\\hat{Y_{i}} = \\hat{\\beta_{0}}+\\hat{\\beta_{1}}x_{i}$ 이었다. $\\hat{Y_{i}}$ 을 구하려면 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 이 필요하다. 따라서 제약조건이 2개다. 자유도$: n-2$ 회귀 제곱합: 총 제곱합 자유도$(n-1)$ - 잔차 제곱합 자유도$(n-2)$ $=1$ 이다.분산분석표(ANOVA Table) 을 이용하면 위 관계와 각 제곱합의 자유도, 평균제곱, F비를 한번에 나타낼 수 있다.회귀의 분산분석표[이미지 출처: 부산대학교 김충락 교수님의 R을 이용한 통계학개론 - 07_회귀분석.pdf 23 페이지] 평균제곱: $\\frac{제곱합}{자유도}$ $F$비: $\\frac{MSR}{MSE}$, 모형 전체의 통계적 유의성을 검정할 때 사용한다. $R^{2}$ 결정계수: $\\frac{SSR}{SST} = 1-\\frac{SSE}{SST}$ R에서 단순선형회귀분석 하기# 단순선형회귀분석x &lt;- c(3,3,4,5,6,6,7,8,8,9)y &lt;- c(9,5,12,9,14,16,22,18,22,24)length(x);length(y)# 단순선형회귀모형으로 적합 fit &lt;- lm(y~x) # y: 종속변수 , x: 설명변수 summary(fit)summary() 결과 설명Residuals$Y_{i} - \\hat{Y_{i}}$ 잔차 값들의 최솟값, 1분위수, 중앙값, 3분위수, 최댓값 출력Coefficients최소제곱추정으로 구한 회귀계수 추정치 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}$ 출력한다.Intercept 가 $\\hat{\\beta_{0}}$ 에 해당하고, x 가 $\\hat{\\beta_{1}}$ 에 해당한다. 각각 -1.3594, 2.7897 이 나왔다(Estimate).한편 두 점 추정치를 표준화 한 $t$ 통계량 값도 볼 수 있다(t value). 각각 -0.544, 6.958 이다. 둘 다 자유도 8(10-2)인 $t$ 분포를 따른다.이 $t$ 통계량을 검정통계량, $t$ 분포를 검정통계량분포로 삼았을 때 유의확률이 가장 오른쪽 값이다. 각각 0.601495, 0.000117 이 나온 걸 관찰할 수 있다. 그리고 그 유의확률에 따른 귀무가설 기각 여부를 별(*) 표시로 알 수 있다.여기서 귀무가설은 $H_{0}: \\hat{\\beta_{i}} = 0$ (회귀계수가 의미 없다) 가 된다. 대립가설은 ‘회귀계수는 통계적으로 유의미하다’가 된다. Intercept는 별이 없다. 유의확률 값이 커서 회귀계수가 통계적으로 유의미하지 않다. 반면 X 는 별이 있다. 유의확률값이 작아서 $\\hat{\\beta_{1}}$ 이 통계적으로 유의미함을 나타낸다.각 회귀계수의 통계적 유의성에 따라, 회귀모형은 최종으로 $\\hat{Y_{i}} = \\hat{\\beta_{1}}X_{i}$ 가 된다.Residual standard error잔차의 표본표준편차 $s$ 를 말한다. 회귀모형이 대체로 어느 정도의 잔차를 갖는지 알려준다. $s = 2.564$ 가 나왔다. 그리고 $s$ 의 자유도는 8(10-2) 가 나온다.Multiple R-squared결정계숫값 $R^{2}$ 이다. 0.8592 가 나왔다. 회귀모형의 설명력이 꽤 높은 편이다.Adjusted R-squared다중회귀모형의 경우 모형에 여러 변수를 많이 넣으면 많이 넣을 수록, 개별 독립변수 $X_{i}$ 의 $Y$ 에 대한 설명력 유무에 관계 없이 모형의 결정계숫값(설명력) 이 올라가는 경향이 나타난다.즉, 모형에 포함된 어떤 $X_{i}$ 가 $Y$ 설명에 별 도움이 안되는데도 모형에 설명변수를 많이 넣었다는 이유 만으로 모형의 ‘설명력이 높다’고 나올 수 있다.이 문제를 해결하기 위해 사용하는 게 조정된 결정계숫값이다. 조정된 결정계숫값은 개별 변수의 데이터 수 보다 변수 갯수가 더 많아지면(선형종속 발생 환경), 추가되는 설명변수에 대해 패널티를 부여해서 값을 산출한다.다중선형회귀모형 일 때는 결정계숫값과 조정된 결정계숫값 두 가지를 모두 보는 것이 좋다. 만약 두 값 사이 차이가 크다면, 종속변수 $Y$ 설명에 별 도움 안 되는 설명변수 $X$ 가 모형에 끼어있을 수 있을 수 있다.F-statisticF비 값이다. $F = \\frac{MSR}{MSE}$. 모형 전체의 통계적 유의성을 검정할 때 사용한다.귀무가설은 ‘$\\hat{\\beta_{0}}$ 을 제외한 모든 회귀계숫값 = 0(통계적 관점에서, 모형이 유의미하지 않다)’, 대립가설은 ‘최소한 회귀계수 하나는 0이 아니다(통계적 관점에서, 모형이 유의미하다)’ 이다.F비 값이 따르는 F 분포는 자유도로 (MSR자유도, MSE자유도) 를 갖는다. 이 경우에는 회귀제곱합의 자유도 1, 잔차제곱합의 자유도 8 이라서 DF가 1 and 8로 나왔다.F분포 상에서 F비 값 48.48의 유의확률은 0.0001174로, $\\alpha = 0.05, 0.01, 0.1$ 세 유의수준보다 모두 낮다. 따라서 이 회귀모형은 통계적 유의성을 갖는다.# 잔차 출력 resid(fit)# 또는 rr &lt;- y - fitted(fit);rrresid() 명령은 잔차 $\\epsilon_{i}$ 를 출력해준다.# 회귀계수 만 출력 coef(fit)# 또는 fit$coefficients# 회귀계수의 신뢰구간 confint(fit, level=0.95)# 산점도에 표본회귀선을 그리고 싶을 때 plot(x,y)abline(fit)# 분산분석표 ANOVA Table anova(fit)요인 중 회귀와 잔차(오차)가 제시된 분산분석표를 볼 수 있다.참고)모수회귀모형 - 다중선형회귀모형p개 변수 관측치 벡터의 선형조합.$Y = \\beta_{0}1+\\beta_{1}X_{1}+\\beta_{2}X_{2}+…\\beta_{p-1}X_{p-1}+\\epsilon$ $X_{i}$ 는 $i$ 번째 변수의 관측치 벡터 $\\beta_{i}$ 는 다른 변수와 독립적으로 변수 $X_{i}$가 1 증가할 때 $Y$ 가 증가하는 양 $\\beta_{i}$ 는 스칼라 값, $1$ 과 $X_{i}$ 는 벡터위 식을 행렬 이용해서 아래와 같이 나타낼 수도 있다.[이미지 출처: 부산대학교 김충락 교수님의 R을 이용한 통계학개론 - 07_회귀분석.pdf 28페이지]$Y = X\\beta + \\epsilon$ $Y$ 는 $(n \\times 1)$ 차원 벡터 $X$ 는 $p-1$ 개 변수의 $n$ 개 관측치로 구성된 $(n\\times p)$ 차원 행렬 $\\beta$ 는 각 변수의 가중치로 구성된 $(p\\times{1})$ 벡터 $\\epsilon$ 은 관측치 $Y_{i}$와 $Y$ 기댓값 예측치 사이 잔차값들로 구성된 $(n\\times{1})$ 벡터다중선형회귀모형의 최종 목표:가중치 벡터 $\\beta$ 를 찾는 것.가중치 벡터 $\\beta$ 는 알 수 없는 모수 값들로 구성되어 있다.$\\beta = [\\beta_{0}, \\beta_{1}, \\beta_{2}, … \\beta_{p-1}]^{T}$따라서 단순선형회귀분석에서 회귀계수 $\\beta_{0}$ 과 $\\beta_{1}$ 을 찾을 때와 마찬가지로, ‘추정’ 해야 한다.가중치 벡터 $\\beta$ 를 추정하는 방법은 단순선형회귀분석과 마찬가지로, 잔차 제곱합(잔차 총 크기)가 최소가 되는 $\\beta$ 를 찾는 것이다.잔차 총 크기 = 잔차 벡터 $norm^{2}$ 하면 얻을 수 있다.${\\vert{\\epsilon}\\vert{}}^{2} = \\sqrt{요소 제곱합}^{2} =$ 요소제곱합$\\Rightarrow \\sum{\\epsilon_{i}^{2}} = \\epsilon^{T}\\epsilon$위에서 $Y = X\\beta+\\epsilon$ 이었다. $X\\beta$ 를 좌변으로 넘기면$\\epsilon = Y-X\\beta$ 가 된다.$\\Rightarrow \\epsilon^{T}\\epsilon = (Y-X\\beta)^{T}(Y-X\\beta)$목표는 $(Y-X\\beta)^{T}(Y-X\\beta)$ 가 최소가 되는 $\\beta$ 를 찾는 것이다.$argmin_{\\beta}{(Y-X\\beta)^{T}(Y-X\\beta)}$$\\Rightarrow (Y-X\\beta)^{T}(Y-X\\beta) = (Y^{T}-\\beta^{T}X^{T})(Y-X\\beta)$앞의 괄호를 뒤로 분배하면$Y^{T}Y-Y^{T}X\\beta-\\beta^{T}X^{T}Y + \\beta^{T}X^{T}X\\beta$두번째 항 $Y^{T}X\\beta$ 는 스칼라 값이다. 통째로 전치연산 해도 같다.$= Y^{T}Y-(Y^{T}X\\beta)^{T}-\\beta^{T}X^{T}Y + \\beta^{T}X^{T}X\\beta$$= Y^{T}Y-\\beta^{T}X^{T}Y-\\beta^{T}X^{T}Y + \\beta^{T}X^{T}X\\beta$최적화(최소화) 목적함수: $Y^{T}Y-2\\beta^{T}X^{T}Y+ \\beta^{T}X^{T}X\\beta$최적화 필요조건인 기울기 필요조건을 만족하는 $\\beta$ 를 찾자.$\\beta$ 로 편미분 한 1차 도함수가 0 되는 $\\beta$ 를 찾아야 한다.$\\frac{\\partial{목적함수}}{\\partial{\\beta}} = -2X^{T}Y+2X^{T}X\\beta = 0$$2X^{T}X\\beta = 2X^{T}Y$$X^{T}X\\beta = X^{T}Y$$X^{T}X$ 는 $(p\\times{p})$ 크기 정방행렬이다. 만약 $X^{T}X$ 행렬의 역행렬이 존재한다면 아래와 같이 처리할 수 있다.$\\beta = (X^{T}X)^{-1}X^{T}Y$위 $\\beta$ 가 최적해(최소해) 다. 잔차 제곱합(총 잔차 크기)을 최소로 만드는 $\\beta$ 다.가중치 벡터 $\\beta$ 의 추정치 이다.$\\hat{\\beta} = (X^{T}X)^{-1}X^{T}Y$다중선형회귀에서 SST, SSR, SSE 사이 관계와 분산분석표SST, SSR, SSE 사이 관계단순선형회귀분석과 같다. 다만 자유도가 다르다.$\\sum{(Y_{i}-\\bar{Y})^{2}}= \\sum{(\\hat{Y_{i}}-\\bar{Y})^{2}}+\\sum{(Y_{i}-\\hat{Y_{i}})^{2}}$ $\\sum{(Y_{i}-\\bar{Y})^{2}}$: 총제곱합(SST) $\\sum{(\\hat{Y_{i}}-\\bar{Y})^{2}}$: 회귀제곱합(SSR) $\\sum{(Y_{i}-\\hat{Y_{i}})^{2}}$: 잔차제곱합(SSE) 총제곱합은 $X$ 관계없이 고정된 값이다. 따라서 회귀제곱합과 잔차제곱합은 반대로 움직인다.자유도 SST: $(n-1)$, $\\bar{Y}$ 가 제약조건 1 SSE: $(n-p)$, $\\hat{Y_{i}} = \\hat{\\beta_{0}}+\\hat{\\beta_{1}}X_{i, 1}+\\hat{\\beta_{2}}X_{i,2}+…+\\hat{\\beta_{p-1}}X_{i,p-1}$ 이다. $\\hat{Y_{i}}$ 값을 구하기 위해서는 $\\hat{\\beta_{0}}, \\hat{\\beta_{1}}, …\\hat{\\beta_{p-1}}$ 의 $\\hat{\\beta_{i}}$ $p$ 개를 알아야 한다. 따라서 제약조건도 $p$ 개다. 자유도는 $(n-p)$ 가 된다. SSR: $(n-1)-(n-p) = (p-1)$ 이다.분산분석표(ANOVA Table)[이미지 출처: 부산대학교 김충락 교수님의 R을 이용한 통계학개론 - 07_회귀분석.pdf 30페이지]F비F비 값 $\\frac{MSR}{MSE}$ 은 다중회귀모형의 유의미성을 검정할 때 사용한다. 귀무가설이 맞다는 전제 하에, F비 값은 $F(p-1, n-p)$ 를 따른다.$F statistic = \\frac{MSR}{MSE} \\sim F(p-1, n-p)$다중회귀모형의 유의성 검정다중회귀모형이 의미가 있는지 없는지 검정한다.$H_{0}: \\hat{\\beta_{1}} = \\hat{\\beta_{2}}= … \\hat{\\beta}_{p-1} = 0$ (다중회귀모형이 의미가 없다)$H_{a}: \\hat{\\beta_{i}}$ 중 최소한 하나는 $0$ 이 아니다 (모형이 의미가 있다)귀무가설 기각하려면 $F$ 비 값이 매우 커야 한다.$F$ 비 값은 $\\frac{MSR}{MSE}$ 이다.$F$ 비 값이 커지려면 $MSR$이 커져야 한다. $MSR$이 커지려면 $SSR$ 이 커져야 한다. $\\Rightarrow$ $F$ 비 값이 커지려면 $SSR$ 이 매우 커져야 한다.한편 $F$ 비 값이 커지려면 $MSE$ 는 작아져야 한다. $MSE$ 가 작아지려면 $SSE$ 가 작아져야 한다. $\\Rightarrow$ $F$ 비 값이 커지려면 $SSE$ 가 매우 작아져야 한다.종합하면, $F$비 값이 커져서 귀무가설을 기각(모형이 의미가 있다) 하려면 $SSR$ 값이 커지고 $SSE$ 값이 작아져야 한다.R에서 다중회귀분석R 내장 stackloss 데이터# 다중회귀분석 dt = stackloss # R 내장 stackloss 데이터 head(dt,3) # air flow, water temp, acid.conc, stackloss 4개 변수의 데이터로 구성된 데이터셋이다. 반응변수와 설명변수 설정# 반응변수 y &lt;- dt$stack.lossx1 &lt;- dt$Air.Flowx2 &lt;- dt$Water.Tempx3 &lt;- dt$Acid.Conc.데이터(관측치) 행렬 X 생성# 데이터 행렬 X &lt;- cbind(x1, x2, x3) # 열벡터 x1, x2, x3를 열로 써서 묶어라 (행렬로 변환)x1, x2, x3 변수 사이 관계 모아보기# 각 변수 사이 관계 산점도로 살펴보기 pairs(X) x1, x2, x3 중 서로 상관관계 있어 보이는 변수들은 y에 대한 설명이 중복될 수 있다.따라서 스캐터 플롯으로 결과를 보고, 서로 상관관계 있어보이는 x 변수들은 모형에 둘 중 하나만 넣거나 둘 다 빼는 걸 고려해 볼 수 있다.다중선형회귀모형에 반응변수와 설명변수 회귀시키기# 다중선형회귀모형 stackfit&lt;-lm(y~x1+x2+x3) # 반응변수~ 설명변수 1,2,3plot(stackfit)plot(회귀모형) 명령은 아래 4개 플롯을 제공한다. Residual vs Fitted Normal Q-Q plot Standardized Residual vs Fitted Residuals vs LeverageResidual vs FittedResidual vs Fitted plot 은 $\\hat{y}$ 값 별 잔차를 보여준다.그래프에서 $y$ 축이 잔차 크기를 나타낸다. 잔차 크기가 $-2$ 에서 $2$ 를 넘어서면 아웃라이어 값이라고 본다.Normal Q-Q plotNormal Q-Q plot 은 잔차의 표본분포가 정규분포를 따르는지 보여준다.잔차는 이론적으로 정규분포 $N(0, \\sigma^{2})$ 을 따른다고 했었다.이 그래프는 잔차가 정규성 가정을 만족하는지 보여준다.선형에 가까울 수록 정규분포에 가까운 것이다.Standardized Residual vs FittedStandardized Residual vs Fitted plot 은 $\\hat{y}$ 값 별 표준화 잔차를 보여준다.$y$ 축이 표준화 잔차 크기를 나타낸다.잔차를 표준화 시키는 방법은 아래와 같다.$r$ 을 잔차라고 칭할 때,표준화 잔차 $= \\frac{\\vert{r}\\vert{}}{잔차의 표준오차}$표준화 잔차 절댓값이 $0$ 기준으로 $2, 2.5,$ 또는 $3$ 을 넘어서는 fitted value를 아웃라이어 값이라고 본다.위 그래프는 표준화 잔차에 제곱근을 취했다. 따라서 $\\sqrt{표준화잔차}$ 가 대략 $1 \\sim 1.2$ 인 값들이 아웃라이어 값들이다.Residuals vs Leverage그래프 X 축(Leverage)은 설명변숫값이 평균에서 떨어져 있는 정도를 의미한다. 레버리지가 클 수록 평균에서 멀리 떨어져 있다는 뜻이다.한편 그래프 상에 붉은 점선으로 된 컨투어 플롯이 쿡 거리를 나타낸다. 맨 가운데 붉은 실선에서 멀어지면 멀어질 수록 쿡 거리가 먼 것(쿡 통계량이 큰 것) 이다. $21, 4, 1$ 이 다른 값들보다 쿡 통계량이 큰 값들이다. 한편 $1$ 과 $21$ 관측치는 레버리지가 크고, 잔차도 상당히 큰 값들이다. $4$ 관측치는 레버리지는 작지만 잔차가 큰 값이다. 쿡 통계량: $\\hat{\\beta}$ 값에 유독 영향 많이 미치는 관측치가 뭔지 알려주는 척도다.# 추정 결과 요약 summary(stackfit)회귀계수 검정 결과를 볼 때, 이 회귀모형은 사실상$Y = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}X_{1}+\\hat{\\beta_{2}}X_{2}$ 와 같다. $\\hat{\\beta_{3}}$ 는 통계적 관점에서 볼 때 의미가 없었다.# 분산분석표 anova(stackfit)위 분산분석표는 (x1, residuals), (x2, residuals), (x3, residuals) 해서 각각 F비를 계산하고 각 변수의 회귀계수가 유의한지 F 분포를 이용해 검정, F비의 p-value 를 나타낸 결과다.summary() 결과와 마찬가지로 변수 x1과 x2가 통계적으로 유의미하게 나왔다.# 회귀모형의 잔차제곱합 deviance(stackfit) # stackfit은 y_hat 값들이다. sum(y-y_hat)^{2} 즉 잔차제곱합 계산한다.178.83# 회귀모형의 총제곱합 deviance(lm(y~1)) # lm(y~1) 은 y 평균 y_bar 를 의미한다. 따라서 이 명령은 sum(y-y_bar)^{2} 총제곱합을 의미한다. 2069.238# 회귀모형의 모든 잔차 residuals(stackfit)# 회귀계숫값들의 분산-공분산 행렬 vcov(stackfit)# 회귀계숫값들 coef(stackfit)# step: 실질적으로 y 설명하는 독립변수만 남겨서 출력하는 명령 step(stackfit)intercept, x1, x2 의 회귀계수만 남아서 출력되었다.이는 분산분석표에서 관찰했던 것과 같다.2차원 평면에서 그림 그리기# 데이터셋 로드 faithfulhead(faithful)x &lt;- faithful$eruptionsy &lt;- faithful$waitingplot(x,y) # 선형 상관관계 있는 것으로 보인다. cor(x,y) # 피어슨 상관계숫값 0.90 으로 높은 선형상관관계가 나타난다. 피어슨 상관계숫값: 0.90# X축, Y축, 제목 라벨 부여하기 # x축, y축 값 제한 설정하기 plot(x,y, xlab='Eruptions', ylab='Waiting',main='Faithful Data',xlim = c(0,7), ylim=c(30,100))# 데이터 별로 구분해서 나타내기 x1 = x[1:136]x2 &lt;- x[137:272]y1 &lt;- y[1:136]y2 &lt;- y[137:272]plot(c(x1, x2), c(y1, y2), type='n', xlab='Eruptions', ylab='Waiting', main='Faithful Data') # type='n'은 '점을 찍지 마라'는 명령이다. points(x1, y1, col='salmon')points(x2, y2, col='cyan')abline(lm(y1~x1), col='salmon')abline(lm(y2~x2), col='cyan')abline(lm(y~x))" }, { "title": "[2021 인공지능전문가 교육과정 복습] 매핑, 딕셔너리, 집합, any(), all()", "url": "/bioinfo.github.io/posts/mapping_type/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, study, data science", "date": "2022-01-07 00:00:00 +0900", "snippet": "매핑(Mapping)키(key) 값(value) 쌍추상자료형속성 키 데이터와 값 데이터를 짝지어 저장한다. 변형이 불가능한 임뮤터블(immutable) 자료형 만 키(key) 가 될 수 있다.연산 각 값(value) 데이터는 키(key) 로만 접근할 수 있다.매핑 예딕셔너리매핑 - 딕셔너리(Dictionary)대표적인 매핑 타입 자료구조다.추상자료형 매핑의 속성, 연산 상속딕셔너리 만의 연산 clear(): 딕셔너리 내 모든 항목을 삭제할 수 있어야 한다. copy(): 딕셔너리 복사본을 반환한다. get(key): 키에 해당 하는 값을 리턴한다. 값이 없으면 None을 리턴한다. update(dict): dict의 키와 값의 목록을 dict에 추가한다. (또는 키-값 pair 를 dict로 수정) items(): 딕셔너리 내 모든 키-값 쌍을 튜플로 묶어서 반환한다. keys(): 키 목록을 반환한다. values(): 값 목록을 반환한다. popitem(): 요소 중 가장 오른쪽에 위치한 pair 삭제 후 반환한다. OrderedDict 이면 popitem() 안에 last=True 또는 False 로 각각 맨 마지막 순서 pair 를 삭제하거나 맨 처음 pair 삭제할 수 있다. pop(key): 특정 key의 value 반환 후 그 pair 삭제한다.딕셔너리 구현 방법 해시 테이블딕셔너리 생성하기 - dict() 또는 {} 이용하는 방법# 빈 딕셔너리 생성 dd = dict()# 또는dd = {}setdefault() 로 특정 키의 기본값 지정하기 dict_name.setdefault(key, 값)dd.setdefault(3, 'hello')ddsetdefault() 에 지정해 준 key값을 딕셔너리가 이미 갖고 있는 경우그 key값에 원래 할당되어 있던 값을 출력한다.a = {'a':3,'b':8}a.setdefault('a',8)출력: 3setdefault() 에 key값만 넣는 경우그 key값의 기본값으로 None 이 할당된다.dd = {}dd.setdefault(3) # 3이 key 된다. dd딕셔너리 생성하기 - Defaultdict Class 이용하는 방법정의: 기본값 갖는 딕셔너리 만드는 클래스.from collections import defaultdictdd = defaultdict(객체 이름, key=value1, key=value2,...) collections 모듈에서 defaultdict 를 불러와서 사용한다. 기본 딕셔너리 는 자신이 포함하고 있지 않은 키 값이 들어오면 key error를 발생시킨다. 하지만 defaultdict 는 딕셔너리 기본값을 지정해줌으로써, 없던 키 값이 들어오면 기본값을 출력하고, 그 키 값에도 기본값 할당해준다. 결국 예상치 못한 key 값 들어왔을 때 key error 발생하는 걸 막을 수 있다.defaultdict ‘객체 이름’ 자리에 넣은 객체 기본값이 ‘기본값’이 된다.예를 들어 int를 넣으면 0을 기본값으로 설정한다. list 를 넣으면 [] 가 기본값이 된다.한편 key= argument를 써서 ‘키 = 값’ 을 넣어줄 수도 있다. 이건 딕셔너리 생성하면서 특정 키-값 쌍을 같이 만들기 위한 것이다.dd = defaultdict(list)dddefaultdict(기본값, 현재 딕셔너리 상태) 가 출력된다.객체 자리에 list를 넣었으므로, 기본값은 [] 빈 리스트가 된다.dd[3] # 빈 딕셔너리에 3이 가지고 있는 값 출력 요구 기본값 빈 리스트 출력한다.그리고 딕셔너리를 확인해보면 key 3이 [] 빈 리스트를 값으로 갖고 있는 걸 볼 수 있다.만약 기본값 자리에 문자열 str 객체를 넣으면 ‘’ 공백이 기본값 된다.dd = defaultdict(str, a=[1,2],b=3)dd[6]dd딕셔너리 생성하기 - OrderedDict Class 이용하는 방법정의: key값 순서 기억하는 딕셔너리 만드는 클래스.쓸모: 딕셔너리로 for문 돌 때 ‘시퀀스 타입처럼’ 일정한 순서 가지고 데이터에 접근할 수 있다.*하지만 파이썬 업데이트 후 기본 딕셔너리도 반복문 돌 때 일정 순서 유지하게 되면서, 별로 안 쓰인다.from collections import OrderedDictod1 = OrderedDict({'a':1, 'b':2,'c':3})for i in od1 : print(f'key:{i}') print(f'value:{od1[i]}') print('-'*3)key값 순서기억od1 = OrderedDict({'a':1, 'b':2,'c':3})od2 = OrderedDict({'a':1, 'c':3, 'b':2})print(od1 == od2)od3 = OrderedDict({'a':1, 'b':2, 'c':3})print(od1 == od3)FalseTruekey 순서가 같아야 두 딕셔너리 같다고 하는 걸 볼 수 있다.기본 딕셔너리는 순서 개념 자체가 없어서 키-값 쌍만 모두 같으면 같은 딕셔너리로 분류된다.딕셔너리 정렬하기sorted() 를 사용해서 딕셔너리를 정렬할 수 있다.sorted(딕셔너리.items(), key=정렬기준) # 정렬 기준은 lambda 함수 써서 지정한다.OrderedDict 정렬시키기d = OrderedDict({'milk':3, 'coffee':1, 'capuchino':4, 'tea':2})print(OrderedDict(sorted(d.items(), key=lambda x : x[1]))) # value를 기준으로 정렬print(OrderedDict(sorted(d.items(), key=lambda x : x[0]))) # key를 기준으로 정렬 print(OrderedDict(sorted(d.items(), key=lambda t : len(t[0])))) # 영단어 알파벳 길이 순 정렬기본 딕셔너리 정렬시키기d2 = dict(d) # 기본 딕셔너리로 만들기 print(dict(sorted(d2.items(), key=lambda x : x[0]))) # key 기준으로 정렬print(dict(sorted(d2.items(), key=lambda x : x[1]))) # value 기준으로 정렬print(dict(sorted(d2.items(), key=lambda x : len(x[0])))) # key 알파벳 길이 짧은 순 오름차순 정렬집합(Set)구별가능한 개체들의 모임 딕셔너리에서 key만 모아놓은 형태추상자료형속성 요소(element) 간 중복 안 된다. 각 요소 별 key 도, 순서(인덱스)도 없다. (따라서 인덱싱도, 슬라이싱도 불가능하다)연산 add(x): 집합 내에 특정 원소 x를 추가한다. discard(x): 집합 내 특정 원소 x를 삭제한다. clear(): 집합 내 모든 원소를 삭제한다. union(s): s와의 합집합 새로 생성한다. difference(s): s와의 차집합 새로 생성한다. 두 집합에 대한 - 연산과 같다. intersection(s): s와의 교집합 새로 생성한다. 두 집합에 대한 &amp; 연산과 같다. symmetric_difference(s): s와의 대칭 차집합 새로 생성한다. 두 집합에 대한 ^ 연산과 같다. issubset(s): 다른 집합 s의 부분집합인지 검사한다. True 또는 False 반환한다. issuperset(s): 다른 집합 s를 포함하는지 검사한다. True 또는 False 반환한다. isdisjoint(s): s 집합과 교집합이 하나도 없는지 검사한다. True 또는 False 반환한다.집합 구현 방법 해시 테이블집합의 효율성집합은 데이터 소속검사에서 리스트보다 빠르다(효율적이다) 집합은 소속검사에 $O(1)$ 만큼 시간복잡도 걸린다. 리스트는 소속검사에 $O(n)$ 만큼 시간복잡도 걸린다.리스트는 요소들에 하나하나, 일일이. 순차접근해서 소속검사를 하는 데 반해, 집합은 해시 테이블 이용해서 한방에 소속검사 하기 때문이다.어떤 값에 대해 소속검사 명령이 들어오면, 집합은 그 값을 해시 함수에 통과시켜 해시 값을 얻는다. 그 해시 값을 주소로 해시 테이블에 접근해서 저장소에 True 가 저장되어 있는지, False가 저장되어 있는지 확인한다. 이렇게 한 번만 검사하면 값 소속 여부를 바로 알 수 있기 때문에, $O(1)$ 만큼 시간 복잡도가 걸린다.[출처: https://rexiann.github.io/2020/11/28/set-in-python.html ]# 집합은 리스트보다 소속검사 속도가 월등히 빠르다set1 = {'k1', 'k2', 'k3', 'k4'}'k1' in set1 # True'k5' not in set1 # False집합은 데이터 삽입, 삭제에서 배열로 구현된 리스트보다 빠르다(효율적이다) 집합은 삽입, 삭제에 $O(1)$ 만큼 시간 복잡도 걸린다. 배열로 구현된 리스트는 삽입, 삭제에 $O(n)$ 만큼 시간 복잡도 걸린다.배열로 구현된 리스트는 데이터를 삽입, 삭제하면 각 항목들의 물리적 이동이 동반된다.예를 들어 0번 인덱스 항목을 삭제하면 그 뒤의 1,2,3,… 번 인덱스 항목들이 앞으로 한 칸씩 물리적 이동한다. 따라서 시간복잡도가 $O(n)$ 만큼 걸린다.하지만 집합은 해시 테이블 사용하기 때문에 삽입, 삭제에 $O(1)$ 만큼 시간복잡도 걸린다.어떤 값을 삽입 할 때는 해시함수로 그 값의 해시를 받아서, 저장소에 해시와 True 만 저장하면 될 것이다.어떤 값을 삭제 할 때는 그 값의 해시(주소)에 접근해서 저장소에 True를 False 로 바꾸면 될 것이다.결국 삽입을 하든 삭제를 하든 $O(1)$ 만큼 시간복잡도만 걸린다.$\\Rightarrow$ 리스트에 소속검사, 삽입, 삭제가 빈번하게 일어날 경우 리스트를 집합으로 변환해서 사용하는게 효율적이다.all() 과 any()반복가능자를 입력으로 받아서. 검사한 뒤 결과를 True / False 로 반환하는 논리연산 함수.all() 반복가능자 입력받는다. 요소가 모두 0 또는 ‘’ 공백 문자열이 아닐 때 True 반환한다. 하나라도 0 또는 ‘’ 가 있으면 False 반환한다. 만약 반복자가 비어있으면 True 반환한다.# all(): 0 또는 공백이 모두 아닐 때 trues1 = {1,2,3}s2 = {''}s11 = [1,2,3]all(s2) # False 반환한다all({}) # True 반환한다all(s11) # True 반환한다any() 반복가능자 입력받는다. 요소 중에 0 또는 ‘’ 공백 문자열 아닌 게 하나라도 있으면 True 반환한다. 요소가 모두 0 또는 ‘’ 공백 문자열 일 때 만 False 반환한다. 만약 반복자가 비어있으면 False 반환한다.# any(): 0 또는 공백이 아닌게 하나라도 있으면 trues3 = {0,\"\",1}s4 = {}any(s3) # 1 때문에 True any(s4) # Falsesorted() 함수로 집합 정렬시키기집합은 순서가 없다. 따라서 정렬이 불가능하다.sorted() 함수는 반복가능자를 입력받아, 일단 리스트로 바꾸고 정렬시켜 결과값을 출력한다.집합도 반복가능자 이므로 sorted() 함수에 넣을 수 있다.다만 결과가 리스트로 바뀌어 나오므로, sorted(집합) 한 결과를 다시 집합으로 바꿔야 한다.이게 집합을 정렬시키는 방법이다. sorted(반복가능자, key=lambda 함수(정렬기준), reverse=True)# sorted() 함수로 집합 정렬시키기s1 = {'key1', 'key2', 'key3'}sorted_s1 = sorted(s1, reverse=True)보다시피 리스트로 정렬된 채 출력된다.집합으로 사용하려면 다시 집합으로 바꿔줘야 한다.# sorted() 결과를 다시 집합으로 바꾸기 s2 = set(sorted_s1)s2" }, { "title": "[2021 인공지능전문가 교육과정 복습] 시퀀스, 리스트, 튜플, zip함수", "url": "/bioinfo.github.io/posts/sequence_type_data_structure/", "categories": "Data Science, python, data structure", "tags": "data structure, computer science, study, data science", "date": "2022-01-07 00:00:00 +0900", "snippet": "시퀀스(Sequence)선형자료구조에 속한다.추상자료형속성 데이터의 ‘연속적 나열’ (‘정렬’ 이 아니다) 각 데이터에 인덱스(순서) 가 자동 부여됨연산 인덱스 사용해서 모든 데이터에 자유롭게 접근 가능해야 한다.시퀀스 예리스트, 튜플, 레인지, 문자열 등시퀀스 - 리스트(List)클래스 개념으로 생각했을 때. 시퀀스가 상위클래스라면 리스트는 시퀀스의 하위클래스다.곧, 리스트는 시퀀스 추상자료형의 속성. 연산을 모두 상속받아 갖는다.추상자료형 시퀀스의 속성, 연산 상속.리스트 만의 속성 숫자, 문자열, 기호 등등 대부분 자료형 모두 요소(element) 로 리스트에 포함 가능하다.리스트 만의 연산 어떤 인덱스 위치에서건, 내용 변경이 자유로워야 한다.$\\Rightarrow$ index(a): 원소 a의 인덱스를 찾을 수 있어야 한다. append(a): 원소 a를 리스트 끝(후단)에 추가할 수 있어야 한다. count(a): 리스트 내에서 a 의 갯수를 반환할 수 있어야 한다. extend([ a1, a2 ]): 어떤 다른 리스트를 받아서 그 리스트 요소를 기존 리스트 마지막에 추가할 수 있어야 한다. insert(index, a): 특정 인덱스에 a를 삽입할 수 있어야 한다. remove(a): 원소 a를 리스트에서 특정해서 삭제할 수 있어야 한다. pop(index): index 위치의 원소를 리스트에서 삭제한 뒤 반환할 수 있어야 한다. sort(): 리스트 요소들을 오름차순 정렬, 키워드로 reverse=True 가 주어지면 내림차순 정렬 할 수 있어야 한다. reverse(): 리스트 요소들을 역순으로 나열할 수 있어야 한다.리스트 구현 방법 배열 연결리스트배열정의: 데이터를 물리적으로 연속되게 나열 시킨 것. 배열이 저장한 데이터들은 메모리 상에서 모두 물리적으로 연속적 위치에 저장된다.특징: 구현이 간단하다. 인덱스 이용해서 원하는 위치 데이터에 곧바로 접근 할 수 있다. 따라서 데이터 접근이 효율적이다. 그 시간복잡도는 $O(1)$ 배열에 할당되는 메모리 용량 제한이 있다. 삽입, 삭제 연산이 비효율적이다. 시간복잡도는 $O(n)$연결리스트정의: 메모리 상에 흩어진 여러 노드를 논리적으로 연결시킨 것. 각 노드는 메모리 상에서 물리적으로 인접하지 않을 수 있다. 하지만 각 데이터는 논리적 관점에서 연속적이다.특징: 구현이 복잡하다. 0번 인덱스에 해당하는 노드에 헤드 포인터가 붙는다. 어디가 시작점인지 알려주는 용도다. 각 노드는 데이터 필드와 링크 필드로 구성된다. 링크 필드에는 다음 노드 주소만 갖는다. 데이터 접근이 배열에 비해 비효율적이다. 헤드 포인터를 찾고, 0번 인덱스에서 시작해 링크 따라 원하는 인덱스까지 순차 접근해야 한다. 시간복잡도는 $O(n)$ 데이터 삽입 또는 삭제가 효율적이다. 새 노드 생성, 다음 노드 링크 삽입, 이전 노드 링크 수정 만 해주면 된다. ‘연결리스트’ 자체의 크기 제한이 없다.종류: 단순연결리스트: 각 노드가 한 방향으로만 연결된 연결리스트. 이중연결리스트: 각 노드가 쌍방으로 연결된 연결리스트. 원형연결리스트: 마지막 노드가 다시 시작 노드로 연결된 연결리스트.시퀀스 - 튜플(Tuple)추상자료형 여러 자료형을 저장할 수 있어야 한다. 데이터 삽입, 삭제, 수정이 불가능 해야 한다 - 불변속성 자료형 count(a): 요소 a 가 튜플 내에 몇 개 있는지 반환할 수 있어야 한다. index(a): 요소 a 가 튜플 내에서 몇 번째 인덱스에 위치하는 지 반환할 수 있어야 한다.특징: 구조가 단순하다. 리스트에 비해 데이터 접근 속도가 빠르다.튜플 패킹과 언패킹 (Packing and Unpacking) 튜플 패킹: 1개 변수에 튜플 할당 하는 것 튜플 언패킹: 튜플 요소(element) 들을 개별 변수에 할당하는 것# 튜플 패킹t = (1,2,3,4,5)# 튜플 언패킹t1, t2, t3, t4, t5 = tt1 = 1, t2 = 2, … t5 = 5튜플 응용 - zip 함수 zip(반복가능자1, 반복가능자2, … 반복가능자n) n개 반복가능자로부터 같은 인덱스에 해당하는 요소들 끼리 튜플로 묶어서 반환한다.zip_result = zip([1,2,3], ('a','b','c'), (1,2,3))list(zip_result)list3 = ['hello', 'world', 'python']list(zip(list3))결과: [(‘hello’,), (‘world’,),(‘python’,)]print(list(zip('abc','def')))zip 결과를 zip 적용 전으로 되돌리려면 zip() 함수에 인자로 *zip 적용 결과 를 넣으면 된다. zip(*zip_result)# zip 역변환list1 = [1,2,3]tu2 = (1,2,3)list3 = ['a','b','c']zip1 = zip(list1, tu2, list3)print(list(zip1)) # result 1print(list(zip(*zip1))) # result 2result1: [ (1,1,’a’),(‘2,2,’b’),(3,3,’c’) ]result2: [ (1,2,3), (1,2,3), (‘a’,’b’,’c’) ]# zip 역변환 응용my_list = [[1,2,3],[4,5,6],[7,8,9]]new_list = list(map(list, zip(*my_list)))new_list튜플 생성-언패킹 동시에 응용하기list1 = ['1','2','3','4']list2 = ['100','200','300','400']list3 = ('가','나','다','라')for i,j,k in zip(list1, list2, list3) : print(i+j+k) zip()으로 4개 튜플 생성한다. (‘1’,’100’,’가’), (‘2’,’200’,’나’),(‘3’,’300’,’다’),(‘4’,’400’,’라’) for문 한번 반복 할 때 마다 변수 i,j,k에 튜플을 언패킹한다. 예를 들어 첫번째 반복에서, i 에는 ‘1’, j 에는 ‘100’, 그리고 k 에는 ‘가’ 가 할당된다. 위 첫번째 반복에서 i+j+k 를 하면 문자열 셋을 이어붙여준다. 결과는 1100가 가 된다. 나머지 3개 튜플에 대해서도 위 과정 반복힌다결과:" }, { "title": "[Python] 리스트 축약식, 중첩 리스트", "url": "/bioinfo.github.io/posts/list_comprehension/", "categories": "python", "tags": "python, study", "date": "2022-01-05 00:00:00 +0900", "snippet": "리스트 축약식 (list comprehension)[ 표현식 for 변수 in 반복자 if 조건 표현식 ] if 조건 표현식 부분은 생략해도 된다.if 조건 표현식 없이# if 조건 없이 list1 = [1,2,3,4,5,6][x**2 for x in list1]결과: [ 1,4,9,16,25,36 ]# 또는[x**2 for x in range(1,7)]# 또는 list(map(lambda x : x**2, list1))if 조건 표현식과 함께list1 = [1,2,3,4,5,6][x for x in list1 if x &gt; 3]결과: [ 4,5,6 ]# 또는 list(filter(lambda x : x &gt; 3, list1))결과: [ 4,5,6 ]리스트 중첩시키기# 중첩리스트 예 1list1 = [[0,1],[1,2],[3,4]]# 중첩리스트 예 2list2 = [[0 for i in [1,2]] for i in [1,2,3]]# or list2 = [[0 for i in range(2)] for i in range(3)]결과: [[ 0,0 ], [ 0, 0 ], [ 0, 0 ]]리스트의 슬라이싱리스트 슬라이싱 결과는 원래 리스트의 ‘부분 복사본’ 이다.원본 리스트는 손상되지 않는다." }, { "title": "[2021 인공지능전문가 교육과정 복습] 자료구조 정의, 알고리즘 성능 분석, 빅오 표기법", "url": "/bioinfo.github.io/posts/data_structure/", "categories": "Data Science, data structure", "tags": "data structure, computer science, study, data science, computer engineering", "date": "2022-01-04 00:00:00 +0900", "snippet": "아래 내용은 부산대학교 소프트웨어 교육센터 ‘인공지능전문가 교육과정 - 데이터사이언스: 데이터 구조’ 수업 내용을 복습하며 제 언어로 다시 정리한 글 입니다.자료구조와 알고리즘자료구조정의: 데이터를 담고 조직화 시키는 틀목적: 편리하고 효율적인 데이터 이용주요 종류: 선형자료구조, 비선형자료구조선형자료구조정의: 데이터 마다 순서(인덱스) 부여되는 자료구조.특징: 각 자료 간 앞 뒤로 1:1 대응, 선형 구조를 이룬다.종류: 리스트, 큐, 스택 등비선형자료구조정의: 데이터에 순서(인덱스) 부여되지 않는다. 대신 데이터 간 1:n, n:n 대응된다.종류: 트리, 그래프 등알고리즘정의: 문제 해결 절차어떤 절차가 알고리즘이 되기 위한 조건: 입력은 없어도 된다. 하지만 반드시 1개 이상 출력을 가져야 한다. 명백성: 각 명령어의 의미가 명확해야 된다. 유한성: 무한루프 돌면 안된다. 반드시 언젠가 끝나야 한다. 유효성: 각 명령어는 실행가능해야 한다.추상자료형정의: 속성, 연산이 명시되었지만 그 구현 방식이 구체적으로 정해지지 않은 ‘클래스’ 와 같다. 연산 구현 방식이 구체적으로 설정되는 경우(예: 배열 자료구조 사용해서 연결리스트 연산 구현), 추상자료형에서 자료구조(자료형)가 된다.알고리즘 성능 분석 방법1. time 등 모듈 써서 직접 실행시간 측정하는 방법알고리즘 별 객관적 성능 비교가 어렵다.2. 알고리즘 복잡도 분석하는 방법1번에 비해 객관적 성능 비교 가능하다.산술, 대입, 비교, 이동. 4개 기본 연산 횟수로 알고리즘 복잡도 나타낸다.$\\Rightarrow$ 4개 기본 연산 횟수로 알고리즘의 ‘시간 복잡도 함수’를 나타낸다.예)$n^{2}$ 를 구하는 문제1 번 방법 : $n$ * $n$ 을 해서 구하는 방법 n에 숫자 대입연산(1) + 두 n 을 곱하는 곱셈연산(1) 총 2번의 기본연산 수행. 시간 복잡도 함수 $T(n) = 2$ 가 된다.2 번 방법 : for문을 써서 n을 n번 더하는 방식 n을 n번 더하는 덧셈연산(n) + n에 숫자를 n+1 번 대입하는 대입연산(n+1) 총 2n+1 번 기본연산 수행. 시간 복잡도 함수 $T(n) = 2n+1$ 가 된다.첫 번째 방법은 n에 상관없이 항상 일정한 시간복잡도 값이 나온다. 반면 두 번째 방법은 n 크기 변화에 따라 시간복잡도가 선형으로 증가한다. 첫 번째 방법이 더 좋은 알고리즘이다.3. 시간 복잡도 분석 방법 최악경우 분석: 시간 상한선 정해 놓고. 여러 알고리즘 중 최악의 경우에도 시간 상한선 보다 적은 시간 걸리는 알고리즘 채택 평균경우 분석: 입력값의 모분포를 균등분포로 둔다. 여러 입력에서의 알고리즘 수행 시간 표본분포를 구하고, 그 모분포 기댓값을 추정한다. 여러 알고리즘 중 기댓값이 가장 작은 알고리즘을 선택한다. 최선경우 분석: 가장 빠른 수행시간이 더 작은 알고리즘 찾기알고리즘 성능측정을 위해 최악경우 분석을 사용한다.시간복잡도 빅오 표기법정의: 시간복잡도 함수 최고차항 만으로 알고리즘 시간 복잡도 나타내는 방법.최고차항으로 나타낸 시간 복잡도는 시간상한 나타낸다. 즉 최악 경우 걸리는 시간 나타낸다.예) 시간복잡도 함수가 $T(n) = n^{2} + n + 1$ 이면, 알고리즘 시간 복잡도는 $O(n^{2})$ 최악 경우 $n^{2}$ 만큼 시간 소요된다는 말이다.조건: 어떤 임의 양의 상수 $c$, $n_{0}$ 에 대해. $n &gt; n_{0}$ 일 때 $0 \\leq f(n) \\leq cg(n)$ 성립하기만 하면. $f(n) = O(g(n))$ 이다. $f(n)$: 시간복잡도 함수 $g(n)$: 시간복잡도 함수의 최고차항(계수도 고려하지 않는다)예)어떤 알고리즘의 시간복잡도 함수가 $f(n) = 5$ 이면, 그 알고리즘의 시간복잡도를 빅오 표기법으로 나타내면 $O(1)$ 가 된다. $c = 10, n_{0} = 1$ 일 때. $n \\ge 1$ 에 대해 $0 \\leq 5 \\leq 10$ 만족한다.예)어떤 알고리즘의 시간복잡도 함수가 $f(n) = 2n+1$ 이면, 그 알고리즘의 시간복잡도를 빅오 표기법으로 나타내면 $O(n)$ 이 된다. $c=3, n_{0} = 2$ 일 때. $n \\ge 2$ 에 대해 $2n+1 \\leq 3n$ 만족한다.빅오 표기법 종류시간복잡도 함수 유형 별 시간 복잡도 빅오 표기$T(n) = 100$ $\\Rightarrow$ $O(1)$상수시간. 입력값 크기와 상관없이 일정. 사칙연산, if문 등$T(n) = 2log{N}$ $\\Rightarrow$ $O(log{N})$로그시간. 이진트리 등$T(n) = 4N+8$ $\\Rightarrow$ $O(N)$선형시간. for 문 등$T(n) = Nlog{N}+N$ $\\Rightarrow$ $O(Nlog{N})$로그 선형시간. 퀵, 병합, 힙 정렬 등$T(n) = 3N^{2}+5N+4$ $\\Rightarrow$ $O(N^{2})$제곱시간. 2중 for 문 등$T(n) = 2N^{3} +3N^{2} +1$ $\\Rightarrow$ $O(N^{3})$세제곱시간.$T(n) = 2^{N}$ $\\Rightarrow$ $O(2^{N})$지수시간. 피보나치수열 등.# 빅오 표기법에 따른 알고리즘 시간복잡도(시간상한) 비교 plt.figure(figsize=(10,8))xx = np.linspace(0, 100, 10000)const = [1 for i in xx]def log(xx) : return np.log2(xx)def linear(xx) : return xxdef linear_log(xx) : return xx*np.log2(xx)def squared(xx) : return xx**2def cubic(xx) : return xx**3def expo(xx) : return 2**xxplt.ylim(0, 200)plt.plot(xx, const, label='상수시간')plt.plot(xx, log(xx), label='로그시간')plt.plot(xx, linear(xx), label='선형시간')plt.plot(xx, linear_log(xx), label='로그선형시간')plt.plot(xx, squared(xx), label='제곱시간')plt.plot(xx, cubic(xx), label='세제곱시간')plt.plot(xx, expo(xx), label='지수시간')plt.legend()plt.xlim(0, 100)plt.title('빅오 표기법에 따른 알고리즘 시간복잡도 (시간상한) 비교')plt.show()" }, { "title": "[수학/확률과 통계] 단순 선형회귀분석, 다중 선형회귀분석", "url": "/bioinfo.github.io/posts/regression_analysis/", "categories": "Data Science, R, mathematics", "tags": "datascience, R, mathematics", "date": "2021-10-04 00:00:00 +0900", "snippet": "아래 글은 부산대학교 송태호 교수님의 ‘마케팅 애널리틱스’ 수업을 듣고 복습한 뒤, 학습 내용을 제 언어로 바꾸어 기록한 글 입니다.단순 선형회귀분석정의 :독립변수 $x$ 와 종속변수 $y$ 사이 관계를 가장 잘 설명하는 모형 찾기선형회귀식$\\hat{y} =b_{0} + b_{1}x_{i}$ 선형회귀식. 선형 모형을 구한다는 건 가중치 $b_{0}$, $b_{1}$ 을 구하는 것이다. 회귀식 가중치는 최소자승법으로 구한다. 최소자승법 : 실젯값 $y$ 와 예측값 $\\hat{y}$ 사이 잔차가 최소화 되는 $b_{i}$ 를 구하는 것이다.$\\Rightarrow$ 한마디로, 예측값이 실젯값에 가장 근사해지도록 하는 가중치 $b_{i}$ 를 구하는 것이다. 예측값-실젯값 사이 잔차크기가 작아질 수록, 선형회귀모형이 ‘x와 y 관계를 잘 설명한다’고 본다.선형회귀모형 = 선형예측모형 = 선형모형회귀선이 벡터 점들과 붙어 있을 수록 잔차크기(잔차 제곱 합)가 작다.정답값과 선형모형 사이 관계$y_{i} = b_{0}+b_{1}x_{1}+\\epsilon_{i}$$r^{2}$ 값 : 선형모형의 설명력 크기정의:회귀분석에서 내가 찾은 선형모형이 x,y 사이 관계를 얼마나 잘 설명해주는가? 나타내는 값 $0 \\leq r^{2} \\leq 1$$r^{2}$ 값이 0이냐 아니냐는 선형모형이 의미가 있는가 없는가 나타낸다.$r^{2} = 0$ 이면 선형모형이 의미없는 것이다.F 통계량 값 : 선형모형이 유의미한 정도정의:독립변수가 여러 개 존재하는 내 선형모형과, 독립변수 $x$ 없이 $b_{0}$ 만 존재하는 선형모형 사이 차이 나타내는 값이다.$\\Rightarrow$ 내가 찾은 선형모형이 의미가 있는지 없는지 보여준다.F값이 작을 수록 선형모형이 의미없다.단순회귀분석 예독립변수 age와 종속변수 heartrate 사이 관계를 가장 잘 설명해주는 선형예측모형(선형회귀모형)을 찾자.# 단순회귀분석 예 # 종속변수에 영향 미치는 독립변수 1개인 경우 # age 독립변수 와 heartrate 종속변수 사이 관계를 # 설명하는 선형모형을 만들자. x = c(18, 23, 25, 35, 65, 54, 34, 56, 72, 19, 23, 42, 18, 39, 37)y = c(202, 186, 187, 180,156, 169, 174, 172, 153, 199, 193, 174, 198, 183, 178)# x 는 age, y 는 heartrate 데이터 length(x) == length(y)x, y 변수의 관계를 예상해보기 위해 스캐터 플롯을 그려보자.# (x,y) 벡터로 스캐터 플롯 그리기plot(x,y) x와 y는 서로 반비례하는 음의 선형 상관관계가 있어보인다.상관관계가 있는 두 변수 x, y를 가지고, 둘 사이 관계를 가장 잘 설명하는 선형예측모형을 찾아보자.$\\Rightarrow$ 선형회귀분석을 해보자y에 영향 미치는 독립변수가 $x$ 하나이므로, 단순회귀분석이다.R로 선형모형을 정의하자.# 선형모형 정의 lm(y~x) # x를 독립변수, y를 종속변수로 두는 선형모형 객체를 만든다# intercept 는 최적 b0 값(절편), x값은 최적 b1 값이다. Coefficients가 내가 구하고자 하는 목표, 가중치 계수들이다.$ = b_{0}, b_{1}$$Intercept = b_{0}, 210.0485$$x = b_{1}, -0.7977$선형모형 도출 결과에 대해 좀 더 자세히 살펴보자.summary(lm(y~x)) # 회귀분석 결과 상세하게 출력 Residuals : 잔찻값들이다. 예측값과 정답값 사이 잔찻값들 중 최솟값, 1분위 수, 중앙값, 3분위 수, 최댓값 을 보여준다. Coefficients : y 절편 $b_{0}$ 값, x 가중치 계수 $b_{1}$ 값 말한다.각각 210.04846, -0.79773 이다.각 값들이 유의미한지 아닌지는 t 검정통계량 값으로 분간한다. 그게 옆에 t-value이다.그리고 이 검정통계량값에 대한 유의확률이 옆에 Pr 로 나와있다.유의확률값 옆에 별이 세 개 있는데, 이는 0.01 유의수준에서 ‘가중치 계숫값이 유의미하지 않다’는 귀무가설을 기각하고, ‘계숫값이 유의미하다’라는 대립가설을 채택할 수 있다는 뜻이다.*참고 0.05 &lt; p-value &lt; 0.1 : 유의함 (significant) * 0.01 &lt; p-value &lt; 0.05 : 매우 유의함 (highly significant) ** p-value &lt; 0.01 : 매우 강력하게 유의함 (highly strongly significant) ***한편, 밑에 $Multiple R-squared$, $Adjusted R-squared$ 값이 있다.두 값은 내 선형모형이 x,y 사이 관계를 얼마나 잘 설명해주는가? 를 나타내는 값이다.R-squared 값은 0과 1 사이 값을 갖는데, 값이 0이면 내가 찾은 선형모형이 의미가 없는 것이다. x, y 관계를 설명해주지 못한다. 값이 1이면 내가 찾은 선형모형이 오차 없이 정확하게 x, y 관계를 설명해 준다는 뜻이다.그리고 0과 1 사이에서 값이 높을수록 모형이 변수 간 관계를 잘 설명한다.한편내 선형회귀모형에 독립변수가 2개 이상이면 $adjusted R-squared$ 값을 고려한다.내 선형회귀모형에 독립변수가 1개 뿐이면 $Multiple R-squared$ 값을 고려한다. F-statistics : F 통계량 값은 내가 찾은 선형모형이 유의미한지, 유의미하지 않은지를 설명해주는 값이다. 이 F 통계량 값의 p-value를 보면 된다. p-value : 귀무가설 - 내 선형모형이 유의미하지 않다.대립가설 - 내 선형모형이 유의미하다.를 놓고, p-value 와 특정 유의수준을 비교해 귀무가설을 검정한다. 이 경우 p-value 값이 매우 작기 때문에, 통상적으로 쓰는 모든 유의수준에서 귀무가설을 기각, 대립가설을 채택한다. 곧, ‘내 선형모형이 유의미하다’는 결론을 내린다.스캐터 플롯 위에 내가 찾은 선형모형(회귀선) 표시하기# 회귀선 그리기 명령# 회귀선만 그린다. 회귀분석 명령 아니다. abline(lm(y~x))lm 명령써서 내가 찾은 선형모형을 기반으로 회귀선만 그려주는 명령이다.회귀분석 명령 아니다.위에서 그렸던 스캐터 플롯 위에 abline 명령으로 회귀선을 표시했다.내가 찾은 선형모형으로 예측값 출력하기 -1특정 독립변숫값 $x$를 넣고, 이 값에서의 예측값 $\\hat{y}$ 를 출력할 수 있다. predict()# 선형회귀모형으로 특정 독립변수일 때 예측값 출력하기 lm_result = lm(y~x)# 데이터프레임만 들어갈 수 있다.predict(lm_result, data.frame(x=c(50,79)))# 독립변수 x 값 50, 79 일 때 예측값 선형회귀모형 객체를 생성한다. 선형회귀모형 객체를 predict() 명령 안에 넣고, 예측값을 구할 독립변숫값들을 데이터프레임 자료형으로 predict() 명령 안에 함께 넣는다.내가 찾은 선형모형으로 예측값 출력하기 -2정답 값을 구간추정할 수도 있다.# 90% 신뢰수준 에서 예측값을 구할 수 있다. predict(lm_result, data.frame(x=sort(x)), level=.9, interval='confidence')# 99% 신뢰수준에서 예측값 구할 수 있다. predict(lm_result, data.frame(x=sort(x)), level=.99, interval='confidence') 신뢰수준 90%에서 점 추정치(예측값)와 점 추정치 기반으로 정답 값이 있을만한 신뢰구간을 구한 것 신뢰수준 99%에서 점 추정치(예측값)와 점 추정치 기반으로 정답 값이 있을만한 신뢰구간을 구한 것다중 회귀분석정의:독립변수 $x$가 2개 이상일 때, 독립변수 $x_{i}$와 종속변수 $y$ 사이 관계를 가장 잘 설명해주는 예측모형 찾기선형회귀식:$\\hat{y} = b_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{3}…b_{n}x_{n}$정답값과 선형모형 사이 관계$y_{i} = b_{0}+b_{1}x_{1}+b_{2}x_{2}+…b_{n}x_{n}+\\epsilon_{i}$다중회귀분석 예)# 다중회귀분석 -1x = 1:10y = sample(1:100,10)z = x+ylm(z~x+y) # +는 x, y를 모두 독립변수로 고려하겠다는 뜻이다. z는 종속변수다. 차례로 $b_{0}, b_{1}, b_{2}$ 값을 구했다.# 다중회귀분석 -2z = x+y+rnorm(10,0,2) # 10개 표본 추출, 정규분포 기댓값 = 0 , 표준편차 = 2summary(lm(z~x+y)) $b_{0}$ 값은 의미없다. $b_{1}, b_{2}$ 값은 모두 유의수준 0.001 에서 ‘유의미 하다’라고 결론지었다. Adjusted R-squared 값이 0.9976이다. $r^{2}$ 값이 거의 1에 가깝기 때문에, 이 선형모형 설명력은 매우 뛰어나다고 해석할 수 있다. F 통계량값에 대한 p-value(유의확률) 값이 매우 작다. 이 선형모형이 통계적으로 유의미하다고 해석할 수 있다." }, { "title": "[수학/확률과 통계] 신뢰구간, 신뢰수준, 표본오차, 표준오차", "url": "/bioinfo.github.io/posts/confidence_interval/", "categories": "Data Science, mathematics", "tags": "mathematics, datascience", "date": "2021-10-02 00:00:00 +0900", "snippet": "다음 그림이 신뢰구간, 신뢰수준이 무엇인지 압축적으로 설명해준다.rv = sp.stats.norm()for i in range(1, 101) : x_mean = np.mean(rv.rvs(100)) if x_mean-1.96*(1/10) &lt;= 0 and 0 &lt;= x_mean+1.96*(1/10) : plt.vlines(i, ymin=x_mean-1.96*(1/10), ymax=x_mean+1.96*(1/10), colors='b') else : plt.vlines(i, ymin=x_mean-1.96*(1/10), ymax=x_mean+1.96*(1/10), colors='r') plt.axhline(0, ls=':', c='r')plt.suptitle('신뢰수준의 의미 : 100개 신뢰구간 중 95개 정도가 모수 $\\mu$ 를 포함한다', y=1.02)plt.title('파란 선 : 모수 $\\mu$ 를 포함하는 신뢰구간들, 빨간 선 :모수 $\\mu$ 를 포함하지 않는 신뢰구간들')plt.show()신뢰구간정의:모수 $\\mu$ 가 있을 만 한 구간유념해야 할 점: 신뢰구간은 하나의 ‘공식’이다. 신뢰구간은 하나로 정해진 값이 아니다.신뢰구간 식:$\\bar{X} \\pm Z\\frac{\\sigma}{\\sqrt{n}}$$\\Rightarrow \\bar{X} - Z\\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + Z\\frac{\\sigma}{\\sqrt{n}}$ $Z$ 는 Z-score 를 말한다. $Z$ 값은 몇 % 신뢰수준에서 신뢰구간 구하느냐에 따라 달라진다. n이 30 이상이고, $\\sigma$ 를 모를 경우 $\\sigma$ 대신 표본표준편차 s를 쓴다.신뢰수준정의:‘측정 방법의 정확도’또는‘신뢰구간이 모수를 포함할 확률(빈도주의 정의에 충실해야 한다)’설명:크기 n인 표본을 100번 추출해서 표본평균을 100개 구한다.표본평균 100개를 신뢰구간 식에 대입하면 신뢰구간도 100개가 생긴다.(예컨대) 95% 신뢰수준은 이 100개 신뢰구간 중 약 95개가 모수를 포함한다는 의미다.$\\Rightarrow$ ‘이 방법대로 하면’ 100개 신뢰구간 중 95개가 모수를 포함한다는 뜻이므로, ‘측정 방법의 정확도’라고 보는 게 맞다.또는위의 100개 신뢰구간은 사실 모두 하나의 $\\bar{X} - Z\\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + Z\\frac{\\sigma}{\\sqrt{n}}$ 구간이라 볼 수도 있다.$\\bar{X}$ 에서 뭐가 생성되든, $\\bar{X}$ 는 $\\bar{X}$ 이기 때문이다.100개 구간을 사실상 모두 같은 ‘하나의 구간’ 이라고 생각해보자.빈도주의 관점에서, 구간 $\\bar{X} - Z\\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + Z\\frac{\\sigma}{\\sqrt{n}}$ 구하기를 100번 반복했을 때, 그 중 95번은 모수를 포함한다(사건 발생횟수). 이렇게 빈도주의 관점에서 볼 때, 구간이 모수를 포함할 확률은 95% 다.한편 구간이 95% 확률로 모수를 포함할 수 있다면, 5% 확률로 모수를 포함 안 할 수도 있다는 걸 명심하자.예)신뢰수준이 95% 이고 표본오차가 $\\pm$ 5% 인 여론조사 결과 A 후보의 지지율이 25%, B 후보 지지율이 30% 라고 해보자.이를 해석하면,n개 표본 얻는 작업을 100번 반복할 때, 100번 중 95번은 A후보 지지율(모수) 이 20%~30% 사이에, B후보 지지율(모수) 이 25%~35% 사이에 포함된다는 말이다.한편 각각 25% 와 30%는 수많은 ‘가능한’ 표본중에 ‘어쩌다가’ 나온 모수 점추정치다.그 말은, 25%, 30%가 아닌 다른 값이 충분히 나올 수도 있었다는 말이다. (또 다른 평행세계에서는 다른 값이 나왔을수도 있다)이렇게 점 추정치가 절대적이고 완벽한 값이 아니기 때문에, 표본오차를 통해 신뢰구간을 구하는 것(모수 구간추정 하는 것)이다.표본오차$\\bar{X} \\pm Z\\frac{\\sigma}{\\sqrt{n}}$ 에서,$\\pm Z\\frac{\\sigma}{\\sqrt{n}}$ 이 부분이 표본오차다. 오차한계(margin of error) 라고도 한다.표준오차 (Standard Error of Mean : SEM)정의:표본평균 값들이 모평균에서 떨어져 있는 정도.$= \\frac{\\sigma}{\\sqrt{n}}$또는표본평균 확률변수에서 실현되는 데이터들이 불확실하게 변화하는 정도를 말한다.#표준오차 예rv = sp.stats.binom(30, 0.6)mean = []for i in range(10000) : mean.append(np.mean(rv.rvs(1000)))sns.distplot(mean, kde=False, fit=sp.stats.norm)plt.axvline(18, ls=':', c='r')plt.annotate('', xy=[18.1,2], xytext=[18, 2], arrowprops={'facecolor':'black'})plt.annotate('', xy=[17.9,2], xytext=[18,2], arrowprops={'facecolor':'black'})plt.text(18.02, 1.5, '표준오차')plt.text(17.92, 1.5, '표준오차')plt.title('표준오차')plt.xlabel('표본평균')plt.show() 표준오차가 작으면, 모수 점 추정 결과 정확도가 높다. 표준오차가 크면, 모수 점 추정 결과 정확도가 낮다." }, { "title": "[수학/확률과 통계] 포아송 분포, 이항분포의 정규근사, 연속수정", "url": "/bioinfo.github.io/posts/binary_distribution_normal_estimation/", "categories": "Data Science, python, mathematics", "tags": "datascience, python, mathematics", "date": "2021-10-01 00:00:00 +0900", "snippet": "아래는 부산대학교 통계학과 김충락 교수님의 ‘R을 활용한 통계학 개론’ 수업을 듣고,학습내용을 제 언어로 다시 정리한 글 입니다.포아송 분포정의 :단위시간. 단위공간 에서 발생하는 사건 수 들의 이산확률분포 를 ‘포아송분포’라고 한다.특징 :기댓값 모수와 분산 모수 값이 같다.포아송 분포 따르기 위한 조건 독립성 : 서로 다른 단위시간/공간에서 발생하는 사건 수는 서로 독립이다. (n이 무한히 클 때, 각 이항분포 표본은 독립이다) 단일성 : 1개 단위시간/공간에서 동시에 2개 이상 사건 발생할 확률은 0에 가깝다. 등발성 : 기댓값 m 은 모든 단위시간. 단위공간에서 일정하다.이항분포와 포아송분포 사이 관계이항분포에서 전체 시행 횟수 $n$이 매우 커지고,베르누이 시행에서 1 나올 확률 $p$가 매우 작아질 때,이항분포는 기댓값과 분산이 $np$ 로 같은 포아송분포에 근사한다.# 이항분포에서, n이 매우 커지고 p가 매우 작아지면 이항분포가 포아송분포에 근사한다.n = 100000p = 0.005# 이항분포 rv = sp.stats.binom(n,p)xx = np.arange(420, 580)pmf = rv.pmf(xx)plt.plot(xx, pmf, 'mo-')print(f'이항분포 기댓값 : {n*p}')print(f'이항분포 분산 : {n*p*(1-p)}')print(f'포아송분포 기댓값과 분산 np : {n*p}')plt.title('n이 매우 커지고, p가 매우 작아지면 이항분포는 포아송분포에 다가간다')plt.show() 한편, 포아송분포는 $np$ 값이 커질수록 오른쪽으로 이동하고, 분산 정도가 커진다. 또한 $np$가 커질 수록 분포가 좌우대칭에 가까워진다. # np(기댓값, 분산값)가 커질 때, 포아송분포 변화n = [300,500,1000,2000,5000]colors = ['bo-','ro-','go-','ko-','mo-']p = 0.005xx = np.arange(-10,100)for n,colors in zip(n, colors) : rv = sp.stats.binom(n,p) plt.plot(xx, rv.pmf(xx), colors, label=f'np={n*p}')plt.xlim(0, 40)plt.title('$np$크기에 따른 포아송분포 확률질량함수')plt.legend()plt.show()이항분포의 정규근사정의 :이항분포에서 n이 매우 크고,p가 0과 1 사이 적당한 값이면(너무 작지도. 크지도 않은)이항분포는 기댓값이 $np$, 표준편차가 $\\sqrt{np(1-p)}$ 인 정규분포에 근사시킬 수 있다.# n이 매우 클 때, 이항분포 정규분포에 근사시키기 n = 10000p = 0.6# 이항분포rv = sp.stats.binom(n,p)xx = np.arange(5700,6300)pmf = rv.pmf(xx)plt.plot(xx, pmf, 'co-')#plt.xlim(3200, 3800)mu = n*pstd = np.sqrt((n*p)*(1-p))# 이항분포가 근사할 정규분포 rv2 = sp.stats.norm(mu, std)pdf = rv2.pdf(xx)plt.plot(xx, pdf, 'k-')plt.title('n=10000 , p=0.6 일 때 이항분포 정규근사')plt.show()검정색 선이 기댓값이 $np$, 분산이 $np(1-p)$ 인 정규분포 나타낸 선이다.무수히 이어진 하늘색 점들이 $n=10000, p=0.6$ 일 때 이항분포 나타낸 것이다.보다시피 점들과 선이 거의(하늘색 부분은 점들이니까) 일치하는 것을 볼 수 있었다.연속수정 (Continuity Correction)이항분포를 정규근사해서 확률을 구할 때, 이항분포 값들에 대해 ‘연속수정’을 한다.이항분포는 이산확률분포, 정규분포는 연속확률분포이다.이항분포를 정규근사 시켜서 확률값을 구하려면, 이산적 구간(불연속적)을 정규분포에 맞게 조정해야 한다.그래서 이항확률변숫값에 정규확률변숫값을 대응시킬 때. 이항확률변숫값에 0.5씩 더하거나 뺀 값을 정규확률변숫값으로 대응시키는데, 이걸 연속 수정이라 한다.이항분포 정규근사 시켜서 확률값 구할 때는 이 연속수정 된 정규확률변숫값들로 확률값 구하면 된다.정리)$\\Rightarrow$ ‘연속수정’은 이항분포를 정규근사시켜 확률값을 구할 때,확률값 구하려는 구간 경계의 각 이항분포 값들을 $0.5$ 만큼 더하거나 $0.5$ 만큼 빼서 변형하는 걸 말한다.예를 들어, 이항분포를 정규근사 시킨 다음, 279 이하 표본들이 실현될 확률을 구하고 싶다.$P(X \\leq 279)$표준화 해서 위 구간의 확률을 구할 건데, 이때 이산확률변숫값인 279를 ‘연속수정’ 해서 279.5로 바꾼다.$P(Z \\leq \\frac{279.5-\\mu}{\\sigma})$그 후 표준정규분포 표를 이용해서 위 구간의 확률을 구한다.또는정규근사 시킨 위 이항분포에서, 316 이상 표본들이 실현될 확률을 구하고 싶다.$P(316 \\leq X)$표준화 하면,$P(\\frac{315.5-\\mu}{\\sigma} \\leq Z)$구간이 이렇게 된다. 이런 느낌인 것이다.만약 $P(160 \\leq X \\leq 180)$ 을 구하고자 하면,표준정규분포에서 $P(\\frac{155.5-\\mu}{\\sigma} \\leq Z \\leq \\frac{180.5-\\mu}{\\sigma})$ 를 구하면 된다." }, { "title": "[수학/확률과 통계] 결합확률, 조건부확률, 베이즈정리, pgmpy, 몬티 홀 문제", "url": "/bioinfo.github.io/posts/conditional_distribution/", "categories": "Data Science, python, mathematics", "tags": "datascience, python, mathematics", "date": "2021-09-20 00:00:00 +0900", "snippet": "결합확률정의 :사건 A와 사건 B가 동시에 발생하는 사건의 확률. (A,B 교집합의 확률)$=$ $P(A,B)$ 사건 A의 원소와 사건 B의 원소로 구성된 벡터의 확률이기도 하다. 2차원 벡터들의 결합확률분포는 3차원 모양 함수로 표현된다.주변확률정의 :개별 사건 A,B의 확률.$= P(A), P(B)$ X,Y 확률변수의 결합확률분포함수에서, X의 주변확률분포는 각 X값에 대한 모든 Y값을 더한 값들의 분포다.조건부확률정의 :사건 B를 새 전체집합으로 삼았을 때, 사건 A의 확률또는조건 B가 있을 때, A의 확률.$= P(A\\vert{B})$ 조건부확률분포는 특정 값에서의 결합확률분포 단면을 특정 값에서의 주변확률분포값 으로 나눈 값들의 분포다.예) $P(X\\vert{Y=3}) = \\frac{P(X, Y=3)}{P(Y=3)}$사건의 독립 (두 사건이 서로 영향 미치지 않는다)사건 A,B 사이에 다음 관계가 성립하면, ‘사건 A,B는 서로 독립이다’ 라고 한다.$P(A,B) = P(A)P(B)$ 사건 A,B가 독립이면 조건부확률이 원래 확률과 같아진다.$P(A\\vert{B}) = P(A)$즉, 사건 B가 사건 A 확률값에 아무 영향 못 미친다는 뜻이다.사슬법칙정의 :결합확률과 조건부확률 사이 관계를 나타내는 법칙이다.$P(A,B,C,D) = P(A\\vert{B,C,D})P(B\\vert{C,D})P(C\\vert{D})P(D)$ 다양한 곳에서 응용이 가능한, 매우 유용한 법칙이다.사건 A,B,C,D가 서로 독립이면, 다음이 성립한다.$P(A,B,C,D) = P(A)P(B)P(C)P(D)$피지엠파이 패키지로 확률모형 시각화 하기pgmpy 패키지를 사용하면 확률모형을 시각화 할 수 있다.- 결합확률모형 시각화 하기pgmpy 패키지의 JointProbabilityDistribution 클래스를 사용하면, 결합확률모형을 시각화 할 수 있다.from pgmpy.factors.discrete import JointProbabilityDistribution as JPDpx = JPD(variables, cardinality, values) variables : 결합확률분포 모형 구성하는 확률변수들 이름 ‘리스트’ 넣는다. cardinality : 각 확률변수 가능한 표본 수를 ‘리스트’ 형식으로 넣는다. values : 확률변수의 모든 표본 조합에 대한 (결합)확률값의 배열결합확률모형 시각화 예)# 확률변수 X,Y의 주변확률분포 시각화 하기 from pgmpy.factors.discrete import JointProbabilityDistribution as JPDpx = JPD(['X'], [2], np.array([12,8])/20)print(px)py = JPD(['Y'], [2], np.array([5,5])/10)print(py)# X,Y 확률변수의 결합확률분포 시각화 pxy = JPD(['X','Y'], [2,2], np.array([3,9,7,1])/20)print(pxy)- 결합확률분포에서 주변확률분포, 조건부확률분포 구해서 시각화 하기 X의 주변확률분포는 X 각 점을 기준으로 Y와의 가능한 모든 결합확률을 더한 값들의 분포다. X의 조건부확률분포는 Y값 고정한 결합확률분포 단면 / 고정한 Y값에서의 주변확률분포값 의 분포다.사용하는 메서드주변확률분포 구하는 메서드 marginal_distribution(‘주변확률분포 구할 확률변수 이름 리스트’, inplace=JPD 객체를 주변확률분포 객체로 대체할 지 말지 입력) maginalize(‘주변화시킬(제거할) 확률변수 이름 리스트’, inplace=)조건부확률분포 구하는 메서드 conditional_distribution(values, inplace=)values : 조건으로 삼을 확률변수 이름과 고정할 값 튜플로 묶은 것들의 리스트- 결합확률분포에서 두 확률변수가 서로 독립인지 확인하기 check_independence([‘확률변수 1 이름’],[‘확률변수 2 이름’])사용 예)# 확률변수 X,Y의 결합확률분포 객체 정의pxy2 = JPD(['X','Y'], [2,2], np.array([3,3,2,2])/10)print(pxy2)# 결합확률분포의 두 확률변수 X,Y가 서로 독립인가? print(pxy2)ind = pxy2.check_independence(['X'],['Y'])print(f'확률변수 X,Y 는 서로 독립인가? : {ind}') # 확률변수 X,Y는 서로 독립이다. TrueX,Y 확률변수는 서로 독립이다.# x=0 일 때 Y의 조건부확률분포print('X=0 일 때 Y의 조건부확률분포')print(pxy2.conditional_distribution([('X',0)], inplace=False)) # X = 0 일 때 Y의 조건부확률분포# x=1 일 때 Y의 조건부확률분포print('X=1 일 때 Y의 조건부확률분포')print(pxy2.conditional_distribution([('X',1)], inplace=False)) # X = 1 일 때 Y의 조건부확률분포 print()# Y의 주변확률분포print('Y의 주변확률분포')print(pxy2.marginal_distribution(['Y'], inplace=False))print()# Y=0 일 때 X의 조건부확률분포print('Y=0 일 때 X의 조건부확률분포')print(pxy2.conditional_distribution([('Y',0)], inplace=False))# Y=1 일 때 X의 조건부확률분포print('Y=1 일 때 X의 조건부확률분포')print(pxy2.conditional_distribution([('Y',1)], inplace=False))print()# X의 주변확률분포print('X의 주변확률분포')print(pxy2.marginal_distribution(['X'], inplace=False))print()marginalize()를 사용하는 경우# Y를 주변화하고 X의 주변확률분포 구하기 py = pxy2.marginalize(['Y'], inplace=False) # X의 주변확률분포 print(py)# X를 주변화 하고 Y의 주변확률분포 구하기 px = pxy2.marginalize(['X'], inplace=False) # Y의 주변확률분포 print(px)베이즈 정리정의 :사건 B라는 새로운 정보가 추가로 들어왔을 때, 사건 A의 사전확률이 어떻게 바뀌는가?(사건 A의 사후확률)$P(A\\vert{B}) = \\frac{P(B\\vert{A})P(A)}{P(B)}$조건부확률의 응용버전. $P(B\\vert{A}) =$ 가능도 $P(A)=$ 사전확률 $P(A\\vert{B})=$ 사후확률 $P(B) =$ 정규화 상수 (중요도 낮음. 크기 조절 역할만 한다)베이즈 정리의 확장 1사건 $A_{i}$ 가 $A_{i}\\cap{A_{j}}= \\varnothing$ $A_{1}\\cup{A_{2}}…\\cup{A_{n}} = \\Omega$일 때 전체확률의 법칙을 베이즈정리에 적용할 수 있다.사건 B가 표본공간 $\\Omega$ 의 또 다른 부분집합일 때,$P(A_{i}\\vert{B})$$= \\frac{P(B\\vert{A_{i}})P(A_{i})}{P(B)}$$= \\frac{P(B\\vert{A_{i}})P(A_{i})}{\\sum{P(B\\cap{A_{i}})}}$$= \\frac{P(B\\vert{A_{i}})P(A_{i})}{\\sum{P(B\\vert{A_{i}})P(A_{i})}}$가 성립한다.위 식은 ‘다중분류 문제’에서 확용할 수 있다.다중분류 문제여러 배타적이고 완전한 사건 중에서 가장 확률이 높은 사건 하나를 고르는 문제가 ‘다중분류 문제’다.정답이 무조건 하나인 4지 선다형 객관식 문제를 푼다고 생각해보자. 정답이 될 수 있는 보기는 1,2,3,4 이다.‘정답’ 확률변수의 가능한 4개 표본(1,2,3,4) 하나하나를 그 표본으로만 구성된 단순사건이라 생각하자.그리고$A_{1} = [1]$$A_{2} = [2]$$A_{3} = [3]$$A_{4} = [4]$로 생각하자.$A_{1}$ ~ $A_{n}$ 의 사건은 각각 1,2,3,4 가 정답인 사건이다.문제의 가능한 정답은 무조건 1,2,3,4 중에 있다. 따라서 $A_{1}$ ~ $A_{n}$ 사건의 합집합은 전체 표본공간을 구성한다.$\\Rightarrow$ $A_{1}\\cup{A_{2}}\\cup{A_{3}}\\cup{A_{4}} = \\Omega$그리고 각 단순사건은 교집합이 공집합이다.$\\Rightarrow$ $A_{1}\\cap{A_{2}}\\cap{A_{3}}\\cap{A_{4}} = \\varnothing$이때, 선생님께서 정답에 대한 힌트를 주셨다고 하자. 힌트에 대한 사건을 B 라고 하자. B는 표본공간 $\\Omega$ 의 또 다른 부분집합이다.보기 1,2,3,4 중에서 주어진 힌트와 가장 비슷한 보기가 정답일 확률이 가장 높을 것이다.그러면 힌트가 주어졌을 때, 1,2,3,4 각각이 정답인 사건의 확률을 구해보자.$P(A_{1}\\vert{B}) = P(B\\vert{A_{1}})P(A_{1})$$P(A_{2}\\vert{B}) = P(B\\vert{A_{2}})P(A_{2})$$P(A_{3}\\vert{B}) = P(B\\vert{A_{3}})P(A_{3})$$P(A_{4}\\vert{B}) = P(B\\vert{A_{4}})P(A_{4})$분모는 모두 같아서 생략했다.$A_{1}, A_{2}, A_{3}, A_{4}$ 는 서로 배타적이며, 이들은 완전하다.이 문제는 힌트 B가 주어졌을 때, 서로 배타적이고 완전한 $A_{i}$ 중 확률이 가장 높은 $A_{i}$ 를 고르는 문제다.= 다중분류 문제다.이 다중분류 문제의 ‘정답’은 위 조건부확률값이 가장 큰 $A_{i}$ 로 분류된다.이진분류 문제만약 정답이 두 개의 서로 배타적이고 완전한 사건 중 확률값 더 높은 걸로 분류된다면, 이진분류 문제라고 한다.$A \\cup{A^{C}} = \\Omega$$A \\cap{A^{C}} = \\varnothing$$\\Rightarrow$ 정답이 $A$ 또는 $A^{C}$ 로 분류된다면 ‘이진분류 문제’다.위 문제를 이진분류 문제로 바꾸면,$P(A\\vert{B}) = P(B\\vert{A})P(A)$$P(A^{C}\\vert{B}) = P(B\\vert{A^{C}})P(A^{C})$힌트 B가 있을 때 $A$ 또는 $A^{C}$ 중에 확률값이 더 높은걸로 ‘정답’을 분류하면 된다.곧, 위 조건부확률값이 더 큰 사건($A$ or $A^{C}$) 으로 ‘정답’을 분류하면 된다.베이즈 정리의 확장 2A에 추가 정보 B가 반영되고 나서 또다시 C가 반영되는 경우, A 사후확률은 다음과 같이 계산할 수 있다.$P(A\\vert{B,C}) = \\frac{P(C\\vert{A,B})P(A\\vert{B})}{P(C\\vert{B})}$또는 추가 정보 C가 반영되고 나서 또다시 B가 반영되는 경우, A 사후확률은 다음과 같다.$P(A\\vert{B,C}) = \\frac{P(B\\vert{A,C})P(A\\vert{C})}{P(B\\vert{C})}$증명은 결합확률과 조건부확률사이 사슬법칙을 사용해서 할 수 있다.$\\Leftarrow P(A,B,C) = P(A\\vert{B,C})P(B\\vert{C})P(C)$다양한 사전확률에 대해 사후확률 계산할 수 있다는 게 핵심 포인트다.몬티 홀 문제. 다중분류 문제로 풀기몬티홀 문제를 다중분류 문제로 풀어보자.내가 분류하고자 하는 건 ‘자동차의 위치’다.자동차의 위치 확률변수를 $C$ 라 하자.자동차의 위치는 0번 문, 1번 문, 2번 문 셋 중에 있다.자동차가 0번 문에 있는 사건을 $C_{0} (C=0)$자동차가 1번 문에 있는 사건을 $C_{1} (C=1)$자동차가 2번 문에 있는 사건을 $C_{2} (C=2)$이라고 하자.$C_{0},C_{1},C_{2}$ 은 서로 배타적이고(교집합이 공집합), 완전하다(세 집합 합집합은 전체집합 $\\Omega$ 다).자동차의 위치는 $C_{0}, C_{1}, C_{2}$ 셋 중 하나로 분류되므로, ‘다중분류 문제’로 풀 수 있다.한편, ‘내가 선택한 문’ 확률변수를 $X$ 라고 하자.$X$ 가 가질 수 있는 표본도 0,1,2 이다.‘사회자가 선택한 문’ 확률변수를 $H$ 라 하자.$H$ 가 가질 수 있는 표본도 0,1,2 이다.맨 처음에 자동차가 0,1,2 각각에 있을 수 있는 확률은$P(C_{0}) = \\frac{1}{3}$$P(C_{1}) = \\frac{1}{3}$$P(C_{2}) = \\frac{1}{3}$이다.게임을 하면서 내가 문을 하나 선택하고, 사회자가 문을 선택해서 염소를 보여줄 것이다.내가 문을 고르고, 사회자가 염소를 보여줬을 때, $C_{0}, C_{1}, C_{2}$ 의 확률이 각각 얼마가 될 지 보자.$\\Rightarrow$ $P(C_{i} \\vert{H_{j}, X_{a}})$예를 들어 내가 2번문을 골랐다. 사회자가 1번문을 열어 염소를 보여줬다. 이때 0,1,2 번 문 각각에 자동차가 있을 확률은 얼마일까?자동차가 0번 문에 있을 확률)$P(C_{0}\\vert{H_{1}, X_{2}}) = \\frac{2}{3}$자동차가 1번 문에 있을 확률)사회자가 1번문을 열여서 염소가 있다는 걸 보여줬기 때문에, 1번 문 뒤에 자동차가 있을 수. 없다.$P(C_{1}\\vert{H_{1}, X_{2}}) = 0$자동차가 2번 문에 있을 확률)$C_{0} \\cup C_{1} \\cup C_{2} = \\Omega$ 였다. 또, $C_{0} \\cap C_{1} \\cap C_{2} = \\varnothing$ 이었다.따라서 $P(C_{0})+P(C_{1})+P(C_{2}) = 1$ 이다.조건부확률일 때도 똑같이 성립한다. 따라서, $1-\\frac{2}{3} = \\frac{1}{3}$ 이다.$P(C_{2}\\vert{H_{1}, X_{2}}) = \\frac{1}{3}$결론 1 : 다중분류 문제 정의에 충실하게다중분류 문제에서, ‘자동차의 위치’는 $C_{0}, C_{1}, C_{2}$ 중에서 가장 확률값이 큰 사건으로 분류된다.세 조건부확률 중 $P(C_{0}\\vert{H_{1}, X_{2}})$ 의 확률값이 가장 크다.따라서 ‘자동차의 위치’는 $C_{0} =$ ‘0번 문 뒤에 자동차가 있다’ 로 분류된다.내가 처음 선택했던 문은 1번 문 이었다. 다중분류 문제 분류 결과, 1번 문 뒤에는 자동차가 없었다.분류결과에 따르면 자동차가 있는 것은 0번 문이었다. 따라서 자동차가 당첨되기 위해서는 1번 문에서 0번 문으로 ‘선택을 바꿔야 한다’.결론 2 : 단순 확률값 비교해서위 세개 조건부 확률은 각각 최종으로 0번문, 1번문, 2번문 뒤에 자동차가 있을 확률이다.내가 선택했던 문은 1번 문이었다. 1번문의 확률값은 $\\frac{1}{3}$ 이었다.한편, 0번 문에 자동차가 있을 확률은 $\\frac{2}{3}$ 이었다.0번 문에 자동차가 있을 확률이 더 높으므로, 나는 ‘선택을 바꾸는 것이 자동차 당첨에 유리하다’.몬티 홀 문제를 pgmpy 베이지안 모형으로 풀어보자.몬티 홀 문제를 pgmpy 베이지안 모형 이용해서 풀어보자.내가 선택을 바꿀 지, 바꾸지 말 지 결정하기 위해 필요한 확률값은 다음 세 가지다.$P(C_{0}\\vert{H_{1}, X_{2}})$$P(C_{1}\\vert{H_{1}, X_{2}})$$P(C_{2}\\vert{H_{1}, X_{2}})$이 세 가지 확률을 베이지안 모형 패키지 사용해서 구하자.사전확률을 정의하자먼저 사전확률을 정의해야 한다.사전확률은 자동차의 위치 $C_{0}, C_{1}, C_{2}$ 의 확률이다.사전확률 값이 모두 $\\frac{1}{3}$ 이다.이제 피지엠파이 TabularCPD 클래스에 위 값들을 넣고, 사전확률 객체를 정의하자.from pgmpy.factors.discrete import TabularCPD# 사전확률 정의하자pre = TabularCPD('C', 3, np.array([[1/3],[1/3],[1/3]]))print('사전확률')print(pre)가능한 모든 가능도를 정의하자.사전확률을 정의했다. 그러면 이제 모든 조건에 대해 가능한 모든 가능도를 정의하자.$P(H,X\\vert{C})$ 에 대해 가능한 모든 경우를 정의할 것이다.결합사건 (H,X) 는 하나의 문자 G 로 통일했다.$\\Rightarrow$ $P(G\\vert{C})$$C$ 를 이용해 정의할 수 있는 가능한 모든 조건은 $C_{0},C_{1}, C_{2}$ 이다.각각의 $C_{i}$ 에 대해 $G$ 는 총 9가지 조건이 가능하다. $(H_{0}X_{0}, H_{1}X_{1},….H_{2}X_{2})$이걸 생각하면서 가능도 객체를 정의하자.# 가능한 모든 가능도 정의values = np.array([ [0,0,0], [0,1/6, 1/3], [0,1/3, 1/6], [1/6, 0, 1/3], [0,0,0], [1/3, 0, 1/6], [1/6, 1/3, 0], [1/3, 1/6, 0], [0,0,0]])likelihood = TabularCPD('G', 9, values, evidence=['C'], evidence_card=[3])print('가능도')print(likelihood)print()위에서 ndarray 객체 values 는 각 경우에 대해 직접 수기계산해서 확률값을 넣었다.정의된 가능도 객체는 위 이미지와 같다.$G$ 는 결합사건 $(H_{i},X_{j})$ 을 의미한다.베이지안 모형 만들기이제 그러면 베이지안 모형 객체를 생성하고, 앞에서 만든 사전확률과 가능도 객체를 넣어주자.# 베이지안 모형 만들기 from pgmpy.models import BayesianModelmodel = BayesianModel([('C','G')]) # 확률변수 이름 순서도 중요하다. model.add_cpds(pre, likelihood) # 사전확률, 가능도 객체 투입!model.check_model() # 모델이 정상으로 생성되었는지 점검True모델이 정상으로 생성되었다.이제 추정 객체를 사용해서, 내가 알고싶은 위 조건부 확률(C의 사후확률) 3개를 구하자.# 베이지안 모형 이용해서 조건부확률 계산from pgmpy.inference import VariableEliminationinfer = VariableElimination(model) # 추정객체post = infer.query(['C'], evidence={'G': 5}) # G = 5 일 때(H1,X2), C에 대한 사후확률 계산print(post)위에서 부터 차례로$P(C_{0}\\vert{H_{1}, X_{2}})$$P(C_{1}\\vert{H_{1}, X_{2}})$$P(C_{2}\\vert{H_{1}, X_{2}})$이다.내가 선택한 2번 문 뒤에 자동차가 있을 확률은 0.33 이고, 남은 0번 문 뒤에 자동차가 있을 확률은 0.666 이다.따라서 선택을 바꾸는 게 ‘자동차 당첨에 유리하다’." }, { "title": "[Python] Lambda 함수, Lambda 함수 안에서 if 문 사용하기", "url": "/bioinfo.github.io/posts/lambda_function_with_if/", "categories": "python, syntaxes", "tags": "python, syntaxes", "date": "2021-09-19 00:00:00 +0900", "snippet": "lambda 함수 이름 없는 함수. 일회용 함수다. 함수 이름, return 을 안에 통합하고 있다. (따로 지정 안 해줘도 된다)문법lambda a, b : a+b # 입력, :, 출력인-라인 람다함수별도 라인에서 함수 호출하고 자시고 할 것 없이, 함수 호출문 내에서 람다함수를 바로 쓸 수 있다.이를 인-라인 람다함수 라고 한다.# 인-라인 람다함수 예(lambda a,b : a+b+5)(1,2)결과: 8filter() 함수와 lambda 함수 같이 사용하기filter() 함수는 함수, 반복가능자 를 입력받는다. 그리고 각 요소에 함수를 적용, 결과가 true 인 것만 추출해준다.list1 = [11,22,33,44,55,66]list(filter(lambda x : x&gt;20 and x&lt;50, list1))결과: [ 22,33,44 ]reduce 함수와 lambda 함수 같이 사용하기 reduce 함수: 누적연산 함수. functools 모듈을 불러와야 쓸 수 있다. reduce(함수, 반복가능자) 반복가능자에서 요소를 받아와서, 누적연산 한 다음 하나의 값을 도출한다.from functools import reducelist1 = [1,2,3,4,5,6]reduce(lambda x,y: x+y, list1)결과: 21계산원리: list1 에서 1과 2를 각각 x와 y로 받는다. 둘을 덧셈연산해서, x에 넣는다. y에 3을 받아와서 다시 덧셈연산한다. 3의 결과를 다시 x에 넣고 4를 받아온다. 과정 반복, 결국 sum(list1) 과 같은 결과 나온다.lamdba 함수 안에서 if문 사용하기lambda (식 1 if 조건문 1) (else 식 2 if 조건문 2) (else 식 3 if 조건문 3) else (식 4) elif 는 사용하지 않는다. 항상 끝은 else 로 끝나야 한다. (모든 조건이 다 틀렸을 때 뭘 할건가)ld = lambda a, b : (2/3)*((b-a)/180) if b &lt;= 180 else (2/3)*((180-a)/180) + (1/3)*((b-180)/180) if a &lt; 180 and 180 &lt; b else (1/3)*((b-a)/180)ld(0, 270)lambda 함수를 map 함수와 함께 사용하기map 함수는 iterator 객체 원소 하나하나를 호출해서, 함수를 적용한다.map(func, iterator) func : 함수 이름 itererator : 리스트, 튜플 등 반복가능자다음과 같은 방식으로, 람다함수와 맵 함수를 유용하게 사용할 수 있다.# lambda + mapld = lambda a : a+3list(map(ld, [1,2,3]))위 경우 맵 함수는 리스트 축약식과 같은 역할을 한다.# 리스트 축약식과 같은 역할 한다[ld(x) for x in [1,2,3]]" }, { "title": "[수학/확률과 통계] 확률의 성질, 확률분포함수", "url": "/bioinfo.github.io/posts/characteristics_of_percentage/", "categories": "Data Science, python, mathematics", "tags": "datascience, python, mathematics", "date": "2021-09-19 00:00:00 +0900", "snippet": "확률의 성질1. 공집합의 확률공집합의 확률은 0 이다.$P(\\varnothing) = 0$2. 여집합의 확률여집합의 확률은 1 - 사건의 확률 과 같다.$P(A^{C}) = 1 - P(A)$한편 여기에 콜모고로프의 정리 1번, $0 \\leq P(A)$ 를 적용하면,$0 \\leq P(A) \\leq 1$ 이 성립한다.$\\Rightarrow 0 \\leq P(A) \\leq 1$3. 포함-배제 원리 (덧셈규칙)$P(A\\cup{B}) = P(A) + P(B) - P(A\\cap{B})$4. 전체 확률의 법칙조건 : $C_{i} \\cap{C_{j}} = \\varnothing$ $C_{1}\\cup{C_{2}}\\cup{C_{3}}…\\cup{C_{n}} = \\Omega$ 일 때,$P(A) = \\sum{P(A\\cap{C_{i}})}$확률분포함수확률분포정의 :확률값이 어디에, 얼마나 분포되어 있는지 나타낸 것을 확률분포라 한다.확률분포함수정의 :확률분포를 묘사해주는 함수를 확률분포함수라고 한다.확률분포함수 종류 확률질량함수 확률밀도함수 누적분포함수단순사건정의 :표본 1개로만 구성된 사건을 ‘단순사건’ 이라 한다.확률질량함수 (pmf)정의 :단순사건에 대한 확률값을 정의하는 함수를 ‘확률질량함수’ 라고 한다.또는표본 1개에 대해 확률값을 정의하는 함수를 ‘확률질량함수’ 라고 한다.확률질량함수 예)# 확률질량함수 예xx = np.arange(1,7)yy = [0.1]*5+[0.5]plt.stem(xx, yy)plt.xlim(0, 7)plt.ylim(-0.01, 0.6)plt.xlabel('주사위 눈금')plt.ylabel('주사위 각 눈이 나올 확률')plt.title('6이 잘 나오도록 조작된 주사위 확률분포의 확률질량함수')plt.show()확률함수가 표본이 아닌 사건에 대해서만 확률을 정의할 수 있는 이유표본공간의 표본 수가 유한한 경우, 확률질량함수 이용하면 표본 하나하나에 대해서 확률값 정의할 수 있다.또는 확률질량함수 이용하면 표본 하나만 포함된 단순’사건’에 대한 확률값 정의할 수 있다.한편,표본공간의 표본 수가 무한한 경우, 표본 하나하나에 대해서 확률값 정의할 수 없다.대신, 구간으로 설정된 ‘사건’ 하나 하나에 대해서는 확률값 정의할 수 있다.확률함수가 언제나 확률값을 정의할 수 있으려면, 표본공간 표본 갯수가 유한하든. 무한하든 확률값 정의할 수 있어야 한다.‘사건’에 대해 확률을 할당하면 표본공간 표본 갯수가 유한하든. 무한하든. 상관 없이 언제나 확률값 정의할 수 있다.$\\Rightarrow$ 이 같은 이유로 확률함수는 표본이 아닌 ‘사건’을 입력으로 받아 확률값을 할당한다.누적분포함수 (cdf)정의 :$P([-\\infty &lt; X \\leq x])$ 를 정의하는 함수.또는특수구간 $[-\\infty &lt; X \\leq x]$ 의 확률 $P([-\\infty &lt; X \\leq x])$ 를 구하는 함수다.특징 : $F(-\\infty) = 0$ $F(\\infty) = 1$ 누적분포함수는 전 구간에서 단조증가한다. 따라서 $x \\leq y \\Rightarrow F(x) \\leq F(y)$$\\Rightarrow$ 누적분포함숫값은 0에서 시작해서 계속 증가하면서 1로 다가간다. 절대 감소하지 않는다.구간 $[a &lt; x \\leq b]$ 의 확률 $P(a,b)$ 는 누적분포함수를 이용하면 다음과 같이 정의할 수 있다.$P(a,b) = F(b)-F(a)$누적분포함수 예)xx = np.linspace(-100,500, 1000)ld2 = lambda x : 0 if x &lt; 0 else (2/3)*(x/180) if 0 &lt;= x &lt;= 180 else (2/3)+(1/3)*((x-180)/180) if 180 &lt; x &lt; 360 else 1yy = [ld2(x) for x in xx]plt.plot(xx, yy)plt.xlabel('$x$')plt.ylabel('$F(x)$')plt.title('조작된 원반의 누적분포함수')plt.xticks([0, 180, 360])plt.ylim(-0.1, 1.1)plt.xlim(-100, 500)확률밀도함수 (pdf)정의 :각 위치(점)에서의 ‘상대적 확률값’ 묘사하는 확률분포함수다.$\\Leftarrow$ 각 점에서의 ‘확률값’이 아니다!또한 각 개별구간(사건)의 확률 나타내는 함수다.특징 : 누적분포함수 $F$ 의 1차 도함수 $=$ 확률밀도함수다.또는 누적분포함수 $F$ 각 지점에서의 기울기 $=$ 각 지점에서의 확률밀도함숫값 이다. 확률밀도함수 면적 = 그 구간(사건)의 확률이다. 누적분포함수는 단조증가 함수다. 기울기는 항상 0 또는 양수다. 따라서 항상 $0 \\leq p(u)$ 이다. 확률밀도함수를 $-\\infty$ 부터 $\\infty$ 까지 적분한 값은 1이다. (전체의 확률 = 1)$\\int_{-\\infty}^{\\infty}{p(u)du} = 1$누적분포함수와의 관계미적분학의 기본정리 이용하면 확률밀도함수 면적(확률값)을 누적분포함수 이용해서 구할 수 있다.$F(b) - F(a) = \\int_{a}^{b}{p(u)du}$확률밀도함수 예)# 확률밀도함수 예xx = np.linspace(-100,500,1000)ld2 = lambda x : 0 if x &lt; 0 else 1/270 if 0 &lt;= x &lt;= 180 else 1/540 if 180 &lt; x &lt; 360 else 0yy = np.array(list(map(ld2, xx)))plt.plot(xx, yy)plt.xlabel('$x$')plt.ylabel('$pdf$')plt.title('조작된 원반의 확률밀도함수')plt.xticks([0, 180, 360])plt.show()" }, { "title": "[Python] Iterable 객체, Iterator 객체, Generator 객체,함수,축약식", "url": "/bioinfo.github.io/posts/iterable_object_and_generator/", "categories": "Data Science, python, mathematics", "tags": "datascience, mathematics, python", "date": "2021-09-15 00:00:00 +0900", "snippet": "iterable 객체와 iterator 객체아래 내용은 ‘레벨업 파이썬’ 문서를 보고이터러블, 이터레이터, 제너레이터 객체에 대해 공부한 내용을 정리한 글 입니다.집합론 기초 - 부분집합 생성 부분을 공부하다가 위 개념들을 만났고, 학습하였습니다.https://wikidocs.net/74399iterable 객체정의 :파이썬 객체 중 클래스 안에 __ iter __ 메소드를 포함하고 있는 객체를 iterable 객체 라고 한다.또는for 문, while 문 등 반복문에서 사용할 수 있는 객체를 iterable 객체 라고 한다.iterator 객체정의 :iterable 객체의 __ iter __ 메소드에 포함된 또 다른 객체를 ‘iterator 객체’라고 한다.$\\Leftarrow$ iterator 객체는 반드시 __ next __ 메소드를 포함하고 있어야 한다.$\\Leftarrow$ next() 내장함수로 next 메소드의 내용을 호출할 수 있다.특징 :iterable 객체의 __ iter __ 메소드를 호출하면 자동으로 튀어나온다. iter(iterable) 을 사용하면 객체의 __ iter __ 메소드를 호출하기 때문에, 결과로 iterator 객체를 호출할 수 있다.반복문 원리는 iterable 객체가 포함하는 iterator 객체를 호출해서, 이 iterator 객체 가지고 도는 것이다.*iterable 객체 자기자신을 iterator 객체로 지정해 줄 수도 있다.__ iter __ 메소드에서 self(자기자신)을 반환하면 된다.# iterable 자기자신이 iterator 객체가 되는 예 class four() : def __init__(self) : self.data = ['봄','여름','가을','겨울'] self.index = 0 def __iter__(self) : return self # 자기자신이 iterator 객체라고 선언iterable 객체, iterator 객체 만들기# 이터러블 객체, 이터레이터 객체 만들고 호출하기 # 1. 이터레이터 객체의 클래스를 따로 만드는 경우# iterable 객체 클래스class Season() : def __init__(self) : pass def __iter__(self) : iterator = iteration() # 이터레이터 객체 return iterator # 이터레이터 객체 클래스 class iteration() : def __init__(self) : self.data = ['봄','여름','가을','겨울'] self.index = 0 def __next__(self) : if self.index &lt; len(self.data) : order = self.data[self.index] self.index += 1 return order else : raise StopIteration # for문이 stopiteration error 인식하고 알아서 멈춘다. s = Season()for i in s : print(i)봄여름가을겨울# 또는 : 다른 방법으로 이터레이터 객체 만들기 class four() : def __init__(self) : self.data = ['봄','여름','가을','겨울'] self.index = 0 def __iter__(self) : return self # 자기자신이 iterator 객체라고 선언 def __next__(self) : if self.index &lt; len(self.data) : s = self.data[self.index] self.index += 1 return s else : raise StopIterationa = four()for i in a : print(i) for문을 사용하면 iterable 객체의 iterator 객체를 호출한다. 반복해서 iterator 객체의 next() 메서드를 호출한다. 계속 반복하다가 stopiteration error 가 나오면 인식하고 자동으로 멈춘다.for문 사용하지 않고, next() 함수를 계속 호출해서 결과물을 출력하는 방법도 있다.이때는 iterator 가 가진 데이터를 모두 출력하면 stopiteration error가 발생한다.print(next(iterator))print(next(iterator))print(next(iterator))print(next(iterator))한편 while 문은class four() : def __init__(self) : self.data = ['봄','여름','가을','겨울'] self.index = 0 def __iter__(self) : return self # 자기자신이 iterator 객체라고 선언 def __next__(self) : s = self.data[self.index] if self.index &lt; len(self.data) : self.index += 1 if self.index == 4 : self.index = 0 return print(s)season = four()a = 0while a &lt; 13 : next(season) a += 1for 문과 달리 next() 내장 함수를 자동 호출하지 않았다.따라서 while 문 안에 next() 내장 함수를 따로 적어줘야 원하는 대로 반복 출력이 가능했다.한편,iterator 객체를 iter() 내장 함수에 넣으면 그대로 ‘통과’ 되어서 넣은 iterator 객체가 그대로 다시 출력된다는 것도 관찰할 수 있었다.# iterable 객체를 iter() 내장 함수에 넣으면 iterator 객체만 추출해온다. # iterator 객체를 다시 iter() 내장 함수에 넣으면 그대로 '통과' 되어서 넣어준 iterator 객체가 그대로 다시 나온다. iterator = iter(s) # 호출된 이터레이터 객체 print('\\n')print(next(iterator))print(next(iterator))print(next(iterator))print(next(iterator))제너레이터 함수정의 :return 대신 yield 키워드를 쓰는 함수.특징 :일반 함수는 return 하고 함수가 끝난다.함수를 다시 불러오면 코드를 처음부터 다시 다 로드 한다.하지만 제너레이터 함수는 이번 순서의 출력물을 yield 하고, 실행 멈추고 대기상태가 된다.다시 next() 내리면 대기상태를 풀고, 그 다음 순서 출력물을 yield 로 출력한다. 그 후 다시 대기.따라서 제너레이터 함수는 ‘코드를 중지 된 상태로 대기’시켜 놓을 수 있다.# 제너레이터 함수 예 def gen() : for i in range(3) : yield ig = gen()print(next(g)) # 0 출력 후 대기print(next(g)) # 1 출력 후 대기print(next(g)) # 2 출력 후 종료print(next(g)) # yield 할 수 있는 범위 벗어나면 stopiteration error 발생시킨다. 이렇게 쓸 수도 있다.# 또 다른 예 def gen() : yield 1 yield 2 yield 3a = gen()next(a)next(a)next(a)next(a)yield 1을 먼저 출력하면서 yield 1을 더이상 기억하지 않을 것이다.따라서 다시 next()로 제너레이터 객체에 출력 명령을 내리면, yield 2부터 간다.그 뒤 yield 2도 기억하지 않을 것이다.다시 next() 명령을 내리면 yield 3 부터 갈 것이다.제너레이터 함수 안에 return 을 함께 쓸 수도 있다.제너레이터 함수 안에서 return 이 실행되면 제너레이터 함수가 StopIteration Error 와 함께 종료된다.# 제너레이터 함수 안에서 return 함께 사용하는 예 def gen() : for i in range(100) : if i == 3 : return '그만합시다' yield igen = gen()next(gen)next(gen)next(gen)next(gen)# 또 다른 예 def gen(x) : for i in range(10) : if x == 3 : return '종료' yield igenerator = gen(3) # 실행대기 for i in range(10) : print(next(generator))제너레이터 객체정의 :제너레이터 함수로 생성하는 객체.특징 :객체이름 = 제너레이터함수() 형태로 생성된다.next() 로 제너레이터 객체 내부 코드를 실행할 수 있다. 제너레이터 객체는 값을 출력하고 나면 값을 ‘소비’ 하고 더이상 기억하지 않는다. 따라서 iterable 객체 처럼 여러 번 같은 값을 가져올 수 없다.iterable 객체 (리스트) 예gen = [i for i in range(10)]for i in gen : print(i)print('\\n')for i in gen : print(i)iterable 객체는 반복해서 여러 번, 같은 값을 가져올 수 있다.반면에generator 객체 예gen = (i for i in range(10))for i in gen : print(i)for i in gen : print(i)제너레이터 객체로 for문을 한번 돌고, 다시 같은 방식으로 for문 돌려고 했지만 아무것도 출력되지 않았다.제너레이터 축약식정의 :제너레이터 함수 없이 제너레이터 객체를 생성하는 축약식.리스트 축약식과 생긴게 똑같다.대신, 리스트 축약식은 대괄호로 감싸줬다면, 제너레이터 축약식은 일반 괄호 () 로 감싼다.또, 리스트 축약식처럼 값을 바로 반환하지 않는다.제너레이터 축약식으로 제너레이터 객체를 생성하면 ‘대기상태’에 들어간다.next() 명령이 떨어질 때 마다, 값을 하나하나 출력한다.# 제너레이터 축약식gen_comp = (combinations(omega, i) for i in range(5))# 또는 gen = (i for i in range(5)) 정리 :iterable, iterator : ‘반복가능자’generator : 비복원 추출만 가능한 ‘공 주머니’" }, { "title": "[수학/확률과 통계] 집합론 기초, 확률은 함수다, 빈도주의 관점과 베이지안 관점", "url": "/bioinfo.github.io/posts/percentage_theory_recap/", "categories": "Data Science, python, mathematics", "tags": "datascience, mathematics, python", "date": "2021-09-14 00:00:00 +0900", "snippet": "집합론 기초파이썬에서 집합 구현하기파이썬에서 집합은 set 또는 frozenset 자료형을 이용해 구현할 수 있다. set은 내용 변경이 가능한 뮤터블(mutable) 자료형이다. frozenset 은 내용 변경이 불가능한 임뮤터블(immutable) 자료형이다.set([1,2,3])frozenset([1,2,3])집합의 크기집합의 크기 = 집합 원소 갯수 다.$\\lvert x \\rvert$ 또는 $card(x)$ 로 집합의 크기를 나타낼 수 있다.파이썬에서 집합의 크기를 알려면 len() 명령을 쓰면 된다.합집합 (union, OR)정의 :집합 A 또는 집합 B에 속하는 모든 원소로 구성된 집합을 합집합 이라고 한다.$A\\cup{B}$ OR 연산이다.파이썬에서A = {1,2,3}B = {3,4,5}A.union(B)# 합집합 메서드또는A | B # 합집합 연산자 로 집합 A와 집합 B의 합집합을 구한다.교집합 (intersection, AND)정의 :집합 A 그리고 집합 B에 동시에 속하는 원소들로만 구성된 집합을 교집합 이라고 한다.$A\\cap{B}$ AND 연산이다.파이썬에서A = {1,2,3}B = {3,4,5}A.intersection(B)또는A &amp; B로 집합 A와 집합 B의 교집합을 구한다.부분집합정의 :어떤 집합의 원소 중 일부만을 포함하는 집합 모든 집합에서 자기자신은 자기자신의 부분집합이다.A $\\subset$ A파이썬에서 집합 A가 집합 B의 부분집합인지. 아닌지. 보려면 issubset() 메서드를 쓰면 된다.# A는 B의 부분집합인가? A = {1,2,3}B = {1,2,3,4,5}A.issubset(B)진부분집합정의 :집합 A의 부분집합 중에서 자기자신을 뺀 나머지 부분집합들을 진부분집합 이라고 한다.차집합 (difference)정의 :집합 A 원소 중에 집합 B에 속하는 원소를 모두 제거하고, 남은 것들로만 이루어진 집합을 집합 A에서 B를 뺀 차집합 이라고 한다.$A-B$# 차집합 메서드 A = {1,2,3,4}B = {2,3,4}A.difference(B)# 또는 A-B여집합정의 :전체집합 $\\Omega$ 중에서 부분집합 A에 속하지 않은 원소들로만 이루어진 $\\Omega$ 의 부분집합또는전체집합 $\\Omega$ 원소들 중에서 부분집합 A에 속하는 원소들만을 뺀 나머지로 이루어진 집합($\\Omega - A$)을 여집합 이라고 한다.$A^{C}$공집합 (null set)정의 :원소가 아무것도 안 들은 집합$\\varnothing$ 공집합은 모든 집합의 부분집합이다.$\\varnothing \\subset A$ 공집합과 어떤 집합 A의 합집합은 집합 A다.$\\varnothing \\cup{A} = A$ 공집합과 어떤 집합 A의 교집합은 공집합이다.$\\varnothing \\cap{A} = \\varnothing$ 집합 A 여집합과 집합 A의 교집합은 공집합이다.$A^{C} \\cap{A} = \\varnothing$집합이 갖는 부분집합의 갯수정리 :어떤 집합은 $2^{n}$ 개의 부분집합을 갖는다.합집합과 교집합 분배법칙덧셈과 곱셈 연산은 분배법칙이 성립했다.$a\\times (b+c) = (a\\times b) + (a\\times c)$합집합과 교집합에 대해서도 위와같은 분배법칙이 성립한다.$A\\cup{(B\\cap{C})} = (A\\cup{B})\\cap{(A\\cup{C})}$$A\\cap{(B\\cup{C})} = (A\\cap{B})\\cup{(A\\cap{C})}$확률의 수학적 정의, 확률값의 의미를 해석하는 두 가지 관점확률의 수학적 정의표본공간 $\\Omega$정의 :‘가능한’ 모든 표본의 집합.표본 (sample, data)정의 :1회 시행의 결과.사건정의 :표본공간의 ‘부분집합’ &amp; 표본들의 집합확률정의 :‘사건’을 입력으로 받아 ‘특정한 실숫값’(확률값) 출력하는 ‘함수’확률은 함수다.확률은 ‘확률이라면 무조건 모두 만족해야 하는’ 공리를 가지고 있다.콜모고로프의 공리 (확률의 기본 공리) $0 \\le P(A)$ $P(\\Omega) = 1$ 교집합이 공집합 $\\varnothing$ 일 때, $P(A\\cup{B}) = P(A) + P(B)$ 표본값 하나하나에는 확률값이 할당되어 있지 않다.대신, 특정한 표본값이 나오는 ‘사건’(경우)에 대해서는 확률값을 할당한다.$\\Rightarrow$ 확률은 표본이 아니라 ‘사건’에 대해 정의한다.$P(1) \\ne \\frac{1}{6}$A = { 1 }, $P(A) = \\frac{1}{6}$콜모고로프 공리만 지켜진다면, 표본공간 상의 사건에 대해 확률값을 마음대로 할당해도 된다.다만 별 다른 정보. 조건이 따로 제시되지 않으면 ‘공정한 주사위’를 가정한다.이때 확률은 다음과 같이 계산한다.$P(A) = \\frac{card(A)}{card(\\Omega)}$하지만 이것 또한 수많은 확률 할당법 중에 하나일 뿐이다. 공리만 지켜진다면, 여전히 확률값을 마음대로 할당할 수 있다.공리만 지키면 아무렇게나 확률값을 할당해도 된다는 건, 언뜻 보기에 확률값이 아무 의미 없어 보인다.의미 없어 보이는 확률값에 의미를 부여하고, 의미를 해석하는 두 가지 방법이 있다.확률값의 의미를 해석하는 두 가지 관점 빈도주의 관점 (반복.비율) 베이지안 관점 (신뢰도)1. 빈도주의 관점에서 확률값 바라보기빈도주의 관점 정의 :n번 ‘반복’했을 때, 특정 사건이 발생한 횟수의 ‘비율’이 확률값이다.$\\frac{특정사건 발생 횟수}{시행 반복 횟수} =$ 확률값(비율)핵심 키워드 : 반복, 비율2. 베이지안 관점에서 확률갑 바라보기베이지안 관점 정의 :확률값은 ‘선택된 표본이 특정한 사건의 원소 중 하나라는 주장의 신뢰도’ 이다. 사건 - 주장예를 들어 { 1 } 이라는 사건은 “선택된 표본이 1 이다!’ 라는 주장이다. 사건이 담고 있는 원소들 - 정답(선택된 표본) 후보군 확률값 - 주장의 신뢰도 선택된 표본이 1이다! 라는 주장의 신뢰도베이지안 관점에서‘사건이 발생했다’ 의 의미예를 들어 사건 A가 발생했다고 해보자.‘사건 A가 발생했다’ 의 의미는“선택된 표본이 사건 A의 원소 중 하나였다.”또는“사건 A의 주장이 진실이었다” 는 의미다.한 가지 확률값에 대해 베이지안 관점과 빈도주의적 관점으로 동시에 해석할 수 있다.확률값에 대한 베이지안 관점과 빈도주의적 관점은 서로 배타적인 관계가 아니다. 서로 양립할 수 있다." }, { "title": "[수학/최적화] 선형계획법(LP문제), 이차계획법(QP) 문제", "url": "/bioinfo.github.io/posts/linear_quadratic_programming/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-09-08 00:00:00 +0900", "snippet": "선형계획법 문제 (LP 문제)$Linear$ $Programming$정의 :선형모형 $c^{T}x$ 을 등식/부등식 제한조건 걸고 최적화 하는 문제목적함수 $c^{T}x$연립방정식 제한조건 (등식 제한조건) ‘기본형’ 선형계획법 문제 $Ax = b$ $x \\ge 0$ (벡터 $x$ 의 모든 원소는 0 또는 양수)연립부등식 제한조건 (부등식 제한조건) ‘정규형’ 선형계획법 문제 $Ax \\leq b$ $x \\ge 0$ (벡터 $x$ 의 모든 원소는 0 또는 양수) 제한조건을 $Ax = b$, $Ax \\leq b$ 로 표시한 것은 사이파이 패키지에 넣을 때 $A$, $b$ 등을 따로따로 명시해서 넣어야 하기 때문이다.제한조건 표기방식만 다를 뿐, 일반적인 제한조건 최적화 문제와 똑같다.$\\Rightarrow$ 그냥 똑같은 제한조건 최적화 문제인데, 목적함수가 선형모형인 경우라 생각하면 된다.사이파이로 LP 문제 해결하기sp.optimize.linprog(f, A_ub, b_ub, A_eq, b_eq, ) f : 목적함수. 선형모형 A_ub : 연립부등식 제한조건의 행렬 $A$ b_ub : 연립부등식 제한조건의 벡터 $b$ A_eq : 연립방정식 제한조건의 행렬 $A$ b_eq : 연립방정식 제한조건의 벡터 $b$# 사이파이 선형계획법 명령sp.optimize.linprog(f, A_ub, b_ub...)사용 예)목적함수 : $-3x-5y$연립부등식 제한조건 : $-x \\leq -100$ $-y \\leq -100$ $x+2y \\leq 500$ $4x+5y \\leq 9800$$x \\ge 0, y \\ge 0$위 경우에서,$c = [-3, -5]^{T}$$A = [[-1,0],[0,-1],[1,2],[4,5]]$$b = [-100, -100, 500, 9800]^{T}$이다.이걸 sp.optimize.linprog() 명령에 argument 로 넣으면 된다.알고리듬 안에 $x \\ge 0, y \\ge 0$ 은 기본 적용되어 있다.c = np.array([-3, -5])A = np.array([[-1,0],[0,-1],[1,2],[4,5]])b = np.array([-100,-100, 500, 9800])# 선형계획법 명령sp.optimize.linprog(c, A, b)CVXPY 이용해서 선형계획법 문제 풀기CVXPY 를 이용해서 선형계획법 문제 풀 수도 있다.선형모형은 CVXPY.curvature 에서 $affine$ 으로 나오기 때문이다.이는 DCP rule 로 CVXPY 가 검사해서 나온 결과다. $affine$ 은 $convex$ 로 볼 수 있다.따라서 선형모형은 DCP rule 을 만족하는 $convex$ 함수라고 볼 수 있다.목적함수가 DCP rule 을 만족했으므로,CVXPY를 이용해서 제한조건 있는 컨벡스 최적화를 해보자.import cvxpy as cp# 최적화 해 찾을 변수 x_1 = cp.Variable()x_2 = cp.Variable()# 부등식 제한조건 f1 = -x_1 &lt;= -100f2 = -x_2 &lt;= -100f3 = x_1+2*x_2 &lt;= 500f4 = 4*x_1 +5*x_2 &lt;= 9800# 목적함수 지정 obj = cp.Minimize(-3*x_1-5*x_2)# 최적화 문제 정의 prob = cp.Problem(obj, constraints=[f1, f2, f3, f4])# 최적화 문제 계산 명령 prob.solve()print(prob.status)print(x_1.value, x_2.value)prob.solve()결과 :optimal299.99, 100.00-1400.00선형계획법문제를 풀 수 있었다.그리고 부등식 제한조건 $f1, f2$ 가 이미 $x_{1} \\ge 0, x_{2} \\ge 0$ 을 만족하고 있기 때문에 따로 지정하지 않아도 된다.CVXOPT 이용해서 선형계획법 문제 풀기앞에서 선형계획법 문제를 ‘제한조건 있는 컨벡스 최적화 문제’로 재정의하고, 푸는 것이 가능했다.CVXPY 처럼 CVXOPT 도 컨벡스 최적화를 위한 패키지였다.그러면 CVXOPT 를 통해서도 선형계획법 문제를 풀 수 있을 것이다.마침 CVXOPT 에는 선형계획법 문제를 해결할 수 있는 solver.lp() 명령이 있다.이 명령을 이용해서 선형계획법 문제를 풀어보자.# cvxopt로 선형계획법 문제 풀기 c = matrix(np.array([-3.0,-5.0]))A = matrix(np.array([[-1.0,0.0],[0.0,-1.0],[1.0,2.0],[4.0,5.0]]))b = matrix(np.array([-100.0, -100.0, 500.0, 9800.0]))np.array(solvers.lp(c, A, b)['x'])이처럼 CVXOPT 를 사용해서도 선형계획법 문제를 풀 수 있다.*CVXPY든, CVXOPT 든 기본조건 $x \\ge 0, y\\ge 0$ 을 부등식 제한조건으로서 별도로 반영할 수도 있다. 각 패키지의 argument 를 잘 보자.이차계획법 문제 (QP문제)$Quadratic$ $Programming$정의 :‘일반화된 이차형식’을 등식/부등식 제한조건 걸고 최적화목적함수 $\\frac{1}{2} x^{T}Qx + c^{T}x$연립방정식 제한조건 (등식 제한조건) $Ax = b$ $x \\ge 0$부등식 제한조건 (부등식 제한조건) $Ax \\leq b$ $x \\ge 0$목적함수인 일반화된 이차형식은 컨벡스 함수인 경우 넌 컨벡스 함수인 경우두 가지 경우로 존재한다.일반화된 이차형식 $\\frac{1}{2} x^{T}Qx + c^{T}x$ 에서행렬 $Q$ 가 양의 준정부호 이면 이차형식은 컨벡스 함수다. 이 경우 컨벡스 최적화 할 수 있다.행렬 $Q$ 가 양의 준정부호가 아니면, 이차형식은 넌 컨벡스 함수다.이때 함수는 다수의 국소 최저점 가질 수 있다. 이 경우 넌 컨벡스 최적화 해야 한다.CVXOPT 를 이용해서 이차계획법 문제를 풀어보자cvxopt 패키지의 solver.qp 명령을 이용해서 qp문제를 풀 것이다.cvxopt 패키지는 ‘컨벡스 최적화’ 패키지다.당연히 solver.qp() 명령도 컨벡스 최적화 명령일 것이다.$\\Rightarrow$ solver.qp() 명령은 이차형식 함수가 컨벡스 함수인 경우만 최적화 할 수 있다.(행렬 $Q$ 가 양의 준정부호인 경우)CVXOPT 로 이차계획법 문제를 푸는 예)목적함수$x_{1}^{2} + x_{2}^{2}$등식 제한조건$x_{1} + x_{2} -1 = 0$일 때 목적함수를 이차형식 꼴 로 만들고, 이차계획법 문제로 최적화 하자.목적함수는 다음과 같이 이차형식 꼴로 바꿀 수 있다.$\\frac{1}{2} [x_{1}, x_{2}][[2,0],[0,2]][x_{1}, x_{2}]^{T} + [0,0][x_{1}, x_{2}]^{T}$제한조건은 다음과 같이 고칠 수 있다.$[1,1][x_{1}, x_{2}]^{T} = 1$따라서$Q = [[2,0],[0,2]]$$c = [0,0]^{T}$$A = [1,1]^{T}$$b = [1]$이다.목적함수가 일반화된 이차형식이므로, 이차계획법 문제로 생각하고 최적화 할 수 있다.(그러면 이제 기본 조건 $x_{1} \\ge 0$, $x_{2} \\ge 0$ 도 만족시켜야 한다)이때, 이차계획법 문제 푸는 데 CVXOPT의 solver.qp()를 이용하기 위해서는 이차형식의 행렬 $Q$ 가 양의 준정부호 여야 한다.$Q = [[2,0],[0,2]]$ 였다.$Q$ 를 이차형식 꼴로 만들면$2x^{2}+2y^{2}$ 가 된다.$x \\ne 0$ , $y \\ne 0$ 이므로,$2x^{2}+2y^{2}$ 는 항상 양수다.$\\Rightarrow 2x^{2}+2y^{2} &gt; 0$$Q$의 이차형식이 0 또는 양수가 되어야 하는 양의 준정부호 조건을 만족한다.곧, 이 문제의 목적함수 이차형식은 컨벡스 함수다.def f(x, y) : return x**2+y**2xx = np.linspace(-10,10,400)yy = np.linspace(-10,10,500)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z, linewidth=0.03, cmap='flare')ax.set_xticks([])ax.set_yticks([])ax.set_zticks([])plt.title('$f = x_{1}**2+x_{2}**2$')plt.show()목적함수가 컨벡스 함수임을 확인했다.이제 CVXOPT의 solver.qp() 명령으로 이차형식을 최적화 하자.# 이차계획법 문제 from cvxopt import matrix, solversQ = matrix(np.array([[2.0,0.0],[0.0,2.0]]))c = matrix(np.array([0.0,0.0]))A = matrix(np.array([[1.0,1.0]]))b = matrix(np.array([1.0]))r = solvers.qp(Q,c,A=A,b=b)['x']np.array(r)최적해 : $array([[0.5], [0.5]])$이 경우에는 최적해가 0.5, 0.5 라서 $x_{1} \\ge 0 , x_{2} \\ge 0$ 가 아무 영향도 미치지 못하기 때문에, 별도의 부등식 제한조건으로 취급하지 않았다.하지만 만약 $x_{1} \\ge 0 , x_{2} \\ge 0$ 에 의해 최적해가 영향을 받는다면,$x_{1} \\ge 0 , x_{2} \\ge 0$ 도 별도의 부등식 제한조건으로 생각하고 solvers.qp() 의 argument로 넣어줘야 한다.*G, h조건만 맞다면. 하나의 함수에 대해 여러가지 최적화 방법. 알고리듬을 사용할 수 있다하나의 함수에 대해서 다양한 최적화 방법을 시도할 수 있다.함수 $x_{1}^{2}+x_{2}^{2}$ 를 최적화 하기 위해 다양한 최적화 방법을 시도해보자.고려할 제한조건은 $x_{1} + x_{2} -1 = 0$ 이다.# 1. sp.optimize.minimize()이 방법은 제한조건을 받지 않는다.라그랑주 승수법을 써서 목적함수를 변형한 다음 위 알고리듬으로 최적화 하겠다.$h = x_{1}^{2} + x_{2}^{2} + \\lambda (x_{1} + x_{2} -1)$변형된 목적함수 $h$ 를 $x_{1}, x_{2}, \\lambda$ 로 편미분 한 뒤, 기울기 필요조건을 만족하는 $\\lambda$ 를 찾자.$\\lambda = -1$$\\Rightarrow$$h = x_{1}^{2} + x_{2}^{2} - (x_{1} + x_{2} -1)$이 목적함수 $h$를 sp.optimize.minimize() 명령에 넣어 최적화 하자.# 하나의 함수에 여러가지 최적화 방법. 알고리듬을 쓸 수 있다. # 1. sp.optimize.minimze()def pf(x) : return x[0]**2+x[1]**2-(x[0]+x[1]-1)sp.optimize.minimize(pf, np.array([0,3]))최적화에 성공했다. 최적해는 $[0.5, 0.5]$ 다.총평 : 굳이 목적함수 변형 안 하고 라그랑주 승수법으로 $x_{1}, x_{2}$ 를 수기 계산하는 게 더 빨랐을 것이다.# 2. fmin_slsqp()이번에는 fmin_slsqp() 명령으로 제한조건 최적화를 바로 하겠다.목적함수 : $x_{1}^{2}+x_{2}^{2}$제한조건 : $x_{1} + x_{2} -1 = 0$이다.# 2. 제한조건 최적화 # 목적함수def pf(x) : return x[0]**2+x[1]**2# 등식 제한조건def con(x) : return x[0]+x[1]-1# 최적화sp.optimize.fmin_slsqp(pf, np.array([1,2]), eqcons=[con])이번에도 최적화에 성공했다.최적해는 역시 $[0.5, 0.5]$ 다.총평 : 첫번째 방법보다는 훨씬 수월하고, 사람이 직접 해야 할 계산이 적어서 편했다.# 3. CVXPY 를 이용한 컨벡스 최적화이번에는 CVXPY 를 이용한 컨벡스 최적화를 해보자.먼저, CVXPY 는 컨벡스 함수 이면서 DCP rule을 만족하는 녀석들만 컨벡스 최적화 하는 패키지다.따라서, 내가 최적화 하려는 목적함수 $x_{1}^{2}+x_{2}^{2}$ 가 컨벡스함수 DCP rule 만족 1,2 조건을 만족해야만 CVXPY로 컨벡스 최적화 할 수 있다.앞에서 봤듯이, 이 함수는 컨벡스 함수다. 이차형식 꼴로 고쳤을 때, 행렬 $Q$ 가 양의 준정부호 였다. 그래프로 그려보면 컨벡스 함수 형상이다.컨벡스 함수임을 확인했으니, 이제 DCP rule을 만족하는 지 봐야한다.(DCP rule 은 컨벡스 필요조건으로, DCP rule 을 만족하면 모두 컨벡스 함수이지만, DCP rule 을 만족하지 않는 컨벡스 함수들도 있다)# 목적함수 obj = cp.Minimize(x**2+y**2)# 목적함수가 컨벡스 최적화 가능한가? (목적함수가 볼록함수인가, 오목함수인가?)print(obj.is_dcp())결과 : True목적함수가 DCP rule 을 만족한다.그러면 이제 목적함수를 CVXPY 로 컨벡스 최적화 할 수 있다.# x**2+y**2 는 볼록함수다. # 3. cvxpy 를 이용한 컨벡스 최적화 import cvxpy as cpx = cp.Variable()y = cp.Variable()# 목적함수 obj = cp.Minimize(x**2+y**2)# 목적함수가 컨벡스 최적화 가능한가? (목적함수가 볼록함수인가, 오목함수인가?)print(obj.is_dcp())# 볼록함수다. # 제한조건 cons = [x+y-1 == 0]# 최적화 문제 정의 prob = cp.Problem(obj, constraints=cons)# 제한조건 감안했을 때, 볼록함수 최적화가 가능한가?print(prob.is_dcp()) # 가능하다. prob.solve(), x.value, y.value결과 :TrueTrue(0.5, 0.5)제한조건을 감안해도 위 최적화 문제를 컨벡스 문제로 풀 수 있었다.최적해는 마찬가지로 $[0.5, 0.5]$ 다.총평 : 주어진 목적함수가 컨벡스 함수인지, DCP rule 을 만족하는지 확인해야 하는 점이 번거롭긴 했지만, 직관적인 심볼릭 연산이 가능해서 편했다.# 4. CVXOPT 를 이용한 최적화앞에서 목적함수 $x_{1}^{2}+x_{2}^{2}$ 가 일반화된 이차형식(quadratic form) 으로 바뀔 수 있다는 걸 봤다.또, 이차형식의 행렬 $Q$ 는 양의 준정부호 조건을 만족했다.따라서 목적함수는 이차형식 꼴인 컨벡스 함수로도 생각할 수 있다.CVXOPT 의 solver.qp() 명령은 목적함수(이차형식)가 컨벡스 함수인 이차계획법 문제를 푸는 명령이었다.문제의 목적함수가 이차형식 이면서 컨벡스 함수이기 때문에, CVXOPT solver.qp() 명령으로 주어진 목적함수를 최적화 할 수 있다.이 경우 문제가 이차계획법 문제가 되었기 때문에 고려해야 할 조건으로 $x_{1} \\ge 0, x_{2} \\ge 0$ 이 추가된다.# x**2+y**2 는 일반화된 이차형식으로 바꿀 수 있다. # 4. cvxopt를 이용해 이차계획법으로 풀기 from cvxopt import matrix, solversQ = matrix(np.array([[2.0,0.0],[0.0,2.0]]))c = matrix(np.array([0.0,0.0]))A = matrix(np.array([[1.0,1.0]]))b = matrix(np.array([1.0]))np.array(solvers.qp(Q, c, A=A, b=b)['x'])결과 : $[0.5, 0.5]$최적화에 성공했다.$x_{1} \\ge 0, x_{2} \\ge 0$ 조건은 최적화에 영향 미치지 못했기 때문에, 없는 거나 다름 없었다. 따라서 따로 argument 를 명시하지 않았다.총평 : 목적함수가 일반화된 이차형식 꼴을 만족하는지, 그리고 행렬 $Q$ 가 양의 준정부호 인지 확인해야 하는 점이 번거로웠다.결론 : 조건만 만족한다면. 1개 함수에 대해 다양한 최적화 방법을 시도해볼 수 있다." }, { "title": "[수학/최적화] 전역 최적화, 컨벡스 최적화, 제한조건 최적화", "url": "/bioinfo.github.io/posts/global_convex_optimization/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-09-08 00:00:00 +0900", "snippet": "전역 최적화 문제정의 :최적화를 통해 함수 전역 최저점을 찾는 문제내가 어떤 최적화 결과를 얻었는데, 그 최적점이 함수 전역의 최적점이라고 확신할 수 있는가?만약 함수형태가 컨벡스함수(볼록함수) 라면, 함수 전역 최저점이라고 생각할 수 있을 것이다.반면에 함수가 전역 최저점 말고도 여러 개의 국소 최저점을 갖고 있다면?내가 얻은 최적화 결과가 전역 최저점이라고 단정지어 말하기 어렵다.곧, 함수에 여러 개의 국소 최저점이 존재하는 경우. 스텝사이즈 나 최적화 시작 위치 등에 따라최적화 결과가 전역 최저점이 아닌 국소 최저점 일 수 있다.최적화 결과가 전역이 아닌 국소 최저점에 수렴한 예)나는 이 목적함수를 대상으로 전역 최적화 문제를 풀고 싶다.함수 가장 아래쪽 ‘글로벌 최저점’에 수렴하는 게 목표다.비선형 목적함수 최적화 : 최대경사법 알고리듬 사용# 위 비선형 목적함수 직접 최적화 해보자. # 최대경사법 import sympyx = sympy.symbols('x')f = x**2-20*sympy.cos(x)sympy.diff(f, x)def gradient(x) : return 2*x+20*np.sin(x)def f_non_linear(x) : return x**2-20*np.cos(x)x = np.arange(-10,10,0.2)plt.plot(x, f_non_linear(x))mu = 0.03# 최적화 시작점a = -7.5for i in range(50) : plt.plot(a,f_non_linear(a), 'go', markersize=5) next_ = a - mu*gradient(a) a = next_plt.plot(a, f_non_linear(a), 'ro', markersize=5)plt.text(a-2, f_non_linear(a)-12, '로컬 최저점에 수렴')plt.suptitle('비선형 목적함수 최대경사법 최적화', y=1.003)plt.title(f'시작점 : [-7.5, {np.round(f_non_linear(7.5),2)}], 결과 : 왼쪽 로컬 최저점 수렴')plt.xlabel('$x$')plt.ylabel('$y$')plt.show()$[-7.5, 49.32]$ 에서 시작한 결과 전역 최저점이 아닌 왼쪽 로컬 최저점에 수렴했다.x = np.arange(-10,10,0.2)plt.plot(x, f_non_linear(x))mu = 0.03# 최적화 시작점a = 7.5for i in range(50) : plt.plot(a,f_non_linear(a), 'go', markersize=5) next_ = a - mu*gradient(a) a = next_plt.plot(a, f_non_linear(a), 'ro', markersize=5)plt.text(a-2, f_non_linear(a)-12, '로컬 최저점에 수렴')plt.suptitle('비선형 목적함수 최대경사법 최적화', y=1.003)plt.title(f'시작점 : [7.5, {np.round(f_non_linear(7.5),2)}], 결과 : 오른쪽 로컬 최저점 수렴')plt.xlabel('$x$')plt.ylabel('$y$')plt.show()같은 최대경사법 알고리듬으로, 시작점 $[7.5, 49.32]$ 에서 최적화를 시작해봤다.결과는 오른쪽 로컬 최저점에 수렴했다.x = np.arange(-10,10,0.2)plt.plot(x, f_non_linear(x))mu = 0.03# 최적화 시작점a = 2.5for i in range(50) : plt.plot(a,f_non_linear(a), 'go', markersize=5) next_ = a - mu*gradient(a) a = next_plt.plot(a, f_non_linear(a), 'ro', markersize=5)plt.text(a-2, f_non_linear(a)-12, '글로벌 최저점에 수렴')plt.suptitle('비선형 목적함수 최대경사법 최적화', y=1.003)plt.title(f'시작점 : [{2.5}, {np.round(f_non_linear(2.5),2)}], 결과 : 글로벌 최저점 수렴')plt.xlabel('$x$')plt.ylabel('$y$')plt.show()한편 시작점을 $[2.5, 22.27]$ 로 잡았을 때는 최적화 결과가 전역 최저점에 수렴했다.이처럼, 함수에 여러 개의 국소 최저점이 있는 경우.시작점이 어디냐에 따라 최적화 결과가 전역 최저점에 수렴하지 않을 수 있었다.비선형 목적함수 최적화 : 뉴턴방법 알고리듬 사용# 뉴턴방법 plt.subplot(1,3,1)x = np.arange(-10,10,0.2)plt.plot(x, f_non_linear(x))a = 1.5plt.title(f'시작점 : {a}')for i in range(100) : plt.plot(a, f_non_linear(a), 'go', markersize=5) next_ = a - g(a)/h(a) a = next_plt.subplot(1,3,2)x = np.arange(-10,10,0.2)plt.plot(x, f_non_linear(x))a = 1.2plt.title(f'시작점 : {a}')for i in range(100) : plt.plot(a, f_non_linear(a), 'go', markersize=5) next_ = a - g(a)/h(a) a = next_plt.subplot(1,3,3)x = np.arange(-10,10,0.2)plt.plot(x, f_non_linear(x))a = 4plt.title(f'시작점 : {a}')for i in range(100) : plt.plot(a, f_non_linear(a), 'go', markersize=5) next_ = a - g(a)/h(a) a = next_plt.suptitle('뉴턴 : 비선형함수 모양이 2차함수 모양과 다르고, 로컬최저점이 많아서 제대로 최적화 안 된다', y = 1.03)비선형 목적함수 최적화 : 준 뉴턴방법(BFGS)sp.optimize.minimize(f_non_linear, 4)컨벡스 최적화정의 :컨벡스 함수를 대상으로 최적화(최소화) 하는 방법 컨벡스 최적화 결과는 항상 전역 최적해다.컨벡스 필요조건 : DCP rule컨벡스 필요조건을 DCP rule 이라고 한다.목적함수가 DCP rule 을 만족하면, 그 함수는 무조건 컨벡스 함수다.하지만 컨벡스 함수인데 DCP rule 만족하지 않는 경우도 왕왕 있다.DCP rule $\\rightarrow$ $Convex$$Convex$ $\\nrightarrow$ DCP rule함수가 DCP rule 을 만족하지 않지만, 컨벡스 함수인 예목적함수 : $2x_{1}^{2} +x_{2}^{2}+x_{1}x_{2}+x_{1}+x_{2}$제한조건 :$x_{1} + x_{2} = 1$$x_{1} \\ge 0$$x_{2} \\ge 0$위 목적함수, 그리고 제한조건을 고려한 목적함수의 최소화 문제도 DCP rule 을 만족하지 않는다.# 목적함수가 DCP rule 만족하지 않는다import cvxpy as cpx1 = cp.Variable()x2 = cp.Variable()obj = 2*x1**2+x2**2+x1*x2+x1+x2obj.is_dcp()# 최소화 문제도 DCP rule 만족하지 않는다obj = cp.Minimize(obj)cons = [x1+x2 == 1]prob = cp.Problem(obj, constraints=cons)prob.is_dcp()하지만, 이 함수를 그려보면def f(x,y) : return 2*x**2+y**2+x*y+x+y Z = f(X,Y)ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z, linewidth=0.03, cmap='flare')ax.view_init(10, -60)plt.title('컨벡스 함수지만 DCP rule 만족하지 않는 것들도 있다')모양이 아래에서 봤을 때 볼록한, 컨벡스 함수임을 확인할 수 있다.따라서 어떤 함수가 DCP rule 에 어긋나지만. 컨벡스 함수인 경우도 존재한다.(위 예시의 함수는 이차계획법 문제로 고쳐서 CVXOPT 의 solver.qp 명령으로 컨벡스 최적화 할 수 있다)(DCP rule에 대해서는 아래 CVXPY 부분에 좀 더 자세하게 기록해두었다)컨케이브(오목) 함수 최대화도 컨벡스 최적화에 포함된다컨벡스 최적화는 컨벡스 함수를 대상으로 최소화 하는 작업으로 정의된다.그런데 컨케이브 함수 최대화도 컨벡스 최적화로 볼 수 있다.컨케이브 함수를 반대로 뒤집으면 컨벡스 함수와 같다.그리고 컨케이브 함수의 최대점은 이 함수를 반대로 뒤집은 컨벡스 함수의 최소점과 같다.$\\Rightarrow$ 컨케이브 함수 최대화 문제와 컨벡스 함수 최소화 문제 둘 중 하나를 풀 수 있으면 나머지 하나도 반드시 풀 수 있다.결국 컨케이브 함수 최대화 문제를 푸는 건 컨벡스 함수 최소화 문제 푸는 것과 같다.$\\Rightarrow$ 컨케이브 함수 최대화 문제를 푸는 것 $=$ 컨벡스 최적화 문제따라서 컨케이브 함수 최대화도 컨벡스 최적화에 포함되는 개념이다.$Maximize(concave), Minimize(convex) \\subset$ $Convex$ $Optimization$한편대부분의 경우 최적화 할 때 최소화 문제만을 고려한다. 최소화 문제를 풀 수 있으면 최대화 문제도 풀 수 있다.그러면 사실상 컨벡스 최적화 문제 $= Minimize(Convex)$ 를 의미한다고 볼 수 있다.그래서 컨벡스 최적화를 다음과 같이 정의하기도 한다.$\\frac{d^{2}h}{dx^{2}} \\ge 0$‘목적함수의 2차 도함수가 0 이상인 구간 에서만 정의된 최적화(최소화)’다변수함수의 경우$x^{T}Hx \\ge 0$‘목적함수의 헤시안 행렬(2차 도함수 행렬)이 양의 준정부호인 영역 에서만 정의된 최적화(최소화)’즉, 목적함수 $h$의 볼록구간(영역)에서만 정의된 최적화(최소화)라는 것이다.전역 최적화 문제를 푸는 도구로서의 컨벡스 최적화# 목적함수가 전역 최저점 뿐 아니라, 국소 최저점이 여러 개 있는 경우위에서 봤던 비선형 목적함수를 다시 보자.국소최저점이 많아서 전역 최적화에 실패했었다.이 함수의 각 볼록구간만 잘라서, 각각 최적화 하는 것은 컨벡스 최적화를 3번 하는 것과 같다.우선 위 비선형 목적함수에서 2차도함숫값이 항상 0 이상인 구간만 구해보자.def f_non_linear(x) : return x**2-20*np.cos(x)x = sympy.symbols('x')f = x**2-20*sympy.cos(x)fprime = sympy.diff(f)sympy.diff(fprime)def h(x) : return 20*np.cos(x)+2x = np.arange(-10,10,0.2)result = np.array([x for x in x if h(x) &gt;= 0 ])plt.plot(result, f_non_linear(result), 'ro-')first_convex = result[result &lt; -4]second_convex = result[(result &gt; -2) &amp; (result &lt; 2)]third_convex = result[result &gt; 4]빨간색 점으로 표현된 3개 구간이 2차 도함수가 항상 0 이상인 컨벡스 구간이다.각 구간별로 컨벡스 최적화해보자.# 구간1plt.plot(first_convex, f_non_linear(first_convex))plt.title('2차 도함수 &gt;= 0 인 첫번째 컨벡스 구간(볼록구간)')mu = 0.03# 최적화 시작점a = -7.5for i in range(50) : plt.plot(a,f_non_linear(a), 'go', markersize=5) next_ = a - mu*gradient(a) a = next_print(f'컨벡스 구간 1의 최소점 : {f_non_linear(a)}')print(f'컨벡스 구간 1의 최적해 : {a}')구간 1 최소점 : 15.79구간 1 최적해 : -5.67# 구간2plt.plot(second_convex, f_non_linear(second_convex))plt.title('2차 도함수 &gt;= 0 인 두번째 컨벡스 구간(볼록구간)')mu = 0.06# 최적화 시작점a = second_convex[3]for i in range(10) : plt.plot(a,f_non_linear(a), 'go', markersize=5) next_ = a - mu*gradient(a) a = next_print(f'컨벡스 구간 2의 최소점 : {f_non_linear(a)}')print(f'컨벡스 구간 2의 최적해 : {a}')구간 2 최소점 : -19.99구간 2 최적해 : -4.512# 구간3plt.plot(third_convex, f_non_linear(third_convex))plt.title('2차 도함수 &gt;= 0 인 세번째 컨벡스 구간(볼록구간)')mu = 0.06# 최적화 시작점a = third_convex[10]for i in range(10) : plt.plot(a,f_non_linear(a), 'go', markersize=5) next_ = a - mu*gradient(a) a = next_print(f'컨벡스 구간 3의 최소점 : {f_non_linear(a)}')print(f'컨벡스 구간 3의 최적해 : {a}')구간 3 최소점 : 15.79구간 3 최적해 : 5.67이렇게 각각 컨벡스 구간별로 컨벡스 최적화를 3번 할 수 있다.한편, 컨벡스 최적화를 하면 각 구간 별 전역 최적해 값을 얻을 수 있다.위 경우에도 구간 1~3의 전역 최적해 값을 얻을 수 있었다.각 구간의 전역 최적해 값은 함수 전체로 보면 국소 최저점들일 수 있다.이 국소 최저점들을 비교했을 때, 가장 작은 값이 전역 최적점이라고 볼 수 있다.컨벡스 구간 2의 최소위치가 가장 출력값이 작으므로, 전역 최소점이라고 볼 수 있다.$\\Rightarrow$ 이렇게 전역 최적화가 어려운 비선형 목적함수를,여러 컨벡스 구간으로 잘라서 컨벡스 최적화 한 다음각 결과값을 비교해서 전역 최적점을 찾아낼 수도 있다.따라서 컨벡스 최적화는 전역 최적화 문제를 푸는 도구가 될 수 있다.파이썬 패키지로 컨벡스 최적화 하기CVXPY목적함수와 최적화 문제 모두 DCP rule 을 만족해야 컨벡스 최적화 가능한 패키지. 목적함수가 비록 컨벡스(컨케이브) 함수라도 DCP rule 에 안 맞으면 최적화 못한다. 목적함수가 DCP rule 에 부합해도, 정의한 최적화 문제가 DCP rule 에 안 맞으면 최적화 못 한다. 직관적 심볼릭 연산 할 수 있다는 장점. 있다.CVXOPT solvers 객체를 이용해서 다양한 컨벡스 최적화가 가능하다. 주로 LP문제(선형계획법 문제), QP문제(이차계획법 문제) 해결을 위해 CVXOPT를 사용했다.CVXPY목적함수와 최적화 문제 모두 DCP rule 을 만족해야 컨벡스 최적화 가능한 패키지. (강조) 목적함수가 비록 컨벡스(컨케이브) 함수라도 DCP rule 에 안 맞으면 최적화 못한다. (강조) 목적함수가 DCP rule 에 부합해도, 정의한 최적화 문제가 DCP rule 에 안 맞으면 최적화 못 한다. 컨벡스 최적화 할 때 등식/부등식 제한조건을 걸 수도 있다.최적화 하려는 목적함수가 DCP rule 만족하는지 보려면object.curvature 명령 입력했을 때 CONVEX, CONCAVE, AFFINE, CONSTANT 로 나오는 목적함수들은 모두 DCP rule 만족하는 것들이다.*Constant 와 Affine 은 Concave 이기도 하고 Convex 이기도 하다. 따라서 Constant 와 Affine 도 컨벡스 최적화 할 수 있다(컨벡스 함수다).object.curvature내가 정의한 최적화 문제가 DCP rule 만족하는지 보려면# 목적함수 최대화, 최소화 명령이 dcp rule 만족하는가object.is_dcp()# 제한조건 반영한 최적화 문제가 dcp rule 만족하는가prob.is_dcp()*참고컨벡스 함수를 최대화 하라고 한다던가, 컨케이브 함수를 최소화 하라고 한다던가,혹은 목적함수에 제한조건을 적용했을 때 최대화 또는 최소화가 불가능한 경우최적화 문제가 DCP rule 위반이 된다.CVXPY 컨벡스 최적화 코드 예시import cvxpy as cpa = cp.Variable()b = cp.Variable() # 심볼릭 변수 지정# 목적함수 지정obj2 = cp.Minimize(a+b)# 제한조건const = a**2+b**2 == 1# 최적화 문제 정의 prob = cp.Problem(obj2, constraints=[const])# 문제 풀어라는 명령prob.solve()CVXPY로 직접 컨벡스최적화 해보자만약 목적함수가 DCP rule 만족하지 않는 경우다음과 같은 에러 메시지가 뜬다.# DCP rule 만족하지 않는 경우import cvxpy as cpa = cp.Variable()b = cp.Variable()# 목적함수 obj2 = cp.Minimize(a+b)# 제한조건 const = a**2+b**2 == 1# 최적화문제 정의 prob = cp.Problem(obj2, constraints=[const])prob.solve()위 경우에는우선 목적함수 obj2 는 $affine$ 이다. 컨벡스 최적화 가능하다.하지만, 제한조건 $const$ 를 반영한 최적화 문제가 DCP rule 에 어긋나기 때문에 에러가 발생한 것이다.즉, 제한조건 하에서 목적함수 최소화 문제 푸는 게 불가능하다는 말이다.라그랑주 승수법으로 제한조건 최적화 목적함수를 직접 구해보면, 가능한 $\\lambda$ 값이 두개가 나온다.$\\lambda = \\frac{\\sqrt(2)}{2}$ or $-\\frac{\\sqrt(2)}{2}$$\\Rightarrow$$h_{1} = x_{1}+x_{2} + \\frac{\\sqrt{2}}{2} (x_{1}^{2}+x_{2}^{2}-1)$$h_{2} = x_{1}+x_{2}-\\frac{\\sqrt{2}}{2} (x_{1}^{2}+x_{1}^{2}-1)$위 $h_{1}, h_{2}$ 가 가능한 두가지 목적함수다.각 목적함수를 시각화해보면 아래와 같다.$h_{1}$xx = np.linspace(-50,50,500)yy = np.linspace(-50,50,500)X,Y = np.meshgrid(xx,yy)def h1(x, y) : return x+y+(np.sqrt(2)/2)*(x**2+y**2-1)Z1 = h1(X,Y)def h2(x,y) : return x+y-(np.sqrt(2)/2)*(x**2+y**2-1)Z2 = h2(X,Y)ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z1, linewidth=0.03, cmap='flare_r')plt.title('1')plt.xlabel('x')plt.ylabel('y')plt.show()$h_{2}$ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z2, linewidth=0.03, cmap='terrain')plt.title('2')plt.xlabel('x')plt.ylabel('y')plt.show()$h_{2}$ 은 $h_{1}$ 를 반대로 엎어놓은 모양이다.여기서 핵심은,주어진 제한조건$x_{1}^{2}+x_{2}^{2} = 1$ 이 최적해에 미치는 영향을 반영해 목적함수를 라그랑주 승수법써서 변형하면서가능한 목적함수의 경우가 두 가지 나온다는 것이다.두 가지 경우 중 $h_{2}$ 는 concave 함수로, 최소화 연산이 불가능하다.사이파이 optimize.minimize 명령을 이용해도 마찬가지였다.def h1(x) : return x[0]+x[1]+(np.sqrt(2)/2)*(x[0]**2+x[1]**2-1)sp.optimize.minimize(h2, np.array([0,0]))그래서 DCP rule 위반이라고 에러 메시지가 발생한 것이었다.제한조건을 반영한 목적함수 $h_{1}$ 만 가지고 최소화 연산을 시도했다.$h_{1}$ 함수는 컨벡스 함수로, 최소화 연산이 가능할 것이었다.# 컨벡스 최적화 1import cvxpy as cpx = cp.Variable()y = cp.Variable()# 목적함수 h = cp.Minimize(x+y+(np.sqrt(2)/2)*(x**2+y**2-1))# 최적화 문제 정의prob = cp.Problem(h)prob.solve()x.value, y.value원하는 대로 최소화 연산 할 수 있었다.한편, $h_{2}$ 는 최대화 연산은 가능할 것이다.# 컨벡스 최적화 2import cvxpy as cpx = cp.Variable()y = cp.Variable()# 목적함수 h = cp.Maximize(x+y-(np.sqrt(2)/2)*(x**2+y**2-1))# 최적화 문제 정의prob = cp.Problem(h)prob.solve()x.value, y.value예상대로 최대화 할 수 있었다.그러면 이제, DCP rule 만족하는 경우에 대해, CVXPY 로 컨벡스최적화를 해보자. 심볼릭연산이다.예1 )# 컨벡스 최적화 테스트 2import cvxpy as cpx = cp.Variable()y = cp.Variable()f = (x-2)**2+2 # convax 함수인지, concave 함수인지 자동으로 인식한다. print(f.curvature) # 함수가 convex 인지, concave 인지, affine 인지, constant 인지 알려주는 명령# 목적함수 obj = cp.Minimize(f)print(obj.is_dcp())# 최적화 문제의 정의 prob = cp.Problem(obj)print(prob.is_dcp())print(prob.solve())print(x.value)결과 :CONVEXTrueTrue2.02.0단변수함수이면서 컨벡스 함수인 $(x-2)^{2}+2$ 를 CVXPY 로 최적화 했다.예2)# 컨벡스 최적화 테스트 3x = cp.Variable()y = cp.Variable()f = x**2+y**2print(f.curvature)obj = cp.Minimize(f)constraints = [x+y-1==0]prob = cp.Problem(obj, constraints=constraints)print(prob.is_dcp()) # 목적함수, 제약조건 종합 고려해서. 목적함수 최소화가 가능한가. print(prob.solve());print(x.value, y.value)결과 :CONVEXTrue0.50.52차원 다변수함수인 $x^{2}+y^{2}$ 를 CVXPY로 컨벡스최적화 했다.물론 함수는 컨벡스함수다.제한조건은 $x+y-1=0$ 등식제한조건을 줬다.예3)# 컨벡스 최적화 테스트 4x = cp.Variable()y = cp.Variable()obj = cp.Minimize(x**2+y**2)constraints = [ x+y-1 &lt;= 0]prob = cp.Problem(obj, constraints)print(prob.is_dcp())print(prob.solve(), x.value, y.value)결과 : True, 0, 0, 0같은 2차원 다변수함수에 대해 이번에는$x+y-1$ &lt;= $0$ 부등식제한조건을 줬다.예 4)# 컨벡스 최적화 테스트 6x = cp.Variable()y = cp.Variable()obj = cp.Minimize((x-4)**2+(y-2)**2)print(obj.is_dcp())constraints = [ x+y-1 &lt;= 0 , -x+y-1 &lt;= 0 , -x-y-1 &lt;= 0 , x-y-1 &lt;= 0 ]prob = cp.Problem(obj, constraints = constraints)print(prob.is_dcp())prob.solve(), x.value, y.valueTrue, True,(13.0, array(1.), array(-1.11022189e-22))이번 시도는 2차원 다변수함수 $(x-4)^{2}+(y-2)^{2}$ 를 가지고 최소화 문제를 풀었다.목적함수는 컨벡스 함수다.제한조건은 부등식제한조건 4개를 동시에 줬다.CVXOPTCVXPY 처럼, 컨벡스최적화 패키지다.LP 문제, QP 문제 등을 비롯해 다양한 컨벡스 최적화가 가능했다. ndarray 객체를 CVXOPT matrix 자료형으로 변환해서 넣어야 한다. 모든 스칼라 값은 부동 소숫점 실수 형태로 바꿔서 넣어야 한다.나는 이 패키지를 LP 문제와 QP 문제 해결을 위해 사용했다.LP 문제와 QP 문제는 뒤에서 다시 정리할 것이다.CVXOPT 로 LP문제 해결하기# cvxopt로 선형계획법 풀기 c = matrix(np.array([-3.0,-5.0]))A = matrix(np.array([[-1.0,0.0],[0.0,-1.0],[1.0,2.0],[4.0,5.0]]))b = matrix(np.array([-100.0, -100.0, 500.0, 9800.0]))np.array(solvers.lp(c, A, b)['x'])CVXOPT 로 QP문제 해결하기QP 문제의 목적함수 - 일반화된 이차형식 - 이 컨벡스함수인 경우만 최적화 할 수 있다. 일반화된 이차형식의 행렬 $Q$ 가 양의 준정부호 여야 한다. $Q$ 가 양의 준정부호가 아니면 넌 컨벡스 함수가 된다. 이 경우, solver.qp 명령으로 이차계획법 문제 못 푼다. 다른 방법 써야 한다.# 이차계획법 문제 from cvxopt import matrix, solversQ = matrix(np.array([[2.0,0.0],[0.0,2.0]]))c = matrix(np.array([0.0,0.0]))A = matrix(np.array([[1.0,1.0]]))b = matrix(np.array([1.0]))r = solvers.qp(Q,c,A=A,b=b)['x']np.array(r)array([[0.5], [0.5]])제한조건 있는 최적화 문제1. 등식 제한조건이 있는 최적화 문제최적해가 목적함수를 최소화 하면서도 $f_{i} = 0$ 꼴로 생긴연립방정식(또는 1개 방정식) 을 동시에 만족해야 하는 경우,‘등식 제한조건이 있는 최적화 문제’ 라고 한다.(등식 제한조건은 $f = 0$ 형태여야 한다. )등식 제한조건 있는 최적화 예)목적함수$f(x_{1}, x_{2}) = x_{1}^{2}+x_{2}^{2}$등식 제한조건$g(x_{1}, x_{2}) = x_{1}+x_{2}-1 = 0$동시에 만족하는 최적해 $x$ 를 찾아라.위 문제는 아래 그림에서 등고선과 붉은 직선이 만나는 벡터 $x$ 를 찾는 것과 같다.xx = np.linspace(-5,5,400)yy = np.linspace(-5,5,400)X, Y = np.meshgrid(xx,yy)def f(x,y) : return x**2+y**2Z = f(X,Y)def g(x) : return -x+1levels=np.flip([16, 4.8, 1.5, 0.5, 0.2])ax = plt.contour(X,Y,Z, levels=levels, colors='gray')plt.clabel(CS=ax)plt.axis('equal')plt.plot(xx, g(xx), 'r')plt.plot(0,0,'rP')plt.plot(0.5, 0.5, 'bo', ms=5)plt.title('목적함수 $x^{2}+y^{2}$를 등식 제한조건 $x_{1}+x_{2}-1=0$ 을 걸고 최적화 ')plt.xlim(-5,5)plt.ylim(-5, 5)plt.xlabel('$x$')plt.ylabel('$y$')plt.show()라그랑주 승수법제한조건이 있는 최적화 문제는 라그랑주 승수법을 이용해서 풀 수 있다.라그랑주 승수법에서는, 목적함수를 다음과 같이 변형한다.$h = f(x) + \\sum_{i}^{n}{\\lambda_{i}g_{i}(x)}$여기서 $g_{i}(x)$ 는 $i$ 번째 제한조건 (등식, 부등식) $\\lambda_{i}$ 는 $i$ 번째 제한조건의 라그랑주 승수 $f(x)$ 는 본래 목적함수 이다.그리고 이처럼 변형된 목적함수 $h$ 를 사용해서 최적화 한다.내가 찾는 최적해는 $h$ 의 그레디언트 벡터 $= 0$영벡터 만드는 $x_{1}, x_{2}, …x_{n}$ 값들이다. 라그랑주 승수는 고려하지 않는다.라그랑주 승수의 의미라그랑주 승수 $\\lambda_{i}$ 는 ‘각 제한조건이 최적해에 미치는 영향의 크기’를 타나낸다. 만약 제한조건이 최적해에 아무 영향도 미치지 못하면, 그 제한조건의 라그랑주 승수 $\\lambda_{i}$ 는 $0$ 이다.위에서 풀었던 등식 제한조건 있는 최적화 문제를라그랑주 승수법으로 풀어보자. 목적함수 : $f(x_{1}, x_{2}) = x_{1}^{2}+x_{2}^{2}$ 등식 제한조건 : $g(x_{1}, x_{2}) = x_{1}+x_{2}-1 = 0$ 였다.목적함수 $f$ 를 라그랑주 승수 이용해서 $h$ 로 바꾸자.$h = x_{1}^{2}+x_{2}^{2} + \\lambda(x_{1}+x_{2}-1)$이 목적함수 $h$의 그레디언트 벡터는$\\nabla{h} = [2x_{1}+\\lambda, 2x_{2}+\\lambda, x_{1}+x_{2}-1]^{T}$ 이다.그레디언트 벡터 각 요소가 $0$ 되게 하는 $\\lambda$ , $x_{1}$, $x_{2}$ 를 찾자.$\\lambda = -1, x_{1}=x_{2} = \\frac{1}{2}$이다. 따라서 붉은 직선 위 점이면서, 동시에 등고선 플롯 $z$ 값을 최소화 하는 최적해는 $[\\frac{1}{2}, \\frac{1}{2}]^{T}$ 다.사이파이로 등식 제한조건 최적화 하기사이파이의 fmin_slsqp() 명령을 사용하면최소자승법 알고리듬을 사용해서 등식 제한조건이 있는 최적화 문제를 해결할 수 있다.sp.optimize.fmin_slsqp(f_name, x_{0}, eqcons=[constraint1, constraint2,...]) f_name : 최소화 할 함수 이름 x_{0} : 최적화 시작점 (적당한 값 넣으면 된다) eqcons : 제한조건 함수 이름. 리스트 자료형 안에 넣어야 한다.fmin_slsqp() 사용 예 )# 위에서 라그랑주 승수법으로 풀었던 문제def f(x) : return x[0]**2+x[1]**2def g(x) : return x[0]+x[1]-1sp.optimize.fmin_slsqp(f, (1,2), eqcons=[g])부등식 제한조건 최적화 문제부등식도 최적화 제한조건으로 걸 수 있다.이 경우는 주어진 부등식을 만족하면서, 주어진 목적함수를 최소화 하는 최적해를 찾는 것이다.연립부등식이 최적화 제한조건으로 제시된다.$g_{j} \\leq 0, (j = 1, 2, …M)$(부등호 방향은 $g \\leq 0$ 이어야 한다. )부등식 제한조건 최적화 문제도 라그랑주 승수법으로 풀면 된다.$h = f(x) + \\sum_{1}^{n}{\\lambda_{i}g_{i}(x)}$등식 제한조건일 때랑 똑같이 변형된 목적함수 $h$ 를 만들면 된다.한편, 등식 제한조건 최적화 문제의 최적화 필요조건은 ‘기울기 필요조건’ 이었다.부등식 제한조건 최적화 문제의 최적화 필요조건은 ‘KKT 조건’ 이다.최적해가 만족해야 하는 KKT 조건은 다음과 같다.1. $\\frac{\\partial{h}}{\\partial{x_{i}}} = 0$목적함수 $h$ 를 $x_{i}$ 로 미분한 값은 모두 0 이어야 한다.2. $\\lambda_{i} * g_{i}(x) = 0$$\\lambda_{i}$ 또는 $g_{i}(x)$ 둘 중 하나는 반드시 0 이어야 한다.(둘 다 0 일수도 있다)3. $\\lambda_{i} \\ge 0$모든 라그랑주 승수는 0 이상이어야 한다.위 3 가지 조건 중 2번 조건만 먼저 만족시키면, 1. 3 번 조건은 자연스럽게 만족된다.이 2번 조건에 의해 부등식 제한조건은 결국 등식 제한조건 문제 푸는 것과 같아진다.case 1$\\lambda_{i} = 0$ 인 경우$i$ 번째 부등식 제한조건이 최적해에 아무런 영향도 못 미친다는 의미다.$\\lambda_{i} = 0$ 이기 때문에, 목적함수 $h$ 에서 $i$ 번째 부등식 제한조건은 사라진다. ‘쓸모가 없다’.case 2$g_{i}(x) = 0$ 인 경우$g_{i}(x) = 0$ 은 ‘등식 제한조건’ 이었다.따라서 등식 제한조건의 $\\lambda_{i}$ 도 0 되는 아주 특수한 경우를 제외하고는제한조건 $g_{i}(x)$ 는 등식 제한조건과 같아진다.따라서 목적함수 $h$ 를 가지고 등식 제한조건 최적화 문제를 풀면(기울기 필요조건 만족) 최적해를 구할 수 있다.$\\Rightarrow$ 결국 부등식 제한조건 최적화 문제는등식 제한조건 최적화 문제 푸는 것과 같다.부등식 제한조건 최적화 문제) 라그랑주 승수법으로 목적함수 변형 (KKT 조건에 의해) 각 제한조건 없애거나. 등식으로 바꾼다. 기울기 필요조건으로 최적화 문제 푼다.$\\Rightarrow$ 제한조건 최적화 문제는 결국 모두 라그랑주 승수법, 기울기 필요조건으로 푼다.부등식 제한조건 최적화 문제를 그림으로 그리면 다음과 같다.다음은 목적함수가 $x^{2}+y^{2}$ 이고,부등식 제한조건이 각각$g_{1}(x_{1}, x_{2}) = x_{1}+x_{2}-1 \\leq 0$$g_{2}(x_{1}, x_{2}) = -x_{1}-x_{2}+1 \\leq 0$인 경우다. 따로따로 하나씩 적용했다.부등식 제한조건이 $g_{1}$ 인 경우def f(x, y) : return x**2+y**2xx = np.linspace(-5,5,500)yy = np.linspace(-5,5,600)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)plt.contour(X,Y,Z, levels=[0.5, 2,8], colors='k')plt.axis('equal')plt.ylim(-3,3)plt.xlim(-5,5)def con1(x) : return -x+1plt.plot(xx, con1(xx), c='r')plt.fill_between(xx, -20, con1(xx), alpha=0.2)plt.plot(0,0,'ro', markersize=10)plt.text(-0.3, -0.5, '최적해')plt.title('부등식 제한조건이 최적해 에 영향 미치지 못하는 경우')plt.xlabel('$x$')plt.ylabel('$y$')plt.show()그림을 보면 이 부등식 제한조건(붉은 직선 아래 푸른색 영역) 은 최적해에 전혀 영향을 못 미치고 있다(쓸모없다).라그랑주 승수의 의미는 ‘제한조건이 최적해에 미치는 영향의 크기’ 였다.이 제한조건이 최적해에 전혀 영향 못 미치기 때문에, 라그랑주 승수 $\\lambda_{1} = 0$일 것이다.부등식 제한조건이 $g_{2} 인 경우$def f(x, y) : return x**2+y**2xx = np.linspace(-5,5,500)yy = np.linspace(-5,5,600)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)CS = plt.contour(X,Y,Z, levels=[0.5, 2,8], colors='k')plt.clabel(CS)plt.axis('equal')plt.ylim(-3,3)plt.xlim(-5,5)def con2(x) : return -x+1plt.plot(xx, con2(xx), 'r')plt.fill_between(xx, 20, con2(xx), alpha=0.3)plt.plot(0.5, 0.5, 'ro', markersize=5)plt.suptitle('부등식 제한조건이 최적해에 영향 미치는 경우', y = 1.0003)plt.title('원래 최적해 : $[0,0]$, 바뀐 최적해 : $[0.5, 0.5]$')plt.plot(0,0, 'bP')plt.xlabel('$x$')plt.ylabel('$y$')plt.show()이 경우에는 부등식 제한조건이 최적해에 영향을 미치고 있다.붉은 직선과 푸른색 영역이 부등식 제한조건이다.부등식 제한조건 때문에 원래 $[0,0]$ 이었던 최적해가 $[0.5, 0.5]$ 로 바뀌었다.이 경우에는 제한조건이 최적해에 영향을 미쳤기 때문에, $\\lambda_{2} \\ne 0$ 일 것이라 추측해볼 수 있다.한편, 위 그림을 잘 보면 제한조건을 만족하는 최적해는 결국 붉은 직선 위의 점이다.곧, 새로운 최적해는 부등식 제한조건 영역의 경계선에 걸린다는 말이다.푸른색 영역이 뒤로 조금 후퇴해도, 제한조건을 걸면서 변화한 최적해(붉은 점)는 결국 푸른색 영역의 경계선인 붉은 선 위의 값이 될 것이다.그러면 결국 원래 목적함수를 최소화 시키는 붉은 직선 위의 점 찾는 문제(= 등식 제한조건 문제) 가 된다.따라서 그림으로도 부등식 제한조건이 결국 쓸모없거나, 등식 제한조건이 된다 는 사실을 확인할 수 있었다.다음은 목적함수가 $(x_{1}-4)^{2} + (x_{2}-2)^{2}$ 이고, 부등식 제한조건이 $\\sum_{i}^{2}\\lvert x_{i} \\rvert-1 \\leq 0$ 인 최적화 문제를 그림으로 표현한 예다.def f(x, y) : return np.sqrt((x-4)**2+(y-2)**2 )xx = np.linspace(-2,5,500)yy = np.linspace(-1.5,3,600)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)CS = plt.contour(X,Y,Z, colors='k', levels=np.arange(0.5, 5, 0.5)*np.sqrt(2))x2 = np.linspace(-1,0,100)x3 = np.linspace(0,1,100)plt.fill_between(x2, x2+1, -x2-1, alpha=0.2, color='m')plt.fill_between(x3, -x3+1, x3-1, alpha=0.2, color='m')plt.plot(1,0,'ro', markersize=10)plt.xlabel('$x_{1}$')plt.ylabel('$x_{2}$')plt.title('부등식 제한조건 최적화 문제')plt.plot(np.linspace(-1,2),np.linspace(-1,2)-1, 'r', alpha=0.2)plt.plot(np.linspace(-1,2),-np.linspace(-1,2)+1, 'r', alpha=0.2)plt.show()원래 $[2,4]$ 였던 최적해가 부등식 제한조건 때문에 변해서 붉은 점 $[1,0]$이 됬다.붉은 점은 위 그림에서 교차하는 두 붉은 직선 상에 동시에 위치한 점이다.즉, 붉은 점은 붉은 두 개 직선이 속한 두 개의 부등식 제한조건 영역 경계에 위치해 있다.$\\Rightarrow$ 두 직선을 포함하는 두 개 부등식 제한조건 영역들은 모두 등식 제한조건으로 바뀔 것이다.나머지 두 개 부등식 제한조건은 붉은 점에 전혀 영향 못 미치고 있다.따라서 보라색 마름모의 나머지 두 변을 포함하는 왼쪽 두 개 제한조건들은 할당된 라그랑주 승수 $\\lambda_{i}$ 값이 $0$ 일 것이다(쓸모없음).사이파이로 부등식 제한조건 있는 함수 최적화 하기등식 제한조건 최적화 할 때 사용했던 fmin_slsqp 명령을 다시 쓸 수 있다.fmin_slsqp 명령은 ieqcons= 라는 argument 로 부등식 제한조건 함수를 받는다.sp.optimize.fmin_slsqp(함수이름, 최적화시작점, ieqcons=[부등식제한조건 함수이름])*부등식 제한조건을 ieqcons argument 에 넣을 때는 부등호 방향을 $\\ge$ 이 되게 해서 넣어야 한다.위 예제를 사이파이로 최적화 해보자.def f(x) : return np.sqrt((x[0]-4)**2+(x[1]-2)**2)def ieqcons(x) : return -np.sum(np.abs(x))+1sp.optimize.fmin_slsqp(f, np.array([0,0]), ieqcons=[ieqcons])데이터사이언스 스쿨 5.2.3 연습문제 )위 예제 문제에서 제한조건을 다음과 같이 바꾼다.$g(x) = \\lvert x_{1} \\rvert$ + $\\lvert x_{1} \\rvert - k = \\sum_{i}^{2}{\\lvert x_{i}\\rvert}-k \\leq 0$$k$ 를 0.1 부터 10까지 변화시키면서, 최적화 해가 어떻게 바뀌는지 살펴봐라.나의 답 )# 5.2.4 연습문제 def f(x, y) : return np.sqrt((x-4)**2+(y-2)**2 )xx = np.linspace(-2,5,500)yy = np.linspace(-1.5,3,600)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)plt.contour(X,Y,Z, colors='k', levels=np.arange(0.5, 5, 0.5)*np.sqrt(2))c = 0colors=['r', 'g', 'b', 'c', 'm', 'k', 'y']for k in np.linspace(0.1, 10, 7) : x1 = np.linspace(-k, 0) x2 = np.linspace(0, k) plt.fill_between(x1, x1+k, -x1-k, alpha=0.1, color=colors[c]) plt.fill_between(x2, -x2+k, x2-k, alpha=0.1, color=colors[c]) c+=1plt.xlim(-2,5)plt.ylim(-1.5, 3)plt.suptitle('$k$ 가 변하면서, 최적화 해에 영향 미치는 부등식 제한조건도 변한다', y=1.0004)plt.title('$k$가 일정 정도 이상 커지면 모든 부등식 제한조건이 최적화 해에 영향 못 미친다')plt.show()겹쳐진 여러 마름모가 변화된 $k$ 를 입력받은 부등식 제한조건 영역이다.원래 최적해는 $[4,2]$ 였다.보면 $k$ 가 일정 정도 이상 커지면, 4개 부등식 제한조건 모두 최적화 해에 영향 못 미친다는 사실을 관찰할 수 있었다.(부등식 제한조건 영역이 최적해 $[4,2]$ 를 포함해 버린다)더 자세히 보면index = 0def f(x, y) : return np.sqrt((x-4)**2+(y-2)**2 )colors=['r', 'g', 'b', 'c', 'm', 'k', 'y']k = np.linspace(0.1, 10, 7) xx = np.linspace(-2,5,500)yy = np.linspace(-1.5,3,600)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)plt.contour(X,Y,Z, colors='k', levels=np.arange(0.5, 5, 0.5)*np.sqrt(2))plt.xlim(-2,5)plt.ylim(-1.5, 3)x1 = np.linspace(-k[index], 0)x2 = np.linspace(0, k[index])plt.fill_between(x1, x1+k[index], -x1-k[index], alpha=0.1, color=colors[index])plt.fill_between(x2, -x2+k[index], x2-k[index], alpha=0.1, color=colors[index])plt.title(f'$k = {k[index]}$ 인 경우')plt.plot(0.1, 0, 'ro',markersize=2)plt.show()이런식으로 변화한다. $k$ 가 커질 수록 부등식 제한조건 영역이 원래 최적해 $[4,2]$ 가까이 간다는 사실을 관찰할 수 있었다.또$k = 6.7$ 일 때는 본래 최적해가 부등식 제한조건 영역 안에 완전히 포함되었다. 곧, 부등식 제한조건이 더 이상 최적해에 영향 미치지 못했다 $\\lambda_{i} = 0$한편부등식 제한조건을 감안한 최적해를 $[x_{1}, x_{2}]$ 라고 보고, $k$값이 변화할 때(부등식 제한조건이 변할 때) 이 벡터의 $x$ 좌표와 $y$ 좌표 값이 어떻게 변해가는지도 그래프로 나타내 봤다.def ieq_constraint(x) : return -np.sum(np.abs(x))+kdef f(x) : return np.sqrt((x[0]-4)**2+(x[1]-2)**2)x1 = []x2 = []for k in np.linspace(0.1, 10, 100) : result = sp.optimize.fmin_slsqp(f, np.array([1,1]), ieqcons=[ieq_constraint], iprint=0) x1.append(result[0]) x2.append(result[1])plt.plot(np.linspace(0.1,10,100), x1, label='$x_{1}$의 최적해')plt.plot(np.linspace(0.1,10,100), x2, ls=':', c='g', label='$x_{2}$의 최적해')plt.legend()plt.xlabel('$k$')plt.ylabel('$x_{i}$')plt.title('$k$값 변화에 따른 $x_{1}, x_{2}$ 최적해 변화')plt.show()보면 $k$ 값이 커지면서 $x_{1}$, $x_{2}$ 값도 함께 커져감을 관찰할 수 있다.그리고 $k = 6$ 에 도달했을 때 부터는 $x_{1}, x_{2}$ 도 더 이상 변화하지 않았다.곧, $k \\ge 6$ 에서 $k$ 값 변화가 최적해 $[x_{1}, x_{2}]$ 에 더 이상 영향 미치지 못했다." }, { "title": "[수학/최적화] 최적화 개념, 그리드서치 방법, 수치적 최적화 방법", "url": "/bioinfo.github.io/posts/optimization_theory/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-09-06 00:00:00 +0900", "snippet": "최적화정의 :함수 출력을 최대 또는 최소로 만드는 ‘최적 입력 찾기’ 보통, 최적화 문제 = 최소화 문제 다.최대화 하고 싶은 어떤 함수 $f(x)$ 를 뒤집어서 $-f(x)$ 에 대해 최소화 문제를 풀면 결국 $f(x)$ 의 최대화 문제를 푼 것과 같다.$\\Rightarrow$ $-f(x)$ 의 최소해는 함수 $f(x)$ 의 최대해와 같다.최적화 목적함수정의 :최적화 대상이 되는 함수를 ‘목적함수’ 라고 한다.예) 성능함수, 손실함수, 오차함수, 등최적화 방법 - 그리드 서치 방법정의 :최적값이 있음직한 일정 구간을 함수에 직접 넣어보는 방법. 직접 넣어보고 함수 출력이 최소화되는 입력값을 찾는다.특징 :노가다. 비효율적이다.특히 입력값이 많아지면 일일이 입력값-출력값 쌍을 계산해야 된다.예 :1차원 목적함수 최적화(최소화)def f(x) : return (x-2)**2+2xx = np.linspace(-1, 4, 1000)plt.plot(xx, f(xx))plt.plot(xx[np.argmin(f(xx))], f(xx)[np.argmin(f(xx))], 'ro', markersize=10)plt.ylim(0, 10)plt.xlabel('$x$')plt.title('1차원 목적함수, 최적해 : $x=2$, 최저출력 : $y=2$')plt.show()위 그래프는그리드 서치 방법으로 1차원 함수 최적화 하는 과정을 시각화 한 것이다.$-1$, $4$ 사이 구간에서, $1000$ 개 입력값을 함수 $(x-2)^{2}+2$ 에 일일이 넣었다.그리고 $1000$ 개 입력에 대응되는 $1000$ 개 출력값을 하나하나 찾았다.그래프는 찾은 $1000$ 개 출력값들을 2차원 벡터공간 상에 일일이 점으로 찍은 것 뿐이다.$-1, 4$ 사이 구간 입력 $1000$ 개를 넣어 본 결과, $x=2$ 에서 가장 출력값이 작았다.따라서 함수 출력을 최소화 하는 최적 입력값은 $x=2$ 이다.최적화 방법 - 수치적 최적화 방법정의 :최소 시도 횟수로 최적화를 성공시키고자 하는 게 목표인 최적화 방법.수치적 최적화 알고리듬 : 현재 위치가 최적점(최소점) 인지 판단하는 알고리듬 현재 위치가 최적점이 아닐 때, 옮겨 갈 다음 위치를 선정하는 알고리듬기울기 필요조건 (최적화 필요조건)정의 :최적해에서, 1차 도함숫값(기울기)은 0이다. 최소해. 최대해 모두 1차 도함숫값이 0 나와야 한다. 2차 도함숫값이 양수면 확실한 최소점 2차 도함숫값이 음수면 확실한 최대점이다.현재 위치가 최적점인지 판단하는 알고리듬 이다.최대경사법(최급강하법)현재 위치가 최적점이 아닐 때, 옮겨 갈 다음 위치를 선정하는 알고리듬이다.정의 :기울기가 가장 크게 감소하는 방향으로 이동하는 수치적 최적화 알고리듬.$x_{n+1} = x_{n} - \\mu\\nabla{f(x_{n})}$ $\\mu$ 는 ‘스텝사이즈’라고 한다. 위치 얼만큼 이동할 건지 거리를 결정짓는다.단변수 함수 $-\\mu$ $\\times$ $\\nabla{f(x_{n})}$ 만큼 $x$ 축 따라 계속 이동하다가, $x_{n+1} = x_{n}$ 이 되면(기울기가 $0$ 되면) 이동 멈춘다.다변수 함수 각 점의 그레디언트 벡터 반대방향으로 $- \\mu\\nabla{f(x_{n})}$ 벡터의 길이만큼 이동한다. 다음 위치는 $- \\mu\\nabla{f(x_{n})}$ 벡터가 가리키는 지점이다.참고)다변수 함수에서점의 이동 거리가 $- \\mu\\nabla{f(x_{n})}$ 벡터 길이인 이유는$x_{n+1} - x_{n} = - \\mu\\nabla{f(x_{n})}$때문이다.단변수 함수 최대경사법 알고리듬으로 최적화 하기def f(x) : return (x-2)**2+2def fprime(x) : return 2*x-4xx = np.linspace(-1,4,100)plt.plot(xx, f(xx)) # 함수 f# 최적화 해보자. x=0에서 시작, 스텝사이즈 mu = 0.4 mu = 0.4def next_step(x, mu) : x_1 = x-mu*fprime(x) return (x_1, f(x_1))plt.plot(k, f(k), 'go', markersize=10)plt.plot(xx, fprime(k)*(xx-k)+f(k), 'b--')plt.text(k, f(k)+0.7, '1차 시도')next_ = next_step(0, mu)plt.plot(next_[0], next_[1], 'go', markersize=10)plt.plot(xx, fprime(next_[0])*(xx-next_[0])+f(next_[0]), 'b--')plt.text(next_[0], next_[1]+0.6, '2차 시도')next_ = next_step(next_[0], mu)plt.plot(next_[0], next_[1], 'go', markersize=10)plt.plot(xx, fprime(next_[0])*(xx-next_[0])+f(next_[0]), 'r--')plt.text(next_[0], next_[1]-1.4, '3차 시도')plt.title('최급강하법을 이용한 1차함수 최적화')plt.xlabel('$x$')plt.ylabel('$f(x)$')plt.ylim(0, 10)plt.show()다변수 2차원 함수 최대경사법 알고리듬으로 최적화 하기def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(-4, 4, 600)yy = np.linspace(-3, 3, 400)X,Y = np.meshgrid(xx, yy)Z = rosenbrook(X,Y)plt.contourf(X,Y,Z, levels=np.logspace(-1,3,10), alpha=0.3)plt.contour(X,Y,Z, colors='green', levels=np.logspace(-1,3,10))a = -1b = -1mu = 8e-4def next_level(a,b) : return np.array([a,b]) - mu*gradient(a,b)vec_list = []for i in range(3000) : vec_list.append((a,b)) result = next_level(a,b) a = result[0] ; b = result[1]for a, b in vec_list : plt.arrow(a,b, -mu*0.95*gradient(a,b)[0], -mu*0.95*gradient(a,b)[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw=2) plt.plot(a,b, 'ro', markersize=3)plt.xlim(-3,3)plt.ylim(-2,2)plt.xticks(np.linspace(-3,3,7))plt.yticks(np.linspace(-2,2,5))plt.xlabel('$x$')plt.ylabel('$y$')plt.suptitle('2차원 로젠브록함수 최급강하법으로 최적화 과정', y=1.03)plt.title('그레디언트 벡터 반대방향 따라서 최적점 찾아가는 중')plt.annotate('',xy=[1,1], xytext=[1.3,1.3], arrowprops={'facecolor':'black'})plt.text(1.2, 1, '최적점')plt.plot(1,1, 'ro', markersize=10)plt.show() 최적화 알고리듬 테스트에 많이 사용되는. 2차원 로젠브록함수를 최대경사법 알고리듬으로 최적화 했다. 위 경우는 $[-1,-1]$ 에서 최적화를 시작한 경우다. 스텝사이즈 $8e-4$ 에서 그레디언트 벡터 반대방향을 따라 서서히 최적점에 수렴해가고 있는 모습을 볼 수 있었다. 최대경사법 단점 1 : 스텝사이즈가 최적화를 방해한다스텝사이즈 크기가 최적화에 방해될 수 있다.스텝사이즈 크기가 너무 크면 최적해에 제대로 수렴 안 할 수 있다.예) 스텝사이즈 : 1.4 (너무 큰 스텝사이즈)mu = 1.4 # 너무 큰 스텝사이즈 def f(x) : return (x-2)**2+2def fprime(x) : return 2*x-4xx = np.linspace(-8,10,100)plt.plot(xx, f(xx))plt.plot(0, f(0), 'go', markersize=10)plt.text(0, f(0)+0.9, '1차 시도')plt.plot(xx, fprime(0)*(xx-0)+f(0), ls='--', c='b')print(f'1차 시도, x값 : {0}, 기울기 값 : {fprime(0)}')next_ = next_step(0, mu)plt.plot(next_[0], next_[1], 'ro', markersize=10)plt.text(next_[0]-0.5, next_[1]+5, '2차 시도')plt.plot(xx, fprime(next_[0])*(xx-next_[0])+f(next_[0]), ls='--', c='b')print(f'2차 시도, x값 : {np.round(next_[0],2)}, 기울기 값 : {np.round(fprime(next_[0]),2)}')next_ = next_step(next_[0], mu)plt.plot(next_[0], next_[1], 'bo', markersize=10)plt.text(next_[0], next_[1], '3차 시도')plt.plot(xx, fprime(next_[0])*(xx-next_[0])+f(next_[0]), ls='--')print(f'3차 시도, x값 : {np.round(next_[0],2)}, 기울기 값 : {np.round(fprime(next_[0]),2)}')plt.xlim(-8, 10)plt.ylim(-100,100)plt.suptitle('최급강하법을 이용한 1차 함수 최적화', y=1.01)plt.title('스텝사이즈 $\\mu$가 너무 커서(1.4) 오히려 최소점에서 멀어진 경우')plt.show()결과물을 보면, 스텝사이즈가 너무 커서 오히려 최저점에서 멀어진 것을 볼 수 있다.곧, 스텝사이즈가 너무 크면 최적화에 방해가 된다.한편,스텝사이즈가 너무 작으면 최적점에 너무 느리게 수렴한다.또한 최적점에 제대로 수렴 안 할 수도 있다.아래 예는 스텝사이즈가 $1.8e-4$ 로, 너무 작은 예다.def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(0, 3, 500)yy = np.linspace(0, 3, 500)X,Y = np.meshgrid(xx, yy)Z = rosenbrook(X,Y)plt.contourf(X,Y,Z, alpha=0.3, levels=np.logspace(-1,4,20))plt.contour(X,Y,Z, colors='green',levels=np.logspace(-1,4,20), alpha=0.2) # 로젠브록함수 계곡에 해당하는 지역 mu = 1.8e-4 # 스텝사이즈 a = 1.5b = 1.5for i in range(3000) : plt.plot(a,b, 'ro', markersize=5) plt.arrow(a, b, -0.95*mu*gradient(a, b)[0], -0.95*mu*gradient(a, b)[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw = 2) next_step = np.array([a,b]) - mu*gradient(a,b) a = next_step[0] b = next_step[1]plt.plot(1,1, 'bo', markersize=5)plt.plot(a,b, 'ro', markersize=5)plt.title('스텝사이즈가 너무 작아서 조금씩 이동하는 예')plt.xlim(0,3)plt.ylim(0,2)plt.xticks(np.linspace(0,3,4))plt.yticks(np.linspace(0,2,3))plt.xlabel('$x$')plt.ylabel('$y$')plt.show()어느 세월에 파란 점(최소점)까지 도달하겠나 싶다.한편 스텝사이즈가 위 경우보다 더 작으면, 3000번이나 이동했음에도 제대로 수렴 안 하는 경우도 있었다.스텝사이즈 : $1.8e-6$ 인 경우이동 횟수 : $3,000$ 번결론따라서, 최대경사법 알고리듬에서는 적절한 크기의 스텝사이즈 설정이 매우 중요하다.스텝사이즈 크기가 적절하지 못하면 오히려 최적화에 방해됬다.최대경사법 단점 2 : 시작점 위치에 따라 최적화 결과가 크게 달라진다.최대경사법 알고리듬은 최적화 시작점 위치에 따라 완전히 다른 최적화 결과를 가져올 수 있다.때때로 이게 최적화 과정에서 비효율을 초래한다.위 로젠브록 함수를 다시 보자.로젠브록함수는 $[1,1]$ 에서 최소점을 갖는다.이 함수를 3차원 지형이라고 생각하면, 검은색 부분은 움푹 파인 골짜기에 해당한다.그리고 최소점이 있는 $(0,2)$ 부터 $(2,0)$ 영역은 깊은 계곡과 같은 모양을 띄고 있다.앞에서 로젠브록함수 최적화 할 때는 $[-1,-1]$ 에서 최적화를 시작했다.계곡이 아닌 다른 어떤 지점에서 최적화 시작했다는 말이다.그렇다면 최적화 시작점을 옮겨서, 최적점 근처 ‘계곡’에서 최적화를 시작하면 어떨까?def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(0, 3, 500)yy = np.linspace(0, 3, 500)X,Y = np.meshgrid(xx, yy)Z = rosenbrook(X,Y)plt.contourf(X,Y,Z, alpha=0.3, levels=np.logspace(-1,4,20))plt.contour(X,Y,Z, colors='green',levels=np.logspace(-1,4,20), alpha=0.2) # 로젠브록함수 계곡에 해당하는 지역 plt.plot(1,1, 'bo', markersize=5)plt.xlim(0,3)plt.ylim(0,2)plt.xticks(np.linspace(0,3,4))plt.yticks(np.linspace(0,2,3))plt.xlabel('$x$')plt.ylabel('$y$')plt.show()바로 여기 이 지역 말이다.진동현상 발생계곡의 $[1.5, 1.5]$ 점에서 최적화를 시작해봤다.def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(0, 3, 500)yy = np.linspace(0, 3, 500)X,Y = np.meshgrid(xx, yy)Z = rosenbrook(X,Y)plt.contourf(X,Y,Z, alpha=0.3, levels=np.logspace(-1,4,20))plt.contour(X,Y,Z, colors='green',levels=np.logspace(-1,4,20), alpha=0.2) # 로젠브록함수 계곡에 해당하는 지역 mu = 1.8e-3 # 스텝사이즈 a = 1.5b = 1.5for i in range(10) : plt.plot(a,b, 'ro', markersize=5) plt.arrow(a, b, -0.95*mu*gradient(a, b)[0], -0.95*mu*gradient(a, b)[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw = 2) next_step = np.array([a,b]) - mu*gradient(a,b) a = next_step[0] b = next_step[1]plt.plot(1,1, 'bo', markersize=5)plt.plot(a,b, 'ro', markersize=5)plt.suptitle('최대경사법 이용한 2차원 함수 최적화 - 진동현상 발생하는 예', y=1.02)plt.title('(1.5, 1.5) 에서 최적화 시작, 각 점 그레디언트벡터 반대방향으로 진동하듯 내려간다')plt.xlim(0,3)plt.ylim(0,2)plt.xticks(np.linspace(0,3,4))plt.yticks(np.linspace(0,2,3))plt.xlabel('$x$')plt.ylabel('$y$')plt.show()스텝사이즈 $1.8e-3$ 에서, $[1.5, 1.5]$ 에서 시작한 점이 그레디언트벡터 반대방향(기울기 가장 크게 감소하는 방향) 따라 좌우로 진동하듯 이동했다.이런 현상을 ‘진동현상’ 이라고 한다.보다시피, 진동현상이 발생하면 최적화 시간이 오래 걸리고, 최적화 효율성이 떨어지는 문제 발생한다.진동현상 말고도최대경사법에서, 최적화 시작점이 어디냐는 진동현상 말고도 완전히 다른 최적화 결과를 내놓을 수 있다.아래는 앞에 기록했던 $[-1,-1]$ 에서 최적화를 시작한 예다.$[-1,-1]$ 에서 시작하면 위에 결과처럼 최적점을 찾아간다.반면다른 스텝 사이즈, 다른 시작 위치로 최적화 했을 때,전혀 다른 최적화 결과를 관찰할 수 있었다.def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(-3,3,400)yy = np.linspace(0,3.5,500)X, Y = np.meshgrid(xx,yy)Z = rosenbrook(X,Y)levels=np.logspace(-1, 4, 10)plt.contourf(X,Y,Z, levels=levels, alpha=0.3)plt.contour(X,Y,Z, levels=levels, colors='g', alpha=0.2)mu = 1.8e-3a = 2b = 2for i in range(1000) : plt.plot(a, b, 'ro', markersize=5) n = np.array([a,b]) - mu*gradient(a,b) n_ = -mu*gradient(a,b) plt.arrow(a,b, 0.95*n_[0], 0.95*n_[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw=2) a = n[0] b = n[1]plt.suptitle('로젠브록함수 최대경사법 최적화(최소화문제)', y=1.03)plt.title('최적화 시작 위치 : $[2,2]$, 스텝사이즈 : 1.8e-3')plt.show()이처럼 최대경사법 알고리듬은스텝사이즈가 얼마냐최적화 시작 위치가 어디냐에 따라서최적화 결과가 완전히 달리질 수 있다.또 최적화 과정에서 큰 비효율이 초래되는 경우도 왕왕 발생했다.뉴턴방법정의 :스텝사이즈 $\\mu$ 대신 헤시안행렬의 역행렬을 사용하는,개선된 최대경사법.$x_{n+1} = x_{n}-H[f(x_{n})]^{-1}\\nabla{f_{x_{n}}}$ 헤시안행렬의 역행렬은 최적 스텝사이즈다. $x_{n+1}-x_{n} = -H[f(x_{n})]^{-1}\\nabla{f_{x_{n}}}$ 특징 :함수가 2차함수에 가까울 수록, 최적점에 빨리 수렴한다.장점 :$\\mu$ 사용하는 최대경사법 대비 수렴 속도가 빠르고 효율적이다.단점 : 2차도함수 행렬.헤시안행렬을 사람이 직접 구해야 하기 때문에 번거롭고 계산이 많다(귀찮다). 함수 형상이 2차함수와 비슷하지 않은 경우, 최적화가 잘 안 될 수 있다.뉴턴방법 예시)위에서 최대경사법으로 최적화 했던 로젠브록함수를 뉴턴방법 최적화 하고, 시각화했다.def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(0, 3, 500)yy = np.linspace(0, 3, 500)X,Y = np.meshgrid(xx, yy)Z = rosenbrook(X,Y)plt.contourf(X,Y,Z, alpha=0.3, levels=np.logspace(-1,4,20))plt.contour(X,Y,Z, colors='green',levels=np.logspace(-1,4,20), alpha=0.2) # 로젠브록함수 계곡에 해당하는 지역 def next_step(x,y) : return np.array([x,y]) - H_INV(x,y)@gradient(x,y)facecolor = ['black', 'green', 'blue', 'red']a = 1.5b = 1.5for i in range(4) : if i == 0 : plt.plot(a,b, 'bo', markersize=5) elif i == 3 : plt.plot(a,b,'go', markersize=5) else : plt.plot(a,b, 'ro', markersize=5) n = next_step(a,b) adjusted_gradient = H_INV(a,b)@gradient(a,b)# 최적스텝사이즈 * 그레디언트벡터 = 변형된 그레디언트벡터 if i == 3 : pass else : plt.arrow(a, b, -0.95*adjusted_gradient[0], -0.95*adjusted_gradient[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw=2) a = n[0] b = n[1]plt.suptitle('뉴턴방법 : 함수형상이 2차함수에 가까울 수록 더 빨리 수렴한다', y=1.02)plt.title('진동현상 없이 단 4번만에 최적점에 수렴')plt.text(0.8, 1.08, '최적해')plt.annotate('', xy=[1.6, 1.8], xytext=[1.8,1.8], arrowprops={'facecolor':'blue'})plt.text(1.6, 1.6, '방향. 길이 조정된 그레디언트벡터(H*g)')plt.xlim(0, 3)plt.ylim(0,3)plt.show()def H(x,y) : np.array([ [1200*x**2-400*y+2, -400*x], [-400*x, 200]])r = 80000*x**2-80000*y+400result = (1/r)*np.array([[200, 400*x],[400*x, 1200*x**2-400*y+2]])def H_INV(x,y) : return (1/(80000*x**2-80000*y+400))*np.array([[200, 400*x],[400*x, 1200*x**2-400*y+2]])def next_step(x,y) : return np.array([x,y]) - H_INV(x,y)*gradient(x,y)최대경사법은 계곡형상 지형에서, 진동현상 나타나는 걸 관찰할 수 있었다.하지만 뉴턴방법은 거리. 방향이 변형된 그레디언트 벡터를 사용하기 때문에, 위 그림처럼 4번만에 최적해에 도달하는 걸 볼 수 있었다.위 코드에는 기록하지 않았지만, 미분은 심파이 심볼릭연산을 사용했다.다른 위치에서 시작하는 뉴턴방법 로젠브록함수 최적화)최대경사법에서 아래와 같았던 최적화 결과가def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(-5,5,400)yy = np.linspace(-4,4,500)X, Y = np.meshgrid(xx,yy)Z = rosenbrook(X,Y)levels=np.logspace(-1, 4, 10)plt.contourf(X,Y,Z, levels=levels, alpha=0.3)plt.contour(X,Y,Z, levels=levels, colors='g', alpha=0.2)a = 2b = 2# 뉴턴방법(개선된 최대경사법)for i in range(10) : plt.plot(a,b, 'bo', markersize=5) n = np.array([a,b]) - H_INV(a,b)@gradient(a,b) n_ = - H_INV(a,b)@gradient(a,b)# 다음위치 plt.arrow(a,b, 0.95*n_[0], 0.95*n_[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw=2) a = n[0] b = n[1]plt.suptitle('로젠브록함수 뉴턴방법 최적화(최소화문제)', y=1.03)plt.title('같은 위치($[2,2]$)에서 단 4번만에 최적화 성공하는 걸 볼 수 있다')단 4번만에 깔끔하게 최적화 성공했다.다른 시작점에서도3번만에 최적화 성공했다.하지만 같은 지점에서 $\\mu$ 스텝사이즈를 사용하는 최대경사법으로는def rosenbrook(x,y) : return (1-x)**2+100*(y-x**2)**2def gradient(x,y) : return np.array([-400*x*(-x**2+y)+2*x-2, -200*x**2+200*y])xx = np.linspace(-3,3,400)yy = np.linspace(-3,3.5,500)X, Y = np.meshgrid(xx,yy)Z = rosenbrook(X,Y)levels=np.logspace(-1, 4, 10)plt.contourf(X,Y,Z, levels=levels, alpha=0.3)plt.contour(X,Y,Z, levels=levels, colors='g', alpha=0.2)mu = 1.8e-3a = -0.2b = -2.3for i in range(3) : plt.plot(a, b, 'ro', markersize=5) n = np.array([a,b]) - mu*gradient(a,b) n_ = -mu*gradient(a,b) plt.arrow(a,b, 0.95*n_[0], 0.95*n_[1], head_width=0.04, head_length=0.04, fc='k', ec='k', lw=2) a = n[0] b = n[1]plt.plot(a,b, 'ro', markersize=5)plt.suptitle('로젠브록함수 최대경사법 최적화(최소화문제)', y=1.03)plt.title('3번 시도로는 최적화 할 수 없다')plt.plot(1,1, 'bo', markersize=5)plt.show()3번 시도로는 최적화 할 수 없었다.준 뉴턴방법정의 :뉴턴방법이면서,헤시안 행렬을 사람이 직접 계산하지 않아도 되는 최적화 방법. 헤시안 행렬을 알고리듬이 수치적으로 대략 계산해서 넣는다. 계산량이 많아졌던 헤시안 행렬 계산을 사람이 직접 안 해도 된다는 장점. 있다. 예 :BFGS 방법사이파이로 최적화 하기디폴트 최적화 알고리듬은 준 뉴턴방법, BFGS 방법이다.단변수함수sp.optimize.minimize(f, x0, jac=) f : 최적화 할 함수 이름 x0 : 최적화 시작 위치 jac : 그레디언트 벡터예)def f(x) : return (x-2)**2+2x0 = 0 # 초깃값sp.optimize.minimize(f, x0)최적화에 성공할 경우. 다음과 같은 결과가 출력된다.nfev 는 함수 호출 횟수를 의미한다.한마디로, ‘얼마만에 최적화에 성공했냐’를 보여주는 것이다.함수 호출 횟수를 줄이고, 최적화를 더 빨리 성공하기 위해서는jac= 인수에 그레디언트 벡터를 직접 만들어서 넣어주면 된다.그레디언트 벡터 함수 직접 넣어서 함수 호출 횟수 줄이는 경우def g(x) : return 2*x-4 # 그레디언트벡터 함수 (1차 도함수)sp.optimize.minimize(f, x0, jac=g)함수 호출 횟수가 6번에서 3번으로 줄어들었다.다변수함수다변수함수를 사이파이로 최적화 할 때는, 함수가 벡터 입력을 받을 수 있도록 바꿔야 한다.def f(x) : return (1-x[0])**2+100*(x[1]-x[0]**2)**2x0 = (-1,1)result = sp.optimize.minimize(f, x0)result보면 f(x) 안에 벡터 x 입력을 받아 요소별로 인식할 수 있도록 $x[0], x[1]$ 형태로 바꿔놨다.마찬가지로 그레디언트벡터 함수 넣어주면 계산 속도가 빨라진다.# 그레디언트벡터 함수 삽입한 결과 def f(x) : return (1-x[0])**2+100*(x[1]-x[0]**2)**2def gradient(x) : return np.array([-400*x[0]*(-x[0]**2+x[1]) + 2*x[0]-2, -200*x[0]**2+200*x[1]])x0 = (-1,1)result = sp.optimize.minimize(f, x0, jac=gradient)result함수 호출 횟수가 120회에서 40회로 줄어들었다." }, { "title": "[수학/미적분] 범함수, 변분법, 최적제어 개념", "url": "/bioinfo.github.io/posts/newton_calculus/", "categories": "Data Science, mathematics", "tags": "datascience, mathematics", "date": "2021-08-30 00:00:00 +0900", "snippet": "범함수정의 :함수를 입력으로 받아 스칼라 출력하는 ‘함수’범함수 또한 함수의 한 종류다.일반적인 함수는 실수를 입력받아 실수를 출력한다.표기 :알파벳 대문자와 대괄호로 범함수 표기한다.예) 엔트로피 $H[p(x)]$, 기댓값 $E[p(x)]$ 등대괄호 안에는 함수를 입력으로 받는다.범함수의 테일러 전개테일러 전개어떤 함수 $f(x)$ 가 있다고 하자.이 함수의 도함수 또는 특정 점에서의 기울기를 알면,함수 $f(x)$ 의 근사함수를 구할 수 있다.$f(x) \\approx f(x_{0}) + \\frac{df(x_{0})}{dx}(x-x_{0})$$f(x,y) \\approx f(x_{0}, y_{0}) + \\frac{\\partial{f(x_{0}, y_{0})}}{\\partial{x}}(x-x_{0})+\\frac{\\partial{f(x_{0}, y_{0})}}{\\partial{y}}(y-y_{0})$이렇게 함수 $f$의 도함수 또는 기울기 만으로$f$의 근사함수를 구하는 과정 또는 그 결과를 테일러 전개 라고 한다.범함수의 테일러 전개그러면 범함수의 근사식은 어떻게 나타낼 수 있을까?우선, 일반적인 함수의 근사식을 조금 변형시켜 보자.$f(x) \\approx f(x_{0}) + \\frac{df(x_{0})}{dx}(x-x_{0})$위 식에서 $x \\Rightarrow x+\\epsilon$ , $x_{0} \\Rightarrow x$ 로 문자를 바꾸자.$\\epsilon$ 은 매우 작은 어떤 상수다.그러면$f(x+\\epsilon) \\approx f(x) + \\frac{df}{dx}\\epsilon$이 된다.이 식을 가지고 범함수의 테일러 전개 식을 유도할 것이다.함수 $f$ 를 함수 $F$로 기호를 바꾸자.변수 $x$ 는 $y$ 로 기호를 바꾸자.똑같은 함수 인데 기호만 각각 바꾼 것이다.$\\Rightarrow F(y+\\epsilon) \\approx F(y) + \\frac{dF}{dy}\\epsilon$만약 함수 $F$ 가 스칼라 $x_{0}, x_{1}, x_{2} …$ 를 입력으로 받는 다변수함수라면, 어떻게 테일러 전개 할 수 있을까?$F(y_{0}+\\epsilon_{0}, y_{1}+\\epsilon_{1}, y_{2}+\\epsilon_{2}, … y_{n}+\\epsilon_{n}) \\approx F(y_{0}, y_{1}, y_{2}, … y_{n}) + \\frac{\\partial F}{\\partial y_{0}}\\epsilon_{0} + \\frac{\\partial F}{\\partial y_{1}}\\epsilon_{1}+…\\frac{\\partial F}{\\partial y_{n}}\\epsilon_{n}$이런 식으로 전개 될 것이다.여기서 $y_{i}$ 를 어떤 실수 $x_{i}$ 를 입력으로 받는 어떤 단변수함수 $y(x_{i})$ 의 출력이라고 보자.또 $\\epsilon_{i}$ 를 어떤 실수 $x_{i}$ 를 입력으로 받는 어떤 단변수함수 $\\eta(x_{i})$ 출력에 아주 작은 공통 상수 $\\epsilon$ 을 곱한 값이라 생각하자.요점은,실수 $y_{i}$ 를 어떤 미지의 실수 $x_{i}$ 에 대한 어느 함수의 출력값으로 보고아주 작은 실수 $\\epsilon_{i}$ 를 어떤 미지의 실수 $x_{i}$ 에 대한 어느 함수의 출력값으로 본다는 거다.( $\\epsilon_{i}$ 은 함수 $\\eta(x_{i})$ 출력에 공통상수 $\\epsilon$ 을 곱해서 모든 $\\epsilon_{i}$ 값 크기를 아주 작게 조정해 준 값이다.)새로운 관점을 가지고테일러 전개식의 기호를 바꿔보자.$F(y(x_{0})+\\epsilon\\eta(x_{0}), y(x_{1})+\\epsilon\\eta(x_{1}), y(x_{2})+\\epsilon\\eta(x_{2}), … y(x_{n})+\\epsilon\\eta(x_{n})) \\approx$$F(y(x_{0}), y(x_{1}), y(x_{2}), … y(x_{n})) + \\frac{\\partial F}{\\partial y_{0}}\\epsilon\\eta(x_{0}) + \\frac{\\partial F}{\\partial y_{1}}\\epsilon\\eta(x_{1})+…\\frac{\\partial F}{\\partial y_{n}}\\epsilon\\eta(x_{n})$$= F(y(x_{0}), y(x_{1}), y(x_{2}), … y(x_{n})) + \\sum_{i=0}^{n}{\\frac{\\partial F}{\\partial y(x_{i})}}\\epsilon\\eta(x_{i})$위 식에서함수 $F$ 는 입력으로 $y(x_{0}), y(x_{1}), y(x_{2}), … y(x_{n})$ 수열을 받는 다변수함수다.만약 입력변수 갯수 $n$ 이 무한대가 된다면 어떻게 될까?그러면 함수 $y$의 입력값 $x_{i}$ 는 가능한 모든 실수가 된다.위 수열은 가능한 모든 $x_{i}$ 에 대한 특정한 출력값들로 구성되어 있다.$\\Rightarrow$ 위 수열은 가능한 모든 입력에 대한 특정한 출력값들로 구성되어 있다.입력과 출력사이 특정한 대응관계를 ‘함수’라고 정의했었다.위 수열의 각 원소는 모든 입력에 대한 각각의 출력을 정의하고 있으므로, 하나의 함수를 표현한 것이라 볼 수도 있다.$y(x_{0}), y(x_{1}), y(x_{2}), … y(x_{n}) \\Rightarrow y(x)$$x$ 는 모든 $x_{i}$ 를 대표하는 기호다.$y()$ 는 모든 $x_{i}$ 에 대한 출력을 대표하는 기호다.$n = \\infty$ 일 때, 테일러 전개식도 바뀐다.$F[y(x)+\\epsilon\\eta(x) ] \\approx F[y(x) ] + \\epsilon\\int{\\frac{\\partial F}{\\partial y(x)}}\\eta(x)$위 식이 범함수에 대한 테일러 전개다.범함수의 도함수위에서 구한 범함수의 테일러 전개를 조금 변형해보자.$\\frac{F[y(x)+\\epsilon\\eta(x) ] - F[y(x) ]}{\\epsilon} = \\int{\\frac{\\partial F}{\\partial y(x)}}\\eta(x)$우변의 $F(x)$ 를 좌변으로 넘겼다.그리고 아주 작은 상수 $\\epsilon$ 으로 양변을 나눴다.이제 좌변 식의 의미는 다음과 같다.” $\\epsilon$ 값 변화에 의한 범함수 $F$ 값의 변화량 “한편, 만약 좌변이 항상 $0$ 이 되어야 한다고 해보자.$\\frac{F[y(x)+\\epsilon\\eta(x) ] - F[y(x) ]}{\\epsilon} = 0$이 경우, 위 식의 의미는 “ $\\epsilon$ 값이 변화해도 범함수 $F$ 값 변화량이 0이다” 라는 의미를 갖는다.곧, 위 식이 성립한다는 건 $\\epsilon$ 값이 변화해도 범함수 $F$ 값은 변화하지 않는다는 소리다.한편, 위 식의 분자를 “범함수 입력을 변화시켰을 때 출력값 변화량’ 으로 정의할 수 있다.위 식의 분자에서 눈여겨 봐야 할 부분은$F[y(x)+\\epsilon\\eta(x) ]$ 이 부분이다.범함수 입력이 원래 $y(x)$ 였다고 생각한다면, $+\\epsilon\\eta(x)$ 만큼 입력을 변화시켰을 때 출력값이 ‘변화한 정도가 얼마인가’ 측정한 것이 분자다.$y(x)$ 를 어떤 임의의 고정된 값이라 생각할 때, $x$도 고정되어 있을 것이다.$x$가 고정되어 있으면 $\\eta(x)$ 값도 고정되어 있을 것이다.입력을 $+\\epsilon\\eta(x)$ 만큼 변화시키려 한다면, $\\eta(x)$ 가 고정되어 있으므로 $\\epsilon$ 값이 어떻게 변화하느냐에 따라 범함수 $F$ 의 입력값도 함께 변화할 것이다.곧, $\\epsilon$ 값 변화는 범함수 $F$ 의 입력값을 변화시킨다.$\\frac{F[y(x)+\\epsilon\\eta(x) ] - F[y(x) ]}{\\epsilon} = 0$이 식이 항상 성립한다는 말은 $\\epsilon$ 값이 변화해도 범함수 $F$ 출력이 변화하지 않는다는 의미다.$\\epsilon$ 값 변화는 범함수 $F$ 의 입력값 변화를 동반한다.$\\Rightarrow$ 범함수 $F$ 입력값이 변화해도, 범함수 $F$ 출력값이 변화하지 않는다는 말이다.이는 모든 입력값에 대한 범함수 기울기가 0 이어야 한다는 의미다.범함수의 도함수 = 0 이어야 한다.한편좌변 = 0 이면 우변도 = 0 성립해야 한다.$\\int{\\frac{\\partial F}{\\partial y(x)}}\\eta(x) = 0$$\\eta(x)$ 값에 상관없이 위 등식이 항상 성립하기 위해서는$\\frac{\\partial F}{\\partial y(x)} = 0$ 이어야만 한다.따라서 우변 = 0 은$\\frac{\\partial F}{\\partial y(x)} = 0$ 을 의미한다.좌변 식의 의미는 범함수의 도함수 = 0 이었다.등식이기 때문에 좌변과 우변은 서로 동일해야 한다.그러면 $\\frac{\\partial F}{\\partial y(x)}$ 가 도함수 $F$ 를 입력변수인 독립함수 $y(x)$ 로 미분한 범함수의 도함수라는 말이다.$\\Rightarrow$ 범함수의 도함수 : $\\frac{\\partial F}{\\partial y(x)}$범함수의 도함수는 라운드 $\\partial$ 기호 대신에 델타 $\\delta$ 기호를 쓴다.$\\frac{\\delta{F}}{\\delta{y(x)}}$적분형 범함수의 도함수범함수는 일반적으로 $x$ 에 대한 적분 형태로 정의된다.적분 기호 안의 연산은 실수 $x$와 함수 $y(x)$ 를 입력으로 받는 또 다른 함수 $G$ 로 간주한다.$F[y(x)] = \\int{G(y(x), x)} dx$이렇게 $x$에 대한 적분형태의 범함수는 다음과 같이 미분한다.적분형 범함수 미분 방법 :$\\frac{\\delta{F}}{\\delta{y}} = \\frac{\\partial{G}}{\\partial{y}}$범함수의 입력변수인 독립함수 $y(x)$ 를 일반 변수처럼 취급해서.적분 내부 연산인 함수 $G$ 를 편미분 한다.예)$L = \\int{\\frac{1}{2}(\\hat{y}(x)-y(x))^{2}}dx$위 함수 $L$ 을 $\\hat{y}(x)$ 을 입력으로 보고 미분해보자.$G = \\frac{1}{2}(\\hat{y}(x)-y(x))^{2}$$G = \\frac{1}{2}(\\hat{y}(x)^{2}+y(x)^{2}-2\\hat{y}(x)y(x))$$\\frac{\\partial{G}}{\\partial{\\hat{y}}} = \\hat{y}(x)-y(x)$오일러-라그랑주 공식정의 :적분형 범함수의 적분 내부 연산에 실수 $x$, 함수 $y(x)$ 이외에도 함수 $y(x)$ 를 $x$로 미분한 $y’(x)$ 가 있는 경우, 적분형 범함수 미분하는 공식.$F[y(x)] = \\int{G(y, x, y’)}dx$ 일 때$\\Rightarrow \\frac{\\delta{F}}{\\delta{y}} = \\frac{\\partial{G}}{\\partial{y}} - \\frac{d}{dx}(\\frac{\\partial{G}}{\\partial{y’}})$최적제어정의 :범함수의 최적화.범함수 최대점, 최소점을 찾는 작업이다.범함수 최적제어 필요조건 :일반적인 함수 최적화 할 때와 조건이 같다.범함수 최적제어 필요조건은‘최적입력 $y^{*}(x)$에서 범함수의 1차 도함숫값이 0 되어야 한다’ 이다.$\\Rightarrow$ $\\frac{\\delta{F}}{\\delta{y}}[y^{*}(x) ] = 0$" }, { "title": "[수학/미적분] 행렬미분, 행렬미분법칙", "url": "/bioinfo.github.io/posts/tensor_calculus/", "categories": "Data Science, python, mathematics", "tags": "datascience, python, mathematics", "date": "2021-08-29 00:00:00 +0900", "snippet": "행렬미분정의 :스칼라, 벡터, 행렬을 출력하는 함수를 스칼라, 벡터, 행렬로 미분하는 것.예 : 스칼라 출력하는 다변수함수를 입력변수인 벡터로 미분 스칼라 출력하는 다변수함수를 입력변수인 행렬로 미분 벡터 출력하는 함수를 입력변수인 벡터로 미분스칼라를 벡터로 미분다변수 입력이 들어오고. 스칼라 출력하는 다변수함수를입력벡터로 ‘편미분’할 수 있다. 편미분 결과인 1차 도함수를 ‘그레디언트 벡터’ 라고 한다.그레디언트 벡터 $(\\nabla{f})$$\\nabla f = \\frac{\\partial f}{\\partial x}$정의 :스칼라 함수 $f$를 입력변수 벡터 $x$로 편미분한 ‘1차 도함수 벡터’스칼라 $f$ 를 벡터 각 원소로 편미분 한 것이다.특징 :그레디언트 벡터 사이즈는 미분하는 입력벡터 사이즈랑 같다.열벡터 형태다.예)$f(x,y) = 3x^{2}+12x-5y^{2}+y-23$ 를 벡터 미분해보자.위 함수는 다변수 스칼라함수다(입력 $x,y$ 벡터, 출력 : 스칼라).스칼라 함수를 입력벡터로 미분하자.$x_{0} = [x,y]$$\\nabla{f} = \\frac{\\partial f}{\\partial x_{0}} = [6x+12, -10y+1]^{T}$입력벡터 $x_{0}$ 각 원소로 스칼라 함수 $f$ 를 편미분 했다.그 결과물 $[6x+12, -10y+1]^{T}$ 이 1차 도함수 벡터인 그레디언트 벡터다.헤시안 행렬 $(H)$스칼라 출력하는 다변수함수를 입력변수 벡터로 1차 편미분 한 결과를 ‘그레디언트 벡터($\\nabla{f}$)’ 라고 했다.그레디언트 벡터는 스칼라 다변수함수의 1차 도함수다.이 1차 도함수를 입력변수 벡터로 한번 더 미분하면 2차 도함수가 나온다.헤시안 행렬($H$)은 스칼라 함수를 벡터로 두번 미분해서 나오는 2차 도함수이다.정의 :스칼라 함수를 입력변수 벡터로 두번 미분해서 구한 2차 도함수 행렬특징 : 1차 도함수 그레디언트 벡터($\\nabla{f}$) 의 자코비안 행렬의 전치행렬과 같다. 맨 처음 스칼라 함수가 연속이고. 전 구간 미분 가능하다면 2차 도함수. 헤시안 행렬은 대칭행렬이다. 퀴버플롯정의 :2차원 컨투어 플롯 위에 각 점에서의 그레디언트 벡터를 화살표로 표시한 것.각 그레디언트 벡터(화살표)는시점 : 컨투어 플롯 위 내가 지정해준 어떤 점종점 : 내가 지정해준 어떤 점의 그레디언트 벡터 값이다. 그레디언트 벡터 길이(크기) 는 각 점(벡터 시작점)의 기울기를 나타낸다. 그레디언트 벡터 방향은 등고선 방향과 직교한다.그레디언트 벡터 방향의 의미 1 :그레디언트 벡터 방향은 입력 $x,y$ 가 출력에 각각 어떤 영향 미치는지 보여준다.설명 )퀴버플롯에서 그레디언트 벡터 방향은 그레디언트 벡터의 원소 $\\frac{\\partial{f}}{\\partial{x}}, \\frac{\\partial{f}}{\\partial{y}}$ 부호에 의해 결정된다.입력변수 $x$ 가 증가할 때, 출력 $f$가 증가한다면.변수 $x$에 대한 기울깃값 $\\frac{\\partial f}{\\partial x}$ 는 양수다.입력변수 $y$ 가 증가할 때, 출력 $f$ 가 감소한다면.변수 $y$ 에 대한 기울깃값 $\\frac{\\partial f}{\\partial y}$ 는 음수다.그러면 그레디언트 벡터 원소 부호가 $+, -$ 이므로. 그레디언트 벡터 방향은 오른쪽 아래를 가리킨다.이 뱡향, ‘오른쪽 아래’ 에서 입력변수 $x$ 가 증가할 때 출력 $f$가 증가하고.입력변수 $y$ 가 증가할 때 출력 $f$ 가 감소하고. 를 읽을 수 있다.$\\Rightarrow$ 각 입력변수가 변화할 때. 출력이 어떻게 변화하는 지 알 수 있다.그레디언트 벡터 방향의 의미 2 :그레디언트 벡터 방향은 각 점(벡터 시작점)에서 값을 살짝 증가시킬 때 기울기가 가장 커지는 방향.그러니까 단위길이 당 함숫값이 가장 크게 증가하는 방향을 가리킨다.임의의 그레디언트 벡터 시작지점이 $x_{0}$ 라고 하자.$x_{0}$ 에서 출발해서 함수 $f$ 최대점을 찾고 싶을 때,$x_{0}$ 에서 입력값을 어떻게. 어디로 변화시켜야최대한 시행착오 줄이면서 함수 $f$ 최대점에 도달할 수 있을까?$x_{0}$ 에서 값을 변화시켰을 때, 함숫값이 기존 $f(x_{0})$ 에서 가장 크게 증가하는 점으로입력값을 변화시켜야 최댓값까지 더 빠르게 올라갈 것이다.변화시킨 입력값을 $x_{1}$ 이라고 하면. $x_{1}$ 에서 다시 함숫값이 가장 크게 증가하는 점으로입력을 변화시켜야 한다. 이 과정을 반복하다보면 최대점에 최소한의 시행착오로 도달할 것이다.$\\Rightarrow$ 그레디언트 벡터 방향은 입력값을 변화시킬 때, 함숫값이 가장 크게 증가하는 방향을 의미한다고 했다.$\\Rightarrow$ 점 $x_{0}$ 에서 그레디언트 벡터 방향에 위치한 점을 새 입력으로 넣어야 함숫값이 가장 크게 증가할 것이다.$\\Rightarrow$ 새 입력에서 다시 그레디언트 벡터를 구하고, 그레디언트 벡터 방향에 위치한 점을 새 입력으로 사용하면 다시 함숫값이 가장 크게 증가할 것이다.$\\Rightarrow$ 함숫값을 계속 증가시켜 가다보면 그레디언트 벡터 값이 0인 지점. 그러니까 1차 도함숫값이 0 나오는 지점에 도달할 것이다. 이 지점이 최대점이다.= 그레디언트 벡터 방향은 2차원 함수 $f$의 최대점에 도달하기 위한 지름길이다.한편, 그레디언트 벡터 방향을 반대로 뒤집으면 어떻게 될까?그레디언트 벡터 방향이 함숫값이 가장 크게 증가하는 지점. 즉 ‘3차원 지형이 가장 가파르게 올라가는 지점’ 이었다면그레디언트 벡터 반대 방향은 ‘3차원 지형이 가장 가파르게 내려오는 지점’ 이 될 것이다.즉 지형의 경사가 가장 가파르게 감소하는 지점이라는 거다.계곡으로 생각하면, 지형 경사가 가장 가파르게 감소하는 방향 따라가다보면 계곡 바닥(=골짜기의 최저점) 에 가장 빠르게 다다를 것이다.계곡 = 2차원 함수 , 지형 경사가 가장 가파르게 감소하는 방향 = 그레디언트 벡터 반대방향 으로 넣고 생각해보자.2차원 함수에서 각 점의 그레디언트 벡터 반대방향을 따라가다보면 2차원 함수의 최저점에 최소한의 시행착오로 도달할 것이다.따라서$\\Rightarrow$ 그레디언트 벡터 반대 방향은 2차원 함수 $f$의 최소점에 도달하기 위한 지름길이다.데이터사이언스 스쿨 4.4.3 연습문제 )문 )함수 $2x^{2}+6xy+7y^{2}-26x-54y+107$ 로 표현되는 지형을 상상해보자.이 지형의 $(14,4)$ 지점에서 공을 두었다면, 어떤 경로로 공이 움직일까?나의 답 )공을 둔 지점이 경사가 있는 지점이라면, 공은 경사가 가장 가파르게 감소하는 방향을 따라 굴러내려가서 경사가 가장 평평한 지점에서 멈출 것이다.경사가 가장 평평한 곳 = 기울기가 0인 곳 = 지형의 최저점 이라 볼 수 있다.공이 굴러내려 갈 경로인 ‘경사가 가장 가파르게 감소하는 방향’ 은 단위길이 당 함숫값이 가장 크게 감소하는 방향. 즉 그레디언트 벡터 반대방향이다.종합하면, 공은 지형의 $(14,4)$ 위치에서 시작해서 그 지점 그레디언트 벡터 반대방향을 타고 굴러내려가 지형 최저점에 도달할 것이다.지형 = 2차원 함수로 생각하면, 2차원 함수의 $(14,4)$ 위치에서 시작해서 그레디언트 벡터 반대방향으로 입력을 변화시켜 가며 끝내 함수의 최저점을 찾은 것과 같다.이 공 굴리기 문제는 결국 2차원 함수 최소화 문제인 거다.$\\Rightarrow$ 2차원 함수 특정 지점에서 시작해서 입력을 변화시켜 가며 함수를 최소화 시키는 최저점을 찾기 위해서는,입력을 그레디언트 벡터 반대방향으로 변화시켜야 한다는 사실을 알 수 있다.행렬미분법칙(스칼라 - 벡터 미분)1. 선형 모형함수 $f(x)$ 가 선형모형인 경우($f$가 스칼라 함수)$f(x) = w^{T}x$$f$ 를 벡터 미분하면 그레디언트 벡터는 가중치 벡터 $w$ 다.$\\nabla{f} = w$2. 이차형식함수 $f(x)$ 가 이차형식인 경우($f$는 스칼라 함수)$f(x) = x^{T}Ax$$f$를 벡터 $x$로 미분하면 그레디언트 벡터는 $(A+A^{T})x$ 이다.$\\nabla{f} = (A+A^{T})x$벡터를 스칼라로 미분- 벡터를 스칼라로 미분하는 경우, 벡터 각 원소를 스칼라로 ‘편미분’ 한다.- 결과는 행벡터로 나타낸다.$f(x) = [f_{1}, f_{2}, f_{3} … f_{n}]^{T}$벡터함수 $f$를 스칼라 $x$로 미분하는 경우$\\frac{\\partial{f}}{\\partial{x}} = [\\frac{\\partial{f_{1}}}{\\partial{x}}, \\frac{\\partial{f_{2}}}{\\partial{x}}, \\frac{\\partial{f_{3}}}{\\partial{x}}, … \\frac{\\partial{f_{n}}}{\\partial{x}}]$벡터를 벡터로 미분- 벡터로 스칼라 미분을 여러 번 하거나- 스칼라로 벡터 미분을 여러 번 하거나.1. 벡터로 스칼라 미분을 여러 번 하는 경우함수 입력 벡터로 미분당하는 벡터(함수)의 스칼라 원소 하나하나를 스칼라-벡터 미분 할때와 똑같이 편미분 한다.결과는 미분한 벡터와 똑같은 사이즈 열벡터인 그레디언트 벡터가 여러 개 나올 것이다.이 열벡터들을 옆으로 (열로) 쌓은 행렬이 벡터-벡터 미분 결과다.2. 스칼라로 벡터 미분을 여러 번 하는 경우함수 입력 벡터 스칼라 원소 하나하나로, 미분당하는 벡터(함수)를 벡터-스칼라 미분할때와 같이 편미분 한다.벡터 - 스칼라 미분 결과인 행벡터 여러 개가 결과로 나올 것이다.이 행벡터들을 위에서 아래로 (행으로) 쌓은 행렬이 벡터-벡터 미분 결과다.자코비안 행렬정의 :벡터를 벡터로 미분해서 나오는 1차 도함수 행렬의 전치행렬행렬미분법칙(벡터 - 스칼라 &amp; 벡터 미분)3. 행렬과 벡터 곱의 미분함수 $f(x)$ 가 행렬과 벡터 곱 인 경우($f$ 가 벡터 함수)$f(x) = Ax$$f$ 를 벡터 $x$로 미분하면 결과는 행렬 $A^{T}$ 가 된다.$\\nabla{f} = A^{T}$스칼라를 행렬로 미분스칼라(함수 $f$)를 입력변수 행렬 각 원소로 편미분.$\\frac{\\partial{f}}{\\partial{X}}$스칼라를 벡터 미분한 결과인 그레디언트 벡터는 미분한 벡터와 사이즈가 같았다.스칼라를 행렬로 편미분한 도함수 행렬도 입력변수 행렬과 사이즈가 같다.if)$X \\in R^{5 \\times 5}$,$\\frac{\\partial{f}}{\\partial{X}} \\in R^{5 \\times 5}$.행렬미분법칙 (행렬 곱의 대각합)두 정방행렬 곱해서 만들어진 행렬의 대각합은 스칼라다.$f(X) = tr(WX)$$f$ 는 스칼라 함수.이 스칼라를 뒤의 행렬 $X$ 로 편미분하면 앞의 행렬의 전치행렬이 나온다.$\\frac{\\partial{f}}{\\partial{X}} = \\frac{\\partial{tr(WX)}}{\\partial{X}} = W^{T}$행렬미분법칙 (행렬식에 로그 취한 경우)어떤 행렬 $X$가 있다고 하자.이 행렬의 행렬식 $\\lvert X \\rvert$ 는 스칼라다.행렬식 $\\lvert X \\rvert$ 에 $\\log$ 를 씌워도 스칼라다.$f(X) = \\log{\\lvert X \\rvert}$$f(X)$ 는 스칼라 함수.스칼라 함수 $f(X)$ 를 행렬 $X$ 로 편미분하면 $(X^{-1})^{T}$ 가 나온다.$\\frac{\\partial{f}}{\\partial{X}} = \\frac{\\partial{\\log{\\lvert X \\rvert}}}{\\partial{X}} = (X^{-1})^{T}$" }, { "title": "[수학/미적분] 수치미분, 심볼릭연산을 이용한 미분과 적분, 수치적분", "url": "/bioinfo.github.io/posts/sympy_calculus/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-08-27 00:00:00 +0900", "snippet": "데이터분석에서 미분의 쓸모데이터분석의 중요한 목표 중 하나는 예측모형 최적화다.곧, 예측모형 성능을 최대화(오차를 최소화) 하는 것이 매우 중요하다.$\\Rightarrow$ 예측모형의 성능함수 또는 손실함수가 있을 것이다.성능함수 또는 손실함수 출력은 최대화 또는 최소화 되어야 한다.최적화를 통해 목적함수 출력을 최대화 또는 최소화 시키는 최적해를 찾을 것이다.이 최적 입력을 찾기 위해선 입력값을 변화시키면서 출력이 어떻게 변하는지 확인해야 한다.바로 이 과정, 입력값이 변화할 때 출력값이 어떻게 변하는지 알려주는 게 ‘미분’이다.결국 예측모형 최적화를 위해서는 성능함수(or 손실함수) 미분이 필수적이다.$\\Rightarrow$ 미분 : 입력값이 변할 때 출력값이 어떻게 변하는지 알려주는 ‘신호’, ‘도구’기울기 (민감도)$\\lim_{\\Delta{x} \\to 0} \\frac{f(x+\\Delta{x})-f(x)}{\\Delta{x}}$정의 :임의의 특정 입력값 $x_{0}$ 에서, 입력값이 매우 미세하게 증가할 때. 출력값이 어떻게 변할지 알려주는 신호.만약 $x_{0}$ 에서 기울기가 양수이면입력값을 $x_{0}$ 에서 살짝 증가시켰을 때 출력값이 증가한다는 뜻이다.출력을 최대화 하는 게 목표라면, $x_{0}$ 에서 기울깃값을 확인하고 $x_{0}$ 에서 좀 더 증가시킨 입력값을 다시 넣어볼 것이다.이 기울깃값은 함수에서 $x_{0}$ 점에 접하는 접선의 기울기와 같다.이 접선 기울기는$\\frac{\\Delta{y}}{\\Delta{x}}$x 증가량에 대한 y 증가량의 비율과도 같다.수치미분정의 :dx 값을 직접 받아특정 점에서의 대략적 기울깃값 계산.수치미분을 위한 파이썬 코드 : scipy.misc.derivative(함수 이름, 기울깃값 구할 지점, dx=)# 수치미분from scipy.misc import derivativederivative(f, x0, dx=1/100000)주의점 : ‘대략적’ 기울깃값이다. 정확한 값은 아니라는 걸 기억하자. dx 값은 작으면 작을 수록 좋지만, 너무 작아지면 오차가 커진다. 유의해서 넣자.미분정의 :도함수 찾는 작업. 어떤 함수를 미분해서 찾은 또 다른 함수를 ‘도함수’라고 한다. 각 $x$ 점에서의 도함숫값이 $x$ 점에서의 기울깃값이다.미분가능함수가 전 구간 연속일 때, 함수는 전 구간 ‘미분가능’하다.불연속 지점에서 함수는 ‘미분 불가능’하다.미분불가능 예)$x=0$ 지점에서 불연속인 렐루함수 예.def ReLU(x) : return np.where(x&gt;0, x, 0)xx = np.linspace(-5,5,100)plt.plot(xx, ReLU(xx))plt.plot(0,0, 'o', ms=10)plt.title('ReLU 함수 : $x=0$ 에서 미분불가능(불연속)')plt.xlabel('$x$')plt.ylabel('$ReLU$')plt.show()렐루함수는 $x=0$ 지점에서 불연속이다.따라서 이 함수는 $x=0$ 에서 ‘미분불가능’이다.핵심 미분공식1. 로그를 미분하면 $x^{-1}$ 나온다.$\\frac{d}{dx}(logx) = \\frac{1}{x}$2. 밑이 $e$ 인 지수는 미분해도 안 바뀐다.$\\frac{d}{dx}(e^{x}) = e^{x}$3. 어떤 함수 형태가 두 함수의 곱 이면 다음과 같이 미분한다.$\\frac{d}{dx} (f\\cdot g) = f^{‘}g+fg^{‘}$이를 미분 곱셈법칙이라 한다.4. 어떤 함수 입력이 또 다른 함수 출력인 경우, 다음과 같이 미분한다.$\\frac{d}{dx} h(g(x)) = \\frac{d}{dg}h \\cdot \\frac{d}{dx}g$이를 미분 연쇄법칙이라 한다.로그함수에 미분 연쇄법칙 적용할 경우, 다음과 같은 결과가 나온다.$\\frac{d}{dx}(\\log{f(x)}) = \\frac{f’(x)}{f(x)}$2차 도함수정의 :2차 도함수는 1차 도함수를 다시 한번 미분해서 구한 함수다. 1차 도함수의 기울기다. 함수 $f(x)$ 의 볼록도볼록도 (convexity) :함수 $f(x)$ 각 점에서의 2차 도함숫값을 ‘볼록도’ 라고도 한다.이 볼록도는 점 $x_{0}$ 까지 구간에서 함수가 ‘볼록한 정도’를 나타낸다.또아래쪽에서 바라봤을 때2차 도함숫값이 양수인 구간에서 원래 함수 $f(x)$ 는 ‘볼록’하다.2차 도함숫값이 음수인 구간에서 원래 함수 $f(x)$는 ‘오목’하다.편미분미분은 한번에 한 개 변수에 대해서만 할 수 있다.정의 :변수가 둘 이상인 다변수함수. 에서 1개 변수에 대해서만 미분하는 것.다른 나머지 변수는 상수 취급한다.$\\partial$ 라운드 기호를 쓴다.편미분 의미 :다변수함수에 두 변수 $x, y$가 있다고 하자.$x$ 에 대한 편미분은 $y$ 변수는 고정시켜둔 채. $x$ 입력변수만 변화시킬 때. 함수 출력이 어떻게 변화하는가 알려주는 신호다.$y$ 에 대한 편미분은 그 반대다.다변수함수의 연쇄법칙다변수함수 입력이 다른 여러 함수들 출력인 경우, 똑같이 연쇄법칙 작용한다.예를 들어어떤 다변수함수 $g$ 가 있다고 하자.$g$의 입력은 $x$ 를 입력으로 갖는 단변수함수 $f_{1}, f_{2}, f_{3}…f_{n}$ 이다.$z = g(f_{1}, f_{2}, f_{3}…f_{n})$또는$z = g(y_{1},y_{2}, y_{3}, … y_{n})$ 이때 함수 $g$는 사실상 변수 $x$ 를 입력으로 갖는 단변수함수와도 같다.$g$ 를 $x$로 미분하면$\\frac{dg}{dx} = \\frac{\\partial g}{\\partial y_{1}}\\cdot \\frac{dy_{1}}{dx} + \\frac{\\partial g}{\\partial y_{2}}\\cdot \\frac{dy_{2}}{dx}+ …\\frac{\\partial g}{\\partial y_{n}}\\cdot \\frac{dy_{n}}{dx}$이다.만약 $g$ 의 입력이 $x_{1}, x_{2}, …x_{n}$ 을 입력으로 받는 다변수함수 $f_{1}, f_{2}, f_{3}…f_{n}$ 이라면 어떨까?$z = g(f_{1}, f_{2}, f_{3}…f_{n})$또는$z = g(y_{1},y_{2}, y_{3}, … y_{n})$ $g$는 사실상 입력이 $x_{1}, x_{2}, …x_{n}$ 인 다변수함수다.만약 $x_{1}$ 입력변수 변화에 따라 $g$ 의 출력 $z$ 가 어떻게 변하는지 알고 싶으면. 다음처럼 미분하면 된다.$\\frac{\\partial g}{\\partial x_{1}} = \\frac{\\partial g}{\\partial y_{1}}\\cdot \\frac{\\partial y_{1}}{\\partial x_{1}} + \\frac{\\partial g}{\\partial y_{2}}\\cdot \\frac{\\partial y_{2}}{\\partial x_{1}}…+\\frac{\\partial g}{\\partial y_{n}}\\cdot \\frac{\\partial y_{n}}{\\partial x_{1}}$2차 편미분정의 :$x$ 나 $y$ 로 한번 편미분 마친 상태에서. 다시 $x$ 나 $y$ 로 편미분을 한번 더 하는 작업이다.슈와르츠 정리 : 편미분 순서는 상관 없다!$x$로 편미분 하고 $y$로 편미분 하건.$y$로 편미분 하고 $x$로 편미분 하건.결과는 같다.$x$로 먼저 하든, $y$로 먼저 하든.편미분 순서는 상관없다.테일러 전개정의 :특정 점 $x_{0}$ 에서의 기울기 만 가지고. 함수 $f(x)$의 근사함수를 찾는 작업.단변수함수 테일러 전개 식 :$f(x) \\approx \\frac{df(x_{0})}{dx}(x-x_{0})+f(x_{0})$다변수함수 테일러 전개 식 :$f(x,y) \\approx \\frac{\\partial f(x_{0}, y_{0})}{\\partial x}(x-x_{0}) + \\frac{\\partial f(x_{0},y_{0})}{\\partial y}(y-y_{0})+f(x_{0}, y_{0})$심파이 sympy심볼릭연산 하게 해 주는 파이썬 패키지다.심볼릭연산이란 내가 연필로 미분. 적분 하는 작업을 컴퓨터에서 그대로 구현해놓은 거라 생각하면 된다.심볼릭 변수파이썬에서 지금까지 사용해온 변수는 언제나 특정 숫자, 문자 등 데이터가 담겨 있었다.하지만 심볼릭 변수는 아무것도 담겨 있지 않다. ‘변수’를 ‘의미 그대로’ 표현해 놓은 것이 심볼릭 변수다.심파이로 심볼릭 연산 하기 위해서는 심볼릭 변수가 필요하다.곧, 심볼릭 변수를 지정해주는 작업이 필요하다.sympy.symbols(‘문자열’)x, y = sympy.symbols('x y')위 코드를 사용해서 심볼릭연산에 쓸 심볼릭 변수를 지정해줄 수 있다..symbols() 괄호 안에 들어가는 문자열에 특정한 문자를 집어넣어서 그 문자를 심볼릭 변수로 만든다.문자열 안에는 심볼릭변수로 지정해주고 싶은 여러 문자 동시에 넣어도 된다. 이때 각 문자 간 구분은 띄어쓰기나 , 로 한다.x, mu, y = sympy.symbols('x mu y')위 코드처럼 입력해주면 x, mu, y가 심볼릭 변수로 지정된 것이다.심볼릭함수심볼릭 변수를 지정했으면, 이 변수 이용해서 미분. 적분 등 연산하려고 하는 함수 만들어주면 된다.편의상 ‘심볼릭함수’라고 이름붙였다.x = sympy.symbols('x')f = x*sympy.exp(x)f가 심볼릭변수로 만들어준 심볼릭함수다.심볼릭연산 할 때는 함수들도 모두 심파이 전용함수 써야 한다. 위 코드에서 sympy.exp() 가 그 예다.심볼릭연산 이용한 미분sympy.diff(심볼릭함수이름, 미분할 변수)심볼릭연산으로 함수 미분 할 때는 sympy.diff()를 쓰면 된다.diff() 괄호 안에는 미분할 심볼릭함수 이름을 넣으면 된다.심볼릭변수가 함수 f 안에 하나밖에 없을 때는(단변수함수인 경우) 미분할 변수 굳이 안 지정해줘도 된다.# 단변수함수 미분f = 2*x**4+5*x**3+6*x**2+7*x+8 # 심볼릭함수 sympy.diff(f)하지만 다변수함수를 sympy.diff()로 미분하거나. 단변수함수지만 심볼릭함수 안에 심볼릭 변수가 여러 개 있는 경우는 어떤 변수로 미분 할 건지 정해줘야 한다. 다변수함수 심볼릭연산으로 편미분 하는 경우```python 다변수함수 f = x2+4xy+4*y2 편미분sympy.diff(f, x)&lt;img width=\"114\" alt=\"Screen Shot 2021-08-28 at 21 38 47\" src=\"https://user-images.githubusercontent.com/83487073/131218137-9b50173d-a5e5-4f8a-b82b-3787ef166293.png\"&gt;- 단변수함수인데 심볼릭변수가 여러개라서 미분할 변수 지정 하는 경우```python# 심볼릭변수가 여러 개 일 때는 무조건 편미분하듯 어떤 변수로 미분할건지 지정해야 한다. x, mu, sigma = sympy.symbols('x, mu, sigma')f = sympy.exp((x-mu)**2/sigma**2)sympy.diff(f, x)2차 도함수심볼릭 연산으로 2차 도함수 구하려면, 다음처럼 하면 된다.# 2차 도함수 sympy.diff(f, x, x) # x로 두번 미분simplify()수식 정리 함수다.sympy.simplify(sympy.diff(f, x, x))sympy.simplify() 형태로 쓴다.괄호 안에 식 깔끔하게 정리 할 수식 넣으면 된다.적분부정적분은 ‘반-미분’,정적분은 ‘구간 a,b 에서 함숫값과 수평선이 이루는 면적 구하는 작업’이다.부정적분정의 :미분의 반대연산 (반-미분).미분이 도함수 구하는 과정이었다면, 부정적분은 구한 도함수를 도로 원래 함수로 되돌리는 과정이다.도함수를 $f(x)$ 라고 하면,도함수를 부정적분해서 찾은 원래 함수를 $F(x)$ 로 표기한다.$F(x) = \\int{f(x)dx}+c$$c$ 는 상수항을 의미한다. 생략해도 상관없다.편미분의 부정적분$x(y)$로 편미분 했으면 $x(y)$로 부정적분 해야 한다부정적분은 미분의 반대연산이다.만약 함수 $F(x, y)$ 를 $x$로 편미분 해서 $f(x,y)$ 가 나왔다면.$f(x,y)$ 를 $x$ 에 대해 부정적분 하면 $F(x,y)$ 가 나올 것이다.$F(x,y) = \\int{f(x,y)}dx + c(y)$이때는 뒤에 $c(y)$ 가 붙는다.$c(y)$ 는 y에 대한 식일수도 있고, 단순 상수일 수도 있다.위 과정을 $y$ 에 대해 생각한다면,$F(x,y) = \\int{f(x,y)}dx + c(x)$일 것이다.다차 도함수와 다중적분 다차 도함수 : 원래 함수를 편미분 여러 번 해서 얻어낸 도함수 다중적분 : 부정적분을 여러번 하는 것.위 경우는 편미분을 한번 한 경우였다.편미분 한번 했으면 부정적분 한번 하면 될 것이다.그러면 편미분을 여러번 한 경우는 어떻게 해야 원래 함수를 찾을 수 있을까?다차 도함수다변수함수의 다차도함수는 편미분을 여러번 한 대표적 예다.2차 도함수라면 편미분을 두번 했을 것이고,3차 도함수면 편미분을 세번 했을 것이다.2번 편미분 한 다차도함수에서 원래 다변수함수를 찾아보자.$F(x,y) = \\int_{x}\\int_{y} f_{2}(x,y) dy dx$위 식처럼 부정적분을 여러번. ‘다중적분’ 해서 원래 다변수함수 찾을 수 있다.위 경우는 $F(x,y)$ 를 $x$ 로 편미분하고 $y$로 편미분 해서 얻은 $f_{2}(x,y)$ 를 다시 원래 함수 $F$ 로 되돌리는 경우다.순서를 역으로 $y$로 부정적분하고, $x$로 다시 부정적분 하면 원래 함수가 나올 것이다.한편, 편미분 여러번 할 때 슈와르츠정리에 의해 미분 순서가 상관 없었듯이, 여기서도 부정적분 순서는 상관 없다.$\\int\\int{f_{2}(x,y)}dxdy$$\\int\\int{f_{2}(x,y)}dydx$심볼릭연산을 이용한 부정적분역시 sympy 를 이용한다.sympy.integrate(함수 이름, 적분할 변수 이름)심파이 사용한 부정적분 예 )x, y = sympy.symbols('x y')f = x*y*sympy.exp(x**2+y**2)sympy.integrate(f, x)정적분정의 :구간 a, b 에 대해서 함수 $f(x)$와 수평선이 이루는 면적 계산하는 작업또는 그 값.$\\int^{a}_{b}{f(x)}dx$정적분을 계산하는 방법미적분학의 기본정리, 수치적분.1. 미적분학의 기본정리$\\int^{b}_{a}{f(x)}dx = F(b)-F(a)$ 심볼릭연산으로 계산할 수 있다. 도함수 부정적분 이용하는 방법이다.예)# 미적분학의 기본정리 이용해서 정적분값 계산x = sympy.symbols('x')f = x**3-3*x**2+x+6 # 도함수F = sympy.integrate(f, x)F # 반-미분해서 찾은 원래 함수 F(F.subs(x,2) - F.subs(x, 0)).evalf()subs(값을 넣을 심볼릭변수 이름, 값) 심볼릭변수에 실제로 어떤 값을 넣어 연산하고 싶을 때 쓰느 메서드다..evalf() 심볼릭연산 결과의 실젯값을 계산해준다.예를 들어 결과값이 $\\sqrt{8}$ 이면, 2.82… 이런 식으로 나타내준다.괄호 안에 소수 몇 째 자리 까지 나타낼 건지도 정해줄 수 있다. 예) 102. 수치적분 : 구간의 근사면적 구하기정적분의 정의에 좀 더 걸맞게,구간 a,b 를 작은 사각형들로 실제로 잘게 쪼갠 뒤.이것들 면적 더해서 구간의 근사면적을 구한다. 심볼릭 연산 아니다.scipy.integrate.quad(파이썬함수 이름, 구간 시작점, 구간 끝점)sp.integrate.quad(f, a, b)예)# 수치적분으로 정적분def f(x) : return 3*x**2-6*x+1sp.integrate.quad(f, 0,1)[0] # 수치적분으로 구한 정적분값 out : -1, 1.3085…수치적분 첫번째 결과값은 정적분 값이다.두번째 결과값은 오차 상한값이다.다변수 정적분다변수함수의 ‘부피’를 계산하는 작업정적분의 의미를 잘 생각해야 한다.2차원 평면상의 1차원 함수 기준으로, 정적분은 구간에 대한 함수와 수평선 사이 ‘면적’ 이었다.다변수함수가 입력변수 2개인 2차원 함수라고 하자.2차원 함수면 3차원 공간상의 입체로 표현된다.임의의 구간에 대한 2차원 함수의 함숫값들과 수평선 사이 면적은 ‘부피’다.따라서 다변수 정적분은 다변수함수의 ‘부피’를 계산하는 작업이다.$\\int_{a}^{b}\\int_{c}^{d}{f(x,y)}dydx$$\\Leftarrow$ 구간 (x : a~b), (y : c~d) 에서 다변수함수 $f(x,y)$ 의 부피수치이중적분2차원 다변수함수에 대해 다변수 정적분 하는 것.수치적분과 마찬가지로 구간을 잘게 쪼개서 대략적인 부피를 구한다.scipy.integrate.dblquad(2차원 다변수함수 이름, x구간 시점, x구간 종점, y구간 시점, y구간 종점)sp.integrate.dblquad(f, 1, np.inf, lambda x : 0, lambda x : np.inf) f는 2차원 다변수함수다. x의 구간 시점과 종점 차례로 입력한다. y구간 시점과 종점에는 각 시점. 종점 값들을 입력변수가 x인 함수 꼴로 넣어야 한다.수치 이중적분 예)def f(x,y) : return np.exp(-x*y)/y**2sp.integrate.dblquad(f, 1, np.inf, lambda x : 0, lambda x : np.inf)out : 0.49999, 1.06…왼쪽은 수치이중적분 값, 오른쪽은 오차상한값이 나온다.다차원 함수의 단일 정적분다차원 함수는 정적분 할 때. 그 입력변수 갯수만큼 정적분 해야 한다.예를 들어 2차원 함수는 정적분하려면 반드시 x에 대해 한 번, y에 대해 한 번.정적분을 총 두번 해야 한다.그런데만약 입력변수가 x,y 두 개인 2차원 함수인데 정적분을 x에 대해 한번만 하려면2차원 함수를 1차원 함수로 바꿔줘야 한다.즉, x,y 입력변수 갖는 2차원 함수에서 y 입력변수를 상수취급해야 한다.y 입력변수가 상수가 되면 함수에 입력변수가 x 하나만 남으므로, 함수가 사실상 1차원 함수가 된다.그러면 이 1차원 함수를 x에 대해 한 번 정적분할 수 있다.예)$f(x, y) = 6x^{2}+12xy+8y$라고 해보자.이 함수는 입력변수가 2개인 2차원 다변수함수다.이 함수의 정적분을 구하려면 $x$ 구간으로 한 번, $y$ 구간으로 한 번 총 두번 정적분 해야 한다.그런데 만약 $x$로 한 번만 정적분 하려면 어떻게 해야 할까.변수 $y$ 를 상수취급해서 함수를 1차원 함수로 바꿔야 한다.$f(x;y) = 6x^{2}+(12y)x+(8y)$위와 같이 $y$ 를 상수취급 하면 함수가 입력변수 $x$ 하나인 1차원 함수가 된다.이 1차원 함수를 $x$ 구간 에 대해 정적분 할 수 있다." }, { "title": "[파이썬/넘파이] 데이터분석/머신러닝에 유용한 넘파이 명령어 정리", "url": "/bioinfo.github.io/posts/useful_numpy_commands/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-08-25 00:00:00 +0900", "snippet": "이 글은 데이터분석/머신러닝에 유용한 넘파이 명령어를 기록해둔 것이다.필요할 때 바로바로 꺼내쓸 수 있도록 기록해 둔 저장소.np.argmax(반복가능자) 반복가능자 안 max 값의 인덱스를 반환해준다.np.argmin(반복가능자) 반복가능자 안 min 값의 인덱스를 반환해준다.np.meshgrid(x값, y값) 그리드포인트 (2차원 평면상의 벡터점들) 생성해준다. 3차원 그래프 그릴 때 쓴다. 인자로 각 벡터점들의 x값들, y값들 담는다. X,Y = np.meshgrid(x,y) 이런 식으로 생성한다. 즉, X좌표 Y좌표 배열이 따로 생긴다.np.dstack([X,Y])np.vstack([X,Y])np.hstack([X,Y])np.count_nonzero(배열) 배열 내 데이터 중에서 0이 아닌 값 갯수를 센다.np.bincount(배열) 배열 내에 0과 양의 정수가 각각 몇 개씩 있는지 세어 준다. 리스트 형태로 반환한다. minlength= : np.bincount 명령 결과로 나오는 리스트에 ‘최소’ 몇 개 카테고리값까지 표시할 건지 지정해줄 수 있다.np.where(조건-ndarray 객체, x,y) x,y가 없을 때 출력 : 조건에 맞는 ndarray 객체 원소의 인덱스 x, y가 있을 때 출력 : ndarray 객체 원소 중 조건에 맞으면(True) x 출력. 조건에 안 맞으면(False) y출력예)x = np.array([1,2,3,4,5])np.where(x&gt;3, 0, 1)out : array([1,1,1,0,0])혹은x = np.array([1,2,3,4,5])np.where(x&gt;3)out : array([3,4])ndarray의 3, 4번 인덱스 값이 조건에 맞는다~ 라는 뜻.np.roots([계수1, 계수2, 계수3 …]) 고차방정식 해(근) 구하는 함수 사용법 :예를 들어 고차방정식 $ax^{2}+bx^{1}+c$ 가 있다고 하자.고차방정식의 고차항 계수 a,b,c 를 1차원 array로 만든다. 예) 리스트그리고 np.roots() 에 계수들의 array를 넣어주면 바로 방정식의 근을 뱉어낸다.np.flip() 괄호 안에 array 배열을 받는다. 입력받은 array 좌우를 뒤집는다." }, { "title": "[수학/미적분] 다양한 함수 소개, 함수 기본개념 복습, 함수 그래프로 표현법", "url": "/bioinfo.github.io/posts/function_basic/", "categories": "Data Science, python, mathematics", "tags": "datascience, mathematics, python", "date": "2021-08-25 00:00:00 +0900", "snippet": "함수정의 :입력과 출력 사이 일정한 대응’관계’포인트는 일정한 대응 ‘관계’다.일정한 대응관계 이기 때문에, 임의의 입력값 하나에는 특정한 출력 1개만 대응될 수 있다.예)항상 2에 대해 3이 대응되는 경우 2와 3은 함수관계에 속해있다.$f(2) = 3$만약 임의의 입력값에 대해서 출력값이 계속 바뀌면 함수관계 아니다.예)$f(2) = 3, f(2) = 5 …$함수관계 아니다.정의역정의 : ‘가능한’ 모든 입력변수들 집합 실수 전체를 쓰는 경우가 많다.공역정의 : ‘가능한’ 모든 출력변수들 집합치역정의 : 출력변수들 집합. 함수관계에서 정의역에 대응됨.정의역 갯수가 유한할 경우, 함수관계를 표로 나타낼 수 있다.예)x와 y가 일정한 대응관계에 있다면, 위 표는 x와 y의 함수관계를 표현한 것이다.또, 정의역 갯수가 유한한 경우 딕셔너리로 함수관계를 나타낼 수도 있다.# 딕셔너리로 함수 표현하기 f = {3:3.4, 8:1.2, 9:21, 10:23}f[3] # 3 입력출력 : 3.4‘입력과 출력 사이 일정한 대응관계’한편, 정의역 개수가 무한하면 일일이 표나 딕셔너리로 함수를 나타낼 수 없다.이때는 파이썬의 함수를 이용하면 이러한 수학 함수를 표현할 수 있다.예)# 함수def f(x) : return 2*x함수의 연속과 불연속불연속함숫값이 중간에 갑자기 바뀌면 함수가 ‘불연속’ 이다.함수가 불연속 구간이 있으면 그 구간에서 미분불가능이다.연속함수가 불연속이 아니면 연속이다.연속인 함수는 전 구간 미분가능하다.데이터분석에 자주 쓰이는 함수 정리1. 부호함수 (sign function)정의 : 입력값의 부호를 판별하는 함수입력값이 양수면 1.음수면 -1.0이면 0 출력.# 부호함수def sign(x) : if x &gt; 0 : return 1 elif x &lt; 0 : return -1 else : return 0넘파이 부호함수# 넘파이 부호함수np.sign(입력값)2. 단위계단함수(heavisidestep function)정의 : 0에서 계단 높이가 1인 함수입력값이 0 또는 양수 : 1입력값이 음수 : 0출력# 단위계단함수def heavi_side_step(x) : if x &gt;= 0 : return 1 elif x &lt; 0 : return 0넘파이 코드는 따로 없다. 만들어 쓰자.부호함수 &amp; 단위계단함수 그래프xx = np.linspace(-3,3,100)yy = np.sign(xx)plt.subplot(211) # plt.subplot(2,1,1)과 같다. plt.plot(xx, yy, 'ro-')plt.title('부호함수')plt.hlines(0, xmin=-3, xmax=3, colors='r', ls=':')plt.subplot(2,1,2)plt.title('단위계단함수')def heavi_side_step(x) : if x &gt;= 0 : return 1 elif x &lt; 0 : return 0heavi_side_step = [heavi_side_step(x) for x in xx]plt.plot(xx, heavi_side_step, 'ro-')plt.suptitle('부호함수와 단위계단함수', y=1.03)plt.tight_layout()plt.show()지시함수정의 : ‘지시’해둔 값이 입력으로 들어오면 1(True) 출력, 아니면 0(False) 출력하는 함수$I_{i}(x)$$I(x=i)$$i$ 가 미리 지정해놓은 값이다# 지시함수def indicator_function(x, i) : if x == i : return 1 # true elif x != i : return 0 # false 지시함수는 표본중에 내가 찾고 싶은 특정 값이 몇 개 있는지 셀 때 유용하다.예)$N_{3} = \\sum_{i}^{N}{I(x_{i} = 3)}$np.random.seed(0)x = np.random.randint(1,5,100)def indicator_function(x, i) : if x == i : return 1 # true elif x != i : return 0 # falseresult = np.sum([indicator_function(x, 3) for x in x])print('3갯수 : {}'.format(result))3 갯수 : 19np.bincount(x, minlength=10)[3]19역함수정의 : 어떤 함수에서 x와 y 자리를 바꾼 함수.또는 함수를 $y=x$ 에 대해 대칭시킨 함수를 원래 함수의 ‘역함수’ 라고 한다.xx = np.linspace(0,3,300)def f(x) : return x**2def finv(x) : return np.sqrt(x)plt.figure(figsize=(4,4))plt.plot(xx, f(xx), ls='-.')plt.plot(xx, finv(xx), ls=':')plt.plot(xx, xx, ls='--', c='g')plt.axis('equal')plt.xlim(-1, 3)plt.ylim(0,3)plt.title('원래 함수 $y=x^{2}$의 역함수 $(x&gt;0)$')plt.show()최대함수정의 :입력변수 $x$, $y$ 둘을 입력받아서 둘 중 최댓값을 출력하는 함수 $x = y$ 인 경우에는 $x$ 를 출력한다.$max(x,y)$# 최대함수def max(x,y) : if x &gt;= y : return x elif x &lt; y : return y넘파이 최대함수# 넘파이 최대함수 np.maximum(x,y)최대함수 그래프# 최대함수 그래프 np.maximum(2,3)xx = np.linspace(-10,10,1000)plt.plot(xx, np.maximum(xx,5))plt.scatter(5,5, 100, 'r')plt.title('최대함수')plt.text(8.5, 6.5, '$y=x$')plt.text(5.4, 5.3, '$y=0$')plt.text(-2.5, 5.1, '$y=0$')plt.show()최소함수정의 :입력변수 $x$, $y$ 를 입력받아 둘 중 최솟값을 출력하는 함수. $x=y$ 일때는 $x$ 출력한다.$min(x,y)$# 최소함수 def min(x,y) : if x &lt;= y : return x elif x &gt; y : return y넘파이 최소함수# 넘파이 최소함수 np.minimum(x,y)최소함수 그래프# 최소함수 xx = np.linspace(-3,6,1000)plt.plot(xx, np.minimum(xx, 3))plt.scatter(3,3,100, 'r')plt.text(4,2.8, '$y=3$')plt.text(3, 2.7, '$y=3$')plt.text(0, -0.5, '$y=x$')plt.title('최소함수')plt.show()ReLU 함수정의 :y값을 0으로 고정시킨 최대함수.$max(x,0)$ $x$가 0보다 클 때는 $x$ 출력 $x$가 0보다 작을 때는 0 출력 $x=0$ 일때는 $x$출력# ReLU 함수 def ReLU(x) : if x &gt;=0 : return x elif x &lt; 0 : return 0넘파이 ReLU 함수# 넘파이 렐루함수np.maximum(x,0)ReLU 함수 그래프# 렐루함수 xx = np.linspace(-5,5,1000)plt.plot(xx, np.maximum(xx, 0))plt.xlabel('$x$')plt.ylabel('$ReLU(x,0)$')plt.title('$max(x, 0)$ 또는 $ReLU$ 함수')plt.scatter(0,0, 100, 'r')plt.text(3, 1.5, '$y=x$')plt.text(-2, 0.25, '$y=0$')plt.text(0.1, 0, '$y=0$')plt.show()지수함수정의 :오일러수 $e$의 거듭제곱으로 이루어진 함수.$y = e^{x}$특징 : 그래프가 전구간 $x$축 위에 있어서 출력값 항상 양수다. $x$ 가 $0$ 일때 출력값이 $1$ 이다. $x$가 $+\\infty$ 로 갈 때, $y$도 $+\\infty$ 로 간다. $x_{1}$ &gt; $x_{2}$ 일 때, $f(x_{1})$ &gt; $f(x_{2})$ 이다.지수함수 그래프xx = np.linspace(-2,2,100)yy = np.exp(xx)plt.plot(xx,yy)plt.title('지수함수 $y=e^{x}$')plt.xlabel('$x$')plt.ylabel('$exp(x)$')plt.axhline(1, ls=':', c='r')plt.axhline(0, ls=':', c='g')plt.axvline(0, ls='-.', c='b')plt.show()로지스틱함수 (시그모이드함수)정의 :지수함수의 변형함수.회귀분석, 인공신경망 등에 자주 쓰인다.$y = \\frac{1}{1+e^{(-x)}}$# 로지스틱함수 xx = np.linspace(-10,10,100)def plot_logistic(x) : return 1/(1+np.exp(-x))yy = plot_logistic(xx)plt.plot(xx, yy)plt.title('로지스틱함수(시그모이드함수)')plt.xlabel('$x$')plt.ylabel('$logistic(x)$')plt.show()로그함수정의 :지수함수 $y=e^{x}$ 의 역함수.$y = \\log_{e}{x}$$y = \\log{x}$특징 : $x$ &gt; $0$ 인 구간에서만 정의된다. $x = 1$ 일 때 출력값 $0$ 이다. $x$가 $0$을 향해 다가갈 때, $y$는 $-\\infty$ 를 향해 다가간다. $x_{1}$ &gt; $x_{2}$ 일 때, $f(x_{1})$ &gt; $f(x_{2})$ 가 성립한다.로그함수 그래프# 로그함수xx = np.linspace(-10,10,1000)yy = np.log(xx)plt.title('$\\log_{e}{x}$ 로그함수')plt.plot(xx, yy, 'r')plt.axvline(0, c='b', ls=':')plt.axvline(1, c='b', ls=':')plt.axhline(0, c='g', ls='-.')plt.scatter(1,0, 100, 'r')plt.xlabel('$x$')plt.ylabel('$\\log_{e}{(x)}$')plt.show()로그함수의 몇 가지 유용한 성질1. 로그는 곱셈을 덧셈으로 바꿔준다.$\\log{(ab)} = \\log{a}+\\log{b}$많은경우, 로그 씌우면 계산이 편해진다.예) 로그가능도함수2. 정의역이 양수만으로 구성되어 있을 때, 최적화 목적함수에 로그 씌워도. 최소점,최대점 위치는 바뀌지 않는다.최적화 할 때 매우 유용하다.최적화의 목적은 최소출력, 최대출력을 만드는 최적해 찾기다.목적함수에 로그 씌워도 함수 높낮이는 변할지언정 최소점, 최대점은 변하지 않는다.곧, 최적해는 그대로라는 말이다.따라서 목적함수에 로그 씌울 때 계산이 더 편한 경우 로그 씌우고 최적화 할 수 있다.def ff(x) : return x**3-12*x+20*np.sin(x) + 7xx = np.linspace(-4,4,300)yy = ff(xx)plt.subplot(2,1,1)plt.plot(xx, yy)plt.title('$x^{3}-12x+20\\sin(x) + 7$')plt.xlabel('$x$')plt.ylabel('f(x)')plt.axhline(np.max(yy), ls=':', c='k')plt.axhline(np.min(yy), ls=':', c='k')plt.axvline(xx[np.argmax(yy)], c='g')plt.axvline(xx[np.argmin(yy)], c='g')plt.subplot(2,1,2)plt.plot(xx, np.log(yy))plt.axhline(np.max(np.log(yy)), ls=':', c='r')plt.axhline(np.min(np.log(yy)), ls=':', c='r')plt.axvline(xx[np.argmax(np.log(yy))], c='g')plt.axvline(xx[np.argmin(np.log(yy))], c='g')plt.title('$\\log(x^{3}-12x+20\\sin(x) + 7)$')plt.ylabel('$\\log{f(x)}$')plt.suptitle('최적화 목적함수 $f(x)$에 로그 취해도 최적해 위치는 같다', y=1.03)plt.tight_layout()plt.show()3. 0~1 사이 고만고만한 값들 로그 씌우면. 값들 간 간격을 $-\\infty$ 부터 $0$ 사이로 쭉쭉 늘려준다.따라서 비슷비슷한 값들 간 비교가 쉬워진다.np.random.seed(0)x = np.random.rand(5)x = x/np.sum(x)plt.subplot(211)plt.bar(np.arange(1,6), x)plt.ylim(0, 1)plt.ylabel('$x$')plt.title('0, 1 사이 숫자들의 $\\log$ 변환')plt.subplot(212)sns.barplot(np.arange(1,6), np.log(x))plt.ylabel('$\\log{x}$')plt.show()소프트플러스 함수지수함수와 로그함수를 합쳐놓은 형태다.$y = \\log{(1+e^{x})}$ $x=0$ 부근에서 함수가 부드럽게 증가한다. 렐루함수와 비슷하게 생겼다. 하지만 렐루함수는 $x=0$ 에서 불연속이기 때문에 $x=0$ 지점에서 미분불가능하다. 반면 소프트플러스함수는 $x=0$ 지점에서 연속이기 때문에 미분가능하다.# 소프트플러스 함수 def plot_softplus(xx) : return np.log(1+np.exp(xx))# 소프트플러스 함수 그래프xx = np.linspace(-10,10,1000)yy = plot_softplus(xx)plt.plot(xx, yy)plt.suptitle('소프트플러스 함수', y=1.03)plt.title('장점 : 전 구간 미분가능(연속)')plt.xlabel('$x$')plt.ylabel('$\\zeta(x)$')plt.show()다변수함수정의 :다차원 벡터 입력 받아 스칼라 출력하는 함수$f(x_{1}, x_{2})$입력벡터 $x$$x = [x_{1}, x_{2}]$$n$차원 함수 :다변수함수를 입력벡터 차원에 따라 $n$차원 함수라고도 부른다.예) 입력벡터 : 2차원 벡터$\\Rightarrow$ 2차원 함수2차원 함수를 그래프로 표현하기예를 들어 입력벡터 차원이 2차원인 다변수함수는 2차원 함수다.2차원 함수는 그래프로 표현하면 3차원 형상으로 표현된다.(마치 3차원 지형과도 같다)2차원 함수를 3차원 그래프로 표현해보자.$f(x,y) = 2x^{2}+6xy+7y^{2}-26x-54y+107$위 2차원 다변수함수로 3차원 서피스 플롯, 컨투어플롯을 그려보자.3차원 서피스플롯# 3차원 서피스플롯def f(x,y) : return 2*x**2+6*x*y+7*y**2-26*x-54*y+107xx = np.linspace(-10,10,100)yy = np.linspace(-10,10,100)X,Y = np.meshgrid(xx,yy)Z = f(X,Y)fig = plt.figure()ax = fig.gca(projection='3d')ax.plot_surface(X,Y,Z,linewidth=0.3, cmap='BrBG')ax.view_init(40, -110)plt.xlabel('$x$')#plt.ylabel('$y$')ax.set_zlabel('$z$')plt.title('3차원 서피스 플롯')ax.set_zticks([])ax.set_xticks([])ax.set_yticks([])plt.show()컨투어플롯CS = plt.contour(X,Y,Z, levels=np.logspace(0,3,10))plt.clabel(CS, fmt= '%d')plt.title('컨투어 플롯')plt.ylim(-10,10)plt.xlim(-10,10)plt.show()위 컨투어 플롯을 다시 서피스플롯으로 표현해보자.ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z, linewidth=0.3, cmap='RdYlGn')ax.view_init(30,100)ax.set_zticks([])ax.set_yticks([])ax.set_xticks([])plt.show()위 서피스플롯(가운데가 들어가고 바깥쪽이 위로 솟는) 을 위에서 바라본 것이 앞에서 그렸던 컨투어플롯이다.분리가능 다변수함수정의 :$f(x,y) = f_{1}(x)f_{2}(y)$.2차원 다변수함수 $f(x,y)$ 가 있을 때, 이를 $f_{1}(x)f_{2}(y)$ 로 나타낼 수 있으면. ‘분리가능 다변수함수’ 라고 한다.두 확률변수가 독립일 때, 두 확률변수에서 나온 모든 표본들은 서로 독립이었다.확률에서 두 사건이 독립인 경우, 다음과 같은 성질이 있었다.$p(x,y) = p(x)p(y)$결합확률밀도함수를 주변확률밀도함수 곱 으로 표현가능했다.이때의 결합확률밀도함수 또한 분리가능 다변수함수라고 볼 수 있다.$f(x,y) = f(x)f(y)$$p(x,y) = p(x)p(y)$분리가능 다변수함수 단면모양은 모두 같다위 경우 분리가능 다변수함수는 2차원 함수다.2차원 함수는 3차원 그래프로 나타낼 수 있다.예를 들면 이렇게 생겼다는 거다.(아래 이미지는 2차원 함수를 3차원 그래프로 나타낸 예시일 뿐, 분리가능다변수함수와는 상관 없다.)# 2차원 함수의 3차원 그래프 예시mu = np.array([1,0])rv = sp.stats.multivariate_normal(mu)xx = np.linspace(-5,5,100)yy = np.linspace(-5,5,100)X,Y = np.meshgrid(xx,yy)ax = plt.gca(projection='3d')ax.plot_surface(X,Y, rv.pdf(np.dstack([X,Y])), linewidth=0.2, cmap='coolwarm')ax.set_xticks([])ax.set_yticks([])ax.set_zticks([])plt.title('2차원 함수의 입체 3차원 그래프 예시')plt.show()이렇게 3차원 ‘지형’과도 같은 2차원 함수는 $x$ 또는 $y$ 값을 고정한 채 케이크 썰듯이 단면을 자를 수 있다.예를 들면 $y$ 값을 $3$ 으로 고정한 채 $x$ 값만 전 구간 변화시키면 $x$변수에 대한 그래프는 위 3차원 도형을 $y=3$ 에서 칼로 자른 단면이 된다.분리가능다변수함수의 경우, 이 단면 모양이 모두 같다.$p(x,y) = p(x)p(y)$if $ y = y_{0}, $$p(x, y_{0}) = p(x)p(y_{0})$위 식에서 $p(x, y_{0})$ 은 $x$ 변수만 갖는 단변수함수가 된다.또, 3차원 도형을 $y=y_{0}$ 지점에 고정시켜놓고 자른 단면을 표현한 것이다.$p(x)p(y_{0})$ 에서, $p(y_{0})$ 은 $y_{0}$ 값에 따라 변하는 특정 상수다.그러면,$k_{0}p(x)$ 이다.결국$p(x, y_{0}) = k_{0}p(x)$ 가 된다.마지막 수식 의미는.$p(x,y)$ 를 $y=y_{0}$ 에서 자른 단면은 $k_{0}p(x)$ 와 같다는 것이다.$k_{0}p(x)$ 는 모양은 $p(x)$ 이고, 그 높이가 $k_{0}$ 에 따라 변한다.반대로 $x = x_{0}$ 으로 고정시켰을 때도 똑같이 성립한다.결국 분리가능다변수함수 $p(x,y) = p(x)p(y)$ 단면은 모양은 $p(x)$ 또는 $p(y)$ 로 모두 같고, 그 높이만 다르다.$\\Rightarrow$ 분리가능다변수함수 단면은 모양이 모두 같다!시각적으로 나타내면 아래와 같다.가운데 가장 큰 컨투어플롯이 분리가능다변수함수의 그래프다.위쪽 $g_{1}(x)$ 는 $y=y_{0}$에 고정시켜 놓고 분리가능다변수함수를 케잌 자르듯 자른 단면들이다.보면 높이는 다르지만 모양은 다 같은 걸 볼 수 있다.다변수 다출력 함수정의 :단변수함수는 스칼라를 입력받아 스칼라를 출력하는 스칼라함수이다.다변수함수는 다차원벡터를 입력받아 스칼라를 출력하는 스칼라함수이다.다변수다출력함수는 다차원벡터를 입력받아 다차원벡터를 출력하는 벡터함수이다.소프트맥스 함수다변수 다출력함수의 대표적 예다.다차원 벡터 입력받아 다차원 벡터 출력한다.주요 기능 및 특징 :다차원벡터를 입력 받아 벡터 각 원소 꼴을 ‘확률 꼴’로 바꿔서 출력해주는 함수다.물론 출력은 벡터다. 출력벡터 각 원소는 0과 1 사이 값이다. 출력벡터 각 원소 총합 $=1$ 이다. 입력벡터 원소 크기 순서가 출력벡터에서 그대로 유지된다.쓰임 :주로 인공신경망 끝단에 사용되어서 인공신경망의 출력을 입력받아 확률 꼴로 바꿔 다시 출력한다.수식 :$softmax(x_{1}, x_{2}, x_{3}) =$$[\\frac{exp(w_{1}x_{1})}{exp(w_{1}x_{1})+exp(w_{2}x_{2})+exp(w_3, x_{3})}, \\frac{exp(w_{2}x_{2})}{exp(w_{1}x_{2})+exp(w_{2}x_{2})+exp(w_{3}x_{3})}, \\frac{exp(w_{3}x_{3})}{exp(w_{1}x_{2})+exp(w_{2}x_{2})+exp(w_{3}x_{3})}]^{T}$파이썬 코드로 표현한 소프트맥스함수 :# 소프트맥스 함수 def softmax(x,w) : e = np.exp(w*x) return e/np.sum(e)예)소프트맥스 함수를 사용해서 임의의 입력벡터 각 원소를 ‘확률 꼴’ 로 바꿔 출력해보자.$x = [2, 0.8, 1]$ 을 입력벡터로 쓰겠다.가중치벡터 $w$는 1벡터 $1_{3} = [1,1,1]$ 쓰겠다.# 소프트맥스함수 사용 예w = np.ones(3)x = np.array([2,0.8,1])def softmax(x,w) : e = np.exp(w*x) return e/np.sum(e)y = softmax(x,w)y, np.sum(y)벡터 $x = [2,0.8, 1]$ 을 소프트맥스 함수에 넣은 결과물을 보면 출력벡터 각 원소는 0과 1 사이 값이다. 출력벡터 모든 원소 합은 1이다. 입력벡터 크기 순서가 출력벡터에서 그대로 유지된다.소프트맥스 함수 출력의 세 가지 주요 특징이 그대로 성립한다.입력벡터 $x$ 를 받아 이 벡터 각 원소를 ‘확률 꼴’로 바꿔 출력했음을 확인할 수 있다.가중치가 커지면 최댓값_최솟값 사이 간격 더 벌어진다 :소프트맥스 함수에서는 가중치벡터 $w$ 각 원소 값(가중치)들이 커지면, 입력벡터의 최댓값과 최솟값 사이 간격이 각 출력값에서 더 벌어진다.# 예) 가중치 크기 1-&gt; 3 으로 증가softmax(x, 3*w)예를 들어 모두 $1$ 이었던 가중치 $w_{1}, w_{2}, w_{3}$ 크기를 $3$ 으로 증가시켜보았다.가중치를 증가시켰을 때, 출력벡터는 위와 같다.앞에서 가중치 1일 때 출력은 아래와 같았다.가중치 1이었을 때는 최댓값과 최솟값이 0.59 _ 0.18 로 바뀌어 출력됬다면, 가중치 3일 때는 최댓값 최솟값이 0.92 _ 0.02 로 둘 사이 간격이 훨씬 멀어졌음을 볼 수 있다.plt.subplot(2,1,1)plt.xlim(0, 1)plt.axhline(0, c='b', ls=':')plt.scatter(0.18045591, 0, 100, 'r')plt.scatter(0.59913473, 0, 100, 'r')plt.text(0.2, 0.02, '최솟값')plt.text(0.55, 0.02, '최댓값')plt.hlines(0, xmin=0.18, xmax=0.6, colors='g')plt.title('가중치 1일 때')plt.subplot(2,1,2)plt.xlim(0,1)plt.axhline(0, c='b', ls=':')plt.scatter(0.02536761, 0, 100, 'b')plt.scatter(0.9284096, 0, 100, 'b')plt.text(0.03, 0.015, '최솟값')plt.text(0.92, 0.015, '최댓값')plt.hlines(0, xmin=0.03, xmax=0.92, colors='g')plt.title('가중치 3일 때')plt.suptitle('소프트맥스 함수 출력의 최댓값_최솟값 사이 거리 변화')plt.tight_layout()plt.show()함수 평행이동정의 :‘출력’을 이동하라 (입력이 그대로 일 때)설명)함수는 ‘입력과 출력 사이 일정한 대응관계’였다.만약 $A$ 라는 입력에 출력이 1만 대응된다면, $A$와 1은 함수관계가 있다.하지만 같은 입력에 출력이 무작위로 바뀐다면, 둘은 함수관계가 있다고 말할 수 없다.곧, 함수관계에서는 어떤 입력에 특정한 출력이 대응된다고 정리할 수 있다.함수가 ‘대응관계’라면, 함수 평행이동은 ‘대응관계’를 이동시켜라는 의미다.이는 대응관계를 어떤 특정 방식으로 ‘변화’시켜라는 의미로 해석할 수도 있다.대응관계를 변화시킨다는 말은, 기존 입력값들에 대해 이제부터 다른 출력값들이 대응되게 한다는 말과 같다.따라서, 함수를 평행이동시킨다는 건 입력은 유지시키면서 출력을 변화시킨다는 뜻과 같다.함수평행이동 = [출력 이동]그러면 입력값들이 같을 때, 기존 입력값에 어떤 출력이 새로 대응되어야 함수가 ‘평행이동’ 할까?예를 들어 함수를 오른쪽으로 2.5만큼 평행이동 하고싶다면 뭘 새로 대응시켜야 할까?함수 $f(x)$ 의 입력값 $x$ 가 있다고 하자.$x$에 대응되는 출력값은 $f(x)$ 다.함수 $f(x)$ 를 오른쪽으로 $2.5$ 만큼 이동시키려면, 원래 $x$보다 2.5만큼 뒤에 있던 점의 함숫값이 $x$에 대응되어야 한다.곧, $x$에 대해 $f(x-2.5)$ 가 대응되어야 한단 뜻이다.평행이동 전 함수 $f(x)$의 정의역 모든 원소들에 똑같이 $f(x-2.5)$ 를 대응시키면, 결과적으로 함수가 오른쪽으로 $2.5$ 만큼 이동한다.# 함수 평행이동xx = np.linspace(-10,10,100)plt.plot(xx, plot_logistic(xx), c='c', label='f(x)')plt.scatter(2.5,0, 100, 'c')plt.text(2.3, 0.05, '$x$')plt.scatter(0,0,100, 'm')plt.text(-0.05,0.05, '$x-2.5$')plt.scatter(0, plot_logistic(0), 100, 'm')plt.hlines(0, xmin=0.3, xmax=2.2, colors='m')plt.annotate('', xy=[2.5, plot_logistic(0)], xytext=[0, plot_logistic(0)], arrowprops={'facecolor' : 'm'})plt.scatter(2.5, plot_logistic(0), 100, 'm')plt.text(2.65, 0.55, '$f(x-2.5)$')plt.text(-2.3, 0.55, '$f(x-2.5)$')plt.vlines(2.5, ymin=0.03, ymax=plot_logistic(0), colors='r', ls=':')plt.scatter(2.5, plot_logistic(2.5), 100, 'm')plt.annotate('', xy=[5, plot_logistic(2.5)], xytext=[2.5, plot_logistic(2.5)], arrowprops={'facecolor' : 'm'})plt.scatter(5, plot_logistic(2.5), 100, 'm')plt.scatter(1.02, plot_logistic(1.02), 100, 'm')plt.annotate('', xy=[3.52, plot_logistic(1.02)], xytext=[1.02, plot_logistic(1.02)], arrowprops={'facecolor' : 'm'})plt.scatter(3.52, plot_logistic(1.02), 100, 'm')plt.plot(xx, plot_logistic(xx-2.5), c='m', ls=':', label='f(x-2.5)')plt.title('함수 평행이동 원리')plt.xlabel('$x$')plt.legend()plt.show()결국 함수를 오른쪽으로 2.5만큼 이동하고 싶으면$f(x) \\Rightarrow f(x-2.5)$하면 되는 것이다.정리 및 요약 :- 함수를 오른쪽으로 2.5만큼 이동 :$f(x) \\Rightarrow f(x-2.5)$- 함수를 왼쪽으로 2.5만큼 이동 :$f(x) \\Rightarrow f(x+2.5)$- 함수를 위로 2.5만큼 이동 :$f(x) \\Rightarrow f(x)+2.5$- 함수를 아래로 2.5만큼 이동 :$f(x) \\Rightarrow f(x)-2.5$함수 평행이동 예)로지스틱함수를 오른쪽으로 5 이동, 아래로 1 이동 해보자.$f(x) \\Rightarrow f(x-5)-1$# 로지스틱함수 오른쪽으로 5, 아래로 1 이동xx = np.linspace(-10,10,1000)plt.plot(xx, plot_logistic(xx), c='m', label='$\\sigma(x)$')plt.plot(xx, plot_logistic(xx-5)-1, c='c', label='$\\sigma(x-5)-1$')plt.title('로지스틱함수 오른쪽으로 5 이동, 아래로 1 이동')plt.xlabel('$x$')plt.legend()plt.show()다변수함수 평행이동다변수함수 평행이동도 본질은 같다.다만 y축 방향으로 평행이동 할 때 좀만 더 주의 기울이면 된다.만약 다변수함수를 y축방향으로 $+0.75$ 하고싶다면 어떻게 해야 할까?y축 방향으로 $+0.75$ 이동한다는 건 y축 관점에서는 함수를 오른쪽으로 0.75만큼 이동한다는 거다. 따라서 기존 y 값에 $f(y-0.75)$ 값을 대응시키면 x축 관점에서는 함수가 y축 방향으로 $+0.75$ 만큼 이동한다.정리하면 다음곽 같다.다변수함수 평행이동 정리- x축 방향으로 +a, y축 방향으로 +b 만큼 이동 :$f(x) \\Rightarrow f(x-a, y-b)$- x축 방향으로 +a, y축 방향으로 -b 만큼 이동 :$f(x) \\Rightarrow f(x-a, y+b)$- x축 방향으로 -a, y축 방향으로 +b 만큼 이동 :$f(x) \\Rightarrow f(x+a, y-b)$- x축 방향으로 -a, y축 방향으로 -b 만큼 이동 :$f(x) \\Rightarrow f(x+a, y+b)$다변수함수 평행이동 예)# 다변수함수 오른쪽으로 0.7, 위로 0.8 이동xx = np.linspace(-1,1,100)yy = np.linspace(-1,1,100)def g(x,y) : return np.exp(-x**2-16*y**2)X,Y = np.meshgrid(xx,yy)Z = g(X,Y)Z2 = g(X-0.7, Y-0.8)plt.contour(X,Y,Z)plt.contour(X,Y,Z2, linestyles=':')plt.ylim(-0.5, 1)plt.text(-0.02, 0.02, '$f(x,y)$')plt.text(0.6, 0.8, '$f(x-0.7, y-0.8)$')plt.title('다변수함수의 평행이동')plt.annotate('', xy=[0.75, 0.0], xytext=[0,0], arrowprops={'facecolor' : 'red'})plt.annotate('', xy=[0.75, 0.8], xytext=[0.75, 0.0], arrowprops={'facecolor' : 'blue'})plt.show()함수 스케일링정의 :“축 방향으로 함수 잡아 늘리기”- 함수를 x축 방향으로 $a$ 배 늘리고 싶다면 :$f(x) \\Rightarrow f(\\frac{x}{a})$- 함수를 y축 방향으로 $b$ 배 늘리고 싶다면 :$f(x) \\Rightarrow bf(x)$함수 스케일링 예)# 로지스틱 함수를 x축 방향으로 1/5배, y축 방향으로 5배 스케일링xx = np.linspace(-10,10,1000)plt.plot(xx, plot_logistic(xx), label='$f(x)$')# x축으로 1/5배, y축 방향으로 5배 늘리자. plt.plot(xx, 5*plot_logistic(5*xx), label='5$f(5x)$', ls=':')plt.legend()plt.title('로지스틱함수 스케일링 : x축으로 1/5배, y축으로 5배 스케일링 결과')plt.show()" }, { "title": "[수학/선형대수] 주성분분석 (PCA)", "url": "/bioinfo.github.io/posts/PCA/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-08-21 00:00:00 +0900", "snippet": "잠재변수정의 :기저에 숨어서 여러 확률변수에 영향. 여러 확률변숫값을 동시에 결정짓는 확률변수특징 :직접 데이터 획득이 불가능하다.측정데이터와 잠재변숫값 사이 관계저차원벡터공간 기저벡터가 모두 단위벡터이고 정규직교한다고 하자.이때, 저차원벡터공간에 대한 투영벡터는 다음과 같이 나타낼 수 있다.예) 1차원$x^{\\Vert W} = [w_{1}][(x_{i}^{T}w_{1})]^{T}$예) 2차원$x^{\\Vert W} = [w_{1}, w_{2}][(x_{i}^{T}w_{1}),(x_{i}^{T}w_{2})]^{T}$예) 3차원$x^{\\Vert W} = [w_{1}, w_{2}, w_{3}][(x_{i}^{T}w_{1}),(x_{i}^{T}w_{2}), (x_{i}^{T}w_{3})]^{T}$특정 기저벡터 공간 상에서 벡터의 좌표는 기저벡터 선형조합에서 각 기저벡터 스칼라 계수와 같다.즉, 3차원이면 $[(x_{i}^{T}w_{1}),(x_{i}^{T}w_{2}), (x_{i}^{T}w_{3})]^{T}$ 이 부분이 3차원 기저벡터 상 투영벡터의 좌표다.한편, 위 식을 전개하면 $[(x_{i}^{T}w_{1}),(x_{i}^{T}w_{2}), (x_{i}^{T}w_{3})]^{T}$ 이 부분은 각 기저벡터 $w_{i}$ 의 가중치와 같다.저차원 공간 상에서 투영벡터 각 좌표 = 각 기저벡터가 투영벡터에서 차지하는 비중(가중치)저차원 공간 기저벡터 하나하나는 주성분벡터와 같았다.그러면각 기저벡터 가중치 = 투영벡터에서 각 주성분벡터 비중이다.이 주성분벡터 비중을 잠재변숫값으로 본다.결론적으로잠재변숫값 1개 = $(x^{T}w_{i})$ 이다.우변을 전개하면잠재변숫값 1개 = $ax_{1} + bx_{2}$ 이다.$x_{1}, x_{2}$ 는 $x_{i}$ 벡터가 담고 있던 측정데이터 1,2 다.$a,b$는 기저벡터 i의 각 요소다. 고정되어 있다.이를 통해 잠재변숫값은 측정데이터와 선형관계를 맺고 있다는 사실을 알 수 있다.$+$ 위 선형방정식에서는 측정데이터 $x_{1}, x_{2}…$ 별 가중치가 정해져 있다.이 가중치들은 각 변수들이 잠재변숫값에서 차지하는 비중이라 볼 수도 있다.만약 위 선형방정식이 다음과 같다고 해보자.$\\mu = 0.96x_{1}+0.27x_{2}$$x_{1}$ 은 잠재변숫값에서 0.96만큼의 비중을 차지할 것이다. $x_{2}$ 는 0.27만큼 비중을 차지할 것이다.잠재변숫값이 증가하거나 감소할 때, $x_{1}, x_{2}$ 도 대략 0.96 : 0.27의 비율을 유지하면서 증가, 감소할 것이다.잠재변수와 측정데이터 간 선형관계로 데이터가 규칙적으로 변이하는 이유를 설명할 수 있다.역으로, 데이터가 규칙성 가지고 변이한다면 기저에 잠재변수가 있기 때문일 수 있다.데이터가 규칙성 갖고 변이 할 때 PCA를 시도해 볼 수 있는 이유다.여러 확률변수에 동시에 영향 미치는 공통 잠재변수가 있는 것으로 보일 때 주성분분석PCA 를 시도할 수 있다.주성분분석PCA 목표와 의의목표 :다변수확률변수 데이터를 통해.다변수확률변수가 어떤 공통 잠재변수(들)의 영향을 받았고,해당 데이터는 어떤 잠재변수 영향을 얼만큼 받은 데이터인지 알아내는 것.의의 :다변수확률변수 데이터는 보통 2차원 이상의 고차원데이터이다.PCA를 통해 복잡해보이는 고차원데이터 변이를 몇 가지 요인(잠재변수)들 만 가지고 간단히 설명 가능하다.주성분분석PCA (차원축소)정의 :고차원데이터(벡터)와 가장 비슷한 저차원투영벡터를 찾고(차원축소),이 투영벡터를 만드는 ‘저차원공간 기저벡터’를 찾는 과정이다.곧, 랭크-K 근사 문제를 푸는 것 = PCA 분석이다.전제 :잠재변수 = 주성분(물론 완전히 똑같지는 않다. 하지만 비슷한 개념으로 이해했다.)따라서 주성분을 찾아야 잠재변수를 찾는 것이다.분석 :공통 잠재변수 영향 받는 것으로 보이는 고차원 데이터에 적용.고차원데이터를 저차원공간에 투영시켜 가장 비슷한 투영벡터를 만든다.이 투영벡터는 각 데이터의 공통부분, 노이즈를 제거하고 주성분으로만 구성된 벡터다. (주성분 선형조합으로 구성되어있다.)각 투영벡터마다 주성분이 얼만큼씩 들었는가를 찾아낸다.주성분은 원래 고차원 데이터를 구성하고, ‘결정’짓는 핵심성분이라 할 수 있다.투영벡터 별 주성분 비중을 찾아냄으로써 원래 고차원데이터가 어떤 핵심성분이 얼마나 들어있었는지 알아낸다.한편, 찾아낸 주성분을 통해 각 고차원데이터를 주성분 만으로 ‘설명’ 할 수 있다.예)올리베티 얼굴 이미지 데이터 : 이 데이터는 미소를 결정짓는 주성분 1이 7.5 만큼, 찡그린 표정을 결정짓는 주성분 2가 -9.9 만큼 들어있는 데이터다.이 이미지 속 인물이 다른 이미지에 비해 크게 미소짓고 있는 이유는 1번 주성분이 매우 많이 들어가고, 2번 주성분이 매우 적게 들어있기 때문이다.사이킷런 PCA 클래스from sklearn.decomposition import PCApca = PCA(n_components=n) pca 변수는 PCA 클래스로 생성한 객체다. n_components= 에 주성분 몇 개를 찾을 건지 넣어주면 된다. (몇 차원 공간에 투영할 건지 입력한다)PCA 클래스의 주요 속성과 메서드pca.components_ #1.pca.mean_ #2.pca.fit_transform(특징행렬) #3.pca.inverse_transform(좌표변환 된 저차원투영벡터) #4.속성 pca.components_ : 주성분벡터 (저차원공간 기저벡터) pca.mean_ : 특징행렬 데이터들의 평균벡터메서드 pca.fit_transform(특징행렬) : ‘평균 제거’한 고차원데이터들을 저차원투영벡터로 만들고, 좌표변환까지 해서 반환한다. (차원축소) pca.inverse_transform(fit_transform 결과물) : fit_transform 해서 차원축소된 고차원데이터의 저차원투영벡터를. 고차원기저벡터 기준.으로 다시 좌표변환한다. 그리고 처음에 제거했던 평균을 더해서 반환한다. PCA 분석하기1. 붓꽃 데이터 PCA 분석하기붓꽃 꽃받침 길이, 꽃받침 폭만 가지고 PCA 분석을 해보자.데이터 살펴보기두 데이터를 먼저 한번 살펴보자.from sklearn.datasets import load_irisiris = load_iris().dataN = 10X = iris[:N,:2]plt.plot(X.T, 'o:')plt.xticks(range(4), ['꽃받침 길이', '꽃받침 폭', '',''])plt.xlim(-0.5,2)plt.ylim(2.5, 6)plt.title('꽃받침 길이-꽃받침 폭 크기 특성')plt.legend([f'표본 {i+1}' for i in range(N)])plt.show()위 그래프에서 두 확률변수에서 얻은 데이터 사이 관계를 보자.대체로 꽃받침 길이가 증가하면, 꽃받침 폭도 함께 증가했다.혹은 꽃받침 폭이 증가하면, 꽃받침 길이가 증가했다.두 확률변수 사이에는 상관관계가 있는 것으로 보인다.df = pd.DataFrame(X, columns=load_iris().feature_names[0:2])sns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', data=df)위 스캐터 플롯으로 봐도 마찬가지다. 한 개 확률변숫값이 증가하면, 다른 확률변숫값도 증가했다.두 확률변수 사이 선형상관관계가 있는 건 확실해 보인다.X_0 = X[:,0]X_1 = X[:,1]sp.stats.pearsonr(X_0, X_1)[0]피어슨상관계수 값 : $0.7872066124624175$한편, 위 두 그래프를 보면 두 확률변숫값들의 비율은 대체로 일정함을 알 수 있다.종합하면, 두 확률변숫값들은 대체로 일정한 비율을 유지하며 함께 변화한다.이렇게 데이터 변이에 규칙성이 보일 때, 데이터들에 공통 잠재변수가 작용하고 있는 것은 아닌지 의심해볼 수 있다.데이터들에 작용하고 있는 공통 잠재변수와, 각 잠재변수 값들을 알아내는 방법이 PCA였다.PCA 분석 수행하기from sklearn.decomposition import PCApca = PCA(n_components=1)X_low = pca.fit_transform(X)X_low # 좌표변환된 1차원 투영벡터들기저에서 전체 데이터에 영향 미치고 있는 1개 주성분만 찾아보자. PCA 클래스 n_components 인자에 1을 넣으면 1차원에 벡터들을 근사시켜준다.결과array([[ 0.30270263], [-0.1990931 ], [-0.18962889], [-0.33097106], [ 0.30743473], [ 0.79976625], [-0.11185966], [ 0.16136046], [-0.61365539], [-0.12605597]])결과로 나온 위 행렬 각 행이 좌표변환한 1차원 투영벡터들이다.고차원 데이터를 차원축소시켜서 나오는 위 결과물은 각 잠재변수(주성분)가 1개 데이터 레코드마다 얼만큼 들어있는지 나타내기도 한다.위 결과물을 보니 첫번째 표본은 두번째 표본보다 주성분이 크게 작용하고 있음을 볼 수 있다.주성분 벡터전체 데이터레코드 기저에서 작용하고 있는 주성분은 다음과 같았다.pca.components_[0]$array([0.68305029, 0.73037134])$이 주성분은 특징행렬의 고차원데이터들과 가장 비슷한 저차원 투영벡터들을 만들어내는 저차원공간의 기저벡터다.PCA는 랭크-K문제를 푸는 것과 같다고 했다.랭크-K 문제에서는 가장 비슷한 투영벡터들 만들어내는 저차원공간 기저벡터가가장 큰 K개 특잇값에 대응되는 특징행렬 오른쪽 특이벡터들.또는 특징행렬로 만든 분산행렬에서 가장 큰 K개 고윳값에 대응되는 고유벡터들 과 같았다.PCA 클래스를 통해서 구한 주성분벡터(=저차원공간 기저벡터) 가 특징행렬의 특이벡터 또는 분산행렬 고유벡터와 같은지 직접 알아보자.1. 오른쪽 특이벡터와 주성분 벡터가 같은가?# 증명해보자. # 1. 특잇값분해 X0 = X-X.mean(axis=0)U, S, VT = np.linalg.svd(X0)-VT.T[:,0]array([0.68305029, 0.73037134])PCA 통해 주성분을 1개만 찾았기 때문에, 내가 찾은 주성분은 가장 큰 특잇값에 대응하는 오른쪽 첫번째 특이벡터일 것이다.PCA에서는 근사성능을 높이기 위해 특징행렬 데이터에서 평균값들을 제거하고 남은 데이터로 저차원 투영한다.따라서 특이벡터 찾을 때도맨 처음 특징행렬 $X$ 에서 평균값들을 제거한 것을 특징행렬로 써서 특잇값분해 한 뒤 특이벡터를 찾았다.특징행렬 $X0$를 특잇값분해 한 뒤, 오른쪽 첫번째 특이벡터를 구해서 주성분벡터와 비교했더니 같았다.2. 분산행렬 고유벡터와 주성분 벡터가 같은가?# 2. 고유분해 XTX = X0.T@X0ld, V = np.linalg.eig(XTX)-V[:, np.argmax(ld)]한편 평균 제거한 특징행렬로 만든 분산행렬 $X^{T}X$ 를 만들었다. 특잇값분해 - 고윳값분해 사이 관계에 의해서 오른쪽 특이벡터 행렬은 고유벡터 행렬과 같았다.오른쪽 특이벡터 행렬에서 첫번째 특이벡터가 주성분 벡터와 같았다.그러면 고유벡터 행렬에서 첫번째(가장 큰 고윳값에 대응) 고유벡터가 주성분 벡터와 같을 것이다.파이썬 eig() 명령으로 분산행렬을 고윳값분해 한 뒤, 가장 큰 고윳값에 대응되는 고유벡터를 찾았다.array([0.68305029, 0.73037134])역시 주성분 벡터와 같았다.붓꽃 주성분의 의미앞에서 PCA를 통해 붓꽃 데이터의 주성분을 찾아냈다.pca.components_[0]array([0.68305029, 0.73037134])그리고 fit_transform() 을 통해 각 데이터 레코드에 이 주성분이 얼마나 들어있는지(주성분비중) 도 찾아냈다.from sklearn.decomposition import PCApca = PCA(n_components=1)X_low = pca.fit_transform(X)X_low # 1차원 투영벡터들array([[ 0.30270263], [-0.1990931 ], [-0.18962889], [-0.33097106], [ 0.30743473], [ 0.79976625], [-0.11185966], [ 0.16136046], [-0.61365539], [-0.12605597]])첫번째 데이터레코드에는 두번째보다 상대적으로 많이 들어있는 이 주성분의 의미는 뭘까?위 주성분 비중은 측정데이터와 선형관계를 가진다.예를 들어 첫번째 데이터에서 주성분비중과 측정데이터 관계는 다음과 같다.첫번째 측정 데이터X-pca.mean_[0]$[ 0.24, 0.19]$$0.30270263 = [ 0.24, 0.19][0.68305029, 0.73037134]^{T}$$ 0.30270263 = 0.68 \\times (0.24) + 0.73 \\times (0.19) $괄호 안이 측정데이터다.잠재변숫값이 꽃잎 길이와 꽃잎 폭의 선형조합 결과로 나온다. 곧, 이 잠재변수는 ‘꽃 크기’ 임을 추측해볼 수 있다.이렇게 결론 내리고 다시 맨 처음 특징행렬 데이터로 돌아가보자.특징행렬 데이터array([[ 0.24, 0.19], [ 0.04, -0.31], [-0.16, -0.11], [-0.26, -0.21], [ 0.14, 0.29], [ 0.54, 0.59], [-0.26, 0.09], [ 0.14, 0.09], [-0.46, -0.41], [ 0.04, -0.21]])(평균이 제거되어 있다.)주성분 비중 데이터array([[ 0.30270263], [-0.1990931 ], [-0.18962889], [-0.33097106], [ 0.30743473], [ 0.79976625], [-0.11185966], [ 0.16136046], [-0.61365539], [-0.12605597]])이렇게 결론내릴 수 있다.첫번째 데이터레코드(특징행렬 1행) 는 ‘꽃 크기’라는 주성분 비중이 크다. 곧, 꽃잎 길이와 꽃잎 폭이 모두 다른 데이터레코드보다 큰 이유는 꽃 크기가 커서 그렇다.이미지 PCA이번에는 올리베티 얼굴사진 데이터에 PCA 분석을 해보자.얼굴사진 데이터를 PCA 분석하면, 얼핏 비슷비슷해보이는 각 이미지 데이터들의 차이를 결정짓는 몇 가지 핵심성분을 뽑아낼 수 있을 것이다.이 과정을 통해데이터를 구성하는 핵심 성분이 뭔지,이게 어떻게 작용하면서 각 데이터 간 차이를 만들어내는지 분석할 수 있다.from sklearn.datasets import fetch_olivetti_facesK = 21faces_all = fetch_olivetti_faces()face_data = faces_all.data[faces_all.target == K]fig = plt.figure(figsize=(10,5))plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)for i in np.arange(0,10) : plt.subplot(2,5,i+1) plt.imshow(face_data[i].reshape(64,64), cmap=plt.cm.bone) plt.xticks([]) plt.yticks([])plt.suptitle('올리베티 얼굴 이미지 데이터')plt.tight_layout()plt.show()데이터 살펴보기각 얼굴이미지 데이터들은 64*64 행렬이다.분석할 때는 10개 이미지 모두 각각 4096*1 사이즈 벡터로 변환시켜서, 10개 벡터로 특징행렬 하나를 만들 것이다.구상하기10개 이미지 데이터로 이루어진 특징행렬 1개를 가지고 분석할 것이다.각 이미지 데이터는 특징행렬의 행벡터로 들어가 있다.이 행벡터들을 PCA로 차원축소 시켜서, 각 데이터 평균을 제거하고, 노이즈도 제거하고, 주성분 만으로 구성할 것이다.주성분들이 각 데이터를 구성하는 ‘핵심성분’이다. 주성분들은 모든 데이터에 공통적으로 들어있는데, 이들이 각 데이터에 얼만큼씩 들었느냐가 각 데이터 간 차이 결정한다.주성분을 찾고, 데이터 별 주성분 비중을 통해 주성분 의미를 추측해보고, 주성분 비중을 조정시켜가며 이 주성분이 데이터에 어떤 영향 미치는지 알아보자.그리고 각 주성분의 의미를 찾아내자.분석하기데이터에서 주성분 4개를 뽑아보자.얼굴사진 데이터의 주성분을 ‘아이겐페이스(고유얼굴)’ 이라고도 한다.이 주성분들이 실제로 고유벡터들이기도 하고, 인물사진 별로 고유의 아이겐페이스를 가지고 있기 때문에 ‘고유얼굴’ 이라고 부른다.여기서부터는 내 추론이다. 좀 더 공부가 되고 난 뒤 추론 내용이 옳았는지 보려고 한다.인물별로 고유의 아이겐페이스를 가지고 있을 것이다.A라는 인물 얼굴사진을 여러장 찍으면 A 인물의 아이겐페이스 몇 개를 뽑아낼 수 있을 것이다.B라는 인물 얼굴사진을 여러장 찍으면 B 인물의 아이겐페이스 몇 개를 뽑아낼 수 있을 것이다.인물 A의 거의 모든 얼굴사진은 A에서 뽑아낸 아이겐페이스 선형조합으로 나타낼 수 있을 것이다.B도 마찬가지다.한편, 만약 어떤 얼굴 이미지를 얼굴인식기에 넣었는데 아이겐페이스 선형조합으로 표현되지 않는다면(오차가 매우 크다면) 인풋 사진은 A가 아닌 다른 인물의 사진일 가능성이 높다.B도 마찬가지다.그러면 인물 A와 B는 각 인물을 식별할 수 있는 고유의 특징얼굴을 갖고 있는 것이다.이 ‘고유의 특징얼굴’을 ‘아이겐페이스(고유얼굴)’ 이라고 한다.다시 돌아와서, 동일인물 얼굴사진 10개의 아이겐페이스 4개를 뽑아내보자.mean_face = pca4.mean_component1 = pca4.components_[0]component2 = pca4.components_[1]component3 = pca4.components_[2]component4 = pca4.components_[3]face_list = [mean_face, component1, component2, component3, component4]face_name_list = ['mean', 'component1', 'component2', 'component3', 'component4']for i in range(5) : plt.subplot(1,5,i+1) plt.imshow(face_list[i].reshape(64,64), cmap=plt.cm.bone) plt.xticks([]) plt.yticks([]) plt.title(face_name_list[i])plt.suptitle('평균 얼굴과 아이겐페이스 1,2,3,4')plt.tight_layout()plt.show()가장 왼쪽은 ‘평균얼굴’(모든 데이터 공통성분)그리고 왼쪽에서 오른쪽 순서로 주성분1, 주성분2, 주성분3, 주성분4 이다.1~4 주성분은 벡터 형태다. 지금은 이미지로 표현하기 위해 64*64 사이즈 행렬로 변환된 것이다.각 아이겐페이스의 의미를 보자.먼저 1번 주성분은 어떤 의미를 갖는지 보자.# 1번 주성분w = np.linspace(5,10,10)for i in range(10) : plt.subplot(2,5,i+1) plt.imshow(mean_face.reshape(64,64)+w[i]*component1.reshape(64,64), cmap=plt.cm.bone) plt.xticks([]) plt.yticks([]) plt.title(f'주성분 1 비중 : {np.round(w[i],2)}')plt.tight_layout()plt.show()첫번째 줄 왼쪽부터 두번째 줄 가장 오른쪽 10번째 이미지까지,평균벡터(공통성분) 에 1번 주성분만 가중치를 변화시켜가며 더했다.가중치 $w = [5,5.55, 6.11, 6.66, 7.22, 7.77, 8.33, 8.88, 9.44, 10]$주성분 비중 변화에 따라 데이터가 어떻게 바뀌는지 보면, 이 주성분의 의미를 파악할 수 있을 것이다.위 이미지는 왼쪽에서 오른쪽으로, 주성분 비중이 커진다.(아쉽게도 VSCODE 상의 문제인지, 이미지별 title이 달리지 않았다)이 주성분 비중이 커질 수록 인물이 눈을 감게 되는 것을 관찰할 수 있었다.곧, 이 주성분은 이미지 속 인물이 눈을 뜨고 있느냐, 감고 있느냐 여부 결정하는 주성분이다.이 주성분 비중이 높은 이미지 데이터는 인물이 눈을 감고 있을 것이다.2번 주성분의 의미를 보자.# 2번 주성분w = np.linspace(-5,5,10)for i in range(10) : plt.subplot(2,5,i+1) plt.imshow(mean_face.reshape(64,64)+w[i]*component2.reshape(64,64), cmap=plt.cm.bone) plt.xticks([]) plt.yticks([]) plt.title(f'주성분 2 비중 : {np.round(w[i],2)}')plt.tight_layout()plt.show()마찬가지로 평균얼굴에 2번 주성분만 비중을 변화시켜가며 더했다.왼쪽에서 오른쪽으로 갈 수록 주성분 비중이 높아진다.이 주성분 비중이 높아질 수록 인물이 미소짓게 된다.곧, 2번 주성분은 인물이 미소짓고 있는가, 무표정한가 여부를 결정짓는 주성분이다.이 주성분 비중이 높은 데이터는 인물이 미소짓고, 낮은 데이터 일 수록 인물이 무표정하고 있을 것이다.3번 주성분의 의미를 보자.# 3번 주성분w = np.linspace(-5,5,10)for i in range(10) : plt.subplot(2,5,i+1) plt.imshow(mean_face.reshape(64,64)+w[i]*component3.reshape(64,64), cmap=plt.cm.bone) plt.xticks([]) plt.yticks([]) plt.title(f'주성분 2 비중 : {np.round(w[i],2)}')plt.tight_layout()plt.show()평균얼굴에 3번 주성분 아이겐페이스 비중을 변화시켜가며 더했다.이 주성분 비중이 높아질 수록 인물이 치아를 드러내고 있다.반대로 주성분 비중이 낮을 수록 입술을 다물고 있다.3번 주성분은 인물이 치아를 드러내고 있는가 여부를 결정짓는 주성분이다.이 주성분이 높은 이미지 데이터일 수록 인물이 치아를 드러내고 있을 것이다. 낮은 데이터일 수록 인물이 입술을 다물고 있을 것이다.마지막 4번 주성분의 의미를 살펴보자.# 4번 주성분w = np.linspace(-5,5,10)for i in range(10) : plt.subplot(2,5,i+1) plt.imshow(mean_face.reshape(64,64)+w[i]*component4.reshape(64,64), cmap=plt.cm.bone) plt.xticks([]) plt.yticks([]) plt.title(f'주성분 2 비중 : {np.round(w[i],2)}')plt.tight_layout()plt.show()4번 주성분 비중이 높아질 수록 인물이 턱을 살짝 들고 있다.반대로, 주성분 비중이 낮아질 수록 인물이 정면을 바라보고 있다.4번 주성분은 인물이 정면 보고 있는가, 아니면 턱을 살짝 들고 있는가 여부를 결정하는 주성분이다.주식 연간수익률 데이터 PCA이번에는 미국, 인도, 멕시코, 독일, 이탈리아 5개 국가의 주식 연간 수익률 데이터를 가지고 PCA를 해보자.먼저 1990년-2020년까지 31년간 5개 국가의 주가 데이터를 불러왔다.pd.core.common.is_list_like = pd.api.types.is_list_likeimport pandas_datareader.data as webimport datetimesymbols = [ 'SPASTT01USM661N', 'SPASTT01INM661N', 'SPASTT01MXM661N', 'SPASTT01DEM661N', 'SPASTT01ITM661N']data = pd.DataFrame()for sym in symbols : data[sym] = web.DataReader(sym, data_source='fred', start=datetime.datetime(1990, 1,1), end=datetime.datetime(2020,12,31))[sym]data.columns = ['US', 'IN', 'MX', 'DE', 'IT']data = data/data.iloc[0]*100styles = ['b-.', 'g--', 'c:', 'r-', 'k']data.plot(style=styles)plt.title('미국, 인도, 멕시코, 이탈리아, 30년간 주가')plt.show()주가 데이터를 연간 수익률 데이터로 바꾸자.# 주식 연간수익률 데이터df = ((data.pct_change() + 1).resample('A').prod()-1).T*100print(df.iloc[:,:5])이제 위 데이터를 가지고 PCA를 할 것이다.위 데이터는 31차원 벡터 5개를 담고 있는 특징행렬이다.각 31차원 벡터를 차원축소 시켜 주성분만으로 구성하고, 기저에서 어떤 주성분이 작용하고 있으며 국가별로 주성분이 얼만큼씩 작용하고 있는지 살펴보았다.우선 31차원 벡터들을 살펴보자.df.T.plot(style=styles)plt.title('미국,인도,멕시코,독일,이탈리아 과거 30년간 수익률')plt.xticks(df.columns)plt.show()5개 31차원 벡터 그래프로 그렸을 때, 형상이 비슷비슷함을 관찰할 수 있다.특정 구간에서 올라가면 다음 구간에서 내려가고 하는 식이다.즉, 5개 벡터 모두에서 데이터 변이가 규칙적으로 일어나고 있었다.그러면 31차원 벡터의 각 확률변수 기저에 공통 잠재변수가 작용하고 있음을 추측해볼 수 있다.공통 잠재변수 값(주성분 비중)이 큰가, 작은가에 따라 각 데이터가 달라질 것이다.이 주성분을 찾아내고, 주성분의 의미를 파악해보자.그리고 각 국가 데이터별로 주성분 비중이 얼만큼씩 인지도 파악해보자.주성분은 1개를 찾겠다.from sklearn.decomposition import PCApca5 = PCA(n_components=1) # 주성분 1개를 찾아보자. X_low = pca5.fit_transform(df)m = pca5.mean_pca5.components_찾아낸 1개 주성분은 다음과 같다.이제 이 주성분 비중 변화에 따라 데이터가 어떻게 변화하는지 살펴보자.평균벡터를 기준으로 두고, 평균벡터에 주성분 비중을 증가시켜가며 더했다.x_range = np.linspace(1990, 2020, 31, dtype=int)for i in np.linspace(0,100,5) : plt.plot(x_range, m+pcomponent1[0]*i)plt.plot(x_range, m+pcomponent1[0]*100, label='주성분 100배')plt.plot(x_range, m, 'ko-', lw=5, label='평균수익률')plt.title('주성분 비중이 커질 때')plt.legend()plt.show()주성분 비중이 커짐에 따라, 데이터가 평균보다 위쪽으로 증가함을 관찰할 수 있었다.이제 그러면 평균에 주성분 비중을 감소시켜가며 더해보자.즉, 주성분 비중을 줄여가는 것이다.x_range = np.linspace(1990, 2020, 31, dtype=int)for i in np.linspace(0,-100,5) : plt.plot(x_range, m+pcomponent1[0]*i)plt.plot(x_range, m+pcomponent1[0]*-100, label='주성분 -100배')plt.plot(x_range, m, 'ko-', lw=5, label='평균수익률')plt.title('주성분 비중이 작아질 때')plt.ylim(-60, 80)plt.legend()plt.show()주성분 비중이 작아질 수록, 평균을 기준점으로 점점 아래쪽으로 데이터가 형성됨을 관찰할 수 있었다.주성분 변화 관찰 후 결론 : 이 주성분이 많아질 수록 데이터 형상이 평균에서 위쪽으로 변화한다. 이 주성분이 적어질 수록 데이터 형상이 평균에서 아래쪽으로 변화한다.국가별 데이터의 주성분 비중df_low = pd.DataFrame(X_low, columns=['주성분 비중'], index=['US','IN','MX','DE','IT'])df_low저차원 투영벡터의 저차원 공간 기저벡터 기준 좌표는 주성분 비중과 같았다.위 표가 국가 데이터 별 주성분 비중이다.미국, 독일, 이탈리아는 주성분 비중이 - 값이고(적고), 인도, 멕시코 데이터는 주성분 비중이 +값이었다(많다)위에서 이 주성분이 + 방향으로 많아질 수록 데이터가 평균수준에서 위쪽으로 형성되었다.반대로 주성분이 - 방향으로 많아질 수록 데이터가 평균수준에서 아래쪽으로 형성되었다.미국, 독일, 이탈리아의 데이터는 평균수준에서 아래쪽으로 비슷비슷하게 형성되고,인도. 멕시코의 데이터는 평균수준에서 위쪽으로 비슷비슷하게 형성될 것이다.멕시코. 인도는 많고, 미국.독일.이탈리아는 비중이 적은 주성분이다.fit_transform() 명령을 통해 31차원 데이터를 1차원 근사시킨 후, inverse_transform() 명령을 통해 다시 31차원으로 복귀시켰다.복귀시킨 벡터는 31차원 저차원 투영벡터로, 노이즈가 제거되고 평균과 주성분1개 만으로 구성되어 있다.사실상 데이터 별로 주성분 비중만 다르다.실제 데이터가 어떻게 형성되는지 함 보자.df2 = pd.DataFrame(pca5.inverse_transform(df_low))df2.columns=df.columnsdf2.index=df.indexdf2.T.plot(style=styles)plt.title('각 데이터에서 노이즈 제거하고 평균+주성분으로만 구성한 근사데이터')plt.xticks(df.columns)plt.show()근사데이터들이 형성된 것을 보면, 앞에서 했던 예상이 맞았음을 볼 수 있다.평균을 기점으로 이 주성분이 많을 수록 데이터 형상이 인도,멕시코와 유사하게 변할 것이다.반대로 이 주성분이 적을 수록 데이터 형상이 미국, 독일, 이탈리아의 데이터와 비슷하게 변할 것이다.인도, 멕시코를 개발도상국으로 놓고, 미국. 독일. 이탈리아를 선진국으로 둔다면, 이 주성분은 비중이 높아질 수록 데이터를 선진국 쪽에서 개도국 쪽으로 변화시키는 주성분이다.곧, 이 주성분은 ‘개도국이냐. 아니냐’ 여부를 결정짓는 ‘개도국 요인’임을 알 수 있었다." }, { "title": "[수학/선형대수] 행렬 고윳값분해, 특잇값분해", "url": "/bioinfo.github.io/posts/eigen_characteristic/", "categories": "Data Science, python, mathematics", "tags": "data_science, python, mathematics", "date": "2021-08-19 00:00:00 +0900", "snippet": "고윳값분해(고유분해) 정방행렬 $A$의 고윳값과 고유벡터를 찾는 과정 오직 정방행렬만 고유분해 할 수 있다.고유분해 식$Av = \\lambda v$$A$는 정방행렬, $v$는 벡터, $\\lambda$ 는 스칼라.위 식 만족하는 $\\lambda$를 ‘고윳값’, $v$ 벡터를 ‘고유벡터’라고 한다.고유벡터 정의 : 정방행렬 $A$를 고유벡터에 곱해서 변환해도. 길이만 변하고 방향은 절대 안 바뀌는. 영벡터가 아닌 벡터 여기서 ‘방향이 같다’에는 정반대 방향도 포함된다. # 고유벡터 v 변환plt.xlim(-3,3)plt.ylim(-3,3)xx = np.linspace(0,1,10)def line(x) : return 2*xr = line(xx)color = ['red', 'blue', 'green', 'black']for a,b in [(0,7),(2,3)] : plt.annotate('', xy=[xx[b], r[b]], xytext=[0,0], arrowprops={'facecolor' : color[a]})plt.annotate('', xy=[-xx[5], -r[5]], xytext=[0,0], arrowprops={'facecolor' : 'blue'})plt.scatter(0,0,100, 'r')plt.text(0.8, 1.3, '$Av$')plt.text(0.2, 0.1, '$v$')plt.text(-0.2, -0.7, '$Av$')plt.title('고유벡터 $v$ 변환 예시')plt.show()위 그림에서 초록색 화살표를 고유벡터 $v$ 라고 하자. 고유벡터는 정방행렬 $A$를 곱해서 변환해도 위 그림처럼 길이만 변할 뿐, 방향 자체는 변하지 않는다. 고유벡터는 실수배 해도 모두 같은 고유벡터다. 따라서 정규화해서 길이 1짜리 단위벡터로 만들어 쓴다.$cv = v$$\\frac{v}{\\lVert v \\rVert}$ 고유벡터는 고윳값에 각각 대응된다. 따라서 고유벡터 수 = 고윳값 수 다.고윳값 정의 : 고유벡터 $v$에 정방행렬 곱해서 변환한 벡터 $Av$ 와 원래 고유벡터 $v$ 의 크기 비율 변환하면서 변한 길이 만큼이 고윳값 $\\lambda$ 이다.특성방정식 : 행렬 A 고유분해 하기$det(A-\\lambda I) = 0$위 식이 행렬 $A$를 고유분해 하는 특성방정식이다.원래 고유분해 식 $Av = \\lambda v$ 를 변형해서 구해낸 식이다.$Av - \\lambda v = 0$$(A -\\lambda I)v = 0$두번째 식에서 고유벡터 $v$ 는 영벡터가 될 수 없다.만약 $(A -\\lambda I)$ 행렬이 역행렬이 존재한다면 $v$ 는 영벡터가 될 것이다.따라서 $(A -\\lambda I)$ 역행렬은 없어야 한다.역행렬이 없기 때문에 위 행렬의 행렬식도 $0$ 이 되어야 한다.여기 따라서 특성방정식 $det(A-\\lambda I) = 0$ 가 나온다. 특성방정식 풀어서 고윳값 $\\lambda$ 찾고, 고윳값에 대응되는 고유벡터를 찾으면 된다. 만약 특성방정식 풀었는데 해 $\\lambda$ 가 중복값이라면, 이 $\\lambda$ 를 중복고윳값 이라고 한다. 만약 고유벡터도 중복값이라면, 고유벡터를 ‘중복 고유벡터’라고 한다. 고윳값의 개수정리 : 중복된 고윳값을 별개로 생각하고, 복소수 고윳값도 고려한다면 $n$ 차원 정방행렬은 항상 $n$ 개 고윳값을 갖는다.고윳값과 대각합/행렬식n차원 정방행렬은 항상 n개 고윳값 갖는다.이 n개 고윳값 합은 정방행렬 대각합과 같다.n개 고윳값 곱은 정방행렬 행렬식과 같다.$tr(A) = \\sum_{i}^{n} \\lambda_{i}$$det(A) = \\prod_{i}^{n} \\lambda_{i}$넘파이로 고유분해 하기np.linalg.eig(행렬) 고유벡터를 아이겐벡터라고도 한다. 명령 이름 $eig$는 거기서 따온 것이다. 고유분해 결과는 고유값들이 벡터 꼴로 나오고, 고유벡터들이 고유벡터행렬 꼴로 나온다. 고유벡터들은 고유벡터 행렬의 열 들이다. A = np.array([[1,-2],[2,-3]])ld, V = np.linalg.eig(A)print(ld) # 고윳값들print(V) # 고유벡터 행렬 (열벡터들이 고유벡터)첫번째 리스트 안에 들어있는 값들이 고윳값들이다.두번째 이차원 리스트 안에 들어있는 값들이 고유벡터다. 이차원 리스트 각 열 하나씩이 고유벡터다.대각화 (고유분해 식의 변형)정방행렬 $A$를 다음과 같이 나타내는 걸 ‘대각화’한다고 한다.$A = V\\Lambda V^{-1}$$V$는 고유벡터를 열로 쌓아서 만든 ‘고유벡터 행렬’$V \\in R^{N*N}$$\\Lambda$ 는 대각행렬 대각성분들을 고윳값들로 채운 ‘고윳값 행렬’ 이다.$\\Lambda \\in R^{N*N}$대각화 가능 행렬 $A$가 ‘대각화 가능’ 이기 위해선 고유벡터행렬 $V$가 풀랭크여야 한다. 고유벡터 행렬 $V$는 정방행렬이었다. 정방행렬이 풀랭크이면 항상 역행렬 존재한다. 따라서 $V^{-1}$을 구할 수 있고, 위 대각화 식이 성립하게 된다. 고윳값과 역행렬정리 : 대각화가능한 행렬 $A$ 의 고윳값 중에 $0$ 이 없다면, 행렬 $A$는 항상 역행렬 존재한다.대칭행렬의 고유분해정리 : 행렬 $A$가 실수로 이루어진 대칭행렬이면, 행렬 $A$는 실수 고윳값을 갖는다. 또 고유벡터 행렬은 정방정규직교 행렬이 된다. 정방정규직교 행렬의 역행렬은 자기자신의 전치행렬이다.$V^{T}V = I$$VV^{T} = I$$V^{-1} = V^{T}$정리 : 따라서 대칭행렬은 ‘항상 대각화 가능’ 이다.$A = V\\Lambda V^{T}$대칭행렬을 랭크-1 행렬 합으로 분해 $N$ 차원 대칭행렬은 랭크-1 행렬 $N$ 개 합으로 분해할 수 있다.$A$$= V\\Lambda V^{T}$$= \\sum_{i}^{N}\\lambda_{i} v_{i}v_{i}^{T}$$= \\sum_{i}^{N}\\lambda_{i} A_{i}$$A_{i}$ 는 임의의 랭크-1 행렬 $v_{i}v_{i}^{T}$ 이다.A = np.array([ [60,30,20], [30,20,15], [20,15,12]])ld, V = np.linalg.eig(A) #고유분해 l1 = ld[0]l2 = ld[1]l3 = ld[2]v1 = V[:,0].reshape(3,1)v2 = V[:,1].reshape(3,1)v3 = V[:,2].reshape(3,1)A2 = l1*v1@v1.T + l2*v2@v2.T+l3*v3@v3.TA2 대칭행렬의 고윳값 부호정리 1 : 대칭행렬이 양의 정부호이면 고윳값은 모두 양수다. 역도 성립한다.정리 2 : 대칭행렬이 양의 준정부호이면 고윳값은 모두 0 또는 양수다. 역도 성립한다.분산행렬 $X^{T}X$ $XX^{T}$ 정방행렬이고, 대칭행렬이다.정리 : 분산행렬은 기본적으로 양의 준정부호이다. 고윳값은 모두 0 또는 양수다.분산행렬의 역행렬정리 : 행렬 X가 풀랭크이면, 분산행렬 $X^{T}X$ 는 항상 역행렬 존재한다.두 가지 정리를 통해 위 정리를 설명할 수 있다.첫째, 분산행렬은 대칭행렬이다.대칭행렬은 항상 대각화 가능하다.항상 대각화 가능한 행렬은 고윳값 중에 0이 없을 경우 항상 역행렬 존재했었다.이번에 증명하고자 하는 정리에서, 행렬 $X$ 가 풀랭크라면 분산행렬은 양의 정부호이다.(행렬 $X$의 열이 모두 선형독립 이므로 영벡터 아닌 모든 벡터 $v$ 에 대해$Xv = \\mu$ 에서$\\mu$ 가 영벡터 될 수 없다. 영벡터 아닌 벡터 $v$에 대해 $\\mu$ 가 영벡터가 된다면 행렬 $X$ 열벡터들은 선형종속이 될 것이다.따라서$v^{T}(X^{T}X)v = (Xv)^{T}(Xv) = \\mu^{T}\\mu$ &gt; $0$ 이 된다)분산행렬이 양의 정부호라면, 고윳값들이 모두 양수이다(대칭행렬이므로).대각화 가능한 대칭행렬인데 $0$ 인 고윳값이 없으므로 분산행렬 $X^{T}X$ 는 항상 역행렬 존재한다.둘째,행렬식이 $0$ 아니면 역행렬은 항상 존재한다.행렬 $X$가 풀랭크일 때, 분산행렬은 양의 정부호였다. 대칭행렬이 양의 정부호이면 고윳값은 모두 양수다.고윳값 곱은 행렬식과 같았다. 양수 고윳값을 모두 곱하면 행렬식은 절대로 $0$ 나오지 않는다. 행렬식이 항상 양수이므로, 분산행렬의 역행렬도 항상 존재한다.고유분해 성질 요약 &amp; 정리$N$ 차원 정방행렬 $A$에 대해, 행렬 $A$는 $N$ 개 고윳값-고유벡터를 갖는다. 행렬의 대각합은 모든 고윳값 $\\lambda$ 합과 같다. 행렬의 행렬식은 모든 고윳값 $\\lambda$ 곱과 같다. 행렬 $A$ 가 대칭행렬이면, 실수 고윳값 $N$ 개를 가지며 고유벡터행렬은 정방 정규직교 행렬이다. 행렬 $A$ 가 대칭행렬이고 고윳값이 모두 양수이면, 행렬 $A$는 양의 정부호다. 역도 성립한다. 행렬 $A$ 가 어떤 행렬 $X$의 분산행렬 $X^{T}X$ 이면 양의 준정부호로, $0$ 또는 양의 고윳값을 갖는다. 분산행렬 $X^{T}X$ 의 행렬 $X$가 풀랭크이면, 분산행렬은 역행렬이 항상 존재한다.특잇값분해(특이분해) 모든 행렬에 대해 특잇값분해 할 수 있다.고유분해는 정방행렬에만 가능했다.특잇값분해 식$A = U\\Sigma V^{T}$ A는 모든 행렬$A \\in R^{N*M}$ U는 왼쪽 특이벡터행렬, 열벡터들이 특이벡터들이다. 또 정방 정규직교행렬이다.$U \\in R^{N*N}$ $\\Sigma$ 는 특잇값 행렬, 대각성분에 양수인 특잇값들로 구성된 대각행렬이다.대각성분은 왼쪽 상단부터 오른쪽 하단까지 크기순 배치된다.특잇값행렬은 본래 행렬 $A$와 크기가 같다.$\\Sigma \\in R^{N*M}$ V는 오른쪽 특이벡터행렬, 열벡터들이 특이벡터들이다. 정방 정규직교행렬이다.$V^{T}$ 에서는 행벡터들이 오른쪽 특이벡터들이다.$V^{T} \\in R^{M*M}$특잇값 개수$N$(특잇값 수) $=$ $min(N,M)$행렬 $A$의 행 수가 $N$, 열 수가 $M$ 일 때, 특잇값 개수는 $N,M$ 중 더 작은 값과 같다.예) $A \\in R^{2*3}$ 인 경우 : 특잇값 2개 갖는다.특잇값분해 축소형특잇값행렬은 원래 행렬 $A$와 사이즈가 똑같다. $(N*M)$만약 특잇값행렬 사이즈가 $3*2$ 인데 특잇값 수는 $2$ 인 경우,대각행렬인 특잇값행렬은 다음과 같아진다.$[[s1, 0],[0, s2],[0,0]]$한편 특잇값행렬 사이즈가 $2*3$ 인데 특잇값 수가 2인 경우, 특잇값행렬은 다음과 같다.$[[s1,0,0],[0, s2,0]]$이렇게 특잇값행렬 행, 열 수가 다를 경우, 행렬 아래쪽 또는 오른쪽에 영벡터 부분이 생긴다.이 영벡터 부분은 계산에서 있으나 없으나 결과가 같기 때문에 생략할 수 있다.특잇값분해 과정에서 이렇게 특잇값행렬의 영벡터 부분을 ‘생략’하는 것을 ‘특잇값분해 축소형’ 이라고 한다. 특잇값행렬 아래쪽 영으로 구성된 행벡터 1개를 생략할 때, 왼쪽 특이벡터행렬에서 가장 오른쪽 열벡터 1개도 함께 생략한다. 특잇값행렬 오른쪽 영으로 구성된 행벡터 중 1개를 생략할 때, 오른쪽 특이벡터행렬에서 가장 아래쪽 행벡터 1개도 함께 생략한다. 더 간략하게 다시 정리하면 다음과 같다.1. 아래쪽에 영행렬 $\\rightarrow$ 왼쪽특이벡터행렬 열 제거2. 오른쪽에 영행렬 $\\rightarrow$ 오른쪽특이벡터행렬 행 제거축소하든, 안 하든 결과는 같다($= A$).파이썬으로 특잇값분해 하기np.linalg.svd(행렬)특잇값분해가 singular value decomposition 이기 때문에 명령 이름이 svd() 다. 결과물은 왼쪽 특이벡터행렬, 고윳값(스칼라값들), 오른쪽특이벡터 행렬의 전치행렬($V^{T}$) 가 나온다.예)데이터사이언스스쿨 연습문제 3.4.1넘파이를 사용하여 다음 행렬을 특잇값분해 하라.$B = [[3,2,2],[2,3,-2]]$#1. B = np.array([[3,2,2],[2,3,-2]])U, S, VT = np.linalg.svd(B)U2, S2, VT2 = np.linalg.svd(B, full_matrices=False) 축소 안 했을 때 U, np.diag(S, -1)[1:, :], VT 축소했을 때 U2, np.diag(S2), VT2 특잇값과 특이벡터 사이 관계$Av_{i} = \\sigma_{i}\\mu_{i}$성립한다. 특잇값 1개 당 좌우 특이벡터가 하나씩 대응된다.특잇값분해-고윳값분해 사이 관계 특잇값분해 결과를 고윳값분해 결과에 대응시킬 수 있다.분산행렬 $A^{T}A$ 가 있다고 하자.행렬 $A$ 특잇값분해 결과를 $A^{T}A$ 에 대응하면 다음과 같다.$A^{T}A = (U\\Sigma V^{T})^{T}U\\Sigma V^{T}$$= V\\Sigma^{T}U^{T}U\\Sigma V^{T}$$=V\\Sigma^{T}\\Sigma V^{T}$한편 분산행렬 $A^{T}A$ 는 정방대칭행렬이므로 고유분해 가능하다.$A^{T}A = V\\Lambda V^{T}$결국$V(\\Sigma^{T}\\Sigma) V^{T} = V\\Lambda V^{T}$ 이다. 오른쪽특이벡터행렬 $V$는 고유벡터행렬 $V$와 같다. 특잇값 제곱(과 0) 은 고윳값과 같다.$\\Lambda \\in R^{M*M}$$N$ &gt; $M$ 일 때$diag(\\sigma_{1}, \\sigma_{2}, … \\sigma_{M}) = \\Lambda$$N$ &lt; $M$ 일 때$diag(\\sigma_{1}, \\sigma_{2}, … \\sigma_{N},0 … ,0) = \\Lambda$" }, { "title": "[수학/선형대수] 공간 속 벡터의 좌표와 좌표변환", "url": "/bioinfo.github.io/posts/coordinance_and_conversion/", "categories": "Data Science, python, mathematics", "tags": "datascience, python, mathematics", "date": "2021-08-17 00:00:00 +0900", "snippet": "좌표와 변환 (공간 속 좌표 의미와 좌표 변환)벡터의 선형종속과 선형독립벡터공간의 틀. 기준인 기저벡터를 정의하기 위해 쓰인다.예측모형 성능 극대화를 위해서는 벡터들의 선형종속을 없애야 한다.선형종속 정의 : 벡터들을 선형조합 할 때 쓰이는 스칼라 계수들이 전부 0이 아닌 경우에도 선형조합 결과가 0벡터 되는 경우가 있으면 ‘벡터들이 선형종속이다’라고 한다. 스칼라 계수들이 전부 0이어서 선형조합 결과가 영벡터 나오는 경우는 생각하지 않는다. 선형독립 정의 : 벡터들 선형조합 할 때 쓰이는 스칼라 계수들이 전부 0일 때만, 선형조합 결과가 0벡터 나오면 ‘벡터들이 선형독립이다’라고 한다. 선형독립을 논리 기호로 아래처럼 표기한다. $c_{1}x_{1}+c_{2}x_{2}+…c_{n}x_{n} = 0 \\rightarrow c_{1}, c_{2}, … c_{n} = 0$또는$c_{1}x_{1}+c_{2}x_{2}+…c_{n}x_{n} = 0 \\leftrightarrow c_{1}, c_{2}, … c_{n} = 0$오른쪽에서 왼쪽 방향 화살표는 굳이 표시 안 해도 당연히 성립한다.위 논리기호를 아래처럼 표시하기도 한다.$Xc = 0 \\rightarrow c = 0$또는$Xc = 0 \\leftrightarrow c = 0$메모)두 벡터만 있을 경우 두 벡터 방향이 다르면 선형독립 두 벡터 방향이 같으면 선형종속 이었다. 양벡터 아닌 벡터 N개가 있을 때, 이들 N개가 서로 모두 직교하면 N개 벡터는 ‘선형독립’이다.벡터들이 선형종속인 전형적인 경우예측모형에 입력 데이터로 넣으려는 특징행렬에 선형종속이 발생하는 전형적 경우는 아래와 같다.1. 특징행렬의 행 개수보다 열 개수가 더 많은 경우 선형종속 발생한다.특징행렬을 스칼라 계수들과 함께 선형연립방정식이라 생각했을 때, 이 경우 방정식 개수보다 미지수 개수가 더 많은 경우다.방정식 수 보다 미지수 수가 더 많으면, 방정식 해가 무한히 많이 존재한다.이 무한히 많은 해 중에 선형연립방정식을 0과 같게 하는, 스칼라 계수 벡터가 0벡터 아닌 경우가 반드시 존재하므로, 선형종속이다.행 개수와 열 개수가 같거나, 열 개수보다 행 개수가 더 많은 경우 대부분 벡터들이 선형독립이다.2. 특징행렬 열벡터 중에 서로 중복되는 벡터가 있으면 선형종속이다.한 열벡터가 또 다른 벡터의 실수배 인 경우도 선형종속이다.3. 특징행렬 열벡터 중 하나가 다른 벡터들의 선형조합 결과와 같으면 선형종속이다.랭크와 풀랭크랭크 내가 예측모형에 입력데이터로 쓰려고 하는 특징행렬에 선형종속이 있는지, 없는지 확인하는 데 사용할 수 있다. 정의 : 행렬 행벡터 또는 열벡터 들 중 서로 선형독립인 벡터들의 수 행 랭크와 열 랭크 값은 같다. 따라서 그냥 ‘랭크’라고 부른다. 행렬 X가 있을 때, 다음이 성립한다.$rank(X) \\le min(M,N)$M, N은 각각 행렬의 행, 열 갯수풀랭크앞에서 랭크 값은 다음과 같았다.$rank(X) \\le min(M,N)$만약$rank(X) = min(M,N)$ 이면 ‘풀랭크’라고 한다.넘파이로 랭크 계산하기X = np.array([ [1,2,3], [4,5,6], [7,8,9]])np.linalg.matrix_rank(X)로우-랭크 행렬 정의 : 서로 선형독립인 벡터들을 자기자신의 전치행렬과 선형조합해서 만든 행렬들 통칭한다.종류)랭크-1 행렬벡터 1개를 자기자신의 전치행렬과 선형조합해서 만든 행렬$xx^{T} \\in R^{N*N}$정방행렬이다.랭크-1행렬의 랭크는 1이다.랭크-2 행렬선형독립인 벡터 2개를 자기자신의 전치행렬과 선형조합해서 만든 행렬$x_{1}x_{1}^{T} + x_{2}x_{2}^{T}$랭크-2행렬 랭크는 2다.랭크-M 행렬선형독립인 벡터 M개를 자기자신의 전치행렬과 선형조합해서 만든 행렬$\\sum_{i}^{M}{x_{i}}{x_{i}^{T}}$랭크는 M이다.벡터공간과 기저벡터벡터공간 정의 : 서로 선형독립인 N개 벡터(기저벡터)를 선형조합해서 만든 벡터들의 집합 벡터공간의 차원은 기저벡터 개수가 결정짓는다. 예를 들어 3차원 기저벡터 2개를 가지고 선형조합해서 벡터공간 만들면, 2차원 벡터공간인 것이다.N차원 벡터공간 만드는 데 기저벡터의 차원은 아무 상관도 없다.따라서 7차원 기저벡터로 2차원 벡터공간을 만들 수 있는 것이다. 서로 선형독립인 N차원 벡터 N개가 있으면, 이것들을 선형조합해서 모든 N차원 벡터를 만들 수 있다.= 기저벡터들이 정방행렬 이루면, 기저벡터 선형조합해서 모든 N차원 벡터 만들 수 있다. 기저벡터들이 정방행렬 이룰 때, 모든 기저벡터에 직교하는 영벡터 아닌 임의의 벡터 $x$는 존재하지 않는다.다음처럼 증명이 가능하다.기저벡터들을 열벡터 삼아 정방행렬을 만들자.이 행렬은 열벡터가 모두 선형독립이므로, 풀랭크인 정방행렬이다.정방행렬이 풀랭크이면, 역행렬이 반드시 존재한다.한편, “모든 기저벡터에 직교하는 영벡터 아닌 벡터 $x$ 가 존재한다면”, 으로 가설을 놓고, 이 문제를 증명하자. 만약 증명 결과가 처음 놓았던 가설에 배치된다면 첫 가설을 기각하고 그와 반대되는 가설을 채택하면 될 것이다.모든 기저벡터에 직교하는 영벡터 아닌 벡터 $x$ 가 존재한다면, 다음 식이 성립한다.$X^{T}x = 0$X는 기저벡터 정방행렬이다.$X^{T}$의 역행렬은 $X^{-1}$의 전치행렬과 같다. $X^{-1}$ 가 항상 존재하므로, $X^{T}$ 의 역행렬도 항상 존재한다.$X^{T}$ 를 $A$ 라 하면,$x = A^{-1}*0$ 이 성립한다.우변은 영벡터다. 따라서 x도 영벡터다.처음 세웠던 가설에서 벡터 x의 조건은 ‘영벡터가 아닐 것’ 이었다. 하지만 증명 결과 $x$ 가 영벡터 일 때만 $x$가 모든 기저벡터에 직교했다.따라서 처음 세웠던 가설을 기각하면, ‘모든 기저벡터에 직교하는 영벡터 아닌 벡터 $x$ 는 존재하지 않는다’는 결론이 나온다.기저벡터 정의 : 벡터공간의 ‘축’, ‘틀’, ‘기준’ 서로 선형독립인 N개 벡터 벡터에 좌표를 부여하는 ‘기준’이다. 기저벡터 선형조합해서 벡터공간 내 벡터들을 만든다.N차원 기저벡터들이 정방행렬 이루면, 이 기저벡터들 선형조합해서 모든 N차원 벡터 만들 수 있다.한편, 기저벡터들이 정방행렬 이루지 않는 경우 N차원 기저벡터 선형조합해도 만들 수 없는 N차원 벡터들이 존재했다.예를 들어2차원 벡터공간의 기저벡터 $[1,0,0], [0,1,0]$ 가 있다. 이 벡터들을 어떻게 선형조합해도 절대 3차원 벡터 $[1,1,1]$ 은 만들지 못한다.정방행렬 랭크와 역행렬정방행렬 랭크와 역행렬 사이에는 다음 정리가 성립한다.정방행렬이 풀랭크다 $\\leftrightarrow$ 역행렬이 존재한다고차원 벡터의 저차원 벡터공간 투영M개의 N차원 기저벡터가 있다. (N &gt; M)또 N차원 벡터 $x$ 가 있다.만약M개의 N차원 기저벡터를 선형조합해서 만든 벡터($a$ 라 하자)와 N차원 벡터 $x$ 의 차 $x-a$ 가 M개 기저벡터 모두에 직교하면,벡터 $a$를 벡터 $x$의 ‘벡터공간에 대한 투영벡터($x$ 의 투영성분)’라고 하고,$x - x^{\\Vert V}$ 를 벡터 $x$의 ‘벡터공간에 대한 직교벡터($x$ 의 직교성분)’ 라고 한다. 이 ‘투영벡터’는 저차원 벡터공간 상의 모든 벡터 중 원래 벡터 $x$와 가장 비슷한 벡터다(코사인 유사도 모두 동일 할 때, 유클리드 거리 기준). 투영벡터 : 벡터 $x$를 저차원 벡터공간의 기저벡터 가지고 표현한다면? 의 답. $x$와 가장 비슷하지만, 그럼에도 벡터 $x$를 완전히 표현하지 못하는, $x$의 일부분이다. 정규직교 기저벡터로 이루어진 벡터공간 기저벡터 $v_{1}, v_{2}, … v_{n}$ 이 정규직교이면, 이 벡터공간에 대한 투영벡터는 각 기저벡터에 대한 내적값이다.$x^{\\Vert V} = \\sum_{i}^{n}(x^{T}v_{i})v_{i}$ 투영벡터 길이 제곱은 벡터 $x$와 각 기저벡터 내적의 제곱합이다.$\\lVert x^{\\Vert V} \\rVert ^{2} = \\sum_{i}^{M}(x^{T}v_{i})^{2}$ 벡터공간에 대한 벡터 $x$의 직교벡터 $x^{\\perp V}$ 는 벡터공간의 모든 벡터에 대해 직교한다. 벡터공간에 대한 벡터 $x$의 투영벡터 $x^{\\Vert V}$ 는 벡터공간 상 모든 벡터 중에 벡터 $x$와 가장 비슷한(가까운) 벡터다. 표준기저벡터 정의 : 선형독립인 벡터들 중에서, 벡터 요소가 하나만 1이고 나머지는 모두 0으로 구성된 벡터를 ‘표준기저벡터’라고 한다.$[1,0,0], [0,1,0], [0,0,1]$ 등 표준기저벡터를 열로 가지는 행렬은 항등행렬 $I$ 가 된다.좌표 정의 : 벡터공간 상 벡터의 ‘상대적 위치’ 어떤 벡터의 좌표는 기저벡터에 따라 결정된다. = 1개 벡터의 좌표가 기저벡터에 따라 여러개 존재할 수 있다.일반적으로 쓰는 표준기저벡터 직교좌표계 또한 벡터 좌표를 결정짓는 여러 ‘기준’ 중 하나일 뿐이다. 벡터의 좌표는 벡터공간 기저벡터 선형조합 할 때 사용하는 스칼라 계수 벡터와 같다.$a = c_{1}x_{1}+c_{2}x_{2}$ 일 때 $x_{1}, x_{2}$ 가 기저벡터이면 $c_{1}, c_{2}$ 가 그 기저벡터가 이루는 벡터공간 상에서 벡터 $a$ 좌표다.위 식은$a = [x_{1}, x_{2}][c_{1}, c_{2}]^{T}$로 바꿔 나타낼 수 있다. 이때 식의 의미는 ‘기저벡터가 $x_{1}, x_{2}$ 일 때, 벡터 $a$ 의 좌표는 $c_{1}, c_{2}$ 이다’ 로 이해할 수 있다.좌표변환과 변환행렬 좌표변환이란 어떤 벡터 x의 좌표를 새 기저벡터 상에서의 좌표로 바꾸는 작업이다.내가 이해한 좌표변환 과정은 다음과 같다. 새 기저벡터로 삼으려는 임의의 벡터 g1, g2 가 있다. g1, g2는 어떤 좌표를 갖고 있긴 한데, 어떤 기저벡터를 기준으로 삼고 있는지 ‘모른다’ 또다른 어떤 기준 따르는 벡터 x 좌표를 g1, g2를 기준으로 좌표변환 하려 한다. 벡터 x의 좌표를 규정하는 기준과 g1, g2 좌표를 규정하는 기준이 다르면 좌표변환 할 수가 없다. ($\\Leftarrow$ 정확한 이유가 아직 논리적으로 정리되지 않는다) 따라서 벡터 x의 좌표를 규정하는 기준과 g1, g2 좌표를 규정하는 기준을 같게 만들어야 한다. g1, g2의 좌표를 벡터 x의 좌표가 따르는 기저벡터를 기준으로 변환한다.$[g1, g2] = [e1, e2][ge1, ge2]^{T}$$[ge1, ge2]^{T}$ 가 g1, g2의 새 좌표다. 벡터 x 좌표와 벡터 g1, g2 좌표가 따르는 기준이 같아졌다. $[ge1, ge2]^{T}$ = $A$ 라 하자. 벡터 $x$ 좌표를 기저벡터 g1, g2 기준으로 변환하자. 아까 구한 g1, g2 새 좌표를 이용한다. $x_{e} = Ax_{g}$ $A$ 행렬은 기저벡터들로 구성된 행렬이므로 풀랭크다. 역행렬 항상 존재한다. 역행렬 곱해서 좌변으로 넘기면$x_{g} = A^{-1}x_{e}$ 이다.$x_{g}$ 가 새 기저벡터 상에서의 벡터 x 좌표다. 새 기저벡터 좌표를 열로 담은 행렬 $A$ 의 역행렬 $A^{-1}$ 을 변환행렬 $T$ 라고 한다.핵심 요약 :$x_{g} = A^{-1}x_{e}$ 에 의해, 새 좌표 = 변환행렬 * 기존좌표 다.예)데이터사이언스스쿨 연습문제 3.2.8만약 새로운 기저벡터 좌표가 다음과 같다면, 원래의 좌표 $ [1,0], [1,2], [-1, 2] $ 는 어떤 좌푯값이 될 지 계산하라.$g1 = [1, 0.75]$$g2 = [-1, 0.75]$나의 답)$[1,0]$ 을 좌표변환한다고 하자.$[1,0]$ 의 좌표는 2차원 표준기저벡터 $[1,0],[0,1]$ 에 의해 정의되어 진 것이다.그러면 새 기저벡터로 쓸 벡터의 좌표도 2차원 표준기저벡터 $[1,0],[0,1]$ 에 의한 좌표를 가지고 있어야 한다.$[1,0],[0,1]$ 가 항등행렬이므로, $[1,0],[0,1]$ 상에서 g1, g2의 좌표는 원래 좌표와 똑같다.이제 그러면 좌표변환 식에 값들을 넣어서 벡터 좌표를 변환하면 된다.$x_{g} = A^{-1}x_{e}$" }, { "title": "[수학/선형대수] 기하학적 관점에서의 벡터", "url": "/bioinfo.github.io/posts/vector_in_geometry/", "categories": "Data Science, python, mathematics", "tags": "datascience, mathematics, python", "date": "2021-08-16 00:00:00 +0900", "snippet": "선형대수와 해석기하의 기초선형대수 : 선과 도형, 수와 수의 관계를 다루는 학문n차원 벡터의 기하학적 의미 n차원 벡터 공간 상의 ‘점’ n차원 벡터 공간의 원점과 점을 연결한 화살표화살표로서의 벡터는 크기와 방향 두 가지를 표현한 것이다.벡터를 화살표로 생각할 경우, 길이와 방향을 고정한 채 화살표만 평행이동 해도 상관없다(= 같은 벡터다)벡터의 길이 벡터의 길이(크기)는 norm놈 값으로 나타낸다.$\\lVert a \\rVert =\\sqrt{a^{T}a}$벡터 요소 제곱합에 루트 씌운 것.#벡터 놈a = np.array([0.5, 0.3, 0.1, 0.2])np.linalg.norm(a) # 놈 계산스칼라와 벡터 곱 벡터에 양의 실수(스칼라)를 곱하면 방향은 안 변하고 벡터 길이만 변한다. 벡터에 음의 실수(스칼라)를 곱하면 방향이 반대로 바뀌고 벡터 길이가 변한다.단위벡터 벡터 길이(놈 값이)가 1인 벡터$norm(a) = 1$영벡터 아닌 임의의 벡터에 대해 다음처럼 하면 원래 벡터와 방향은 같지만 길이가 1인 단위벡터가 된다.$\\frac{x}{\\lVert x \\rVert}$벡터 합 벡터 합은 차원이 같은 벡터끼리 할 수 있다. 결과도 벡터다. 기하학적 관점에서 벡터 합은 다음과 같다.plt.ylim(-1,1)plt.xlim(-1,2)black = {'facecolor' : 'black'}blue = {'facecolor' : 'blue'}plt.annotate('', xy=[1,0], xytext=[0,0], arrowprops=black)plt.annotate('', xy=[2/5, -1/2], xytext=[0,0], arrowprops=black)plt.annotate('', xy=[3/5,1/2], xytext=[0,0], arrowprops=black)plt.annotate('', xy=[1,0], xytext=[3/5, 1/2], arrowprops=blue)plt.scatter(1,0, 100, 'r')plt.text(0.1, -0.28, 'a')plt.text(0.19, 0.3, 'b')plt.text(0.6, 0.1, 'c')plt.show()a 벡터와 b 벡터 합은 c벡터로, 위 그림과 같다.a 벡터를 더하고자 하는 b 벡터 점으로 평행이동 시켰을 때, 평행이동한 a벡터(파란색 화살표) 가 가리키는 점이 a+b 벡터(c벡터)이다.벡터 차 기하학적 관점에서 벡터 차는 다음과 같다.# 벡터 차plt.ylim(-1,1)plt.xlim(-1,2)black = {'facecolor' : 'black'}blue = {'facecolor' : 'blue'}plt.annotate('', xy=[2/5, -1/2], xytext=[0,0], arrowprops=black)plt.annotate('', xy=[3/5,1/2], xytext=[0,0], arrowprops=black)plt.annotate('', xy=[2/5, -1/2], xytext=[3/5, 1/2], arrowprops=blue)plt.text(0.1, -0.28, 'a')plt.text(0.19, 0.3, 'b')plt.text(0.6, 0.0, 'a-b')plt.scatter(2/5, -1/2, 100, 'r')plt.scatter(3/5,1/2, 100, 'r')plt.show()a-b를 계산한다고 치자.b벡터가 가리키는 점에서 a벡터가 가리키는 점으로 화살표를 연결하면, 그 벡터가 a-b 벡터(파란색 화살표)가 된다.유클리드 거리 a,b 두 벡터가 있다고 할 때, 두 벡터가 가리키는 점과 점 사이 거리$\\rVert a-b \\lVert^{2} = \\rVert a \\lVert^{2} + \\rVert b \\lVert^{2} - 2a^{T}b$ 유사도 구하려는 두 벡터 길이가 비슷비슷 할 때, 유클리드 거리는 코사인유사도와 비슷하게 쓸 수 있다.벡터 내적 $a^{T}b$ 가 $\\rVert a \\lVert \\rVert b \\lVert cos\\theta$ 와 같기 때문이다.벡터 a,b 길이가 모두 비슷하다면 결국 유클리드거리 제곱 값을 결정짓는건 벡터 간의 코사인 유사도 값이다.따라서 두 벡터 길이가 비슷할 때, 유클리드 거리를 코사인 유사도 처럼 사용할 수 있다.한편, 유클리드거리를 이용하면 고차원벡터의 저차원 투영성분이 여러 저차원벡터 중 원래 벡터와 가장 비슷한 벡터라는 사실을 알 수 있다.예를 들어 2차원 벡터를 1차원 공간에 투영한다고 해보자.plt.ylim(-2,3)plt.xlim(-2,3)black = {'facecolor' : 'black'}blue = {'facecolor' : 'blue'}plt.annotate('', xy=[1,2], xytext=[0,0], arrowprops=black)plt.text(0.5, 1.5, 'a')plt.scatter(1,2, 100,'r')plt.hlines(0, xmin=-2, xmax=3)plt.annotate('', xy=[1,0], xytext=[0,0], arrowprops=blue)plt.text(0.5, -0.3, 'b')plt.scatter(1,0, 100,'r')plt.vlines(1, ymin=0, ymax=2, ls=':', colors='r')검은색 벡터 a 가 2차원 벡터다. 파란색 벡터 b가 2차원벡터 a를 1차원 공간에 투영한 투영성분 b다. 벡터 a의 나머지 성분은 붉은 점선 자리에 해당하는 직교벡터일 것이다.곧, 파란색 벡터 b는 벡터 a 점과 수직이다. (a,b 둘 사이 거리가 수직 거리다)한편, 파란색 선인 1차원 공간상에 무수히 많은 점들이 있을 것이다. 수많은 점(벡터) 중에서 벡터 b는 벡터 a와 가장 비슷한 벡터라고 볼 수 있다.a,b 사이 유클리드거리를 통해 위 사실을 알 수 있다.파란색 직선(저차원 공간) 상의 모든 점들은 벡터 a와의 코사인 유사도가 모두 같다.코사인 유사도 관점에서, 직선 상의 모든 벡터들은 ‘다 똑같은 정도로 비슷하다’.따라서 코사인 유사도만 가지고는 저차원 공간 상의 벡터 중 어떤 벡터가 벡터 a와 가장 비슷한지 알 수 없다.벡터는 크기와 방향을 가지고 있었다. 두 벡터가 이루는 방향만 고려했을 때, 직선 위 모든 점들은 벡터 a와 똑같은 정도로 비슷했다. 방향만으로는 벡터 유사도 비교가 불가능하다.그러면 벡터 크기도 방향과 함께 고려해서 벡터 간 유사도를 비교해보자. 유클리드거리를 이용할 수 있다. 유클리드거리는 벡터가 가리키는 점과 점 사이 거리로, 이 거리는 비교하는 두 벡터의 크기와 방향 모두를 감안한 값이다.xx = np.arange(0,2+0.005, 0.005)def test(b) : return np.sqrt(5+(b**2)-2*np.sqrt(5)*b*(np.sqrt(5)/5)) tr = [test(b) for b in xx]plt.plot(xx, tr)plt.xlim(0,2)plt.xlabel('벡터 b 길이')plt.suptitle('고차원 벡터 a와 저차원 투영벡터 a_b 사이 유클리드 거리', y=1.03)plt.title(': 고차원 벡터 a와 수직인 지점 벡터 a_b에서 유클리드 거리가 가장 작아졌다')plt.show()그래프를 그려보니 벡터 a의 저차원 투영벡터인 벡터 b(a_b) 에서 유클리드거리가 가장 작았다. 이를 통해 고차원벡터의 저차원 투영성분이 저차원공간의 벡터 중 원래 벡터와 가장 비슷한 벡터임을 알 수 있었다.또, 점과 점 사이 수직거리가 두 점 사이 거리 중 가장 최단거리임을 알 수 있었다. 이처럼 유클리드 거리가 유용하긴 하지만, 위에 예시에 들었던 전제들 없이(예:벡터방향 모두 동일) 유클리드 거리만 가지고는 두 벡터 유사도 제대로 비교할 수 없다.정규직교 n개 벡터가 있는데, 이것들이 모두 단위벡터이고 서로 직교(벡터 간 내적이 0) 하면 ‘정규직교’라고 한다.$\\lVert v_{i} \\rVert = 1$$v_{i}^{T}v_{i} = 1$$v_{i}^{T} v_{j} = 0 (i \\ne j)$코사인 유사도$\\cos{\\theta} = \\frac{a^{T}b}{\\lVert a \\rVert \\lVert b \\rVert}$ 두 벡터가 비슷한 정도두 벡터가 담고 있는 데이터가 얼마나 비슷한지 비교할 수 있다.벡터의 길이는 상관없고, 벡터 방향만으로 두 벡터가 얼마나 비슷한지 판단할 수 있다. 두 벡터 방향이 비슷하면 코사인 유사도가 크다. 두 벡터가 비슷하다. 두 벡터가 담고 있는 데이터가 비슷하다. 두 벡터 방향이 다를 수록 코사인 유사도가 작아진다. 두 벡터가 다르다. 두 벡터가 담고 있는 데이터도 별로 유사하지 않다. 코사인 유사도 최댓값은 1이다. 두 벡터 방향이 같을 때 코사인 유사도 값이 1이다. 이때 코사인 유사도 관점에서 두 벡터는 ‘매우 비슷하다’ 방향이 같은데 벡터 길이도 같다면, 두 벡터는 완전히 같은 벡터일 것이다.벡터 내적으로 코사인 유사도 계산할 수 있다벡터 내적은 다음과 같았다.$a^{T}b = \\lVert a \\rVert \\lVert b \\rVert \\cos{\\theta}$여러 벡터들을 가지고 쌍을 지어서 유사도를 비교할건데, 내적 식에서 $\\lVert a \\rVert \\lVert b \\rVert$ 이 부분이 다 비슷하다면 내적값은 결국 코사인 유사도 값일 것이다.여기서 다음 사실을 알 수 있었다. 두 벡터 길이가 비슷할 때는 내적 만으로도 두 벡터가 비슷한지 알 수 있다. 만약 두 벡터 길이가 다르면, 코사인 유사도 구해서 두 벡터가 비슷한 지 알 수 있다.예)벡터 내적만 가지고 코사인 유사도를 구하고, 두 벡터 사이 유사도를 계산해보자.사이킷런 패키지 데이터셋 중에 숫자 이미지 데이터셋을 가져와서, 두 이미지가 비슷한지 안 비슷한지를 벡터 내적으로 구해보자.벡터 내적만 가지고 두 벡터가 비슷한지, 안 비슷한지 보려면 벡터들의 길이가 다 비슷비슷해야 한다. 그래야 내적값이 곧 코사인 유사도 값이 될 것이다.from sklearn.datasets import load_digitsimport matplotlib.gridspec as gridspecdigits = load_digits().imagesdigits_images = [digits[i] for i in np.arange(1797)]norms = []for i in np.arange(1797) : v = digits[i].reshape(64,1) norms.append(np.linalg.norm(v))plt.stem(norms)데이터셋에 있는 숫자 이미지 데이터 1797개를 모두 가져왔다. 그리고 이들을 모두 벡터로 변환시킨 후 , 각각의 놈 값들을 구해서 stem 플롯으로 나타냈다. 플롯이 균등분포 형태로, 모든 이미지의 놈(벡터 길이) 값이 대체로 비슷비슷함을 볼 수 있었다.이제 그러면 벡터의 내적을 이용해서 코사인유사도를 구하고, 두 벡터가 비슷한지 알아보자.v1 = digits[0].reshape(64,1)v2 = digits[10].reshape(64,1)v3 = digits[1].reshape(64,1)v4 = digits[11].reshape(64,1)숫자 이미지 4개를 골랐다. 모두 벡터로 변환시켰다.어떤 이미지가 같은 종류 이미지고, 어떤 이미지가 다른 종류 이미지일까?print((v1.T@v2)[0][0], (v3.T@v4)[0][0])print((v1.T@v4)[0][0], (v1.T@v3)[0][0])print((v2.T@v3)[0][0], (v2.T@v4)[0][0])3064.0 3661.01883.0 1866.02421.0 2479.0벡터들 간 내적값을 구해보니 v1과 v2 벡터, 그리고 v3와 v4 벡터가 내적값이 높게 나왔다. 나머지 조합에 대해서는 위에서 볼 수 있듯 내적값이 작게 나왔다.이 결과를 놓고 보면 ‘v1과 v2’, ‘v3와 v4’가 같은 이미지겠거니 하고 추측할 수 있다. 벡터가 담고 있는 데이터가 유사하다는 뜻이다.코사인 유사도도 구해보자.# 코사인유사도 함수 def calc_cos(a,b) : return (a.T@b)/(np.linalg.norm(a)*np.linalg.norm(b))print(calc_cos(v1, v2)[0][0])print(calc_cos(v3, v4)[0][0])print(calc_cos(v1, v3)[0][0])print(calc_cos(v1, v4)[0][0])print(calc_cos(v2, v3)[0][0])print(calc_cos(v2, v4)[0][0])0.91910533702517860.85588506068271690.51910234264146860.51544972491053110.62022753281397690.6249243129435831코사인 유사도 값들을 구해도 내적을 통해 내린 결론과 같은 결론 내릴 수 있었다. v1과 v2 벡터는 코사인 유사도가 1에 가까웠고, v3와 v4도 그에 버금가게 나왔다.한편 나머지 벡터 조합에 대해서는 코사인 유사도 값들이 상대적으로 낮게 나왔다.실제로 벡터를 다시 이미지로 변환시켜 출력해보면 v1과 v2가 같은 이미지였고, v3와 v4가 같은 이미지가 나왔다.이를 통해 벡터들 길이가 비슷할 때, 내적을 이용하면 벡터 간의 유사도를 비교할 수 있음을 알 수 있었다.벡터의 분해와 성분 벡터를 다른 두 벡터의 합으로 분리시키는 것을 ‘분해’라고 한다. 벡터를 분해시켜 나온 두 벡터를 각각 원래 벡터의 ‘성분’ 이라고 한다.벡터의 투영성분과 직교성분 어떤 벡터 a를 다른 벡터 b에 평행하는 선분 하나와 벡터 b에 직교하는 성분 하나로 분해할 수 있다. 이때 전자를 ‘투영성분’, 후자를 ‘직교성분’ 이라고 한다.투영성분 : $a^{\\Vert{b}}$직교성분 : $a^{\\perp{b}}$투영성분의 길이 : $\\lVert a^{\\Vert{b}} \\rVert = a^{T}\\frac{b}{\\lVert b \\rVert}$투영성분벡터 : $a^{\\Vert{b}} = a^{T}\\frac{b}{\\lVert b \\rVert} \\frac{b}{\\lVert b \\rVert}$직교성분벡터 : $a^{\\perp{b}} = a-a^{\\Vert{b}}$red = {'facecolor' : 'red'}plt.xlim(-1,3)plt.ylim(-1,3)plt.annotate('', xy=[1,2], xytext=[0,0], arrowprops=black)plt.annotate('', xy=[2,0], xytext=[0,0], arrowprops=blue)plt.annotate('', xy=[1,0], xytext=[0,0], arrowprops=red)plt.annotate('', xy=[0,2], xytext=[0,0], arrowprops=red)plt.text(-0.6, 1.5, '직교성분 $a^{\\Vert b}$')plt.text(0.5, -0.3, '투영성분 $a^{\\perp b}$')plt.title('벡터 $b=[2,0]$ 에 대한 벡터 $a=[1,2]$의 투영성분과 직교성분')plt.show()메모)방정식의 진짜 의미가 뭘까?1 식 그 자체?2 근?방정식 = 함수 관계방정식 = ‘관계’를 표시한 것에 불과하다.$\\Rightarrow$ 특정한 근 들의 관계를 나타낸 것이 ‘방정식’이다.$\\Rightarrow$ 방정식의 진짜 주인공은 특정한 관계를 갖는 근들 이다.$\\Rightarrow$ 수식은 근들의 관계를 나타낸 하나의 기호이자 상징에 불과하다." }, { "title": "[수학/엔트로피] 상호정보량(MI), 최대정보 상관계수(MIC)", "url": "/bioinfo.github.io/posts/mutual_information/", "categories": "Data Science, python, mathematics", "tags": "mathematics, study, data science, python", "date": "2021-08-15 00:00:00 +0900", "snippet": "상호정보량 (Mutual Information) 정의 : 확률변수 $X$ 와 $Y$ 사이 상관관계 정도 나타내는 값피어슨 상관계수 대용으로 쓸 수 있다.피어슨 상관계수는 비선형 상관관계 나타내지 못한다.하지만 상호정보량은 선형, 비선형 상관관계 모두 나타낼 수 있다. $p(x,y)$와 $p(x)p(y)$의 쿨백-라이블러발산값이다. $MI[X,Y] = KL(p(x,y)\\Vert p(x)p(y))$ 확률변수 X,Y 사이 상관관계 정도가 강할 수록 상호정보량 증가확률변수 X,Y 사이 상관관계 정도가 약할 수록 상호정보량 감소두 확률변수 독립이면 쿨백-라이블러 발산값이 0 된다. 따라서 상호정보량값도 0 된다. $MI[X,Y] = H[X]-H[X\\vert Y]$ $MI[X,Y] = H[Y]-H[Y\\vert X]$이산확률변수 사이 상호정보량 계산 sklearn.metrics 패키지의 mutual_info_score()from sklean.metrics import mutual_info_scoremutual_info_score(X 데이터 배열, Y 데이터 배열)X,Y 순서 바뀌어도 상관 없다.이산확률변수 사이 상호정보량 계산 예 )데이터사이언스스쿨 713p 뉴스그룹 카테고리 예제1번부터 2.3만번 뉴스 키워드 확률변수가 있다.각 확률변수는 1~k 사이 정수를 데이터로 내놓는 ‘카테고리확률변수’다.각 확률변수는 1785개씩 데이터를 갖고 있다.한편뉴스그룹카테고리 확률변수가 있다. 이 확률변수는 0,1,2 만을 내놓는 ‘카테고리확률변수’다.뉴스그룹카테고리 확률변수 역시 1785개 데이터를 갖고 있다.1번 - 뉴스그룹 확률변수 , 2번 - 뉴스그룹 확률변수 … 이런 식으로 해서 각 키워드 확률변수와 뉴스그룹 확률변수 사이 상관관계가 있는지, 상호정보량 값으로 알아보자.상호정보량 값이 크다면(상관관계가 크다면) 키워드 확률변숫값을 알 때, 뉴스그룹 키워드 확률변숫값에 대한 대략적 정보를 얻을 수 있을 것이다.바꿔말하면, 키워드가 몇 번 나왔는지 보면 이 뉴스 기사가 어떤 카테고리에 속하는 뉴스 기사 인지 대강 예측할 수 있다는 말이다.# 이산확률변수 간 상호정보량 계산 from sklearn.datasets import fetch_20newsgroupsfrom sklearn.feature_extraction.text import CountVectorizerfrom sklearn.metrics import mutual_info_scorecategories = ['rec.autos', 'sci.med', 'rec.sport.baseball']newsgroups = fetch_20newsgroups(subset='train', categories=categories)vect = CountVectorizer(stop_words='english', token_pattern = '[a-zA-Z]+')X = vect.fit_transform(newsgroups.data).toarray() # 2.3만개 카테고리 확률변수, 각각 확률변숫값 1785개씩 y = newsgroups.target # 뉴스그룹 카테고리확률변숫값(0,1,2)mi = [mutual_info_score(X[:,i], y) for i in range(X.shape[1])] # i번 키워드 확률변수와 뉴스그룹카테고리확률변수 간 상호정보량 값들plt.stem(mi)plt.title('뉴스그룹 카테고리확률변수와 i번 키워드 카테고리확률변수 사이의 상호정보량')plt.xlabel('키워드 번호')plt.show()결과를 해석해보자.위 코드에서 X는 0번~ 2.3만번 까지 키워드 ‘카테고리 확률변수’ 들이다. 각각 1785개씩 데이터를 가지고 있다. 따라서 1785 * 2.3만 의 행렬 형태다.이 행렬에서 각 열과 뉴스그룹카테고리 확률변수 데이터를 가지고 상호정보량을 계산할 것이다.한편 y는 뉴스그룹카테고리 확률변수다. 0,1,2 만을 표본으로 내놓는 카테고리확률변수다.mi = [mutual_info_score(X[:,i], y) for i in range(X.shape[1])] 이제 이 코드를 통해 1번 키워드 - 뉴스그룹, 2번 키워드 - 뉴스그룹, 3번 키워드 … 이런 식으로 각 확률변수 간 상호정보량 값을 계산해서 mi 리스트 안에 담는다.이 값들은 ‘각 키워드 별 뉴스그룹과의 상호정보량’ 값들이다.각 상호정보량 값들의 인덱스 넘버는 키워드 번호와 같다. i번째 상호정보량 값은 i번째 키워드의 (뉴스그룹과의) 상호정보량 값이다.키워드 별 상호정보량 값들을 stem 플롯으로 나타낸 것이 위 이미지와 같다.stem 플롯에서 상호정보량 값이 높을 수록 뉴스그룹카테고리와 상관관계가 강한 키워드다.바꿔말하면, 키워드 빈도를 알 때 뉴스그룹 카테고리가 뭘 지 대강 예측 가능한 키워드다.가장 상호정보량 값이 높은, 상위 10개 키워드만 뽑아보자.inv_vocabulary = {v:k for k, v in vect.vocabulary_.items()} # 0~2.3만번 키워드 idx = np.flip(np.argsort(mi))[inv_vocabulary[idx[i]] for i in range(10)]inv_vocabulary는 번호 : 키워드 이름 으로 구성된 딕셔너리다. 각 번호는 키워드 번호다.idx = np.flip(np.argsort(mi))이 코드를 통해 상호정보량 값들이 작은 순서대로 인덱스 번호들을 따고, 앞뒤 순서를 다시 뒤집는다. 곧, 상호정보량 값들을 내림차순 정렬시킨 뒤 각 값들을 mi 리스트 에서 할당된 인덱스 번호로 바꿨다.idx 리스트는 이제 상호정보량 값이 가장 큰 키워드~ 가장 작은 키워드 순으로 정렬되었다.[inv_vocabulary[idx[i]] for i in range(10)]마지막 코드를 통해, 키워드 사전인 inv_vocabulary 딕셔너리에서 상호정보량 상위 10개 키워드를 영단어 형태로 뽑아낸다.[‘car’, ‘baseball’, ‘cars’, ‘team’, ‘game’, ‘games’, ‘season’, ‘players’, ‘geb’, ‘gordon’]예컨대 가장 상호정보량 값이 높았던 단어, car의 경우, 뉴스 기사에 ‘car’가 몇 번 등장했는지 알면 이 뉴스 기사가 어떤 카테고리에 속하는 뉴스 기사 일 지 대강 예측이 가능하다는 말이다.최대정보 상관계수 (Maximul information coefficient : MIC) 연속확률변수 X,Y 사이 상관관계 정도를 나타내는 값. 상호정보량의 일종이다. max(상호정보량)상호정보량을 계산하려면 확률밀도함수가 필요하다. 연속확률변수에서 나온 데이터를 가지고 이 확률밀도함수를 추정 하는데, 데이터를 여러 단위 구간으로 쪼개서 단위 별로 확률밀도함수를 여러 개 추정한다.그리고 각각 확률밀도함수로 각각 상호정보량 값을 구한다.이 중에서 ‘가장 큰 상호정보량 값’을 골라서 정규화 한 값이 ‘최대정보 상관계수’다.연속확률변수 사이 상호정보량 계산minepy 패키지를 이용해서 MIC 값 계산할 수 있다.from minepy import MINEmine = MINE()1. mine.compute_score(x데이터 배열, y데이터 배열)2. mine.mic() x 데이터 배열과 y 데이터 배열 넣는 순서는 상관 없다. 2번 mine.mic() 명령을 내려야 최대정보 상관계숫값 반환한다.from minepy import MINEmine = MINE()plt.figure(figsize=(8,6))n = 500plt.subplot(231)x1 = np.random.uniform(-1,1,n)plt.scatter(x1, x1)mine.compute_score(x1, x1)plt.title(f'MIC = {np.round(mine.mic(),2)}')plt.subplot(232)x2 = np.random.normal(size=n)y2 = x2 + x1plt.scatter(x2, y2)mine.compute_score(x2, y2)plt.title(f'MIC = {np.round(mine.mic(),2)}')plt.subplot(233)x3 = np.random.uniform(-1,1,n)y3 = 2*x3**5+np.random.uniform(-1,1,n)plt.scatter(x3, y3)mine.compute_score(x3, y3)plt.title(f'MIC = {np.round(mine.mic(), 2)}')plt.subplot(234)x4 = np.random.uniform(-1,1,n)y4 = x4**8+x1/2plt.scatter(x4, y4)mine.compute_score(x4, y4)plt.title(f'MIC = {np.round(mine.mic(),2)}')plt.subplot(235)x5 = np.random.uniform(-1,1,n)y5 = 4*(x5**2-0.5)**3+np.random.uniform(-1,1,n)/5plt.scatter(x5, y5)mine.compute_score(x5, y5)plt.title(f'MIC = {np.round(mine.mic(),2)}')plt.subplot(236)x6 = np.random.uniform(-1,1,n)y6 = (x6**2 + np.random.uniform(-1/7,1/7, n))*np.array([-1,1,])[np.random.random_integers(0,1,size=n)]plt.scatter(x6, y6)mine.compute_score(x6,y6)plt.title(f'MIC = {np.round(mine.mic(),2)}')plt.suptitle('두 연속확률변수 사이 선형, 비선형 상관관계 정도', y=1.03)plt.tight_layout()plt.show()" }, { "title": "[수학/엔트로피] 엔트로피, 결합엔트로피, 조건부엔트로피, 크로스엔트로피, 쿨백-라이블러 발산", "url": "/bioinfo.github.io/posts/distribution_and_entropy/", "categories": "Data Science, python, mathematics", "tags": "datascience, mathematics, python", "date": "2021-08-11 00:00:00 +0900", "snippet": "엔트로피정의확률분포에서 나온 표본 1개가 특정 표본인지 추려내기 위해 필요한 평균 질문 갯수(정보량) 분포의 불확실성 분포에서 새롭게 얻을 수 있는 정보의 양 (=놀람의 정도) 분포의 분산 정도 엔트로피 단위 : 비트표기 H 수학적 정의는 확률변수를 입력으로 받는 범함수다.이산확률변수$H[Y] = -\\sum_{i=1}^{k} p(y_{k})\\log_{2}{p(y_{k})}$연속확률변수$H[Y] = -\\int p(y)\\log_{2} p(y) dy$xx = np.linspace(0,1,10000)ent_values = []for p in xx : if p == 0 or p == 1 : ent_values.append(0) else : ent_value = -(1-p)*np.log2(1-p)-p*np.log2(p) ent_values.append(ent_value)plt.plot(xx, ent_values)plt.title('엔트로피 $H[Y]$')plt.show()사이파이 엔트로피 계산 코드sp.stats.entropy(p, base=2)p 는 엔트로피를 계산할 확률분포다.엔트로피의 성질 엔트로피 최솟값은 0 이다.분포 분산정도가 극단적으로 낮은 경우, 엔트로피 값이 0 나올 수 있다. 분포 분산 정도와 엔트로피값 크기는 정비례 한다.x1 = [1/8, 1/8, 1/4, 1/2]x2 = [1,0,0,0]x3 = [1/4]*4plt.figure(figsize=(9,3))plt.subplot(131)plt.bar([0,1,2,3],x1)plt.xticks([0,1,2,3], ['Y=0', 'Y=1', 'Y=2', 'Y=3'])plt.title('$H[Y] = 1.75$')plt.ylim(0,1.1)plt.subplot(132)plt.bar([0,1,2,3],x2)plt.xticks([0,1,2,3], ['Y=0', 'Y=1', 'Y=2', 'Y=3'])plt.title('H[Y] = 0')plt.ylim(0,1.1)plt.subplot(133)plt.bar([0,1,2,3], x3)plt.xticks([0,1,2,3], ['Y=0', 'Y=1', 'Y=2', 'Y=3'])plt.title('$H[Y] = 2$')plt.ylim(0,1.1)plt.suptitle('분산정도가 작을 수록 엔트로피가 작아진다',y=1.04)plt.tight_layout()plt.show()위 그림에서두번째 분포는 표본 얻었을 때 Y=0이 나올 가능성이 100% 다. 이 분포에서 앞으로 어떤 정보를 얻어도 놀랍지 않을 것이다. 왜냐하면 불 보듯 뻔하게 1이 나올 것이기 때문이다. 따라서 두번째 분포는 새롭게 얻게 될 정보량(엔트로피)가 0 이다.또한 두번째 분포는 분산 정도 또한 극단적으로 낮음을 볼 수 있다. 분산 정도가 작으면 분포의 엔트로피값도 작다.한편세번째 분포는 범줏값 0~3이 나올 확률이 모두 같다. 따라서 내가 이 분포에서 표본을 얻으려 할 경우, 뭐가 나올지 전혀 알 수 없다. 따라서 이 분포에서 데이터를 1개 얻을 경우, 그 데이터는 귀중한 가치를 지닌 ‘정보’ 가 된다. 이후에 얻는 데이터 하나하나도 정보가치가 충분할 것이다. 따라서 이 분포는 새롭게 얻게 될 정보량이 많은 분포라고 생각할 수 있다. 엔트로피는 이런 경우 가장 커진다.또 세번째 분포 분산정도 또한 매우 높음을 볼 수 있다. 분산 정도가 클 수록 분포의 엔트로피 값도 크다.가변길이 인코딩과 고정길이 인코딩가변길이 인코딩 인코딩 : 표본 1개에 대한 질문-응답 결과와 같았다. 가변길이 인코딩 : 확률분포 확률값들에 따라 질문하는, 가장 효율적인 질문 전략가변길이 인코딩 예)$p = [0.5, 0.25, 0.125, 0.125]$ 라는 분포가 있다고 가정해보자.이 분포를 갖는 확률변수에서 뭔진 모르겠지만 어떤 표본 하나가 나온다고 하자.이 표본이 뭔지 어떻게 추려낼 것인가?질문을 던지면 된다.예를 들어 ‘나온 표본은 A’인가? , ‘B인가?’ 등등으로 물을 수 있다. 하나의 질문에 대해 YES 나 NO로 대답해가면서 이번에 나온 표본이 뭔지 추릴 수 있다.가변길이 인코딩은 이 ‘질문 방식’으로 생각할 수 있다.가변길이 인코딩에서는 기본적으로 각 표본마다 할당된 확률값에 기초해 질문을 던진다.예를 들어 A가 0.5로 가장 확률이 높다. 표본 하나를 얻었을 때 그게 A일 확률이 가장 높다. 그러면 첫 질문으로 A인가? 아니면 BCD인가? 이렇게 질문을 던진다.그리고 만약 A이면 A를 추려낸 것이고, A가 아니면 다시 두번째로 확률높은 B인가? 를 질문한다.이런식으로 C,D까지 추려낼 수 있다. 그 후 각 질문에 대한 답변에 기초해 각 문자를 이진수로 인코딩할 수 있다.예를 들어 A는 첫 질문에서 YES라고 답한 후 추려졌다.YES = 0, NO = 1 로 생각하면, A는 곧 0으로 인코딩 된다.나머지 알파벳도 마찬가지다.A는 0으로 인코딩 되었는데, 한 자리다. 이는 비트 하나, 그러니까 질문 1개 를 나타낸다.D는 111로 인코딩 되었는데, 세 자리다. 이는 비트 셋, 그러니까 질문 3개를 나타낸다. 참고) 한 글자에 인코딩 된 이진수는 다른 글자에 인코딩 된 이진수의 접두어가 될 수 없다.고정길이 인코딩 모든 표본이 균등분포에서 나왔다고 전제한다. 어떤 표본이 더 나오고, 덜 나오고 없다.모든 표본이 나올 가능성이 같으므로, 어떤 표본을 먼저 추려내고, 늦게 추려내고 할 수 없다. 따라서 다른 방법으로 추려내야 한다.이때 표본을 추려내는 최적의 질문전략은 다음과 같다.‘ABCD’ 이면, 절반/절반으로 나누어 표본을 추려내고, 다시 거기서 절반/절반을 나누어 표본을 추려낸다.‘AB’, ‘CD’‘A’, ‘B’, ‘C’, ‘D’ 이렇게 나누는 식이다.위 그림과 같다.이렇게 표본을 추려내면 모든 표본에 대해 질문횟수가 같다.YES = 0, NO = 1로 두고, 각 알파벳을 질문 결과에 따라 인코딩 하면A = 00B = 01C = 10D = 11이렇게 인코딩할 수 있는데, 이게 고정길이 인코딩 방식이다.엔트로피 - 가변길이 인코딩 사이 관계 엔트로피 값 = 가변길이 인코딩 했을 때 표본 1개당 평균 정보량예)어떤 문서가 있다. 이 문서는 A,B,C,D,E,F,G,H 로 구성되어 있다. 각 알파벳이 등장할 확률은 다음과 같다.$P = [1/2, 1/4, 1/8, 1/16, 1/64, 1/64, 1/64, 1/64]$이 문서 알파벳들을 전부 가변길이 인코딩 할 때, 알파벳 1개 당 평균 비트 수는?답)먼저, 이 문서는 K = 8 인 카테고리 확률변수에서 나온 표본들을 모아놓은 것과 같다.예컨대 문서가‘AAAAABAAAACDAAAADABBBCCBBABBCABDABADADACBABACBADAABAACAADAABDCDCCABADCAACABABBAAAACDABBBDABCAAADDBBAABAAACAADADBCACBADBABAAABAAAABACABBBABAABCBABAAABACAACAACAAADABBBAAABDCDACDAAAADAAAABDAABABCDABBBDAA’이런 식 이라면, 이건 K = 8인 카테고리 확률변수를 200번 시뮬레이션 해서 얻어낸 데이터 집합이다.이 문서가 결국 카테고리확률변수의 표본이라는 게 핵심이다.앞에서 비트 수는 질문갯수와 같았다.가변길이 인코딩 했을 때 알파벳 1개 당 평균 비트 수는 :확률변수 확률분포에 따라 질문 던지고 각 표본 추려냈을 때, 표본 1개 당 평균 질문 갯수와 같다.확률변수의 확률분포에 따라 질문을 던지고 각 표본값을 추려내 보았다.그리고 각 질문에 대한 대답에 따라 각 표본을 이진수 인코딩 할 수 있었다.A = 0B = 10C = 110D = 1110E = 111100F = 111101G = 111110H = 111111각 표본 1개 당 평균 비트 수는 각 확률분포값에 질문 갯수를 곱해서 가중합 한 것과 같다.(1/2*1)+(1/4*2)+(1/8*3)+(1/16*4)+(1/64*6)*4표본 1개 당 평균 비트 수(질문 갯수, 정보량) : 2.0이 나온다.한편“엔트로피-가변길이 인코딩 간 관계”에 의해서 표본이 나온 분포의 엔트로피 값은 가변길이 인코딩 했을 때 표본 1개 당 평균 정보량(비트 수, 질문 갯수) 와 같았다.따라서 A,B,C,… 표본이 나온 카테고리 확률분포의 엔트로피 값을 구하면, 표본 1개 당 평균 정보량을 구할 수 있다.p = [1/2, 1/4, 1/8, 1/16] + [1/64]*4sns.barplot(np.arange(1,9), p)plt.title('문서 : $k=8$ 인 카테고리 확률분포')avg_info = sp.stats.entropy(p, base=2)plt.xlabel('$k$')plt.xticks(np.arange(8), ['A','B','C','D','E','F','G','H'])plt.show()print(f'표본 1개 당 평균 정보량(=비트 수) : {avg_info}')print(f'k=8인 카테고리 확률분포의 엔트로피 : {avg_info}')k=8인 카테고리 확률분포의 엔트로피 : 2.0표본 1개 당 평균 정보량(=비트 수) : 2.0이다. 확률분포의 엔트로피값과 표본 1개당 평균 질문갯수가 같음을 재확인할 수 있었다.지니불순도 엔트로피 대용으로 쓸 수 있는 값 지니불순도*2 는 엔트로피 값에 근사한다.$G[Y] = \\sum_{k=1}^{k} P(y_{k})(1-P(y_{k}))$엔트로피와 지니불순도 비교p = np.linspace(0.0001, 1-0.0001, 10000)G = [p*(1-p)+(1-p)*p for p in p]H = [-p*np.log2(p)-(1-p)*np.log2(1-p) for p in p]G2 = [(p*(1-p)+(1-p)*p)*2 for p in p]plt.subplot(121)plt.plot(p, G, label='지니불순도')plt.plot(p, H, label='엔트로피')plt.title('지니불순도와 엔트로피')plt.xlabel('$P(Y=1)$')plt.legend()plt.subplot(122)plt.plot(p, G2, label='지니불순도 값 * 2')plt.plot(p, H, label='엔트로피')plt.title('지니불순도*2 와 엔트로피')plt.xlabel('$P(Y=1)$')plt.legend()plt.suptitle('엔트로피와 지니불순도 비교', y=1.007)plt.tight_layout()plt.show()지니불순도 *2 를 하면 엔트로피값에 근사하는 것을 볼 수 있었다.결합엔트로피 결합확률분포의 엔트로피 (벡터 분포의 엔트로피) 일반적인 엔트로피와 성질이 같다. 분포 분산 정도가 작을 때 엔트로피 값 작아지고, 분산 정도가 클 때 엔트로피 값 커진다. 최솟값은 0이다.이산확률변수 X,Y$H[X,Y] = -\\sum_{i=1}^{K_{X}} \\sum_{j=1}^{K_{Y}} p(x_{i}, y_{j})\\log_{2}{p(x_{i}, y_{j})}$연속확률변수 X,Y$H[X,Y] = -\\int_{x} \\int_{y} p(x,y)\\log_{2}{p(x,y)}dxdy$조건부엔트로피 확률변수 X로 확률변수 Y를 예측할 수 있는 정도 나타낸다 X,Y 사이 상관관계, 독립 정도를 나타낸다. $X = x_{i}$ 일 때 $Y$ 확률변수 조건부엔트로피를 $X$ 주변확률분포값을 가중치 삼아 가중합 한 것이다.1. $X = x_{i}$ 일 때 Y 확률변수 조건부엔트로피이산확률변수$H[Y\\vert X = x_{i}] = -\\sum_{j=1}^{K_{Y}}p(y_{i}\\vert x_{i})\\log_{2}{p(y_{i} \\vert x_{i})}$연속확률변수$H[Y\\vert X = x] = -\\int_{y}p(y\\vert x)\\log_{2}{p(y\\vert x)}dx$2. 조건부엔트로피이산확률변수 X,Y$H[Y\\vert X] = \\sum_{i=1}^{K_{X}} p(x_{i})H[Y\\vert X=x_{i}]$연속확률변수 X,Y$H[Y\\vert X] = \\int_{x} p(x)H[Y\\vert X = x]dx$X로 Y예측가능한 정도와 조건부엔트로피는 반대로 움직인다 확률변수 X로 확률변수 Y 예측가능한 정도가 클 수록 조건부엔트로피 감소 확률변수 X로 확률변수 Y 예측가능한 정도가 작을 수록 조건부엔트로피 증가조건부엔트로피 계산함수def cond_entropy(df) : cond_p1 = df.values[0]/df.values[0].sum() cond_p2 = df.values[1]/df.values[1].sum() ent1 = sp.stats.entropy(cond_p1, base=2) ent2 = sp.stats.entropy(cond_p2, base=2) return (df.values[0].sum()/df.values.sum())*ent1 + (df.values[1].sum()/df.values.sum())*ent2조건부엔트로피 활용 예데이터사이언스스쿨 연습문제 10.2.1문) 사이킷런 패키지 붓꽃 데이터에서, 꽃받침 길이와 꽃받침 폭 중 어떤 데이터가 붓꽃 종 분류(예측)에 더 도움이 되는가?꽃받침 길이, 꽃받침 폭 데이터의 최솟값과 최댓값 사이를 0.05 간격 구간으로 나누어, 각각의 값을 분류 기준값으로 삼았을 때 조건부엔트로피값이 어떻게 변하는지 그래프로 그려서 설명해라.from sklearn.datasets import load_irisdata = load_iris()df = pd.DataFrame(data.data, columns=data.feature_names)df['species'] = data.targetdef plot_cond_entropy(df, name) : len_min = np.min(df[name].values) len_max = np.max(df[name].values) xx = np.arange(len_min, len_max+0.05, 0.05) entropies = [] for i in xx : df['X1'] = df[name] &gt; i pivot_table = df.groupby(['X1', 'species']).size().unstack().fillna(0) cond_p1 = pivot_table.values[0]/pivot_table.values[0].sum() cond_p2 = pivot_table.values[1]/pivot_table.values[1].sum() ent1 = sp.stats.entropy(cond_p1, base=2) ent2 = sp.stats.entropy(cond_p2, base=2) cond_entropy = (pivot_table.values[0].sum()/pivot_table.values.sum())*ent1 + (pivot_table.values[1].sum()/pivot_table.values.sum())*ent2 entropies.append(cond_entropy) ind = entropies.index(np.min(entropies)) optimized_value = np.round(xx[ind],2) ; min_ent = np.round(np.min(entropies),2) print(f'최적해 : {optimized_value}, 최저 조건부엔트로피 : {min_ent}') plt.plot(xx, entropies) plt.scatter(optimized_value, min_ent, 30, 'r') plt.title(f'{name} 기준값 별 조건부엔트로피 변화') plt.xlabel('꽃받침 길이 기준값') plt.ylabel('조건부엔트로피') plt.show()1. 꽃받침 길이를 기준값으로 삼았을 때조건부엔트로피가 최소가 되는 꽃받침길이 기준값(최적해) 는 5.55 였다. 이때의 최저 조건부엔트로피값은 1.03 이었다.2. 꽃받침 폭을 기준값으로 삼았을 때조건부엔트로피가 최소가 되는 꽃받침 폭 기준값(최적해) 는 3.35 였다. 이때의 최저 조건부엔트로피값은 1.3 이었다.3. 결론꽃받침 길이를 기준값으로 썼을 때는 꽃받침 길이가 5.55cm 를 넘느냐/넘지 않느냐를 기준으로 종 분류가 가능했다.꽃받침 폭을 기준값으로 썼을 때는 꽃받침 폭이 3.35를 넘느냐/넘지 않느냐를 기준으로 종 분류가 가능했다.그리고 각 기준값에서, 조건부엔트로피값은 각각 1.03, 1.3 이었다.조건부엔트로피 값은 ‘X 확률변수로 Y 확률변수를 예측할 수 있는정도’를 의미했다. 조건부엔트로피 값이 작을수록, X 확률변수로 Y 확률변수를 더 잘 예측할 수 있다. 꽃받침 길이를 기준값으로 삼았을 때 조건부엔트로피가 더 작았다. 꽃받침 길이가 꽃받침 폭 보다 ‘이 꽃의 종이 뭔지’ 더 잘 분류할 수 있는 특징값이라는 뜻이다.$\\Rightarrow$ ‘꽃받침 길이’가 ‘꽃받침 폭’ 보다 종 분류에 더 도움되는 특징값이다!크로스엔트로피 (교차엔트로피)https://hyunw.kim/blog/2017/10/26/Cross_Entropy.html위 블로그의 크로스엔트로피 설명을 통해 이 개념을 확실히 이해할 수 있었다.도움을 받아 내가 이해한 내용을 다시 정리하면,크로스엔트로피란 다음과 같다.크로스엔트로피 정의 : “P 확률분포에서 나오는 표본이 뭔지 알아맞히기 위해, 질문전략으로 Q분포를 썼을 때 평균 질문 갯수”정의 설명)p 확률분포가 다음과 같다고 가정하자.$p = [0.5, 0.25, 0.125, 0.125]$p는 A,B,C,D 가 나오는 카테고리확률변수다.여기서 어떤 임의의 표본이 하나 나올 때 마다, 내가 얻은 표본이 뭔지 추려내기 위한 질문을 해보자.가변길이 인코딩 파트에 기록했던 것 처럼, 가장 효율적 방식으로 P에서 나온 표본을 추려내기 위한 질문을 하면 다음과 같다.이 경우 각 표본당 평균 질문 갯수를 구하면 1.75다.이 값은 p 분포의 엔트로피($H[p]$)를 구하면 얻을 수 있다.sp.stats.entropy(p, base=2)한편 p분포 이외에도 q 분포가 있다고 하자.q 분포는 다음과 같다.$q = [0.25, 0.25, 0.25, 0.25]$q분포는 확률질량값이 모두 똑같다. 따라서 아래 처럼 질문할 수 있다.이때 표본 1개 당 평균 질문 갯수는 2다.그럼 이제 q분포에 따른 질문전략(모든 표본에 동일한 수의 질문 던지기)을 p분포 표본들을 추려내기 위해 사용해보자.p 분포에서 나오는 표본은 A,B,C,D 였다.이걸 q 질문 전략을 써서 추려내면 표본 1개 당 평균 질문 갯수는 2다.이 값 2가 ‘교차엔트로피(크로스엔트로피)’ 값이다.“p확률분포에서 나온 표본을 q분포에 따라 추려낼 때, p분포 표본 1개 당 평균 질문 갯수” p에서 나온 표본에 대해 최적의 질문전략(위 경우 p)를 썼을 때, 크로스엔트로피값은 최소화된다. 분포 q(새로운 질문전략)가 분포 p(최적 질문전략)와 비슷해질 수록 크로스엔트로피값은 줄어든다. 크로스엔트로피 식p, q가 이산확률분포$H[p,q] = -\\sum_{k=1}^{K} p(y_{k})\\log_{2}{q(y_{k})}$p, q가 연속확률분포$H[p,q] = -\\int_{y}p(y)\\log_{2}{q(y)}dy$또는 (이게 더 편해서 따로 기록)$H[p,q] = KL(p\\Vert q) + H[p]$ 범함수 입력으로 확률변수가 아닌 확률분포함수 p,q가 들어간다. $H[p]$ 값은 분포 p 표본 1개당 평균 질문갯수로, 고정된 값이다. KL 값은 q, p 분포 모양이 다른 정도다.# 크로스엔트로피 def calc_cross_entropy(p, q) : zipped = list(zip(p,q)) cross_entropy = 0 for p,q in zipped : cross_entropy += -p*np.log2(q) return cross_entropy세번째 크로스엔트로피 식에서 알 수 있는 사실 크로스엔트로피는 p분포와 q분포가 같으면 최소화된다. 두 분포가 같을 때 KL 값이 0 되기 때문이다. 이때 크로스엔트로피 최솟값은 $H[p]$ 가 된다. 크로스엔트로피를 최소화 한다는 건 KL 값을 최소화 한다는 것과 같다. 크로스엔트로피는 p, q 분포 모양이 다를 수록 커진다. 크로스엔트로피는 사실상 p분포와 q분포 모양 다른 정도다. 크로스엔트로피 $\\ge$ p분포 엔트로피크로스엔트로피 - 분류모형 성능평가에 사용 p와 q의 모양이 다른 정도(쿨백-라이블러 발산 값과 같다) 정답분포 p와 예측분포 q 설명 :$KL(p\\vert \\vert q) = H[p,q] - H[p]$여기서 분류모형 성능측정할 때는 $H[p]$ 는 0이 된다(정답분포는 원핫인코딩벡터 꼴이기 때문). 따라서$H[p,q] = KL(p\\vert \\vert q)$ 이다.= 데이터 1개에 대한 예측이 틀릴 가능성= 분류모형의 성능 나쁜 정도 분류모형 성능이 나쁠 수록 크로스엔트로피 증가 분류모형 성능이 좋을 수록 크로스엔트로피 감소 로그손실 - 교차엔트로피 평균이진분류 문제에서 크로스엔트로피값은 데이터 1개에 대해 예측이 틀릴 가능성(분류모형 성능 나쁜 정도) 을 의미한다.데이터 N개에 대해 각각의 교차엔트로핏값 평균을 구하면교차엔트로핏값 평균 : 데이터 N개에 대한 이진분류모형의 성능 나쁜 정도= 이진분류모형의 손실함수(오차함수)이 교차엔트로핏값 평균을 로그손실 이라 한다.로그손실을 최소화 (손실함수 최소화) 시킨다 = 분류모형 성능을 극대화 시킨다.따라서로그손실 최소화 = 이진분류모형 성능 최적화 목표.로그손실 이용해 분류모형 성능 최적화(최대화) 예)데이터사이언스스쿨 연습문제 10.3.1사이킷런 패키지 붓꽃 데이터 중에서, 꽃받침 길이 데이터와 꽃받침 폭 데이터 중 어떤 데이터를 사용할 때 분류모형 성능이 극대화 되겠는가?각 데이터 최솟값과 최댓값 구간을 0.05 간격으로 나눠서 각 값을 기준값 삼아 붓꽃 종을 세토사와 베르시칼라로 분류하자.1. 꽃받침 길이 데이터 중 특정 기준값으로 붓꽃 종을 분류해보자.기준값 설정하기 전에, 일단 데이터를 한번 훑어보자.df['sepal length (cm)'].plot()plt.hlines(5.5, xmin = 0, xmax=100, colors='r')greater = np.bincount(df[df['sepal length (cm)'] &gt; 5.5]['species'])less = np.bincount(df[df['sepal length (cm)'] &lt; 5.5]['species'])g = pd.DataFrame(greater, columns=['5.5 보다 큰'])l = pd.DataFrame(less, columns=['5.5 보다 작은'])print(g)print('-'*10)print(l)데이터를 살펴보니 5.5cm 언저리를 기점으로 5.5보다 큰 데이터들은 대체로 정답값이 1로 분류되어 있었고, 5.5보다 작은 값들은 대체로 0번 종으로 분류되어 있었다.내가 만들 붓꽃 종 분류 모형이 5.5 언저리 특정 기준값을 기준으로 이 값보다 크면 1로 분류하고, 이 값보다 작으면 0으로 분류해야 분류모형이 주어진 정답 값(0,1)을 가장 잘 맞추게 될 것이다.# 로그손실 값 그래프 그리는 함수 def plot_log_loss(df, name, reverse=False) : from sklearn.metrics import log_loss criteria = np.arange(np.min(df[name]), np.max(df[name])+ 0.05, 0.05) log_losses = [] for x in criteria : if reverse == True : df['y_hat'] = (df[name] &lt; x).astype(int) log_loss_value = log_loss(df['species'], df['y_hat']) log_losses.append(log_loss_value) else : df['y_hat'] = (df[name] &gt; x).astype(int) log_loss_value = log_loss(df['species'], df['y_hat']) log_losses.append(log_loss_value) plt.plot(criteria, log_losses) min_log_loss = np.min(log_losses) ; optimized_value = criteria[log_losses.index(min_log_loss)] plt.scatter(optimized_value, min_log_loss, 30, 'r') plt.title(f'최저 로그손실 값 : {np.round(min_log_loss, 2)}, 최적해(기준값) : {np.round(optimized_value, 2)}') plt.xlabel(name) plt.ylabel('로그손실값') plt.show()df[‘종 이름’] &gt; 꽃받침 길이 기준 값으로 코드를 짜 주어야 특정 기준값보다 큰 값들을 True=1, 작은 값들을 False=0 으로 분류할 것이다.분류모형의 손실함수인 로그손실값을 각 기준점에서 계산해서 그래프로 그렸더니 위와 같았다.손실함숫값인 로그손실값이 최소가 될 때가 분류모형 성능이 극대화되는 지점이다.꽃받침 길이 5.45 cm 를 기준값으로 삼았을 때 로그손실값이 3.8로 최저가 되었다. 곧, 기준값 5.45일 때 분류모형 성능이 가장 극대화된다.2. 꽃받침 폭 데이터 중 특정값을 기준으로 붓꽃 종을 분류해 보자.이번에도 실현된 데이터들 특징을 먼저 함 살펴보자.df['sepal width (cm)'].plot()plt.hlines(3.0, xmin = 0 , xmax=100, colors='r')np.bincount(df[df['sepal width (cm)'] &gt; 3]['species']) # 대체로 0np.bincount(df[df['sepal width (cm)'] &lt; 3]['species']) # 대체로 1plt.text(20, 4.0, '대체로 0')plt.text(80, 2.3, '대체로 1')대체로 3 언저리 특정값을 기준점으로 삼았을 때, 기준값보다 큰 값은 대체로 0번 종이 많았고, 기준값보다 작은 값은 대체로 1번 종이 많았다.이 경우에는 df[‘종 이름’] &lt; 기준값 으로코드를 짜야 특정 기준값보다 낮은 값은 True=1 로, 특정 기준값보다 큰 값은 False=0 으로 분류되어 실제 정답값을 잘 맞출 것이다.이를 위해 ‘로그손실 값 그래프로 그리는 함수’에서, reverse argument 기본값을 False로 주고, 만약 True 가 들어올 경우 원래 df[‘종 이름’] &gt; 기준값 에서 부등호 방향이 &lt; 가 되도록 했다.plot_log_loss(df, 'sepal width (cm)', reverse=True)꽃받침 폭 특정값을 기준값으로 삼아 각 기준값에서의 로그손실값을 그래프로 그렸다.기준값이 3.05 일 때 로그손실값이 5.53으로 최저가 되었다.곧, 꽃받침 폭 3.05cm 를 기준점으로 삼아 데이터들을 종 별로 분류했을 때 분류모형 성능이 가장 극대화 된다는 의미다.꽃받침 길이 최적값과 꽃받침 폭 최적값 중 로그손실값이 더 작은 값이 분류모형 성능을 더 극대화할 수 있는(종 별 분류를 더 잘 해낼 수 있는) 값이다.꽃받침 길이 최적값에서 로그손실값이 더 작아졌다. 따라서 꽃받침 길이가 분류모형 성능 극대화에 두 값 중 더 적합한 특징값이다.쿨백-라이블러발산 (상대엔트로피)$KL(p\\Vert q) = H[p,q] - H[p]$ 정의 : (임의의 두 분포) q분포가 p분포와 모양 다른 정도p분포는 비교기준이 된다.설명)p분포에서 나온 표본을 q 분포에 따라 추려냈을 때 p분포 표본 1개 당 평균 정보량 - 최적 질문전략 썼을 때 p분포 표본 1개 당 평균 정보량 = KL 발산 값곧, KL 발산값은 정보량(질문갯수) 차이다.이 질문갯수 차이는 p분포와 q분포 모양이 비슷할 수록 줄어들고, p분포와 q분포 모양이 다를 수록 커진다.$\\Rightarrow$ KL 발산값 = q분포와 p분포 모양 다른 정도사이파이 쿨백-라이블러 발산값 계산 코드기존 사이파이 엔트로피 값 계산 코드에 p와 q 분포를 함께 집어넣으면 된다.sp.stats.entropy(p, q, base=2)p : 모양 비교기준이 되는 확률분포q : 기준분포 p와 모양 비교 할 확률분포쿨백-라이블러발산 성질 KL 발산 최솟값은 0이다.p분포와 q분포 모양이 완전히 같을 때 KL 발산값 0 된다. $KL \\ge 0$$KL = H[p,q] - H[p]$ 였다. 크로스엔트로피는 언제나 $H[p]$ 보다 같거나 컸다. 따라서 $KL$ 값도 항상 0 또는 양수다. $KL(p\\Vert q) \\ne KL(q\\Vert p)$" }, { "title": "[수학/확률과 통계] Scipy 패키지를 이용한 검정 방법", "url": "/bioinfo.github.io/posts/scipy_package_estimation/", "categories": "Data Science, python, mathematics", "tags": "mathematics, data science, study", "date": "2021-08-09 00:00:00 +0900", "snippet": "사이파이 사용해서 검정하기 파이썬 사이파이 패키지를 사용하면 다양한 검정을 쉽게 할 수 있다. 검정통계량 분포 그리고, 누적분포함숫값 직접 계산하고 안 해도 된단 거다.요약이항검정검정통계량 분포로 이항분포 사용, 베르누이확률변수 모수가설 검정카이제곱검정카테고리분포 모수 $\\mu$ 벡터 검정카이제곱 독립검정두 범주형 확률변수 사이 독립, 상관관계 유무 검정단일표본 z 검정정규분포 확률변수 기댓값 모수 $\\mu$ 에 대한 가설 검정 ($\\sigma^{2}$ 아는 경우)단일표본 t 검정정규분포 확률변수 기댓값 모수 $\\mu$ 에 대한 가설 검정 ($\\sigma^{2}$ 모르는 경우)독립표본 t 검정두 정규분포 기댓값 모수가 같은지 검정대응표본 t 검정1 : 1 대응되는 표본을 사용해서 독립표본 t 검정 시행등분산 검정두 정규분포 분산 모수 $\\sigma^{2}$ 이 같은 지 검정정규성 검정표본분포가 정규분포 따르는 지 검정KS 검정두 표본분포가 같은 분포에서 나왔는 지 검정정규성 검정에도 사용가능하다.이항검정 검정할 확률변수 : 베르누이 확률변수 검정할 모수가설 : 모수 $\\mu$ 에 대한 귀무가설 검정통계량 분포 : 이항분포 검정통계량 값 : N 번 중 성공 횟수 n 번 (이항분포 표본 1개)이항검정 명령scipy.stats.binom_test(x=, n=, p=, alternative=)x : 검정통계량 값n : N (총 시행 횟수)p : 귀무가설 $H_{0}$ 의 모수alternative : 양측검정이면 ‘two-sided’, 단측검정이면 ‘greater’, ‘less’이항검정 실시 예)데이터사이언스스쿨 - 9.5.3 연습문제문) 어떤 주제에 대해 찬반을 묻는 설문조사를 실시했고, 설문조사 결과 응답자의 70% 가 찬성이라는 결과가 나왔다. 전체 국민의 2/3 가 넘게 찬성한다는 결론을 유의수준 1%에서 얻기 위해 필요한 응답자 수는 얼마인가?단 응답자 수가 바뀌어도 찬성 70% 라는 결과는 바뀌지 않는다고 가정한다.답)문제의 정의 : n에 따른 유의확률을 구해야 한다. 유의확률값이 n이 얼마일 때 유의수준 1% 보다 작아지는 지 찾으면 된다.확률변수 : ‘주제에 대한 찬반’ (베르누이확률변수)시뮬레이션 : 설문조사검정통계량값 : n * 0.7검정통계량분포 : 이항분포시뮬레이션으로 추정해낸 모수 $\\mu$ : 0.7모수추정 결과를 가지고 가설을 세워보자.모수추정 결과를 보니 대략 $\\frac{2}{3}$ 넘는 국민들이 주제에 대해 찬성할 것 같다.저 모수추정 결과는 믿을만 한가?= $\\frac{2}{3}$ 넘는 국민이 주제에 찬성한다고 주장할 수 있는가?내가 주장하고 싶은 바를 가지고 대립가설을 세우자.$H_{a} : \\mu$ &gt; $\\frac{2}{3}$그러면 귀무가설은 다음과 같다.$H_{0} : \\mu = \\frac{2}{3}$귀무가설이 참인지, 거짓인지 증명하기 위해 사이파이 명령을 사용해 유의확률을 구해보자.일정 범위 n 값을 주고, n별 유의확률 값을 그래프로 그린다.n이 얼마일 때 0.01 선 밑으로 내려가는지(작아지는지) 보면 될 것이다.# 9.5.3 연습문제 nn = np.arange(0,2001)p_values = [sp.stats.binom_test(int(np.round(n*0.7)), n=n, p=2/3, alternative='greater') for n in nn]plt.plot(nn, p_values, 'ro-')plt.hlines(0.01, xmin=0, xmax=2000, colors='g', ls=':')plt.ylim(0.004,0.0125)plt.xlim(1110, 1140)plt.title('1116명 이상일 때 항상 대립가설 채택')plt.show()1116명 이상일 때 그래프가 처음으로 0.01 선 밑으로 내려간다.곧, 1116명 이상 설문 응답자를 모으면 이들로부터 얻은 유의확률이 0.01보다 작아져서, 귀무가설을 기각할 수 있게 된다는 뜻이다.귀무가설을 기각하고 대립가설을 채택한다. 따라서 1116명 이상일 때 “ $\\frac{2}{3}$ 넘는 국민들이 주제에 대해 찬성한다 “ 고 주장할 수 있다.카이제곱검정 (=적합도검정) 검정 할 확률변수 : 카테고리확률변수 검정 할 모수가설 : 모수 $\\mu$ 벡터에 대한 가설 검정 검정통계량 : 다항분포 표본 1개를 [이용해서] 검정통계량 값 계산$t = \\sum_{k=1}^{k} \\frac{(x_{k}-m_{k})^{2}}{m_{k}}$카이제곱검정 명령sp.stats.chisquare(다항분포표본 1개, 귀무가설 mu 벡터 값)카이제곱검정 시행 예)사면체 주사위를 100번 던졌다.1은 37번, 2는 32번, 3은 20번, 4는 11번 나왔다.이 주사위는 공정한 주사위인가?답)확률변수 : 사면체 주사위 (카테고리확률변수)시행횟수N : 100검정통계량 값 : 다항분포 표본 1개 이용해서 구하자카테고리확률변수는 원핫인코딩벡터 꼴 표본을 내놓는다.$[0,0,0,1]$ 이런 식이다.이 표본들을 이용해서 카테고리확률변수 시뮬레이션 100번 했을 때의 다항분포 표본 1개를 얻자.$1 = [1,0,0,0]$$2 = [0,1,0,0]$$3 = [0,0,1,0]$$4 = [0,0,0,1]$1이 37번 / 2가 32번 / 3이 20번 / 4가 11번원핫인코딩 벡터 합으로 위 결과 나타내면$[37, 32, 20, 11]$ 이다.이 다항분포 표본 1개 이용해서 검정통계량 값 구한다.한편 나는 이 주사위 나온 결과를 보니 주사위가 불공정한 주사위 같다(모수 벡터 $\\mu$ 값이 불균등하게 분배되어 있다)따라서 나는 ‘이 주사위는 불공정한 주사위다’를 증명해 보이고 싶다.여기 따라 대립가설을 놓는다.$H_{a} : \\mu \\ne [0.25, 0.25, 0.25, 0.25]$그러면 귀무가설은 다음과 같다.$H_{0} : \\mu = [0.25, 0.25, 0.25, 0.25]$이제 카이제곱검정을 실행해서 유의확률을 구해보자.n = 100k = 4np.random.seed(0)mu0 = np.array([0.35, 0.3, 0.2, 0.15])x = np.random.choice(k, n, p=mu0)result = np.bincount(x, minlength = k)sp.stats.chisquare(result, np.array([0.25, 0.25, 0.25, 0.25]))Power_divergenceResult(statistic=16.56, pvalue=0.0008703471978912127)유의확률값이 0.08% 이다. 귀무가설 기각할 수 있다. 대립가설 채택하면, “이 주사위는 공정하지 못한 주사위다”라고 주장할 수 있다.$\\mu \\ne [0.25, 0.25, 0.25,0.25]$카이제곱 독립검정 검정 할 확률변수 : 두 범주형 확률변수 $X$, $Y$ 검정 내용 : 두 범주형 확률변수가 독립인가? 상관관계가 있나?$H_{0} : \\mu_{1} = \\mu_{2}$$H_{a} : \\mu_{1} \\ne \\mu_{2}$ 위 가설에서 $\\mu_{1}$ 과 $\\mu_{2}$ 는 두 조건부확률분포 $P(Y\\vert{X=0})$ 과 $P(Y\\vert{X=1})$ 의 기댓값 모수 $\\mu_{1}, \\mu_{2}$ 라고 보면 된다. 확률변수 $X$ 와 $Y$가 서로 독립이라면 $Y$가 $X$에 영향 받지 않기 때문에 두 확률분포는 ‘같을 것이다’. 그게 귀무가설로 표현된 것이다. 한편, 두 확률변수가 서로 상관관계가 있다면 두 조건부확률분포는 서로 ‘다를 것이다’. 그게 대립가설로 표현된 것이다.귀무가설 채택 : X,Y 확률변수 서로 상관관계 없다. 서로 독립이다.대립가설 채택 : X,Y 확률변수 서로 상관관계 있다.카이제곱 독립검정 명령sp.stats.chi2_contingency(x)x : X, Y 확률변수 결합확률분포 표본 갯수 표예 )x = np.array([ [2,3], [8,9]])카이제곱 독립검정 시행 예)데이터사이언스스쿨 연습문제 9.5.5문 ) 데이터사이언스스쿨 수업을 들었는가 여부가 나중에 대학원에서 머신러닝 수업의 학점과 상관관계가 있는지 알기 위해 데이터를 구한 결과가 다음과 같다고 하자.데이터사이언스 스쿨 수업 듣지 않은 경우 즉 X가 0 이면 A,B,C 학점(Y값) 을 받은 학생의 분포가 4,16,20 이다.데이터사이언스 스쿨 수업 들은 사람의 경우 즉, X가 1일 때 A,B,C학점(Y값)을 받은 학생 분포가 23, 18, 19다.이 결과로부터 ‘데이터사이언스스쿨 수업 들었는가 여부’가 ‘머신러닝 수업 학점’과 상관관계가 있다고 말할 수 있는가?답 )데이터사이언스스쿨수업 들었는가 여부 : 베르누이확률변수 X머신러닝수업 학점 : 카테고리확률변수 Y문제 : 두 확률변수 사이 상관관계가 있다고 할 수 있는가?X,Y 확률변수는 모두 범주형 확률변수다. 두 범주형 확률변수 사이 독립인지, 상관관계있는지 알기 위해 카이제곱 독립검정을 쓰자.결합확률분포 표본갯수 표 :# 연습문제 9.5.5x = np.array([ [4,6,20], [23,18,19]])카이제곱 독립검정 명령result = sp.stats.chi2_contingency(x)[1]print(f'유의확률 : {result}')print(f'귀무가설 기각, 대립가설 채택')print(f'베르누이확률변수와 카테고리확률변수 간 상관관계가 있다고 말할 수 있다')유의확률 : 0.00704786570249751귀무가설 기각, 대립가설 채택베르누이확률변수와 카테고리확률변수 간 상관관계가 있다고 말할 수 있다곧, ‘데이터사이언스스쿨 수업을 들었는가 여부’와 ‘머신러닝 수업 학점’ 간 ‘상관관계’가 있다고 말할 수 있다.단일표본 Z 검정 검정 할 확률변수 : 분산모수 $\\sigma^{2}$ 을 아는 정규분포 확률변수 검정 할 모수가설 : 정규분포 기댓값 모수 $\\mu$ 에 대한 가설 검정통계량 값 : Z 통계량값 검정통계량 분포 : 표준정규분포사이파이 패키지가 따로 없다. 누적분포함수 이용해서 직접 계산하자.예)정규분포 분산값 $\\sigma^{2} = 1$ 인 정규분포에서 데이터 100개를 얻어 단일표본 Z검정을 해보자.귀무가설은$H_{0} : \\mu = 0$대립가설은$H_{a} : \\mu \\ne 0$ 으로 임의 설정했다.참고로 데이터를 얻는 정규분포의 실제 기댓값 모수는 $\\mu = 0$ 이다.가설검정 결과가 위 실젯값대로 정확하게 나오는지 보자.N = 100mu0 = 0sigma2 = 1rv = sp.stats.norm(loc=mu0, scale=1).rvs(N, random_state=0)def z_test(rv, sigma2, N) : z = np.mean(rv)/sigma2*np.sqrt(N) if z &gt;= 0 : p_value = (1-sp.stats.norm().cdf(z))*2 elif z &lt; 0 : p_value = sp.stats.norm().cdf(z)*2 return z, p_valueresult = z_test(rv, sigma2, N)[1]print(f'유의확률 : {result}')print(f'귀무가설 채택')유의확률 : 0.5497864508624168귀무가설 채택한다. 곧, 실젯값 대로 귀무가설이 참이라고 판명되었다.단일표본 t 검정 검정 할 확률변수 : 분산 $\\sigma^{2}$ 값을 모르는 정규분포 확률변수 검정 할 모수가설 : 정규분포 기댓값 모수 $\\mu$ 에 대한 가설 검정 검정통계량 값 : t 통게량 값 검정통계량 분포 : 자유도 N-1 인 스튜던트 t분포 단일표본 t 검정 명령sp.stats.ttest_1samp(a, popmean)a : 정규분포 표본 데이터들 배열popmean : 귀무가설 모수 $\\mu$예)정규분포에서 나온 데이터 100개를 가지고 있다.귀무가설이$H_{0} : \\mu = 0$대립가설이$H_{a} : \\mu \\ne 0$일 때, 가설검정을 해보자.참고로 표본을 뽑아낸 원래 정규분포 기댓값 모수는 0 이었다.N = 100mu0 = 0rv = sp.stats.norm().rvs(N, random_state=0)sp.stats.ttest_1samp(rv, popmean=mu0)Ttest_1sampResult(statistic=0.5904283402851698,pvalue=0.5562489158694675)유의확률이 55%로, 유의수준보다 크다. 따라서 귀무가설 채택한다.$H_{0} : \\mu = 0$독립표본 t 검정 검정 내용 : 두 정규분포의 기댓값이 같은지 검정 두 정규분포는 서로 독립$H_{0} : \\mu_{1} = \\mu_{2}$$H_{a} : \\mu_{1} \\ne \\mu_{2}$ 검정통계량분포 : 스튜던트 t분포 검정통계량 값 : 분산값이 같으냐, 다르냐에 따라 사용하는 검정통계량 값이 다르다. 독립표본 t 검정 명령sp.stats.ttest_ind(a,b, equal_var=True)a : 1번 표본 집합 데이터b : 2번 표본 집합 데이터equal_var : 두 정규분포 분산값 같은지 여부. 같으면 True 아니면 False. 양측검정이다.예)서로 독립인 두 정규분포에서 표본데이터 집합 1,2 를 얻자.이 두 집합으로 독립표본 t 검정 실시해서, 두 정규분포 기댓값이 같은지 검정하자.참고로 두 표본데이터 집단을 얻는 정규분포의 원래 기댓값은 $\\mu_{1} = 0, \\mu_{2} = 0.5$로 다르고 분산은 $\\sigma_{1}=\\sigma_{2}=1$ 로 같으며 표본 수가 $N_{1}=50, N_{2}=100$ 개다.검정 결과가 실재를 잘 반영하는지도 보자.n1 = 50mu1 = 0sigma21 = 1n2 = 100mu2 = 0.5sigma22 = 1np.random.seed(0)x1 = sp.stats.norm(loc=mu1, scale=sigma21).rvs(n1)x2 = sp.stats.norm(loc=mu2, scale=sigma22).rvs(n2)ax = sns.distplot(x1, kde=False, fit=sp.stats.norm, label='표본데이터1')ax = sns.distplot(x2, kde=False, fit=sp.stats.norm, label='표본데이터2')ax.lines[1].set_linestyle(':')plt.legend()plt.title('표본 데이터 갯수 증가 50 : 100')plt.show()np.mean(x1), np.mean(x2)두 표본데이터집단 각 표본평균 : (0.14055927231309787, 0.6177957994523524)큰수의 법칙에 따라 표본평균은 모집단 평균의 근삿값이다.표본평균값을 계산해서 비교해 보았을 때, 두 값이 달랐다.이를 통해 두 표본데이터 집단이 나온 두 정규분포 모수도 다를 것이라고 추정할 수 있다.이 내용을 대립가설로 놓는다.$H_{a} : \\mu_{1} \\ne \\mu_{2}$그러면 귀무가설은 다음과 같다.$H_{0} : \\mu_{1} = \\mu_{2}$이제 두 표본 데이터 집단 1,2 를 이용해서 귀무가설이 참인지, 거짓인지 보자.두 정규분포의 기댓값 모수가 같은지 다른지 검정하기 위해서는 독립표본 t 검정을 실시해야 한다.sp.stats.ttest_ind(x1, x2, equal_var=False)Ttest_indResult(statistic=-2.5427747064864556,pvalue=0.012800307550312669)유의확률 값이 0.0128이다.5% 유의수준에서 귀무가설 기각 가능하다. 대립가설 채택.$H_{a} : \\mu_{1} \\ne \\mu_{2}$“두 정규분포 기댓값이 다르다” 고 주장할 수 있다.처음에 데이터가 나온 정규분포의 실제 기댓값이 다르다는 걸 생각했을 때, 실재를 잘 반영한 검정결과라고 볼 수 있다.대응표본 t 검정 검정내용 : 1 : 1 대응되는 표본들로 독립표본 t 검정 수행(두 정규분포 기댓값이 같은지 검정)$H_{0} : \\mu_{1} = \\mu_{2}$$H_{a} : \\mu_{1} \\ne \\mu_{2}$ 검정통계량값 : t통계량 검정통계량 분포 : t분포 분산이 같은지 다른지는 신경쓰지 않는다. 장점 : 적은 데이터로도 독립표본 t검정을 오류없이 수행할 수 있다.대응표본 t 검정 명령sp.stats.ttest_rel(a,b)a : 1번 표본데이터 집합b : 2번 표본데이터 집합 양측검정이다.등분산검정 검정내용 : 두 정규분포 분산이 같은 지 검정$H_{0} : \\sigma_{1}^{2} = \\sigma_{2}^{2}$$H_{a} : \\sigma_{1}^{2} \\ne \\sigma_{2}^{2}$ 독립표본 t검정 할 때 선행해야 한다.독립표본 t검정에서는 두 정규분포 분산이 같은지 다른지에 따라 검정통계량 값이 달라졌다.따라서 독립표본 t검정 하기 전에는 두 정규분포 분산이 같은지 다른지 확인해야 한다.이때 등분산검정을 활용할 수 있다. 종류 : 바틀렛(bartlett), 플리그너(fligner), 레빈(levene)등분산검정 종류에 따라 검정 결과도 다르다.등분산검정 명령바틀렛 검정sp.stats.bartlett(x1, x2)플리그너 검정sp.stats.fligner(x1, x2)레빈 검정sp.stats.levene(x1, x2)예)실제로 분산이 다른 두 정규분포에서 표본데이터 집합 얻자.두 표본데이터 집합 이용해서 두 정규분포 분산이 같은지, 다른지 검정해보자.n1 = 800n2 = 700sigma1 = 1sigma2 = 1.2np.random.seed(0)x1 = sp.stats.norm(3, sigma1).rvs(n1)x2 = sp.stats.norm(5, sigma2).rvs(n2)ax = sns.distplot(x1, kde=False, fit=sp.stats.norm, label='1번 표본')ax = sns.distplot(x2, kde=False, fit=sp.stats.norm, label='2번 표본')ax.lines[1].set_linestyle(':')plt.legend()plt.title('표본데이터 1, 2')plt.show()두 표본데이터 집합을 얻었다.비편향표본분산은 모분산의 근삿값이었다.두 데이터집단의 비편향표본분산값을 구해서, 모분산이 같을지 다를지 추정해보자.print(x1.var(ddof=1), x2.var(ddof=1))print(f'분산모수 다를 것 같다')비편향표본분산값 :x1 : 0.9941394887614771x2 : 1.3240342982563584두 모집단 분산모수 값이 다를 것 같다.그러면 대립가설을 다음과 같이 세울 수 있다.$H_{a} : \\sigma_{1}^{2} \\ne \\sigma_{2}^{2}$귀무가설은 다음과 같아진다.$H_{0} : \\sigma_{1}^{2} = \\sigma_{2}^{2}$귀무가설이 참인지, 거짓인지 등분산검정으로 검정해보자.바틀렛 검정sp.stats.bartlett(x1, x2)BartlettResult(statistic=15.343053846339838,pvalue=8.964992621009065e-05)플리그너 검정sp.stats.fligner(x1, x2)FlignerResult(statistic=11.821107559476658,pvalue=0.0005856301367977482)레빈 검정sp.stats.levene(x1, x2)LeveneResult(statistic=12.256042270504519,pvalue=0.00047735588309963205)세 등분산검정 모두 귀무가설 기각, 대립가설 채택 결과가 나왔다.따라서$H_{a} : \\sigma_{1}^{2} \\ne \\sigma_{2}^{2}$이다. 두 정규분포 분산이 다르다고 주장할 수 있다.정규성검정 검정내용 : 표본분포가 정규분포 따르는지 검정한다.$H_{0} :$ 표본분포가 정규분포 따른다$H_{a} :$ 표본분포가 정규분포 따르지 않는다. 정규성검정은 여러 종류가 많다.예)사이파이 샤피로-윌크 검정 sp.stats.shapiro(x) x : 표본데이터 집단 다고스티노 K-제곱 검정 sp.stats.mstats.normaltest(x) x : 표본데이터 집단 스탯츠모델스 콜모고로프-스미르노프 검정 statsmodels.stats.diagnostic.kstest_normal(x) x : 표본데이터 집단 옴니버스 검정 statsmodels.stats.diagnostic.omni_normtest(x) x : 표본데이터 집단 KS 검정콜모고로프-스미르노프 검정 두 표본분포가 같은 분포에서 나왔는지 검정$H_{0} : \\theta_{1} = \\theta_{2}$$H_{a} : \\theta_{1} \\ne \\theta_{2}$ 정규성검정에도 사용할 수 있다.예)실제로 다른 분포에서 나온 두 표본분포를 가지고 KS 검정을 해보자.n1 = 200n2 = 50np.random.seed(0)x1 = sp.stats.norm(1,3).rvs(n1)x2 = sp.stats.norm(4,6).rvs(n2)ax = sns.distplot(x1, kde=False, fit=sp.stats.norm, label='1번 데이터 집합')ax = sns.distplot(x2, kde=False, fit=sp.stats.norm, label='2번 데이터 집합')plt.legend()plt.show()두 표본데이터를 얻었다. 두 표본데이터가 어떤 분포에서 나왔을 지 추정해보니 다른 분포에서 나온 것 같다.‘두 분포가 다른 분포에서 나왔다!’ 고 주장하려면 대립가설은 다음처럼 세울 수 있다.$H_{a} : \\theta_{1} \\ne \\theta_{2}$그러면 귀무가설은 다음과 같다.$H_{0} : \\theta_{1} = \\theta_{2}$두 표본분포가 같은 분포에서 나왔는지 검정하기 위해 KS검정을 사용하자.sp.stats.ks_2samp(x1, x2)KstestResult(statistic=0.255,pvalue=0.009610378185668456)유의확률이 1%, 5%, 10% 유의수준보다 모두 작으므로, 귀무가설 기각할 수 있다. 곧, ‘두 분포가 다른 분포에서 나왔다’ 고 주장할 수 있다.$H_{a} : \\theta_{1} \\ne \\theta_{2}$KS검정은정규성검정에도 활용할 수 있다.균등분포에서 표본데이터 10개를 얻었다.이 표본데이터 집단이 특정 정규분포에서 나온 분포인지 알고싶다고 하자.이때, 이 표본데이터 집단을 특정정규분포에서 나온 표본집단과 KS검정 하면 이 데이터들이 그 정규분포에서 나왔는지 알 수 있다.x1 = sp.stats.uniform().rvs(10, random_state=0)rv = sp.stats.norm(1,2).rvs(10000, random_state=0) # 기댓값이 1, 표준편차가 2인 정규분포에서 나온 표본 1만 개 sp.stats.ks_2samp(x1, rv)KstestResult(statistic=0.4972pvalue=0.008347274897892887)KS 검정결과 유의확률이 0.8% 로, 귀무가설 기각할 수 있다.곧, ‘두 분포가 서로 다른 분포에서 나왔다’는 대립가설이 채택된다.결과로, 내가 얻은 표본데이터 집단 x1이 평균1, 표준편차 2인 정규분포를 따르지 않음을 알 수 있다.검정결과 오류(1, 2종 오류) 1종오류 : 귀무가설이 원래 참인데 거짓이라고 기각되는 경우 발생 2종오류 : 귀무가설이 원래 거짓인데 참이라고 채택되는 경우 발생 데이터 수가 부족하면 1,2종 오류가 잘 발생한다.데이터를 더 모으면 1,2종 오류가 사라지거나, 덜 발생한다" }, { "title": "[수학/확률과 통계] 베이즈추정, 검정(testing)", "url": "/bioinfo.github.io/posts/basian_estimation/", "categories": "Data Science, python, mathematics", "tags": "mathematics, study, data science", "date": "2021-08-07 00:00:00 +0900", "snippet": "베이즈추정법 : 모수 $\\mu$ 의 신뢰도 분포를 나타내는 작업 핵심 아이디어 : 모수 = 확률변수 주어진 데이터를 기반으로 모수 $\\mu$ 의 조건부확률분포 $p(\\mu \\vert x_{1}, x_{2}…x_{n})$ 을 계산하는 작업이다. 베이즈정리를 사용한다. 최대가능도추정법과의 연결점 : 가장 가능성 높은 모수를 ‘추정 모수’(추정 결과) 로 쓰겠다. 최대가능도추정법과의 차별점 : 1. 최대가능도추정법에서는 가장 가능도 높은 모수 $\\mu$ 하나를 찾는 게 모든 관심사였다. 하지만 베이지안 추정법은 가장 가능성 높은 모수를 찾고, 찾은 모수가 얼마만큼의 추정 신뢰도와 신뢰구간에서 찾아진건지도 알 수 있다는 장점 있다.즉 가장 가능성 높은 모수를 찾고, 이걸 ‘얼마만큼 믿을 수 있는가’에 대해서도 제시한다. MLE 방법과 비교했을 때 모수추정을 더 세밀하게 할 수 있는 것이다.2. 새 데이터를 추가로 얻었을 때, 계산해둔 기존 결과에 추가된 것만 그대로 반영해서 업데이트된 결과물 얻을 수 있다.최대가능도추정법의 경우 데이터 새로 얻으면 모든 데이터를 가지고 처음부터 다시 계산해야 한다.(번거롭다)모수 $\\mu$ 의 신뢰도 분포 나타내는 방법 모수적 방법 - 모수 $\\mu$ 의 조건부확률분포를 다른 확률분포 빌려서 [직접] 표현하는 방법 비모수적 방법 - 모수 $\\mu$ 의 조건부확률분포에서 직접 표본 추출해서, 히스토그램 그려서 [간접] 표현하는 방법모수적 방법 - 다른 확률분포 빌려서 모수분포 직접 표현하기 모수분포는 베이즈 정리의 출력 모수 $\\mu$ 의 조건부분포를 말한다.$p(\\mu \\vert x_{1}, x_{2}…x_{n}) = p(x_{1}, x_{2}…\\vert \\mu)p(\\mu)$ 모수 $\\mu$ 에 대한 별 다른 정보 없을 경우 사전분포 $p(\\mu)$ 는 모수 a=1, b=1 인 베타분포 또는 기댓값이 0인 정규분포 등의 무정보분포(엔트로피가 가장 큰) 를 사용한다. 사전분포와 사후분포 분포 종류가 같으면, ‘켤레분포’ 또는 ‘켤레사전확률분포’라고 한다. 모수의 분포(사후분포)를 나타내는 다른 확률분포의 모수를 ‘하이퍼 모수’라고 한다. 모수적 방법은 이 ‘하이퍼 모수’를 계산하는 작업이다. 예를 들어 베르누이 확률변수 모수 $\\mu$ 의 사후분포를 모수적 방법으로 나타낼 때, 사후분포의 하이퍼 모수는 다음처럼 계산할 수 있다. $a’ = N_{1}+a$$b’ = N_{0}+b$갱신된 하이퍼 모수를 갖는 베타분포(사후분포)는 곧 모수 $\\mu$ 의 신뢰도분포다.예1 )xx = np.linspace(0,1)a0 = 1b0 = 1 # 사전분포의 하이퍼모수plt.plot(xx, sp.stats.beta(a0,b0).pdf(xx), ls=':', c='r', label='사전분포')a1 = 60+1b1 = 40+1 # 사후분포의 하이퍼모수plt.plot(xx, sp.stats.beta(a1, b1).pdf(xx), ls='--', c='g', label='사후분포')plt.legend()plt.title('상품 B 모수 조건부 분포의 사전분포와 사후분포')예2 )# 실제 베르누이분포 모숫값 : 0.65# 베이즈 추정법 사용한 모수추정을 해보자. # 데이터 50개씩 추가해가면서 추정 결과를 업데이트하자. mu0 = 0.65a,b = 1,1xx = np.linspace(0,1,10000)plt.plot(xx, sp.stats.beta(a,b).pdf(xx), c='r',label='사전분포')np.random.seed(0)ls = [':', '--', '-.']c = ['r', 'g', 'b']for i in np.arange(3) : sample = sp.stats.bernoulli(mu0).rvs(50) n0, n1 = np.bincount(sample)[0], np.bincount(sample)[1] a = n1 + a b = n0 + b plt.plot(xx, sp.stats.beta(a,b).pdf(xx), ls=ls[i], c=c[i], label=f'{i+1}번째 추정') print(f'{i+1}차 추정 : 모드 = {(a-1)/(a+b-2)}')plt.legend()plt.title('데이터 50개씩 추가해가며 베이지안 추정결과 업데이트하기')plt.xlabel('$\\mu$')plt.vlines(0.65, ymin=0, ymax=13, colors='k')plt.show()예3 )베이즈추정법으로 정규분포 기댓값 모수 $\\mu$ 추정하기# 100개 씩 총 4번 데이터 얻어서 기댓값 모수를 추정해보자. target_mu = 2target_sigma2 = 4mu = 0sigma2 = 1xx = np.linspace(1,3,10000)plt.plot(xx, sp.stats.norm(mu, np.sqrt(sigma2)).pdf(xx), ls=':', c='b', label='사전분포')ls = [':', '--', '-.', '-']color= ['k', 'b', 'g', 'r']np.random.seed(1)for i in np.arange(4) : sample = sp.stats.norm(target_mu, np.sqrt(target_sigma2)).rvs(100) mu = target_sigma2/(100*sigma2+target_sigma2)*mu + 100*sigma2/(100*sigma2+target_sigma2)*np.mean(sample) sigma2 = 1/(1/sigma2+100/target_sigma2) plt.plot(xx, sp.stats.norm(loc=mu, scale=np.sqrt(sigma2)).pdf(xx), ls=ls[i], c=color[i], label=f'{i+1}번째 추정') print(f'{i+1}번째 추정 모드 : mode = {mu}')plt.legend()plt.title(f'베이지안 추정법을 통한 정규분포 모수 $\\mu$ 추정')plt.vlines(target_mu, ymin=0, ymax=5)예4 )사이킷런 패키지 붓꽃 데이터 중 ‘꽃받침 길이’ 확률변수의 기댓값 모수 추정 꽃받침 길이 데이터들이 어떤 분포를 이루는지 보고, 이 데이터들이 어떤 분포에서 나왔는지 대강 짐작해보자.from sklearn.datasets import load_irisx = load_iris().datadf = pd.DataFrame(x, columns=load_iris().feature_names)df[['sepal length (cm)']]sns.distplot(df['sepal length (cm)'].values, kde=False, bins=50, fit=sp.stats.norm)모양을 보니 정규분포에서 나온 데이터 일 수 있겠다.정규분포에서 나온 데이터라고 가정하고, 베이즈추정으로 기댓값 모수를 추정해보자.분산모수는 표본분산을 사용해서 안다고 가정한다. 모수 $\\mu$ 가 정규분포 기댓값 모수이므로 $-\\infty +\\infty$ 사이 값일 것이다. 이외에 다른 정보는 주어진 게 없다. 따라서 기댓값 0인 무정보분포를 모수 $\\mu$ 의 사전분포로 쓰자. 무정보분포의 분산 $\\sigma^{2}$ 은 1이라 가정한다.mu = 0sigma2 = 1xx = np.linspace(-5,5,10000)plt.plot(xx, sp.stats.norm(mu, sigma2).pdf(xx))plt.title(f'정규분포 기댓값 모수 $\\mu$ 의 사전확률분포')plt.show() 내가 가진 데이터를 반영한 사후분포의 하이퍼모수를 구한다. 그리고 기댓값 모수 $\\mu$ 의 사후분포를 나타내자.mu = 0sigma2 = 1xx = np.linspace(-3,8,10000)plt.plot(xx, sp.stats.norm(mu, sigma2).pdf(xx), label='사전분포')target_sigma2 = np.var(df['sepal length (cm)'].values, ddof=1)data = df['sepal length (cm)'].valuesmu1 = target_sigma2/(len(data)*mu+target_sigma2)*mu+len(data)*sigma2/(len(data)*sigma2+target_sigma2)*np.mean(data)sigma21 = 1/(1/sigma2+len(data)/target_sigma2)plt.plot(xx, sp.stats.norm(loc=mu1, scale=np.sqrt(sigma21)).pdf(xx), label='사후분포')plt.legend()plt.title('베이지안 추정으로 정규분포의 기댓값 모수 추정 결과')print(f'추정된 정규분포 기댓값 모수 : {mu1}')plt.show()최종적으로 추정된 정규분포 기댓값 모수 : 5.81674331232002모멘트방법으로 구한 기댓값 모수와의 비교모멘트 방법에 따르면 표본평균은 이론적 기댓값과 같았다.주어진 데이터를 이용해서 표본평균을 구하면 약 5.84가 나온다.모멘트방법에 따라 이 5.84가 이론적 기댓값과 같다고 보면 5.84는 곧 정규분포의 기댓값 모수다.내가 베이즈추정법으로 추정한 정규분포 기댓값 모수와 모멘트방법의 결과 5.84를 비교해보면, 약간의 차이가 있긴 하지만 두 방법 모두 비슷한 값을 모수로 추정해 낸 것을 볼 수 있다.plt.subplot(211)sns.distplot(data, kde=False, fit=sp.stats.norm)plt.title(f'표본분포 : 표본평균 이용해 구한 이론적 기댓값 = 5.84')plt.vlines(5.84, ymin=0, ymax=1)plt.ylim(0,1)plt.xlim(4,8)mu = 1sigma2 = 1xx = np.linspace(4,8,10000)target_sigma2 = np.var(df['sepal length (cm)'].values, ddof=1)data = df['sepal length (cm)'].valuesmu1 = target_sigma2/(len(data)*mu+target_sigma2)*mu+len(data)*sigma2/(len(data)*sigma2+target_sigma2)*np.mean(data)sigma21 = 1/(1/sigma2+len(data)/target_sigma2)plt.subplot(212)plt.vlines(5.84, ymin=0, ymax=6, colors='r')plt.vlines(5.82, ymin=0, ymax=6, colors='b')plt.plot(xx, sp.stats.norm(loc=mu1, scale=np.sqrt(sigma21)).pdf(xx))plt.xlim(4,8)plt.title(f'사후분포 : 베이즈추정법으로 구한 추정 기댓값 : 5.82')plt.tight_layout()plt.show()검정 (testing) : 확률분포에 대한 가설이 맞는지 틀리는지 증명하는 작업 검정의 기본 전제 : 추정된 ‘추정값’은 ‘추정값’일 뿐이다!추정 결과가 참인지, 거짓인지 판단할 여지가 남아있다!예)문) 동전을 15번 던졌는데 12번 앞면이 나왔다. 이 동전은 공정한 동전이라 할 수 있을까?답) ‘동전 던지기 결과’는 베르누이확률변수라고 볼 수 있다.베르누이확률변수의 모수는 $\\mu$ 이다.모수가 얼마일지, 추정해보자.먼저 최대가능도추정법(MLE) 방법으로 베르누이확률변수의 모수를 추정해보자.$\\frac{N_{1}}{N}$이다. 따라서 $\\frac{12}{15}$ 가 베르누이확률변수의 모수 $\\mu$ 라고 추정할 수 있다.한편 베이즈추정법으로 모수를 추정해보자.모수 $\\mu$ 의 사후분포를 나타낼 하이퍼모수는 다음과 같이 계산할 수 있다.$a’= N_{1} + a$$b’= N_{0} + b$하이퍼모수로 사후분포를 묘사, 모수를 추정하면 0.8로 나온다. 최대가능도 추정법 결과와 같았다.# 동전 15번 던져 12번 앞면 나왔다. 공정한 동전이라 할 수 있나? # 베이즈 추정법으로 찾은 베르누이 확률변수 모수 a0 = 1b0 = 1a1 = 13b1 = 4xx = np.linspace(0,1,10000)plt.plot(xx, sp.stats.beta(a0,b0).pdf(xx))plt.plot(xx, sp.stats.beta(a1,b1).pdf(xx))mode = 12/15print(f'mode : {mode}')plt.vlines(mode, ymin=0, ymax=4, color='r', ls=':')plt.text(0.77, -0.2, 'mode')plt.show()그렇다면 모수추정 결과값은 0.8이라 할 수 있다. 이 0.8이 정말 모숫값이라면 이 동전은 ‘조작된 동전’일 것이다.한편 0.8이 우연히 나온 결과에 불과하고, 실제 모수가 0.5라면 동전은 ‘공정한 동전’이라 말 할 수 있다.이렇게 추정결과가 참인지 거짓인지 확인해 나가는 과정을 ‘검정’ 이라 한다. 가설(H) : 확률분포에 대한 주장 검정(testing) : 확률분포에 대한 가설이 맞는지, 틀리는지 증명하는 작업 모수검정 : 모수에 대한 가설이 맞는지 틀리는지 증명하는 과정귀무가설 : 기준상태, 도전의 대상 정의 : 모수에 대한 가설 표기 : $H_{0}$영 가설 이라고도 한다. 형태 : 반드시 ‘등식’ 꼴이어야 한다‘모수 = 증명하려는 가설의 기준값 상수’형태다.대립가설 : 연구가설, 증명대상, 내가 증명하고 싶은 것 정의 : 내가 주장하려는 가설 표기 : $H_{a}$ 언제나 귀무가설과 한 쌍(pair)를 이룬다. 귀무가설과 대립가설은 꼭 여집합 관계일 필요는 없다.여집합 관계이면 귀무가설 거짓일 때, 자동으로 대립가설은 참이 된다.한편 만약 여집합 관계가 아니라면 귀무가설이 거짓이라고 해서 자동으로 대립가설이 참 임이 증명되지 않는다.따라서 여집합 관계가 아닐 때 대립가설이 참 임을 증명하려면 1. 귀무가설이 거짓임 2. 대립가설이 참임 1,2, 두 가지를 모두 증명해야 한다.검정통계량 정의 : 귀무가설이 맞거나 틀렸다는 것을 증명할 ‘증거’ t로 나타낸다. 확률변수 X에서 나온 표본데이터를 입력으로 받아 출력된 함숫값이다. 검정통계량 값도 표본데이터에의해 확률적 데이터가 나오는 확률변숫값이다. 따라서 검정통계량확률변수(분포) T 에서 나온 값이라고 본다.*통계량 : 표본데이터를 하나의 공식에 넣어서 얻어낸 하나의 값$\\Leftarrow$ 확률변수 X 의 데이터로부터 어차피 X의 모수 추정하고 모수에 대한 가설(이 모수가 참인가? 거짓인가?)까지 세웠을 것이다.$\\Leftarrow$ 이 가설 증명하려면 이 데이터들을 검정통계량 값으로 바꾸면 된다.$\\Leftarrow$ 이 검정통계량 값은 확률변수 값으로써, 특정한 검정통계량분포에서 나온 값이다.$\\Leftarrow$ 내가 들고 있는 검정통계량 값이 검정통계량 분포 내에서 어디쯤 위치하는지 보고, 귀무가설 참. 거짓 유무 판단하면 된다.자주 사용하는 검정통계량 &amp; 검정통계량분포베르누이분포 확률변수 베르누이확률변수의 모수에 대한 가설을 증명하려면 : 검정통계량 값 : N번 중 성공한 횟수 n 번 검정통계량이 따르는 분포 : 이항분포$\\sigma^{2}$ 모수를 아는 정규분포 확률변수 정규분포확률변수의 모수에 대한 가설을 증명하려면 : 검정통계량 값 : 표본평균을 정규화한 Z 통계량 값 검정통계량이 따르는 분포 : 표준정규분포$\\sigma^{2}$ 모수를 모르는 정규분포 확률변수 정규분포확률변수의 기댓값 모수 $\\mu$ 에 대한 가설을 증명하려면 : 검정통계량 값 : 표본평균을 표본표준편차 s 로 정규화한 t 통계량 값 검정통계량이 따르는 분포 : 자유도 N-1 인 스튜던트 t 분포 $\\sigma^{2}$ 에 대한 가설을 증명하려면 : 검정통계량 값 : 표본분산 $s^{2}$ 을 정규화한 값$t = (N-1) \\frac{s^{2}}{\\sigma^{2}}$ 검정통계량이 따르는 분포 : 자유도 N-1인 카이제곱분포유의확률 (p-value) 귀무가설이 진실이라면, 내가 손에 쥐고 있는 검정통계량 값은 검정통게량분포에서 흔하게, 잘 나오는 값일 것이다. 귀무가설이 거짓이라면, 검정통계량값은 검정통계량분포에서 나오기 어려운 값일 것이다. xx = np.linspace(-4,4,10000)black = {'facecolor' : 'black'}plt.subplot(121)plt.title('나오기 쉬운 값이 나온 경우(귀무가설이 참)')plt.plot(xx, sp.stats.norm().pdf(xx))plt.annotate('실현된 검정통계량값 $t_{0}$', xy=[0.5,0],xytext=[1,0.05], arrowprops=black)plt.scatter(0.5,0,30)plt.subplot(122)plt.title('나오기 어려운 값이 나온 경우(귀무가설이 거짓)')plt.plot(xx, sp.stats.norm().pdf(xx))plt.scatter(3,0,30)plt.annotate('실현된 검정통계량값 $t_{0}$', xy=[3,0], xytext=[3,0.05], arrowprops=black)plt.suptitle('실현된 검정통계량값과 검정통계량분포', y=1.1)plt.tight_layout()plt.show()유의확률 (p-value) 정의 : 검정통계량분포의 표본값 1개가 주어졌을 때, 내가 들고 있는 표본값 또는 그 값보다 더 희귀한 값들이 나올 수 있는 확률또는귀무가설이 맞다고 할 때, 현재 검정통계량값 &amp; 더 희귀한 값들(대립가설 옹호하는) 이 나올 확률$p(t for H_{a}\\vert H_{0})$논리흐름)유의확률이 작다 : 귀무가설이 참 이면 주어진 표본 &amp; 이것보다 희귀한 놈들이 나올 가능성 매우 낮다$\\Rightarrow$ 주어진 표본이 나왔다는 건 귀무가설 참인데 매우 낮은 가능성으로 이 표본이 나왔거나, 또는 귀무가설이 거짓이란 말이다.한편유의확률이 크다 : 귀무가설이 참 일 때 주어진 표본 &amp; 이것보다 희귀한 놈들이 나올 가능성 높다$\\Rightarrow$ 귀무가설이 참이면 내가 들고 있는 표본 같은 놈들이 자주 나온다.$\\Rightarrow$ 주어진 표본은 귀무가설을 기각할만한 증거가 못 된다. 유의확률은 누적분포함수 cdf 이용해서 구할 수 있다. 유의확률이 검정통계량분포의 양쪽 끝단 면적 구한 것과 같으면 ‘양측검정 유의확률’ 이라고 한다. 단측검정 유의확률 정의 : 한쪽방향 유의확률만 사용하는 것. 사용 : 대립가설이 부등식 형태일 때 모수가 특정값 $\\theta_{0}$ 보다 크다는 걸 증명하고 싶으면 ‘우측검정 유의확률’을 써야 한다. 모수가 특정값 $\\theta_{0}$ 보다 작다는 걸 증명하고 싶으면 ‘좌측검정 유의확률’을 써야 한다.유의수준 정의 : ‘기준점’. 귀무가설을 기각할 지 채택할 지 판단하는 기준점이다. 종류 : 1%, 5%, 10% 유의수준유의확률이 유의수준보다 작으면 - 귀무가설 기각, 대립가설 채택유의확률이 유의수준보다 크면 - 귀무가설 채택기각역 : 검정통계량분포에서 유의수준에 해당하는 검정통계량값(지점) 활용 : 유의수준만큼에 해당하는 기각역 계산 내가 얻은 검정통계량 값과 기각역 바로 비교 (지점-지점 비교) 귀무가설 기각 / 채택 여부 판단 가능 위에서 들었던 예를 통해 직접 검정해보자 - 1 동전던지기 결과는 베르누이확률변수다. 추정된 모수 값은 $\\mu = 0.8$ 이었다.plt.bar([0,1], sp.stats.bernoulli(0.8).pmf([0,1]))plt.xticks([0,1])plt.title('최대가능도추정법, 베이즈추정법으로 추정한 모수 : $\\mu = 0.8$')plt.suptitle('불공정한 동전인가?', y=1.1)plt.ylim(0,1)plt.show()추정된 모수 $\\mu = 0.8$ 만 보면 이 동전은 불공정한 동전같다.이 동전이 불공정한 동전이다! 라는 주장을 그러면 검정해보자.대립가설은 이렇게 세울 수 있다.$H_{a} : \\mu \\ne 0.5$그러면 귀무가설은 다음과 같다.$H_{0} : \\mu = 0.5$이제 그러면 귀무가설(도전의 대상)이 참인지 거짓인지 증명해보자.동전던지기 확률변수 X 는 베르누이확률변수였다. 베르누이확률변수 모수 $\\mu$ 에 대한 가설을 증명하고 싶을 때, 검정통계량 값으로 이항분포의 표본값을 쓸 수 있고 검정통계량분포는 이항분포를 쓸 수 있었다.검정통계량분포 기본 전제는 ‘귀무가설이 참이다($\\mu = 0.5$)’ 였다. 검정통계량값 = 12 검정통계량분포 = 이항분포 $B(15, 0.5)$t = 12 # 검정통계량값# 귀무가설을 따르는 검정통계량분포 N = 15xx = np.arange(N+1)black = {'facecolor' : 'black'}plt.subplot(211)plt.stem(xx, sp.stats.binom(N, 0.5).pmf(xx))plt.title('동전 던지기 결과 베르누이분포의 검정통계량분포 : 이항분포 $B(15, 0.5)$')plt.ylabel('pmf')plt.annotate('실현된 검정통계량값 t=12', xy=[12,0.01], xytext=[12,0.05], arrowprops=black)plt.subplot(212)plt.stem(xx, sp.stats.binom(N, 0.5).cdf(xx))plt.title('검정통계량분포의 누적분포함수')plt.ylabel('cdf')plt.tight_layout()plt.show() 양측검정유의확률을 계산하면 다음과 같다.$2(1-F(11))$rv = sp.stats.binom(15, 0.5)result = (1-rv.cdf(11))*2print(f'양측검정 유의확률 : {np.round(result,3)}')계산 결과는 약 3.5% 다.유의수준 5%에서는 유의확률이 더 작으므로, 귀무가설 기각하고 대립가설 채택할 수 있다. 즉 ‘동전이 불공정한 동전이다’ 라는 주장이 참이다.한편 유의수준 1% 에서는 유의확률이 더 크므로, 귀무가설 기각할 수 없다. ‘동전이 불공정한 동전이다’라고 말할 수 있는 증거가 부족하다.예를 들어 직접 검정해보자 - 2어떤 인터넷 쇼핑몰 상품 20개의 상품평이 있고, ‘좋아요’가 11개, ‘싫어요’가 9개다.유의수준 10%에서 상품이 좋다는 주장을 검정해보자.최대가능도 추정법으로 추정한 모수는 $\\frac{11}{20}$ 이다.베이즈추정법으로 추정해도 같다.xx = np.linspace(0,1,10000)plt.plot(xx, sp.stats.beta(12,10).pdf(xx))print(11/20)plt.vlines(11/20, ymin=0, ymax=4, colors='r')모수추정 결과에 따르면 이 상품은 좋은 상품인 것 같다.그러면 ‘이 상품이 좋은 상품이다!’라고 주장할 수 있을까?내가 주장하고 싶은 바 : ‘상품이 좋은 상품이다’를 대립가설로 놓겠다.$H_{a} : \\mu &gt; 0.5$귀무가설은 그러면 다음과 같다.$H_{0} : \\mu = 0.5$귀무가설이 참인지 거짓인지 증명하기 위해, 검정통계량값을 구해보자.주어진 ‘상품평 확률변수’가 베르누이확률변수이므로, 검정통계량 t 값은 N번 중 성공횟수 n 이다.$n = 11$이 검정통계량 값은 검정통계량분포를 따른다. 이 분포는 이항분포 $B(20, 0.5)$ 이다.이 검정통계량 값이 이항분포 상에서 어디 위치하는 지 보자.mu0 = 0.5N = 20xx = np.arange(21)plt.subplot(211)plt.stem(xx, sp.stats.binom(N, mu0).pmf(xx))plt.title('상품평 확률변수의 검정통계량분포 $B(20, 0.5)$')plt.scatter(11, 0, 30, 'r')plt.annotate('실현된 검정통계량 표본', xy=[11, 0], xytext=[11.5, 0.025], arrowprops=black)plt.subplot(212)plt.stem(xx, sp.stats.binom(N, mu0).cdf(xx))plt.title('검정통계량분포의 누적분포함수')plt.scatter(11,0, 30, 'r')plt.tight_layout()plt.show()대립가설이 부등식이고 모수가 특정값보다 크다 를 증명하려 하므로, 우측검정 유의확률 사용하면 된다.$1-F(10)$ 값 계산하면 된다.계산하면,rv = sp.stats.binom(N, mu0)result = 1-rv.cdf(11-1)약 0.411 (=41%) 이 나온다.이 값은 유의수준 10% 보다 크다. 따라서 귀무가설 기각할 수 없다. 즉 상품이 좋다고 주장하기에는 증거가 부족하다.메모 귀무가설-대립가설 설정에 깔려있는 stance :대립가설 - 내가 주장.증명 하려는 바여기에 대해 ‘의심’하고 ‘증명’을 요구한다. 증명 성공하기 전 까진 보수적 기조를 유지한다.보수적 기조 : 귀무가설(도전의 대상)검정 전 과정 내 언어로 요약. 모수추정을 통해 확률변수 X의 모수를 추정했다.하지만 이 추정결과물은 ‘추정값’일 뿐, 정확한 모숫값이라고 말 못한다.추정값이 참인가 거짓인가 따질 여지가 남아있다. 모수 추정값이 참인가, 거짓인가 따져보자.나는 모숫값이 이번에 추정해 낸 바로 그 값이라고 주장하고 싶다.이 추졍결과값을 가지고 대립가설($H_{a}$)을 세운다.귀무가설은 최대한 보수적인 값으로 잡아둔다. 예) 가설의 기준이 되는 특정한 상수내가 추정해낸 모숫값은 아직 확률변수 X의 모수라고 말 못하는 것이다.따라서 확률변수 X의 확률분포 모수도 아직 귀무가설을 그대로 따른다. 귀무가설이 참인지 거짓인지 증명하자.귀무가설 따르는 X 확률변수에서 얻어낸 표본데이터들을 가지고 검정통계량값 구한다.검정통계량값이 따르는 검정통계량분포도 찾는다. 이 검정통계량분포 역시 귀무가설을 기본 전제로 따른다. 검정통계량값이 검정통계량분포에서 어디쯤 위치하는지 보고, ‘귀무가설이 참일 때, 현재 검정통계량 값 &amp; 대립가설 더 옹호하는 값들이 나올 수 있는 확률=유의확률’을 계산한다.‘귀무가설을 기각할 지, 채택할 지 판단하는 ‘기준점’ 인 유의수준과 유의확률을 비교한다.유의수준보다 유의확률이 낮으면, 귀무가설 기각 / 유의수준보다 유의확률이 높으면 귀무가설 채택한다. 귀무가설이 기각되면 대립가설이 채택된다. 이 경우 내가 찾아낸 추정 결과값이 확률변수 X의 실제 모수를 잘 추정한 값이라고 믿을 수 있다.반면에 귀무가설이 채택되면 대립가설이 기각된다. 이 경우, 내가 찾아낸 추정 결과값이 거짓임을 의미한다. 이 경우 데이터를 더 모아야 한다." }, { "title": "[수학/확률과 통계] 추정_기본개념, 모수추정- 모멘트방법, 최대가능도추정법", "url": "/bioinfo.github.io/posts/estimation/", "categories": "Data Science, python, mathematics", "tags": "mathematics, datascience, study", "date": "2021-08-04 00:00:00 +0900", "snippet": "추정과 검정추정 : 내가 들고 있는 데이터가 나온 원래 확률분포(확률변수)를 찾는 작업검정 : 추정결과가 믿을만 한가 아닌가 알아보는 작업 추정결과 신뢰도 올리는 방법 : 더 많은 데이터를 모으면 된다.확률분포의 추정 데이터분석 기본 가정 : 분석할 데이터는 가상의 확률변수에서 떨어져 현실세계에 실현된 ‘표본’, ‘일부분’, ‘파편’이다. 데이터분석 최종목표 : 데이터가 떨어져 나온 원래 확률분포(확률변수)를 찾아내는 것. 확률분포 추정 과정1. 확률분포의 종류 알아내기핵심은 ‘추측’ 데이터 기본특성으로 ‘추측’예) 데이터가 0과 1 둘만 나온다 $\\Rightarrow$ 베르누이분포 아닐까? 히스토그램 그려서 데이터 분포 모양 가지고 확률분포 ‘추측’예) 데이터 분포 모양이 정규분포와 비슷하다. $\\Rightarrow$ 정규분포 아닐까? 보스턴 집값 데이터로 확률분포 종류 추측해보기 from sklearn.datasets import load_bostondata = load_boston().datadf = pd.DataFrame(data, columns=load_boston().feature_names)df['MEDV'] = load_boston().targetdf예)plt.subplot(211)sns.distplot(df['RM'], kde=False, bins=60)plt.title('정규분포일 것이다')예)plt.subplot(211)sns.distplot(df['DIS'], kde=False, bins=60)plt.title('0보다 큰 어떤 값이 자주 발생하는 카이제곱분포?')plt.subplot(212)sns.distplot(np.log(df['DIS']), kde=False, bins=50)plt.title('로그정규분포?')plt.tight_layout()예)plt.subplot(211)sns.distplot(df['AGE'], kde=False, bins=60)plt.subplot(212)sns.distplot(df['AGE']/100, kde=False, bins=60)plt.title('베타분포로 바꿀 수 있지 않을까?')plt.tight_layout()2. 확률분포의 모수 알아내기 모멘트방법, 최대가능도추정법, 베이즈추정법 이용1) 모멘트 방법 전제 : 표본분포 모멘트와 이론적 확률분포 모멘트가 같다고 본다.큰수의 법칙에 따라 표본평균은 모평균 근삿값이다.비편향표본분산은 모분산의 근삿값이다. 표본분포 모멘트 구하고, 이론적 분포 모멘트 구하고, 이론적 분포 모멘트 사용해서 모수 구한다.예) 모수와 이론적 모멘트가 같은 경우 : 정규분포의 예$\\bar{x} = \\mu$$\\bar{s} = \\sigma^{2}$정규분포 모수는 $\\mu, \\sigma^{2}$ 이다. 따라서 표본 모멘트 구하면 바로 정규분포 모수 구할 수 있다. 모수와 이론적 모멘트 다른 경우 : 베타분포 모수 추정$E[X] = \\frac{a}{a+b} = \\bar{x}$$E[(X-\\mu)^{2}] = \\frac{ab}{(a+b)^{2}(a+b+1)} = s^{2}$베타분포는 정규분포와 달리 모수와 모멘트값이 다르다. 따라서 이론적 모멘트-모수 사이 관계를 이용해서 베타분포 모수 a,b를 찾아야 한다.2) 최대가능도 추정법핵심 아이디어 : 전제 : 실현된 표본값은 매우 잘 나오는(흔한) 값이다. ‘주어진 데이터를 가장 높은 확률로 뱉어내는 분포(모수) 찾기’예) 주어진 데이터가 x=1 일 때모수 $\\mu$ 후보군 : -1,0,1-1,0,1 세 $\\mu$ 값 중 주어진 데이터의 확률밀도를 가장 크게 만드는 모수 $\\mu$ 값은?# 최대가능도추정법 원리 L = [sp.stats.norm(loc=mu).pdf(1) for mu in [-1,0,1]]plt.scatter(1, L[0])plt.scatter(1, L[1])plt.scatter(1, L[2])plt.vlines(1.00, ymin=0, ymax=0.5, ls=':')plt.title('데이터 $x=1$ 일 때 데이터의 $\\mu$값 별 확률밀도')black = {'facecolor' : 'black'}xx = np.linspace(-5,5,1000)plt.plot(xx, sp.stats.norm(loc=-1, scale=1).pdf(xx), c='r', label='$\\mu=-1$')plt.plot(xx, sp.stats.norm(loc=0, scale=1).pdf(xx), c='b', ls=':' , label='$\\mu=0$')plt.plot(xx, sp.stats.norm(loc=1, scale=1).pdf(xx), c='g', ls='-.', label='$\\mu=1$')plt.text(0, 0.45, '최대 가능도값(x=1의 확률밀도)')plt.annotate('', xy=[1, 0.4], xytext=[2,0.43], arrowprops=black)plt.xlabel('$x$')plt.ylabel('p')plt.text(0.5, -0.04, '$x=1$')plt.scatter(1,0,30, marker='^')plt.legend()plt.show()모수가 $\\mu=1$ 일 때 내가 들고 있는 데이터 x=1의 확률밀도가 가장 커지는 것을 알 수 있다.이처럼 x=1의 확률밀도(가능도)를 최대로 만드는 모수 $\\mu$ 값을 모수 추정 결과값으로 삼고, $\\hat{\\theta}_{MLE}$ 로 표기한다.= 최대가능도 추정법의 해가능도함수 가능도 : 분포 모수가 특정한 $\\mu$ 값일 때 주어진 데이터(표본)에 할당되는 확률밀도값 가능도함수 특징 : 수식은 확률분포함수 수식과 완전히 똑같다. 가능도함수는 확률분포함수 수식에서 모수 $\\theta$ 를 변수로 바꾸고 데이터 $x$ 를 상수로 바꾼 것이다. 하지만 가능도함수는 확률분포함수가 아니다. 두 함수는 엄연히 다른 함수다.가능도함수 $\\ne$ 확률분포함수 가능도함수 예 내가 손에 들고 있는 데이터가 0이고, 정규분포 모수 중 분산값을 아는 경우# 데이터=0, 정규분포 분산을 아는 경우 \\sigma2 = 1def likelihood(mu) : return sp.stats.norm(loc=mu).pdf(0) # 가능도 값mus = np.linspace(-5,5,100)likelihood_values = [likelihood(mu) for mu in mus]plt.subplot(211)plt.plot(mus, likelihood_values)plt.title('가능도함수 $L(\\mu, \\sigma^{2} = 1 | x=0)$')plt.xlabel('$\\mu$') 내가 손에 들고 있는 데이터가 0이고, 정규분포 기댓값 모수 $\\mu$ 를 아는 경우# 데이터=0, 정규분포 기댓값을 아는 경우 \\mu = 0def likelihood2(sigma2) : return sp.stats.norm(scale=np.sqrt(sigma2)).pdf(0)sigma2s = np.linspace(0.1, 10,1000)likelihood_values = [likelihood2(sigma2) for sigma2 in sigma2s]plt.subplot(212)plt.plot(sigma2s, likelihood_values)plt.title('가능도함수 $L(\\mu=0, \\sigma^{2}|x=0)$')plt.xlabel('$\\sigma^{2}$')plt.tight_layout()plt.show() 만약 정규분포 모수 $\\mu$ , $\\sigma^{2}$ 둘 다 모르는 경우 (=둘 다 입력변수인 경우) 가능도함수내가 들고 있는 데이터는 마찬가지로 $x = 0$ 이다.입력변수가 2차원 벡터다. 함수는 2차원 벡터를 받아 스칼라를 출력하므로 2차원 다변수함수다.따라서 3차원 surface plot으로 가능도함수를 그릴 수 있다.MU, SIGMA2 = np.meshgrid(mus, sigma2s)L = np.exp(-MU**2/(2*SIGMA2))/np.sqrt(2*np.pi*SIGMA2)fig = plt.figure()ax = fig.gca(projection='3d')plt.title('다변수 가능도함수 $L(\\mu, \\sigma^{2}|x=0)$')ax.plot_surface(MU, SIGMA2, L, linewidth=0.3)plt.xlabel('$\\mu$')plt.ylabel('$\\sigma^{2}$')ax.view_init(10,-70)plt.show()복수의 표본 데이터가 있는 경우 가능도함수 복수 표본데이터를 들고 있다면, 벡터꼴일 것이다. 이는 벡터 하나를 얻었다고 가정할 수 있다. 벡터를 내뱉는 분포는 결합확률분포다. 따라서 어떤 결합확률분포로부터 벡터표본 1개를 얻었다고 생각하고, 가능도함수를 구한다.예) 정규분포에서 복수 표본데이터를 얻은 경우표본데이터 : $[-1,0,3]$이는 어떤 결합확률분포에서 벡터꼴 데이터를 1개 얻은 것과 같다.이 때 가능도함수는 다음과 같다.$L(\\theta ; x_{1}, x_{2}, x_{3}) = p(x_{1}, x_{2}, x_{3} ; \\theta)$$x_{1}, x_{2}, x_{3}$ 은 모두 똑같은 정규분포에서 독립적으로 얻은 표본이다.따라서 결합확률밀도함수는 개별 확률밀도함수 곱으로 나타낼 수 있다.$p(x_{1}, x_{2}, x_{3}) = p(x_{1})p(x_{2})p(x_{3})$참고) 결합확률과 조건부확률 사이에 성립하는 연쇄법칙을 쓰면 된다.$p(x_{1}, x_{2}, x_{3}) = p(x_{1} \\vert x_{2}, x_{3})p(x_{2} \\vert x_{3})p(x_{3})$위 식에서 $x_{1}, x_{2}, x_{3}$ 이 모두 서로 독립이라면, 조건부확률에서 조건의 영향을 안 받는다.따라서 $p(x_{1} \\vert x_{2}, x_{3})p(x_{2} \\vert x_{3})p(x_{3})$ 은 $p(x_{1})p(x_{2})p(x_{3})$ 과 같다.결국 $L(\\theta) = p(-1)p(0)p(3)$ 이 된다.$p$ 는 정규분포의 확률밀도함수 이므로, -1,0,3을 각각 대입해서 가능도함수 $L$ 을 구할 수 있다.이 $L$을 최적화 해서 최대해 $\\hat{\\theta}_{MLE}$ 를 찾으면 그게 곧 최대가능도추정법의 해다.로그가능도함수 최적화 할 때 가능도함수에 로그 씌워서(로그가능도함수) 하면 계산이 편하다! 로그 씌워도 최대점, 최소점 위치가 안 바뀐다.최대가능도추정법 사용헤서 추정한 베르누이분포의 모수 $\\frac{N_{1}}{N}$표본 중 1 나온 횟수와 전체 시뮬레이션 횟수의 비율과 같다.최대가증도추정법 사용해서 추정한 카테고리분포의 모수 $\\mu_{k} = \\frac{N_{k}}{N}$최대가능도 추정법에 의한 카테고리분포의 모수는 각 카테고리값(범줏값) 나온 횟수와 전체 시행 횟수의 비율이다.카테고리분포의 모수 벡터 $\\mu = [\\mu_{1}, \\mu_{2}, … \\mu_{k}]$최대가능도추정법 사용해서 추정한 정규분포의 모수 $\\mu = \\bar{x}$ $\\sigma^{2} = s^{2}$최대가능도추정법 사용해서 추정한 다변수정규분포의 모수 $\\mu = \\bar{x} 표본평균벡터$ $\\Sigma = s 표본공분산행렬$결론 : 모멘트방법은 일리있었다. (=결과가 모멘트방법으로 구한 모수와 같았다)" }, { "title": "[수학/확률과 통계] 베타, 감마, 디리클레분포", "url": "/bioinfo.github.io/posts/betta_gamma_diliclet_distribution/", "categories": "Data Science, python, mathematics", "tags": "mathematics, study, data science", "date": "2021-07-26 00:00:00 +0900", "snippet": "베타, 감마, 디리클레분포 : 분포 형상을 마음대로 조작할 수 있는 분포 분포 모숫값 조작이 가능하다. 베이지안 추정에 사용한다.1. 베타분포 : 베르누이분포 모수 $\\mu$ 의 신뢰도 분포 표본공간 : 0과 1사이 모든 실수 (0 &lt; $x$ &lt; 1) 모수 : a, b 특징 : 모숫값을 마음대로 조작해서, 분포 형상 조작이 가능하다. 사용 : 베르누이분포 모수 $\\mu$ 의 베이지안 추정에 사용한다.xx = np.linspace(0,1,1000)plt.subplot(221)plt.fill_between(xx, sp.stats.beta(1.001, 1.001).pdf(xx))plt.ylim(0, 6)plt.title('(A) a = 1, b = 1')plt.subplot(222)plt.fill_between(xx, sp.stats.beta(4,2).pdf(xx))plt.ylim(0, 6)plt.title('(B) a = 4, b = 2, 최빈값 = {}'.format(3/(4)))plt.subplot(223)plt.fill_between(xx, sp.stats.beta(8, 4).pdf(xx))plt.ylim(0, 6)plt.title('(C) a = 8, b = 4, 최빈값 = {}'.format(7/(10)))plt.subplot(224)plt.fill_between(xx, sp.stats.beta(30,12).pdf(xx))plt.ylim(0, 6)plt.title('(D) a = 30, b = 12, 최빈값 = {}'.format(29/(40)))plt.suptitle('모수 a,b 값에 따른 베타분포 형상 변화')plt.tight_layout()plt.show()베타분포 베이지안 추정 (A) : 베르누이 분포 모수 $\\mu$ 값 추정 불가 (B) : 베르누이 분포 모수 $\\mu$ 값 0.75일 가능성 가장 높다 (정확도 낮음 = 분산이 크다) (C) : 베르누이 분포 모수 $\\mu$ 값 0.7일 가능성 가장 높다 (정확도 중간) (D) : 베르누이 분포 모수 $\\mu$ 값 0.725일 가능성 가장 높다 (정확도 높다 = 분산이 작다)베타분포 모멘트 $E[X] = \\frac {a}{(a+b)}$ $mode = \\frac {a-1}{a+b-2}$ $V[X] = \\frac {ab}{(a+b)^{2}(a+b+1)}$$a,b$ 모숫값이 커질 수록 분산이 작아진다. 결과적으로 추정 정확도가 증가한다.감마분포 : 0과 $+\\infty$ 사이 모수 $\\mu$의 신뢰도 분포 표본공간 : $(0, +\\infty)$ 사이 모든 양수 모수 : a,bScipy gamma 클래스에는 초깃값 b=1로 고정되어 있다. 특징 : 베타분포와 개념상 다 같은데, 표본공간만 다르다.모수 a가 작아질 수록, 추정 정확도가 증가한다 (분산이 작아진다). (단, b=1 고정일 때) 사용 : 베이지안 추정 (모수 $\\mu$ 신뢰도 분포 나타내는 데 쓴다)xx = np.linspace(0,16,100)plt.subplot(221)plt.fill_between(xx, sp.stats.gamma(9).pdf(xx))plt.ylim(0, 0.4)plt.title('(A) a=9, b=1, 최빈값={}'.format(8))plt.subplot(222)plt.fill_between(xx, sp.stats.gamma(6).pdf(xx))plt.ylim(0, 0.4)plt.title('(B) a=6, b=1, 최빈값={}'.format(5))plt.subplot(223)plt.fill_between(xx, sp.stats.gamma(3).pdf(xx))plt.ylim(0, 0.4)plt.title('(C) a=3, b=1, 최빈값={}'.format(2))plt.subplot(224)plt.fill_between(xx, sp.stats.gamma(2).pdf(xx))plt.ylim(0, 0.4)plt.title('(D) a=2, b=1, 최빈값={}'.format(1))plt.suptitle('a,b=1 모숫값 변화에 따른 감마분포 형상 변화')plt.tight_layout()plt.show()감마분포 베이지안 추정 (A) : 임의의 모수 $\\mu$ 가 8일 가능성이 가장 높다(정확도 매우 낮다) (B) : 임의의 모수 $\\mu$ 가 5일 가능성이 가장 높다 (정확도 낮다) (C) : 임의의 모수 $\\mu$ 가 2일 가능성이 가장 높다 (정확도 높다) (D) : 임의의 모수 $\\mu$ 가 1일 가능성이 가장 높다 (정확도 매우 높다)감마분포 모멘트 $E[X] = \\frac {a}{b}$ $mode = \\frac {a-1}{b}$ $V[X] = \\frac {a}{b^{2}}$디리클레분포 : 0과 1사이 값만 갖는 $K$ 차원 벡터들의 신뢰도 분포$Dir(x;\\alpha)$ 표본공간 : $x$ 는 $K$ 차원 확률변수 벡터다.확률변수 벡터 $x$ 의 각 원소 $x_{i}$는 조건이 있다. 0 &lt;= $x$ &lt;= 1 $\\sum_{1}^{K}x_{i} = 1$$K=2$ 일 때 디리클레분포는 베타분포가 된다 모수 : $\\alpha$ 는 $K$ 차원 모수벡터다. 특징 : 모수벡터 $\\alpha$ 를 조정해서 디리클레분포 형상을 조작할 수 있다. 사용 : 베이지안 추정에 사용한다. 예) 카테고리분포 모수벡터 $\\mu$ 의 신뢰도 분포 디리클레분포의 모멘트 $E[x_{k}] = \\frac {\\alpha_{k}}{\\sum \\alpha}$ $mode = \\frac {\\alpha_{k}-1}{(\\sum \\alpha)-K}$ $V[x_{k}] = \\frac {\\alpha_{k}((\\sum\\alpha)-\\alpha_{k})}{(\\sum\\alpha)^{2}((\\sum\\alpha)+1)}$모수벡터 $[\\alpha_{1}, \\alpha_{2}, … \\alpha_{k}]$ 원소 하나의 절댓값이 커지면 $x_{k}$ 는 기댓값 근처의 비슷비슷한 값이 나온다.모수벡터 $[\\alpha_{1}, \\alpha_{2}, … \\alpha_{k}]$ 의 원소 하나하나 전반적인 절댓값이 커지면 결과적으로 표본벡터 $[x_{1}, x_{2}, … x_{k}]$ 가 특정 값 근처에 몰리게 된다.디리클레분포의 응용문) “x,y,z가 양의 난수일 때, 항상 x+y+z=1 이 되게 하려면 어떻게 해야 하는가? 모든 경우는 균등하게 나와야 한다” 디리클레분포 모수벡터 원소들 $\\alpha_{1}=\\alpha_{2}=\\alpha_{3}$ 이면 디리클레분포는 균등분포가 된다.(주어진 문제 조건을 모두 충족한다) 하지만 반대로, 같은 균등분포에서 합이 1되는 표본 3개 뽑아서 구성한 벡터들의 분포는 균등하지 못하다. $\\alpha_{1}=\\alpha_{2}=\\alpha_{3}$ 이면 x,y,z가 모두 같은 분포 따른다는 의미지만, 그 반대는 안 된다는 얘기다.1. 균등분포에서 합 1되는 3개 표본 추출, 3개 표본이 이루는 벡터들의 분포 데이터들이 균일하게 분포하지 못하고, 중앙에 몰려 있다.2. $\\alpha_{1}=\\alpha_{2}=\\alpha_{3}$ 인 디리클레분포$\\alpha_{1} = \\alpha_{2} = \\alpha_{3}$ 이고 $\\alpha_{i}$ 가 모두 1일 때, 디리클레분포는 균등분포를 이루었다.한편 디리클레분포 $\\alpha_{i}$가 모두 같아도 $\\alpha_{i}$ 절댓값이 크면, 디리클레분포 분산이 작아져서 특정 점 근처에 표본 분포가 몰리게 된다.x2 = sp.stats.dirichlet([50]*3) # 모수벡터 원소가 모두 같은 디리클레분포 객체 rs = x2.rvs(10000) # k는 모수벡터 차원 따라 알아서 지정된다. plot_triangle(rs, kind='scatter') $\\alpha_{i}$ 가 모두 같아도, $\\alpha_{i}$ 절댓값이 작으면 디리클레분포 분산이 작아져서 표본분포가 삼각형 세 꼭짓점 $(1,0,0), (0,1,0), (0,0,1)$ 에 몰리게 된다.x2 = sp.stats.dirichlet([0.001]*3) # 모수벡터 원소가 모두 같은 디리클레분포 객체 rs = x2.rvs(10000) # k는 모수벡터 차원 따라 알아서 지정된다. plot_triangle(rs, kind='scatter')디리클레분포를 이용한 베이지안 추정핵심 아이디어 모수벡터 $\\alpha$ 를 조정해서 디리클레분포 분포 형상을 조작할 수 있다. $K$차원 표본 벡터들의 신뢰도 분포를 나타낼 수 있다. 신뢰도(가능성) 이 가장 높은 값이 ‘모수추정값’이 된다. 예) 카테고리분포의 모수벡터 $\\mu$ 의 신뢰도 분포를 나타낼 수 있다.if $\\alpha = [1,1,1]$ 앞에 2차원 삼각형으로 나타냈던 것처럼, 표본 분포가 균등분포가 된다. 삼각형 전체 면적에 데이터들이 골고루 퍼진다. 따라서 어떤 벡터값이 신뢰도가 높은지 알 수 없고, 모수추정이 불가능하다.if $\\alpha = [2,3,4]$ 검정색 부분(신뢰도 가장 높은 지점 값)이 모수추정값이 될 수 있다. 하지만 전체 분포의 분산 정도가 커서, 추정 정확도는 ‘낮다’if $\\alpha = [20,30,40]$ $\\alpha = [2,3,4]$ 일 때와 같은 지점이지만 분포의 분산이 훨씬 작다.분산이 작아진 이유는 모수벡터 $\\alpha$ 의 절댓값이 커졌기 때문이다. 이 경우 $\\alpha = [2,3,4]$ 일 때와 같은 값을 ‘모수추정값’으로 제시할 수 있지만, 추정 정확도는 더 높다." }, { "title": "[수학/확률과 통계] F분포, 다변수정규분포(조건부분포, 주변분포 포함)", "url": "/bioinfo.github.io/posts/F_distribution_and_others/", "categories": "Data Science, python, mathematics", "tags": "mathematics, study, data science", "date": "2021-07-25 00:00:00 +0900", "snippet": "F분포 : 카이제곱분포 표본/각각의 자유도 의 비율들이 이루는 분포 모수 : 자유도 쌍 $(N1, N2)$ 자유도 : $(N1, N2)$ 카이제곱분포 표본 = 같은 정규분포에서 얻은 표본들의 제곱합 t통계량 제곱의 분포도 자유도가 $(1,N)$ 인 F분포 따른다. # t 통계량 제곱의 분포는 F(1, N)를 따른다. # N = 2t = sp.stats.t(2)t = t.rvs(100, random_state=0)**2plt.subplot(1,2,1)sns.distplot(t, kde=False)plt.xlim(0, 100)plt.title('t통계량 제곱의 분포')f = sp.stats.f(1,2)xx = np.linspace(0,100,100)plt.subplot(1,2,2)plt.plot(xx, f.pdf(xx))plt.title('f분포 : 자유도 = (1,2)')plt.tight_layout()plt.show()# 2. N=30t = sp.stats.t(N[1])t = t.rvs(100)**2plt.subplot(1,2,1)sns.distplot(t, kde=False)plt.xlim(0, 10)plt.title('t통계량 제곱의 분포')f = sp.stats.f(1,N[1])xx = np.linspace(0,10)plt.subplot(1,2,2)plt.plot(xx, f.pdf(xx))plt.ylim(0, 0.8)plt.title('f 분포 : 자유도 = (1,30)')plt.tight_layout()plt.show()혹은# 다시해보기 def plot(N) : np.random.seed(0) t = sp.stats.t(N).rvs(1000)**2 f = sp.stats.f(1, N).rvs(1000) plt.hist(t, label=f't통계량 제곱 분포 | 자유도 = {N}', bins=50, range=(0, 10), rwidth=0.5, align='left', color='r') plt.hist(f, label=f'f분포 표본 | 자유도 = (1, {N})', bins=50, range=(0,10), rwidth=0.5, align='mid', color='b') plt.xlim(0, 5) plt.legend() plt.title(f'N = {N} 인 경우') plt.show()plt.subplot(211)plot(2)plt.subplot(212)plot(30)F분포 특징 직관적으로 생각했을 때, $N1 = N2$ 일 경우 1근처 어떤 값이 가장 자주 나올 거라 생각된다.그 이유는 다음과 같다.카이제곱분포 표본은 같은 정규분포에서 나온다.표본 갯수인 $N1, N2$ 가 같다면, 아무래도 정규분포 상에서 확률밀도 높은쪽에서 N개 표본이 자주 발생할 것이다.예) 기댓값, 최빈값 근처이 경우 카이제곱분포 표본값(정규분포 표본 제곱합)도 2개가 서로 비슷비슷한 값일 거다.$N1, N2$ 가 서로 같기 때문에 약분하면 결국 분자 분모에 서로 비슷비슷한 값이 남는다.이 비율값은 대략 1 근처 값이라 생각할 수 있다.이 경우 ‘자주 발생하는 F분포 표본값’은 ‘1근처 값 이다’ 라고 직관적으로 생각할 수 있다.하지만 실제로는 1이 아닌 다른 어떤 값이 더 자주 나온다. 이 현상은 $N1=N2$ 값이 커질수록 사라진다. 결국 1 근처 값이 가장 자주 발생하게 된다. F분포 특징 : $N1=N2$ 가 커질 수록 1근처 값이 가장 자주 발생한다.N = [10,100,1000,10000]M = 10000np.random.seed(0)rv = sp.stats.norm()for i,n in enumerate(N) : plt.subplot(1,4,i+1) x1 = (rv.rvs(size=(n, M))**2).sum(axis=0) x2 = (rv.rvs(size=(n, M))**2).sum(axis=0) t = x1/x2 sns.histplot(t, bins=200) plt.axvline(1, ls=':') plt.xlabel('$x$') plt.title(f'자유도 : {n}')plt.suptitle('F분포 자유도 (N1,N2)가 커질 수록 1근처 값이 가장 자주 나온다')plt.tight_layout()plt.show()다변수 정규분포 다변수 정규분포 차원은 확률변수벡터 차원 따라간다메모고윳값 lambda1, lambda2는 곧 확률변수 X1의 분산, X2의 분산값과 같다. 다변수정규분포 확률밀도함수 식을 보면 이 확률밀도함수는 타원이다. (반지름 다양한 여러 개 타원을 이룬다) 타원 식을 보면 타원 반지름은 ld1, ld2 값에 비례한다. 곧, ld1, ld2값은 ‘사실상’ 타원 반지름이라 볼 수 있다. 타원 반지름 = 타원 사이즈 다. 타원 사이즈 = 값들의 분포 정도 (X1쪽, X2쪽으로 각각 값들이 얼마나 퍼져 있는가(평균을 중심으로)) 값들의 분포정도 = X1, X2의 분산 (분산 : 평균을 중심으로 퍼져있는 정도) 타원 반지름 = X1, X2의 분산 $ld1, ld2 = V[X1 ], V[X2 ]$–&gt; 공분산 행렬에 w = np.diag([ld1, ld2]) 를 넣는 이유메모 2다변수정규분포함수 확률밀도함수 모양, 방향, 사이즈의 의미표준기저벡터 직교좌표계에서 모양 : 타원 중심 : mu 분포사이즈(타원 반지름) 는 공분산행렬 고윳값에 비례한다 분포방향은 공분산행렬 고유벡터 방향이다plt.subplot(1,2,1)mu = np.array([1,2])cov = np.array([[4, -3],[-3, 4]])xx = np.linspace(-6, 6, 100)yy = np.linspace(-6,6, 120)X, Y = np.meshgrid(xx, yy)rv = sp.stats.multivariate_normal(mu, cov)plt.contour(X, Y, rv.pdf(np.dstack([X,Y])))plt.axis('equal')plt.scatter(mu[0], mu[1])plt.annotate('', xy= mu+0.35*w[0]*v[:,0], xytext=mu, arrowprops=d)plt.annotate('', xy= mu+2*v[:,1], xytext=mu, arrowprops=d)plt.title('좌표변환 전')plt.xlabel('$x_1$')plt.ylabel('$x_2$')plt.subplot(1,2,2)rv2 = sp.stats.multivariate_normal((0,0), np.diag(w))plt.contour(X,Y, rv2.pdf(np.dstack([X,Y])))plt.annotate('', xy= 0.5*w[0]*np.array([1,0]), xytext=[0,0], arrowprops=d)plt.annotate('', xy= 1.5*w[1]*np.array([0,1]), xytext=[0,0], arrowprops=d)plt.scatter(0,0, c='k',s=1.2)plt.axis('equal')plt.title('좌표변환 후')plt.xlabel('$x_1$')plt.ylabel('$x_2$')plt.suptitle('다변수정규분포 결합확률밀도함수')plt.tight_layout()plt.show()한편 확률변수들의 공분산 값도 대략적인 분포 방향 알게 해준다 단변수 확률변수 분산값도 대략적인 분포 사이즈 알게 해준다plt.subplot(1,2,1)mu = np.array([1,2])cov = np.array([[4, 0],[0, 4]])xx = np.linspace(-6, 6, 100)yy = np.linspace(-6,6, 120)X, Y = np.meshgrid(xx, yy)rv = sp.stats.multivariate_normal(mu, cov)plt.contour(X, Y, rv.pdf(np.dstack([X,Y])))plt.axis('equal')plt.scatter(mu[0], mu[1])plt.title('X1, X2 공분산이 0이고 단변수확률변수 분산 4인 경우')plt.subplot(1,2,2)mu = np.array([1,2])cov = np.array([[4, -3],[-3, 4]])plt.title('다 같은데 X1, X2 공분산만 -3으로 바뀌면')xx = np.linspace(-6, 6, 100)yy = np.linspace(-6,6, 120)X, Y = np.meshgrid(xx, yy)rv = sp.stats.multivariate_normal(mu, cov)plt.contour(X, Y, rv.pdf(np.dstack([X,Y])))plt.axis('equal')plt.scatter(mu[0], mu[1])plt.annotate('', xy= mu+0.35*w[0]*v[:,0], xytext=mu, arrowprops=d)plt.annotate('', xy= mu+2*v[:,1], xytext=mu, arrowprops=d)plt.axvline(mu[0], ls=':')plt.axhline(mu[1], ls='--')plt.tight_layout()메모 3matplotlib로 벡터 화살표 표현하기plt.annotate()주요 arguments 텍스트 내용 입력 / 예) ‘ ‘ $xy$ = 가리킬 끝점 / 예) $v[:,0 ]$ xytext = 화살표 시작점 / 예) $mu$ arrowprops = d화살표로서 벡터 표현에 요긴하게 쓸 수 있었다.다변수정규분포-조건부확률분포다변수정규분포 따르는 결합확률분포의 ‘조건부확률분포’는 다변수정규분포 따른다. D차원 입력벡터 만들어내는 확률변수 x가 있다. 이 확률변수 x는 $N(X \\vert \\mu, \\Sigma)$ 다변수 정규분포를 따른다고 하자. 입력벡터 X의 표본인 D차원 벡터를 열벡터로 쌓아 만든 행렬을 X라 하자. 이 행렬 X를 분할해서 두 개 행렬로 나누자. 다음과 같이 표기할 수 있다. $X$ = [[$X_{a}$ ], [$X_{b}$ ]] (열로 생각하자)이거는 와 같다. $X_{a}$ 의 벡터 1개는 M차원을 갖고, $X_{b}$의 벡터 1개는 D-M 차원을 갖는다. 행렬 단위에서는 $X_{a}$ 는 (M*N), $X_{b}$는 ((D-M)*N) 행렬일 것이다. 이 때 대응되는 평균은 다음과 같다. $\\mu$ = [[$\\mu_{a}$ ], [$\\mu_{b}$ ]]$\\mu_{a}$ 는 행렬 $X_{a}$에 벡터들의 평균이다.$\\mu_{b}$ 는 행렬 $X_{b}$에 벡터들의 평균이다. 공분산행렬은 다음과 같다.$\\Sigma$ = [[$\\Sigma_{aa}$, $\\Sigma_{ab}$ ],[$\\Sigma_{ba}$, $\\Sigma_{bb}$ ]]예를들어 $\\Sigma_{aa}$는 다음과 같다. $X_{a}$ 와 $X_{b}$ 간 공분산은 $\\Sigma_{ab}$ 도 마찬가지다. 이렇게 해서 $\\Sigma$ = [[$\\Sigma_{aa}$, $\\Sigma_{ab}$ ],[$\\Sigma_{ba}$, $\\Sigma_{bb}$ ]] 가 나온다. 공분산 행렬 $\\Sigma$ 는 대칭행렬이다. 따라서 $\\Sigma^{T}$ = $\\Sigma$ 다. 따라서 $\\Sigma_{ba}$ = $\\Sigma_{ab}$ 다. 정밀도행렬(공분산행렬의 역행렬)은 다음과 같이 정의할 수 있다. $\\Lambda$ = $\\Sigma^{-1}$참고로 $\\Sigma$ 는 풀랭크(모든 열이 서로 독립) 이므로 항상 역행렬 존재한다. $\\Lambda$ 는 다음처럼 정의할 수 있다.$\\Lambda$ = [[$\\Lambda_{aa}$ , $\\Lambda_{ab}$ ],[$\\Lambda_{ba}$ , $\\Lambda_{bb}$]] $\\Lambda$ 도 대칭행렬이다. (대칭행렬 $\\Sigma$ 의 역행렬은 대칭행렬이다)$\\Lambda_{ab}$ = $\\Lambda_{ba}$ 성립한다. 단, $\\Lambda_{aa}$ 는 $\\Sigma_{aa}$ 역행렬 구한다고 얻을 수 있는 게 아니다.공분산의 부분행렬의 역행렬이 부분행렬의 정밀도 행렬이라 정의할 수 없다. 우리가 찾는 건 $p(X_{a} \\vert X_{b})$ 의 확률분포다. 여기서 현재의 결합확률분포 $p(X)$ = $p(X_{a} \\vert X_{b})$ 로 나타낼 수 있다. X는 맨 처음 언급했던, D차원 벡터 만들어내는 확률변수 X다. 만약 여기서 $X_{b}$ 가 고정된 값이라면 $X_{a}$ 의 조건부 확률분포 얻을 수 있을 것이다.정규분포 ‘지수의 이차형식’ 꼴에 X, $\\mu$ 등을 넣어서 지수의 이차형식 꼴로 정리된다면, X가 정규분포 따르게 될 것이라 볼 수 있다.또 정리된 식에서 평균, 공분산 구할 수 있어야 한다.만약 지수의 이차형식 꼴로 정리되면서, 평균, 공분산 구할 수 있으면 X의 분포가 정규분포 따른다’ 고 할 수 있다. 지수의 이차형식$\\Delta^{2}$ = $-(1/2)*$ $(X-\\mu)^{T}$ $\\Sigma^{-1}$ $(X-\\mu)$ 위 식에 $X$ 와 $\\mu$ 를 넣어서 식을 전개해보자. 앞에서 $X_{b}$ 는 특정한 값에 고정되어 있다고 생각하기로 했다. 따라서 위 식은 그냥 $X_{a}$ 에 대한 식이라 볼 수 있다. 또, 정리하면 이차형식 꼴이 된다. 이차형식에서 평균과 공분산 구할 수 있으면 ‘정규분포 따른다’고 할 수 있다. 정규분포의 이차형식 구조를 좀 더 살펴보자.$-(1/2)*$ $(X-\\mu)^{T}$ $\\Sigma^{-1}$ $(X-\\mu)$$=$ $-(1/2)*X^{T} \\Sigma^{-1}X$ $+$ $X^{T} \\Sigma^{-1} \\mu$ + $const$이 전개 방식을 ‘completing the square’라 부른다. $const$ 영역은 $X$ 와는 독립적인 영역이다. 이차형식을 두번 미분한 값은(즉 2차식 계수에 주목해야 한다) $\\Sigma^{-1}$ 이 된다. 이를 통해 공분산의 역행렬을 구할 수 있다. ($\\Sigma^{-1}$) 다음으로 1차식 계수는 $\\Sigma^{-1} \\mu$ 가 된다. 따라서 공분산행렬 구한 다음, 1차항 계수에서 평균벡터 $\\mu$ 를 구할 수 있다. 이제 조건부 분포의 평균과 분산을 구해보자. $X_{a}$ 와 $X_{b}$ 로 표현된 이차형식 영역을 $X_{a}$ 에 대해 두번 미분한다고 하면, 2차식 부분은 다음과 같다.$-(1/2)*X_{a}^{T} \\Lambda_{aa} X_{a}$ $X_{b}$ 와 관련된 영역은 모두 상수취급하면 된다. 두번 미분한 값(2차 항의 계수) 은 공분산의 역행렬과 같았다. 따라서, 조건부분포 $p(X_{a} \\vert X_{b})$ 의 공분산은 다음과 같다. $\\Sigma_{a\\vert b}$ $=$ $\\Lambda_{aa}^{-1}$ 이제 평균을 구하기 위해 $X_{a}$ 의 1차식 계수를 확인해 보자. 1차식 계수는$X_{a}^{T}${$\\Lambda_{aa}$ $\\mu$ - $\\Lambda_{bb} (X_{b} - \\mu_{b})$}이다. $\\Lambda_{ba}^{T}$ $=$ $\\Lambda_{ab}$ 였다.(앞에서 대칭행렬 설명할 때) 위 식은 앞에서 계산한 $\\Sigma_{a \\vert b}^{-1} \\mu_{a \\vert b}$ 와 같아져야 한다. 식을 전개하면 다음과 같다. $\\Sigma_{a \\vert b}^{-1}\\mu_{a \\vert b} = [\\Lambda_{aa}\\mu_{a} - \\Lambda_{ab}(X_{b}-\\mu_{b})]$$\\Rightarrow$ $\\mu_{a \\vert b} = \\Sigma_{a \\vert b} [ \\Lambda_{aa} \\mu_{a} - \\Lambda_{ab} (X_{b} - \\mu_{b}) ]$$\\Rightarrow$ 앞에서 $(\\Sigma_{a \\vert b} = \\Lambda_{aa}^{-1})$ 이었다. 적용하면$\\Rightarrow$ $\\mu_{a\\vert b} = \\Lambda_{aa}^{-1}$ $[\\Lambda_{aa}\\mu_{a} - \\Lambda_{ab} (X_{b} - \\mu_{b})]$ $\\mu_{a \\vert b}$ $=$ $\\mu_{a} - \\Lambda_{aa}^{-1}\\Lambda_{ab}(X_{b}-\\mu_{b})$ 이 된다. 평균과 분산을 정밀도 행렬 $\\Lambda$ 말고, $\\Sigma$ 로 표현해보자. $M^{-1}$ 은 schur completement라 불리는 행렬을 의미한다. 이 식을 아래 행렬에 대입해서 풀어본다. $\\Lambda_{aa} = (\\Sigma_{aa} - \\Sigma_{ab} \\Sigma_{bb}^{-1}\\Sigma_{ba})^{-1}$ $\\Lambda_{ab} = -(\\Sigma_{aa}-\\Sigma_{ab}\\Sigma_{bb}^{-1}\\Sigma_{ba})^{-1}$ $\\Sigma_{ab}\\Sigma_{bb}^{-1}$여기서 얻은 결과를 $p(X_{a} \\vert X_{b})$ 의 평균. 분산에 대입하면 $\\mu_{a \\vert b} = \\mu_{a} + \\Sigma_{aa}\\Sigma_{bb}^{-1}(X_{b}-\\mu_{b})$ $\\Sigma_{a \\vert b} = \\Sigma_{aa} - \\Sigma_{ab}\\Sigma_{bb}^{-1}\\Sigma_{ba}$가 나온다.결론 $\\mu_{a \\vert b}$ 는 $X_{b}$ 에 대한 선형함수 꼴이다. $\\Sigma_{a \\vert b}$ 는 $X_{b}$ 에 대해 독립적인 식이다. $X_{2}$ 가 어떤 값으로 주어지면 $X_{1}$의 조건부확률분포는 조건부 기댓값 $\\mu_{a \\vert b}$, 조건부공분산 행렬 $\\Sigma_{a \\vert b}$ 갖는 다변수 정규분포를 따르게 된다.다변수정규분포 따르는 결합확률분포의 주변확률분포도 다변수정규분포 따른다. 앞에서는 $p(X_{a}, X_{b})$ 분포가 다변수정규분포이면 $p(X_{a} \\vert X_{b})$ 분포도 다변수 정규분포가 된다는 걸 확인했다. 그렇다면 주변확률분포는 어떨까? $p(X_{a}) = \\int p(X_{a}, X_{b})dX_{b}$ &lt; 주변확률분포 식 &gt;위 주변확률분포가 ‘지수의 이차형식’ 꼴로 정리되고, 평균 분산구할 수 있으면 정규분포 따른다고 할 수 있다. 지수의 이차형식은 앞에서 다음과 같았다.$-(1/2)*(X-\\mu)^{T}\\Sigma^{-1}(X-\\mu)$$= -(1/2)*X^{T}\\Sigma^{-1}X + X^{T}\\Sigma^{-1}\\mu + const$ $X$ 에 $[[X_{a}],[X_{b}]]$ 넣고 $\\mu$ 에 $[[\\mu_{a}],[\\mu_{b}]]$ 넣어서 전개하면 다음과 같다.$-(1/2)*X_{b}^{T}\\Lambda_{bb}X_{b} + X^{T}_{b}m$$= -(1/2)(X_{b}-\\Lambda_{bb}^{-1}m)^{T}\\Lambda_{bb}(X_{b}-\\Lambda_{bb}^{-1}m)+(1/2)m^{T}\\Lambda_{bb}^{-1}m$ 위 식은 $X_{b}$ 에 대한 2차식으로 부분 변형하고, $(1/2)*m^{T}\\Lambda_{bb}^{-1}m$ 을 보충해준 식이다. $m = \\Lambda_{aa}\\mu_{b}-\\Lambda_{ba}(X_{a}-\\mu_{a})$ $X_{b}$ 로 적분해보자. 첫번째 항 $-(1/2)(X_{b}-m^{T})\\Lambda_{bb}(X_{b}-\\Lambda_{bb}^{-1}m)$ 은 $X_{b}$ 에 대한 식이다.두번째 항 $(1/2)m^{T}\\Lambda_{aa}^{-1}m$ 은 $X_{a}$ 에만 종속되는 식이다. 적분한 식을 $X_{a}$ 에 대해 정리한다.$(1/2)[\\Lambda_{bb}\\mu_{b}-\\Lambda_{ba}(X_{a}-\\mu_{a})]^{T}\\Lambda_{bb}^{-1}[\\Lambda_{bb}\\mu_{b}-\\Lambda_{ba}(X_{a}-\\mu_{a})]-(1/2)X_{a}^{T}\\Lambda_{aa}X_{a}+X_{a}^{T}(\\Lambda_{aa}\\mu_{a}+\\Lambda_{ab}\\mu_{b})+const$$= -(1/2)X_{a}^{T}(\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})X_{a} + X_{a}^{T}(\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})\\mu_{a}+const$ 이것 역시 이차형식 꼴이다. 따라서 $p(X_{a})$ 가 정규분포 따를 것이라 예상할 수 있다. 이제 위 식에서 평균. 분산만 구할 수 있으면 ‘$p(X_{a})$ 는 정규분포 따른다’고 말할 수 있다. 복기해보면, 공분산은 이차형식 내 2차식의 계수, 평균은 이차형식 내 1차식의 계수와 같았다. 이차식 계수 = $\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba}$ 의 역행렬$\\Rightarrow$ $(\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})^{-1} = \\Sigma_{a}$ 일차식 계수 = $\\Sigma^{-1}\\mu$ 와 같았다.위에 식에서 일차식 계수는 $(\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})\\mu_{a}$ 이었다.$\\Sigma^{-1}\\mu = [(\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})\\mu_{a}]$ 라고 두고 풀면$\\mu = \\mu_{a}$ 가 된다. 결국 $\\Sigma_{a} = (\\Lambda_{aa}- \\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})^{-1}$ $\\mu_{a} = \\mu_{a}$가 된다.한편 $[[\\Lambda_{aa}, \\Lambda_{ab}],[\\Lambda_{ba},\\Lambda_{bb}]]^{-1} = [[\\Sigma_{aa},\\Sigma_{ab}],[\\Sigma_{ba},\\Sigma_{bb}]]$ 였다. $[[A,B],[C,D]]^{-1} = [[M, -MBD^{-1}],[-D^{-1}CM, D^{-1}CMBD^{-1]}]$ 을 이용해서 식을 전개해 보자. $(\\Lambda_{aa}-\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba})^{-1} = \\Sigma_{aa}$ 가 나온다. 정리하면 다음과 같다. $E[X_{a}] = \\mu_{a}$ $COV[X_{a}] = \\Sigma_{aa}$직관적으로 매우 타당한 식이 결과로 나왔다.정리 및 요약다변수정규분포 따르는 어떤 결합분포가 다음과 같을 때 $X = [X_{a}, X_{b}]$ $\\mu = [\\mu_{a}, \\mu_{b}]$ $\\Sigma = [[\\Sigma_{aa},\\Sigma_{ab}],[\\Sigma_{ba},\\Sigma_{bb}]]$ $\\Lambda = [[\\Lambda_{aa},\\Lambda_{ab}],[\\Lambda_{ba}, \\Lambda_{bb}]]$- 조건부 확률분포 $p(X_{a} \\vert X_{b}) = N(X_{a} \\vert \\mu_{a \\vert b}, \\Lambda_{aa}^{-1})$- 주변확률분포 $p(X_{a}) = N(X_{a} \\vert \\mu_{a}, \\Sigma_{aa})$모두 다변수정규분포 따른다.8.6.2 연습문제문제2차원 다변수정규분포가 다음과 같은 모수를 가진다고 하자.$\\mu = [\\mu_{1}, \\mu_{2}]$,$\\Sigma = [[\\sigma_{1}^{2}, p\\sigma_{1}\\sigma_{2}],[p\\sigma_{1}\\sigma_{2}, \\sigma_{2}^{2}]]$$x_{2}$가 주어졌을 때 $x_{1}$ 의 조건부확률분포함수가 다음과 같음을 보여라. $N(x_{1} \\vert \\mu_{1}+(p\\sigma_{1}\\sigma_{2}/\\sigma_{2}^{2})(x_{2}-\\mu_{2}), \\sigma_{1}^{2} - ((p\\sigma_{1}\\sigma_{2})^{2}/\\sigma_{2}^{2}))$내 풀이 $\\mu = [[\\mu_{1}], [\\mu_{2}]]$ $\\Sigma = [[\\Sigma_{11},\\Sigma_{12}],[\\Sigma_{21},\\Sigma_{22}]]$ $\\Lambda = [[\\Lambda_{11},\\Lambda_{12}],[\\Lambda_{21}, \\Lambda_{22}]] = (\\Sigma^{-1})$ $p(x_{1} \\vert x_{2})$ 는 $N(x_{1} \\vert \\mu_{1 \\vert 2}, \\Sigma_{1 \\vert 2})$ 따른다$\\Rightarrow$ $-(1/2)(x-\\mu)^{T}\\Sigma^{-1}(x-\\mu) =$$-(1/2)x^{T}\\Sigma^{-1}x+x^{T}\\Sigma^{-1}\\mu + const$지수의 이차형식에 $x$, $\\mu$ 넣어서 전개한 다음 이차형식 형태로 정리되는지 보자.정리하면 다음과 같다. (계산과정 생략)$-(1/2)x_{1}^{T}\\Lambda_{11}x_{1}$$+ (-(1/2)\\Lambda_{21}x_{2} - (1/2)\\Lambda_{12}x_{2}+\\Lambda_{11}\\mu_{11}+\\Lambda_{12}\\mu_{2})x_{1}$$+ (-(1/2)\\Lambda_{22}x_{2}^{2} + \\Lambda_{21}x_{2}\\mu_{1} + \\Lambda_{22}x_{2}\\mu_{2}+ const)$ $\\Lambda_{11} = \\Sigma^{-1}$ $\\Lambda_{11}^{-1} = \\Sigma_{a \\vert b}$ $\\Sigma^{-1}\\mu = (-(1/2)\\Lambda_{21}x_{2}-(1/2)\\Lambda_{12}x_{2}+\\Lambda_{11}\\mu_{1} + \\Lambda_{12}\\mu_{12})$ $\\Sigma*\\Sigma^{-1}\\mu = \\Sigma(-\\Lambda_{21}x_{2} + \\Lambda_{11}\\mu_{1}+\\Lambda_{12}\\mu_{2})$ $\\mu_{a \\vert b} = \\Lambda_{11}^{-1}(-\\Lambda_{21}x_{2}+\\Lambda_{11}\\mu_{1}+\\Lambda_{12}\\mu_{2})$$[[\\Sigma_{11}, \\Sigma_{12}],[\\Sigma_{21},\\Sigma_{22}]]^{-1} = [[\\Lambda_{11},\\Lambda_{12}],[\\Lambda_{21}, \\Lambda_{22}]]$를 이용하자. (구체적인 식은 앞에 참고) $\\Lambda_{11} = (\\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21})^{-1}$ $\\Lambda_{12} = -(\\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21})^{-1}\\Sigma_{12}\\Sigma_{22}^{-1}$ $\\Sigma_{a \\vert b} = \\Lambda_{11}^{-1}$ $\\mu_{a \\vert b} = \\Lambda_{11}^{-1}(-\\Lambda_{21}x_{2}+\\Lambda_{11}\\mu_{1}+\\Lambda_{12}\\mu_{2})$= $-\\Lambda_{11}^{-1}\\Lambda_{21}x_{2}+\\mu_{1}+\\Lambda_{11}^{-1}\\Lambda_{12}\\mu_{2}$= $\\mu_{a \\vert b} = \\mu_{1} + (\\Lambda_{11}^{-1}\\Lambda_{12})(\\mu_{2}-x_{2})$ 앞에서 구한 $\\Lambda_{11}$ 과 $\\Lambda_{12}$ 을 이용해서 $\\Sigma_{a \\vert b}$, $\\mu_{a \\vert b}$ 식을 바꾸면 다음과 같다. $\\mu_{a \\vert b} = \\mu_{1}+\\Sigma_{12}\\Sigma_{22}^{-1}(x_{2}, \\mu_{2})$ $\\Sigma_{a \\vert b} = \\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$앞에서$\\Sigma$$= [[\\sigma_{1}^{2}, p\\sigma_{1}\\sigma_{2}],[p\\sigma_{1}\\sigma_{2}, \\sigma_{2}^{2}]]$$= [[\\Sigma_{11},\\Sigma_{12}],[\\Sigma_{21}, \\Sigma_{22}]]$였다.$\\mu_{a \\vert b}$, $\\Sigma_{a \\vert b}$ 에 대입해서 식 정리하면 $\\mu_{a \\vert b} = \\mu_{1} + ((p\\sigma_{1}\\sigma_{2})/\\sigma_{2}^{2})$ $(x_{2}-\\mu_{2})$ $\\Sigma_{a \\vert b} = \\sigma_{1}^{2}-(p\\sigma_{1}\\sigma_{2})^{2}/\\sigma_{2}^{2}$ 로, 증명이 완료된다.위 내용을 공부 &amp; 정리 하면서 참조한 곳 : http://norman3.github.io/prml/docs/chapter02/3_1.html" }, { "title": "[수학/확률과 통계] 스튜던트 t분포, 카이제곱분포", "url": "/bioinfo.github.io/posts/normal_distribution/", "categories": "Data Science, python, mathematics", "tags": "study, data science, mathematics", "date": "2021-07-21 00:00:00 +0900", "snippet": "t분포 (스튜던트 t분포) : t통계량 분포 팻테일 현상 보이는 데이터에 적용하기 좋은 확률분포다. (예: 주식 일간수익률 데이터) 기댓값, 정밀도, 자유도를 모수로 갖는다. 자유도는 2이상의 자연수를 쓴다. 형상은 정규분포와 비슷하다.자유도 = 1 인 t분포는 ‘코시분포’라고 부른다. t통계량의 분포다.t통계량 정규분포에서 나온 표본들 평균을 정규화 해서 구한 값이다. 정규화 할 때 Z 통계량 처럼 모분포 표준편차 안 쓰고, 비편향 표본표준편차 s 써서 정규화 한 값이다. 비편향 표본표준편차 s는 정규분포 표본 N개의 비편향 표본표준편차를 말한다. t통계량들의 분포를 t분포라고 한다. t분포 모수 기댓값과 정밀도는 각각 0, 1이 기본이다. t분포 자유도는 N-1이다. N은 표본평균 계산한 정규분포 표본 수다.t분포와 자유도 간 관계자유도가 커지면 정규분포에 가까워진다.자유도가 작아지면 정규분포에서 멀어지고, 팻테일 현상이 나타난다.카이제곱 분포 : 정규분포 표본 N개 제곱합의 분포 t분포 처럼 자유도 모수를 갖는다. 자유도 = N 모든 표본값이 양수인 분포다.# 카이제곱분포 확률밀도함수 xx = np.linspace(0.01, 10, 100)dfs = np.arange(1,5)ls = ['-', ':', '--', '-.']for df, ls in zip(dfs, ls) : rv = sp.stats.chi2(df = df) plt.plot(xx, rv.pdf(xx), ls=ls, label=f'자유도 : {df}')plt.xlim(0, 10.01)plt.ylim(0, 0.6)plt.legend()plt.title('자유도 변화에 따른 카이제곱분포 확률밀도함수 변화')plt.xlabel('표본값')plt.ylabel('$p(x)$')plt.show() 자유도가 2까지는 0 언저리 값이 가장 많이 나온다. 자유도가 3 이상일 때(표본 갯수 N이 3 이상 일 때) 0보다 큰 어떤 수가 가장 많이 나온다. 이는 중심극한정리 때문이다. 카이제곱 분포는 결국 ‘정규분포 표본 제곱’ 이라는 확률변수 N개 합의 분포와 같다.정규분포 표본 제곱 값들은 같은 정규분포 따르는 확률변수에 의해 결정된다. 곧, 제곱값 확률변수들은 같은 분포를 따른다.결국 중심극한정리에 따라, 제곱값 확률변수 갯수 N이 커질 수록 정규분포에 근사해간다.N = [6,30,100,150]M = 2000np.random.seed(0)rv = sp.stats.norm()for i, n in enumerate(N) : plt.subplot(1,4,i+1) x = rv.rvs(size=(n, M)) data = (x**2).sum(axis=0) sns.distplot(data, kde=False) plt.title(f'자유도 : {n}')plt.tight_layout()plt.suptitle('중심극한정리에 따라 N 커질 수록 정규분포 형상에 가까워진다', y=1.1)plt.show()" }, { "title": "[수학/확률과 통계] 중심극한정리 ", "url": "/bioinfo.github.io/posts/clt/", "categories": "Data Science, python", "tags": "study, data science, mathematics", "date": "2021-07-21 00:00:00 +0900", "snippet": "중심극한정리 정의기댓값이 mu 이고, 분산이 $sigma^{2}$ 이며 서로 독립인 분포 N개가 있다.각 분포에서 나온 표본 N개의 평균(또는 합)의 분포는 N이 커질수록 기댓값이 mu이고 표준편차가 sigma/np.sqrt(n) 인 정규분포에 근사한다. 혹은기댓값이 mu이고, 분산이 sigma^{2} 인 분포가 있다.이 분포에서 서로 독립인 표본 N개를 추출했다.N이 커질수록, 이 표본들의 평균(또는 합)이 이루는 분포가 기댓값이 mu이고 표준편차가 sigma/np.sqrt(n) 인 정규분포에 근사한다. 위 표본평균(합) 값들도 그 자체로 하나의 확률변수가 된다. 표본평균 확률변수에서 얻은 데이터들을 정규화하면, N이 증가할 수록 표준정규분포에 수렴한다.표본 시뮬레이션으로 중심극한 정리 성립하는지 보자.# 균일분포 표본 얻어서 중심극한정리 검증해보기 np.random.seed(0)xx = np.linspace(-2,2,100)plt.figure(figsize=(6,9))for i, N in enumerate([1,2,5]) : x = np.random.sample([5000, N]) x_bar = (np.mean(x, axis=1)-0.5)/(1/12) ax = plt.subplot(3,2,2*i+1) sns.distplot(x_bar, bins=10, kde=False, norm_hist=True) plt.xlim(-5,5) plt.yticks() ax.set_title(f'N={N}') plt.subplot(3,2,2*i+2) sp.stats.probplot(x_bar, plot=plt)plt.tight_layout()plt.show() N이 커질수록 분포가 정규분포에 수렴하는 것을 볼 수 있다.그렇다면 N개 정규분포에서 얻은 표본들 평균(합)은 어떻게 될까? N개 정규분포에서 얻은 표본들 평균(합)은 N에 관계 없이 언제나 정확한 정규분포를 이룬다. 기댓값 : N *mu, 분산 : N *sigma^{2} N=1이면 원래 정규분포에서 나온 표본들이니 표본분포도 정규분포 그대로 따라갈 것이다.정규분포 따르는 표본들을 정규화 하면 어떻게 될까? 정규분포 따르는 표본들을 정규화 한 값을 ‘Z 통계량’ 이라 한다. 앞에서는 표본평균들을 정규화 하면 N이 커질 때, 표준정규분포에 수렴했다. 이와 달리, 정규분포 따르는 표본들의 평균값들을 정규화 하면 정확하게 표준정규분포를 이룬다. 시뮬레이션으로 직접 알아보자rv = sp.stats.norm(0, 1)plt.figure(figsize=(6,9))for i, v in enumerate([1,10,100]) : fig = plt.subplot(3,2,2*i+1) data = rv.rvs(size=(5000, v), random_state=0) x_bar = np.mean(data, axis=1) sns.distplot(x_bar, kde=False, bins=10) plt.xlim(-5,5) plt.yticks([]) fig.set_title(f'N={v}') ax = plt.subplot(3,2,2*i+2) sp.stats.probplot(x_bar, plot=plt)plt.suptitle('정규분포에서 나온 표본들 평균은 N상관없이 항상 정규분포 따른다', y=1)plt.tight_layout()plt.show()왼쪽 분포 형상도 정규분포와 같고, 오른쪽 Q-Q 플롯을 보면 스캐터 플롯이 모두 일직선으로,N에 상관없이 표본데이터들 분포가 정확하게 정규분포를 이룬다는 걸 알 수 있다.선형회귀 모형과 정규분포 정규분포는 선형회귀 모형에서 잡음(disturbance) 모형화에 사용된다.선형회귀모형y = (c1 * x1) + (c2 * x2) … (cn * xn) + epsilonepsilon이 ‘잡음’ 이다. ‘잡음’의 정의 : y 형성하는 영향력 중, 측정 불가한 ‘나머지’ 영향력 하나로 퉁 친 것.책 567p 메모 )원래 y값은 무한한 독립변수의 영향을 받는다.각각의 (cn * xn) 값은 독립변수 값에 따라 달라지는 ‘확률변수 값’ 이다. 확률적 데이터가 나오기 때문에, 다음 번에 뭐가 나올지 알 수 없다.각 확률변숫값을 내놓는 공통의 확률변수가 있을 것이다. 이를 ‘y에 대한 영향’ 확률변수라고 명명하겠다.epsilon은 확률변숫값들 중 가장 ‘작고’, ‘미미해서’ y에 거의 영향조차 못 미치는 값들을 더한 것이다.epsilon을 구성하고 있는 확률변숫값들은 무한개다.같은 확률변수(확률분포) 에서 나온 표본값들 갯수(N) 이 무한대이므로, 중심극한정리에 따라 epsilon의 분포는 정규분포로 가정할 수 있다.한편, epsilon의 기댓값은 매우 작은 0 근처 값일 것이다.이 값은 매우 작아서 y에 영향 주지 못한다. 이를 이용해y = $E[epsilon ] + c1x1+ c2x2…+epsilon$ 으로 선형회귀식을 변형할 수 있다.이때 앞에서 y는 $c1x2+c2x2+…+epsilon$ 과 등호가 성립했으므로,$c1x2+c2x2+…+epsilon = E[epsilon] + c1x1+ c2x2…+epsilon$ 으로 놓을 수 있다.양변에서 같은 항을 제거하면 $E[epsilon ] = 0$ 이 된다.이런 방법으로, $y = E[epsilon ] + c1x1+ c2x2…+epsilon$ 를 쓰면서 $E[epsilon] = 0$ 이라고 할 수 있다.따라서epsilon의 분포는 기댓값이 0인 정규분포로 가정할 수 있다.epsilon ~ N(0, sigma^{2}) 한편 y도 N개(무한대) 확률변숫값의 합이므로, y의 분포도 정규분포를 이룬다." }, { "title": "[수학/확률과 통계] 공분산, 상관계수, 조건부 기댓값과 분산", "url": "/bioinfo.github.io/posts/pearson/", "categories": "Data Science, python, mathematics", "tags": "study, mathematics, datascience", "date": "2021-07-21 00:00:00 +0900", "snippet": "상관관계상관관계 정의확률변수-확률변수 간 한 확률변숫값을 알면 다른 확률변숫값에 대한 정보 얻을 수 있는 관계 또는 두 확률변수가 서로 영향 주고받는 관계상관관계 종류 선형 상관관계 비선형 상관관계표본 공분산 정의 : 확률변수 벡터(표본)들이 축에서 평균적으로 떨어진 정도 전제 : ‘축’ = 확률변수 각 표본값들의 평균 $(\\bar{X}, \\bar{Y})$피어슨 상관계수 정의 : 두 확률변수 사이 선형상관 정도를 나타낸다.$p = 1$ 이면 ‘완전 선형 상관관계’$p = 0$ 이면 ‘무상관’ (선형 상관관계 없음)$p = -1$ 이면 ‘완전 선형 반상관관계’피어슨 상관계수 부호는 다변수 확률변수 표본 벡터 분포 방향을 알려준다 음수 : 오른쪽 아래 양수 : 오른쪽 위피어슨 상관계수 절댓값 크기는 분포 기울기와는 아무 상관 없다 (얼마나 선형에 가까운지만 나타낸다)피어슨 상관계수 한계 두 확률변수 사이 비선형 상관관계 있는 경우, 피어슨 상관계수값 적용 할 수 없다. 피어슨 상관계수만으로 벡터 분포 형상 완벽하게 추측하기엔 한계가 있다.앤스콤 데이터셋에서 볼 수 있듯, 단 하나의 아웃라이어 데이터가 피어슨 상관계수값에 독보적 영향을 미칠 수 있다.결과적으로 전체 분포가 선형 형상임에도, 피어슨 상관계수값은 1 또는 -1 안 나오는 경우가 생긴다.다변수 확률변수의 표본공분산 다변수 확률변수는 단변수 확률변수 여러 개를 말한다.또는 단변수 확률변수 모아놓은 벡터라고 봐도 된다. 다변수 확률변수 표본 공분산은 여러 개 단변수 확률변수의 표본들 간 공분산 구하는 것과 같다.예를 들어 $X = [X1, X2, X3, X4]$ 인 경우 ($X$ 가 다변수 확률변수다)$X1$ 의 표본과 $X2$ 의 표본 간 공분산 구하고, $X1$ 의 표본과 $X3$ 표본 간 공분산 구하고…모든 단변수 확률변수 조합의 표본공분산 구하고, 표본공분산 행렬로 나타내면 된다. 다변수 확률변수의 이론적 공분산 행렬로 같은 개념에 기반해 구하면 된다.예) $X1$ 과 $X2$ 모든 표본 간 공분산, $X1$ 과 $X3$ 모든 표본 간 공분산…조건부 기댓값 조건부 기댓값 : 기댓값 구할 때, 원래 확률질량함수를 가중치로 써서 구했다.조건부 기댓값은 확률질량함수 대신, 조건부확률질량(밀도)함수를 가중치로 써서 구한다. 조건부 기댓값은 예측문제의 답이 된다. $\\hat{y}$ 으로 쓰기도 한다.조건부 기댓값의 성질 상수에 대한 조건부 기댓값은 상수 일반적인 기댓값 성질 그대로 모두 만족한다전체 기댓값의 법칙 조건부 기댓값의 기댓값은 $Y$ 확률변수 기댓값과 같다조건부 분산 예측문제에서, 예측으로 못 맞추는 범위. 예측의 불확실성 의미한다.조건부 편차 제곱의 조건부 기댓값. 내가 제시하는 예측 답은 조건부 확률분포 기댓값이다. 조건부 분산은 y값들이 이 기댓값에서 떨어져 있는 정도를 의미한다. 기댓값에서 떨어져 있는 y값들은 기댓값으로는 못 맞추는 값이다. [분산 크기 = 내가 기댓값으로 못 맞추는 범위]따라서 조건부 분산이 크다 : 예측 불확실성이 높다 (못 맞추는 범위가 넓다) 조건부 분산이 작다 : 예측 불확실성이 작다 (못 맞추는 범위가 좁다)전체 분산의 법칙 전체 분산의 법칙 식에서 편향-분산 상충법칙이 발생한다.편향_분산 상충법칙 편향(예측오차)를 낮춰서 주어진 데이터에서 정답을 잘 맞추게 하면 모델이 복잡해지고, 자칫 과적합(오버핏팅) 문제가 발생할 수 있다.오버핏팅이란 과적합 이라고도 하고, 주어진 데이터 내에서 정답은 매우 잘 맞추지만, 다른 데이터를 넣으면 예측 모델이 형편없이 못 맞추는 현상을 말한다.즉 예측모델이 주어진 데이터는 과할 정도로 학습해서 거의 ‘외워 버렸지만’, 새 데이터는 형편없이 못 맞추는 것이다. 과최적화를 피하기 위해 모델을 단순하게 만들면, 분산(예측값 변동 정도)는 떨어지지만 이제 예측오차(틀렸을 때 얼마나 빗나가는가) 가 커진다.이 같은 상충 현상을 ‘편향_분산 상충법칙’이라고 한다." }, { "title": "[수학/메모] 다변수확률변수 공분산_메모", "url": "/bioinfo.github.io/posts/covariance/", "categories": "Data Science, python, mathematics", "tags": "mathematics, python, datascience", "date": "2021-06-30 00:00:00 +0900", "snippet": "표본 공분산일반적인 확률변수는 시뮬레이션(=시행) 한 번 할 때 마다 스칼라 표본 하나씩을 내놓는다.이 표본은 확률적 데이터로, 확률변수의 확률분포에 따라 현실세계로 튕겨져 나온 ‘데이터’다.만약 스칼라 표본을 내놓는 이러한 확률변수가 $X,Y$ 둘이 있다고 가정해보자.표본 공분산은 $x$ 표본과 $y$ 표본이 동시에 $x$ 평균과 $y$ 평균에서 떨어진 정도의 평균으로, 2차원 평면에서 나타낼 경우 축과 점 사이 거리를 선으로 연결한여러 크고 작은 사각형 면적의 평균이 된다.확률변수 벡터들의 표본공분산그렇다면 확률변수 벡터를 표본으로 갖는 다변수 확률변수의 표본 공분산은 어떨까?X = pd.DataFrame(np.array( [[x11,x21,x31], [x12, x22, x32], [x13, x23, x33]] ),columns=['X','Y','Z'])위와 같은 행렬이 있다고 가정하자.행렬의 각 행은 다변수확률변수 표본들이다. 표본 하나가 곧 벡터 하나다.다변수 확률변수에서 시뮬레이션을 한 번 하는 것은 단변수 확률변수 $X,Y,Z$ 에서 표본 하나씩 총 표본 3개를 한번에 꺼내오는 것과 같다.다변수 확률변수의 표본인 확률변수 벡터는 이 값들을 ‘모아놓은 것’이다.이렇게 생각한다면, 다변수 확률변수 표본 1개는 단변수 확률변수 표본 3개와 같다.다변수 확률변수에 대해 시뮬레이션을 3번 하면 표본 추출한 결과를 위 행렬처럼 나타낼 수 있다.각 행에 담긴 스칼라값 3개가 곧 1번 추출해서 나온 ‘표본들’이다.따라서 이 표본들의 표본 공분산을 구하고 싶다면, columns에 있는 단변수 확률변수들 조합 $(X,Y),(Y,Z),(X,Z)$ 의 표본공분산을 모두 구하면 된다.표본공분산 행렬 은 이 결과를 한번에 모아서 행렬로 나타낸 것이다.기록 요지위 예시 행렬 기준, 다변수 확률변수 표본 1개는 곧 단변수 확률변수 표본 3개와 같다.곧, 단변수 확률변수 3개에서 표본 하나씩을 동시에 추출한 것이다.$\\Rightarrow$ 다변수확률변수 1개는 단변수 확률변수 3개인 것과 같다.그래서 ‘다변수 확률변수’ 인 것이다.$V = [X1, X2, X3]$" }, { "title": "[수학/확률과 통계] 확률변수벡터, 결합.조건부.주변확률분포, 확률변수 독립", "url": "/bioinfo.github.io/posts/random_variable_vector_and_others/", "categories": "Data Science, python, mathematics", "tags": "datascience, mathematics, python", "date": "2021-06-28 00:00:00 +0900", "snippet": "다변수 확률변수 벡터를 표본으로 내놓는 확률변수결합확률분포함수는 기본적으로 다변수함수다 (입력변수 여러개-벡터 / 출력변수 1개-스칼라)따라서 결합확률분포함수는 3d 서피스플롯 등 3차원 그래프로 나타낼 수 있다.예컨대 P_XY(x,y) 라는 결합확률질량함수가 있다. 이 함수는 2차원 벡터 $[x, y]$ 의 확률질량값을 할당하는 함수다. 결합확률분포함수 p(x,y) 히트맵으로 나타내기 sns.heatmap(pmf, cmap=mpl.cm.bone_r, annot=True, xticklabels=grades,yticklabels=grades)plt.title('결합확률질량함수 p(x,y)- 히트맵')plt.tight_layout()plt.show() 이산확률변수 벡터 : [표본공간이 모두 같은] 이산확률변숫값들로 구성된 벡터 이산확률변수들의 표본공간이 모두 같아야 한다예) 주사위 던져서 나오는 수의 확률변수 X,Y둘 다 표본공간이 {1,2,3,4,5,6} 으로 같다.Z = [x, y] Z는 이산확률변수 벡터결합확률질량함수 이산확률변숫값들로 구성된 벡터(이산확률변수 벡터)에 할당된 확률질량값 정의하는 함수다.주변확률질량함수 결합확률질량함수와 전체확률의 법칙 이용해서 구하는, 개별확률변수의 확률질량함수다.조건부 확률질량함수 X,Y 결합확률질량함수에서, 확률변숫값 하나를 고정시켜놓고 나머지 확률변수 변화시키면서 조건부 확률 구한 것. 조건부확률. 확률질량함수 결합확률질량함수(3차원 그래프) 자른 단면 / 조건이 되는 확률변수의 주변확률질량함숫값 조건부 확률질량함수 모양은 결합확률질량함수 자른 단면과 ‘비슷’하다연속확률변수 벡터 : 연속확률변숫값들로 구성된 벡터결합누적확률분포함수 두 특수구간 교집합의 확률 할당하는 함수 P(X &lt; x, Y &lt; y)결합확률밀도함수 연속확률변수 벡터의 확률밀도값 할당하는 함수 (2차원함수, 다변수함수, 3차원 그래프)결합확률밀도함수 이중적분하면 2차원 함수 부피 구하는 것과 같다.결합누적확률분포함수를 편미분 두번 해서 구한다.# 결합확률밀도함수 를 그려보자. # 다변수 정규분포 mu = [70,170]cov = [[150,140],[140,300]]rv = sp.stats.multivariate_normal(mu, cov) # 다변수 정규분포 객체xx = np.linspace(20,120,100)yy = np.linspace(100,250,100)X,Y = np.meshgrid(xx,yy) # 10,000개의 그리드포인트 grid_point = np.dstack([X,Y]) # 좌표점 # 그리드포인트Z = rv.pdf(grid_point)ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z, color='r',linewidth=0.5)plt.title('다변수정규분포의 결합확률밀도함수')plt.xlabel('$x$')plt.ylabel('$y$')#ax.view_init(80,100)plt.show()주변확률밀도함수 결합확률밀도함수에서 구한 개별 확률변수 확률밀도함수 결합확률밀도함수를 하나의 확률변수에 대해 전구간 적분해서 날리고, 1개 확률변수의 확률밀도함수 구한 것. 1차원 함수$p_{x}{(x)}$$p_{y}{(y)}$조건부확률밀도함수 결합확률밀도함수 단면 / 조건이 되는 확률변수의 주변확률밀도함숫값 조건부 확률. 확률밀도함수 1차원 단변수함수다. 결합확률밀도함수에서 연속확률변수 하나를 고정시켜놓고, $x$ 값 변화시켜 가며 구한 확률. 을 조건이 되는 확률변수의 주변확률밀도함숫값으로 나눈 것.정리 결합~~ 분포함수는 말 그대로 결합사건 확률 할당하는 함수다. 주변~~ 분포함수는 개별 확률변수의 확률분포함수 구한 것이다. (결합~~에서 떼어낸다) 조건부~~ 분포함수는 말 그대로 조건부확률 할당하는 함수다. (확률변숫값 하나를 특정값에 고정했을 때의 조건부확률)확률변수의 독립확률변숫값 변화가 조건부 확률분포 변화시키면. 두 확률변수는 서로 ‘상관관계가 있다’고 한다.확률변수가 상관관계가 없으면 서로 ‘독립’이다.(사건 : 독립 &lt;-&gt; 종속)사건의 독립처럼 $P(A,B) = P(A) P(B)$ 성립한다. 두 확률변수 독립 이면, 조건부확률분포 = 주변확률분포 다.조건을 걸든 안 걸든, 같단 소리다.독립확률변수의 기댓값 $E[X Y] = E[X]E[Y]$ $E[(X-mu )(Y-mu )] = 0$성립–&gt; ‘다중적분은 적분을 연속한 것과 같다’ 는 푸비니 정리 이용해서 첫번째 성질 증명 가능–&gt; 증명된 첫번째 성질 이용하면 두 번째 성질 증명 가능 두 확률변수가 독립이면 아래 성질 성립한다.$V[X + Y] = V[X] + V[Y]$증명)V[X+Y] = E[(X-mu_X)^2]--&gt; E[(X+Y-(mu_X+mu_Y)^2)]--&gt; E[(X-mu_X)+(Y-mu_Y)^2]--&gt; E[(X-mu_X)^2+(Y-mu_Y)^2+2(X-mu_X)(Y-mu_Y)]--&gt; V[X]+V[Y]+2E[(X-mu_X)(Y-mu_Y)]# 두 확률변수 X,Y 독립일 때 2E[(X-mu_X)(Y-mu_Y)]가 0 이므로, V[X]+V[Y]만 남는다.참고 enumerate()함수반복문 돌 때, iterator의 인덱스와 컬렉션 원소를 tuple형태로 묶어서 반환한다." }, { "title": "[수학/확률과 통계] 확률변수, 확률분포 모멘트", "url": "/bioinfo.github.io/posts/random_variable/", "categories": "Data Science, python, mathematics", "tags": "data science, python, mathematics, study", "date": "2021-06-27 00:00:00 +0900", "snippet": "2021-06-27 7. 확률변수, 확률변수 모멘트 복습확률변수 변환기존 확률변수 이용해서 새 확률변수 만드는 것.통계량특정 표본값 전부를 하나의 공식에 넣어서 구해낸 하나의 값큰 수의 법칙 표본평균 확률변수 기댓값은 원래 확률변수 기댓값과 같다.$E[\\bar{X}] = E[X]$$\\Rightarrow$ 표본평균은 모평균에 근사한다(큰수의 법칙) 비편향 표본분산 기댓값도 원래 확률변수 분산과 같다.$\\Rightarrow$ (비편향)표본분산은 모분산에 근사한다 표본 갯수 n이 무한히 많아지면 표본평균은 확률변수 기댓값(평균)과 같아진다. 표본개수 n이 충분히 크면, 표본평균은 확률변수 기댓값의 근삿값이다. 확률변수 기술통계값 &amp; 모멘트확률변수 중앙값중앙값보다 큰 값 나올 확률과 중앙값보다 작은 값 나올 확률이 0.5-0.5로 동일한 지점 값중앙값 = 누적분포함수 역함수(0.5)확률밀도함수 면적 0.5-0.5 되게 하는 표본공간 표본값확률변수 최빈값확률밀도, 확률질량이 가장 높은 값현실 데이터로 가장 빈번하게 나오게 될 값이다.확률변수 기댓값얻어질 거라 기대(예측)되는 값확률변수 분산기대. 예측의 신뢰도분산값이 크면 : 예측 신뢰도 낮을 것이다.분산값이 작으면 : 예측 신뢰도 클 것이다.확률변수 확률분포의 비대칭도확률변수의 3차 모멘트 값에서 계산비대칭도 0 이면 좌우대칭비대칭도 + 이면 기댓값 기준 오른쪽 표본들에 할당된 확률값들이 높다.비대칭도 - 이면 기댓값 기준 왼쪽 표본들에 할당된 확률값들이 높다.확률변수 확률분포의 첨도(뾰족도)확률변수의 4차 모멘트 값에서 계산확률분포 모양이 얼마나 뾰족한가?(확률값들이 얼마나 중앙에 모였나?)정규분포가 기준확률분포가 정규분포보다 중심에 모여있으면 : 첨도 양수 +확률분포가 정규분포보다 중심에서 멀면 : 첨도 음수 -확률변수의 독립두 확률변수가 서로 영향 미치지 않는다!서로 영향 미치면 = 두 확률변수는 ‘종속’편향표본분산은 대체로 확륩변수 분산보다 작다(경향성).비편향표본분산은 실제 확률변수 분산의 근삿값이다. 이는 표본데이터들이 편향되어 있어서 그렇다. = 표본데이터들은 대체로 한 쪽에 몰려 나오는 경우가 많다." }, { "title": "[수학/확률과 통계] 표본모멘트, 확률변수", "url": "/bioinfo.github.io/posts/sample_moments/", "categories": "Data Science, python, mathematics", "tags": "study, mathematics, python", "date": "2021-06-26 00:00:00 +0900", "snippet": "2021-06-26 7장 확률변수와 상관관계 복습표본 모멘트 : 표본분포 각종 특성치 표본평균1차 모멘트표본값들 산술평균이자 대푯값x_bar = np.mean(x) 표본분산 &amp; 표준편차2차 모멘트표본값들이 평균에서 떨어진 정도 (분포의 대푯값)x_var = np.var(x, ddof=1) 비편향 표본분산x_std = np.std(x, ddof=1) 비편향 표본표준편차 표본 비대칭도3차모멘트에서 유도표본 비대칭도가 양수 + : 표본분포에서 표본평균 기점으로 오른쪽에 있는 데이터들 빈도가 높다.표본 비대칭도가 음수 - : 표본분포에서 표본평균 기점으로 왼쪽에 있는 데이터들 빈도가 높다.표본 비대칭도가 0 : 표본평균 기점으로 표본분포가 완벽한 좌우대칭이다.sp.stats.skew() 표본 첨도 (뾰족도)4차 모멘트에서 유도기준 : 정규분포표본 첨도가 양수 : 표본분포 형상이 정규분포보다 표본평균에 모여있음 (뾰족)표본 첨도가 음수 : 표본분포 형상이 정규분포보다 표본평균에서 멈 (뭉툭)sp.stats.kurtosis()확률변수 : 확률변수가 ‘내포’하고 있는 표본공간에 들어있는 표본들을 실수값으로 바꿔서, 현실세계 데이터(표본)으로 보내준다.확률변수는 ‘확률적 실수데이터 생성기’ 이다. 이산확률변수 : 확률변숫값이 [불연속적]인 경우 연속확률변수 : 확률변숫값이 [연속적]이고 [무한개] 일 경우확률변숫값(=표본값=데이터)에 할당된 확률은 정확히 알 수 없다. 빈도만 보고 대강 이정도 확률이 할당 되어서 나왔겠구나’라고 추정.짐작 만 할 수 있다.이 확률변숫값(=데이터)의 확률 하나하나를 직접 찾는 과정이 추정이다.데이터 하나하나만 가지고는 할당된 확률을 말할 수 없다. 빈도만 측정할 수 있다. 빈도를 보고 대략 확률이 어느정도 할당 되어 있겠거니 짐작할 뿐이다.확률변수를 사용한 데이터분석 과정 시뮬레이션 해서 확률변수로부터 표본을 얻는다. 얻은 표본의 분포를 활용해서 확룰변수의 확률분포를 추정. 짐작한다. &lt;– 추정. 짐작에 자주 사용되는 방법이 ‘기술통계값이 비슷한 확률분포를 찾는 방법’이다. 확률변수의 확률분포를 결정하면, 그걸 써서 다음번에 나올 데이터 또는 데이터 특성 예측한다." }, { "title": "[수학/확률론] 베이즈 정리", "url": "/bioinfo.github.io/posts/baysian/", "categories": "Data Science, python, mathematics", "tags": "study, datascience, python, mathematics", "date": "2021-06-24 00:00:00 +0900", "snippet": "2021-06-24 베이즈정리 복습베이즈 정리 중간에 들어온 정보로 인해(사건 B가 발생) 사건 A 사전확률이 어떻게 사후확률로 변하는지 보여준다.$P(A\\vert{B}) = \\frac{P(B\\vert{A})P(A)}{P(B)}$ $P(A)$ : 사전확률 $P(B\\vert{A})$ : 가능도 $P(B)$ : 정규화상수(크기조절, 별 의미 없음)베이즈정리의 확장 일반형 : 전체확률의 법칙 사용해서 정규화 상수 변형 축소형 : $A$와 $A$여집합 두 개를 전체확률의 법칙 적용, 정규화 상수 변형베이즈 정리의 확장 2 $P(A\\vert B,C) = \\frac{P(C\\vert A,B)P(A\\vert B)}{P(C\\vert B)}$ 사건 A에 대해 여러 사건 동시에 발생했을 때(B,C…) 사건 A 사후확률은? 증명 : [조건부확률-결합확률] 사슬법칙 두번 적용해서 증명한다.사슬법칙 사용하면 여러 종류 베이즈정리 확장 식 증명할 수 있다.몬티 홀 문제 정의하기 핵심 : 문제가 결국 이진분류문제다. 진행자는 반드시 염소를 제거할 수 밖에 없고, 내 최종선택은 염소 vs 자동차 둘 중 하나에서 하게 된다. 최종선택 : 내가 처음에 고른 문 뒤에 자동차가 있다 vs 내가 선택하지 않은 문에 자동차가 있다. $\\Rightarrow$ 결과가 둘 중 하나로 나오는 이진분류문제다따라서 나는 ‘내가 처음에 고른 문 뒤에 자동차가 있는 확률 vs ‘내가 선택하지 않은 문에 자동차가 있는 확률’ 을 비교하면 된다.둘 중 확률이 높은 것이 채택되고, 결과값이 된다. 예) 이 상황은 내가 처음에 고른 문 뒤에 자동차가 있다! 고 분류될 것이다.한편, 내 선택의 관점에서 보면 둘 중 확률 높은 것을 선택하는 게 [자동차_당첨에_유리할_것이다]문제해결 _1 C : 자동차가 있는 경우를 의미하는 확률변수. 가질 수 있는 값 =(0,1,2) X : 내 선택한 문을 뜻하는 확률변수. 가질 수 있는 값 =(0,1,2) H : 진행자가 선택하는 문을 뜻하는 확률변수. 가질 수 있는 값 =(0,1,2)유의점 1 : 확률변수 C와 확률변수 X는 서로 독립(=영향 미치지 않음)이다. 따라서 $P(C,X) = P(C)P(X)$ 로 나타낼 수 있다.유의점 2 : 진행자의 선택은 내가 어떤 문을 골랐느냐 &amp; 자동차 위치가 어디였느냐에 달려있다. 따라서 진행자 선택을 뜻하는 조건부확률은 다음과 같다. 참가자 첫 선택이 자동차 아닌 경우$P(H1\\vert X2,C0) = 1$$P(H0\\vert X2,C0) = 0$$P(H2\\vert X2,C0) = 0$ 참가자 첫 선택이 알고보니 자동차인 경우$P(H0\\vert X2,C2) = 1/2$$P(H1\\vert X2,C2) = 1/2$$P(H2\\vert X2,C2) = 0$문제해결 _2이제 참가자가 고른 문 뒤에 차가 있을 확률 vs 참가자가 고르지 않은 문 뒤에 차 있을 확률 비교하면 된다. 두 확률 합은 1이다. (이진분류문제다. 예를들어 c1,c0둘 중 하나에 차가 있다면 결과는 c1에 차가 있다 vs c0에 차가 있다 둘 중 하나다. 확률 공리 이용해 교집합 없는 두 사건 합치면 합은 1이 된다)식으로 쓰면 다음과 같다.$P(C1 \\vert X2,H1)+P(C0 \\vert X2,H1) = 1$이제 문제를 풀어보자. 두 케이스 중 하나의 확률을 구하면 나머지 확률도 구할 수 있으므로, 나는 참가자가 첫번째 고른 문 뒤에 차가 있을 확률’을 구했다.$P(C2\\vert X2,H1) = P(C2,X2,H1)/P(X2,H1) = P(H1\\vert C2,X2)P(C2,X2)/P(X2,H1)$$= P(H1\\vert C2,X2)P(C2)/P(H1\\vert X2) = (1/2)P(C2)/(P(H1,C0\\vert X2)+P(H1,C1\\vert X2)+P(H1,C2\\vert X2))$$= ((1/2)(1/3))/(P(H1\\vert C0,X2)P(C0)+P(H1\\vert C1,X2)P(C1)+P(H1\\vert C2,X2)P(C2))$$= ((1/2)(1/3))/((1/3)+(1/2)(1/3))$$= [1/3]$따라서 내가 처음에 골랐던 문 뒤에 자동차가 있을 확률은 $\\frac{1}{3}$이다.$1-(1/3)$ 하면 진행자가 열지 않았고, 내가 선택하지 않았던 남은 문 하나에 자동차 있을 확률이 $\\frac{2}{3}$ 으로 나온다.$\\frac{2}{3}$ 은 $\\frac{1}{3}$ 의 두배이므로, 내가 고르지 않은 문 뒤에 결과적으로 자동차가 있을 확률이 더 높다.따라서 ‘자동차 당첨을 위해서는’ 선택을 바꾸는 것이 [‘유리하다’]" }, { "title": "[수학/확률론] 결합확률과 조건부확률, 결합확률분포 정의내리기- 확률론 기초 복습 (2)", "url": "/bioinfo.github.io/posts/percentage_recap2/", "categories": "Data Science, mathematics, python", "tags": "study, data science, mathematics", "date": "2021-06-23 00:00:00 +0900", "snippet": "2021-6월-23일 &lt;6장 확률론 복습 -2 &gt;확률밀도함수확률값과 똑같은 성질 갖는다. 확률밀도함숫값 p(x)는 항상 0 이상이다. -무한대~+무한대 구간 확률밀도함수 면적 구하면 1이다.결합확률 P(A,B) or P(AnB) 사건 A,B가 동시에 발생할 확률결합확률 P(A,B) or P(AnB) 사건 A,B가 동시에 발생할 확률 A,B 교집합 확률주변확률 P(A),P(B) 개별 사건 확률을 주변확률이라 한다.사건의 독립 사건이 서로의 확률에 영향 안 주면 서로 독립이다. $P(A,B) = P(A)P(B)$ 성립한다. 사건이 독립이면 [조건부확률=주변확률] 성립한다.결합활률 &amp; 조건부확률 간 관계 $P(A,B) = P(A \\vert B)P(B)$ 위 관계 확장하면 ‘사슬법칙’을 쓸 수 있다. 사슬법칙 : X1 ~ XN 여러 개 사건 결합확률을 조건부 확률 이용해 나타내는 법칙 $P(X1,X2,X3) = P(X3 \\vert X1,X2)P(X2 \\vert X1)P(X1)$확률변수 확률적 실수 데이터 생성기 - 두 확률변수에서 나오는 사건들이 서로 독립 &lt;=&gt; 두 확률변수가 서로 독립 표본값 하나하나를 실수 데이터로 바꿔서 현실 세계로 보내준다. 예를 들어 X=0 은 확률변숫값이 모두 0인 데이터 집합을 말한다. {0,0,0,0,0,0,0,0,….}결합확률분포함수 확률변수 X,Y에서 나오는 사건 두 개 교집합 확률을 정의하는 함수- 결합확률질량함수 이산확률변수 X,Y에서 나오는 [표본 두 개 (단순사건_두개)] [결합확률] 정의하는 함수 - 결합누적분포함수 연속확률변수 X,Y의 [특수구간사건 결합확률] 정의하는 함수 - 결합확률밀도함수 연속확률변수 X,Y에서 나오는 표본 두 개 결합확률 정의하는 함수 이중적분하면 x구간 &amp; y구간_결합확률 구할 수 있다.결과적으로 결합확률질량함수 &amp; 결합확률밀도함수는 확률변수벡터의 확률 할당하는 함수다.다시- 결합확률질량함수 : 확률변수벡터(다변수확률변수 표본값)의 확률질량함수- 결합확률밀도함수 : 확률변수벡터(다변수확률변수 표본값)의 확률밀도함수둘 다 기본적으로 다변수함수다.조건부확률질량/확률밀도함수 : ‘조건부확률’ 확률질량함수, 확률밀도함수- ‘원인’에 해당하는 확률변숫값 고정, ‘결과’에 해당하는 확률변수값의 확률질량함수, 확률밀도함수다.피지엠파이 패키지 계산. 연산 하지 않는다. 결합확률분포를 시각적으로 나타내기만 한다." }, { "title": "[수학/확률론] 확률론 기초 복습", "url": "/bioinfo.github.io/posts/percentage_recap/", "categories": "Data Science, python", "tags": "study, data science, 수학", "date": "2021-06-22 00:00:00 +0900", "snippet": "[06-22-2021] 데이터사이언스스쿨 - 6장 확률론 기초 복습확률변수표본을 실수 데이터로 바꿔서 현실에 보내주는 것 1 동전 앞 뒤 중 하나 뽑기 : 베르누이 확률변수 2 트펌프 카드 뭉치에서 한 장 뽑기 : 카테고리 확률변수 3 동전 두변 던진 결과 : 다변수 확률변수 4 약속날짜가 31일인가 아닌가 : 베르누이 확률변수 5 손님이 과일가게에서 산 과일은? : 카테고리 확률변수 6 삼성전자 주식은 몇 %나 내일 오를까? : 연속확률변수 7 회전하는 원판에 화살 박힌 각도는 ? : 연속확률변수 8 체온 측정 결과는? : 연속확률변수확률문제 : 확률적 데이터 생성하는 문제확률의 수학적 정의 : ‘확률은 함수다’확률론 용어 정리 표본 : 1회 시행 결과 표본공간 : ‘가능한’ 모든 표본의 집합 사건 : 표본공간의 부분집합 &amp; 표본들의 집합 이산확률변수 : 표본과 표본 사이에 다른 실수가 들어갈 수 있으면 이산확률변수 (불연속) 연속확률변수 : 표본과 표본 사이 다른 실수 못 들어가면 연속확률변수 (연속적, 개수 : 무한대) 확률 : 함수다. {입력 : 사건, 출력 : 실숫값(확률값)}itertools : 새로운 반복자를 만들어주는 모듈 chain() : iterable 객체 여러개를 연결시켜서 하나의 반복자로 만들어준다. combinations(iterator, 조합 크기) combinations(iterator, 조합 크기) 입력받은 크기의 조합 예시를 만들어준다.# 다시해보자. omega = {1,2,3,4}from itertools import chain, combinationsdef get_set_of_subsets(omega) : return set([frozenset(s) for s in chain.from_iterable(combinations(omega, r) for r in range(len(omega)+1))])get_set_of_subsets(omega)확률은 함수[입력-출력 사이 대응관계]다. 입력 : 사건(확률변숫값) 출력 : 실숫값(확률값)확률의 기본공리 [콜모고로프 공리] 모든 확률값은 0이상이다. 표본공간 (전체)의 확률값은 1이다. 두 사건 교집합이 공집합 일 때, 두 사건 합집합 확률은 개별사건 확률합과 같다.확률변숫값은 1개 표본(표본, 사건) 이고 확률밀도함수 이용해서 확률 정의할 수 있다.핵심 : 확률값은 콜모고로프 3 공리만 만족하면 뭐든 할당해도 된다.확률값이 불공정하게 배당된다는 증거가 없으면 공정하다고 보고, 다음 식을 확률함수 식으로 사용한다. 표본공간 크기에 대한 특정 사건 크기아무 의미없는 확률값에 의미부여 : 빈도주의 관점, 베이지안 관점 빈도주의 관점에서는 [반복에 대한 비율] 을 확률값으로 삼는다. 베이지안 관점에서는 [주장에 대한 신뢰도] 를 확률값으로 삼는다.베이지안 관점에서특정 사건이 발생했다 = 선택된 표본이 그 사건 원소중 하나였다 = 그 사건이 말하는 주장이 진실임을 알게 되었다.1개 사건 &amp; 확률값에 대해 빈도주의관점과 베이지안 관점 모두 설명 가능하다. 빈도주의 관점 &amp; 베이지안 관점은 양립가능하다.확률의 3가지 주요 성질 여집합 확률 포함-배제 원리 전체확률의 법칙확률분포함수- 확률분포 : 확률값 [분포위치],[분포정도] 나타낸다.- 확률분포함수 : 바로 이 확률분포를 묘사해주는 함수가 확률분포함수다.세 가지 확률분포함수- 확률질량함수 : 단순사건 확률값 정의하는 함수 [확률변숫 값이 이산적. 불연속적 일 때 사용] [실질적으로 표본 하나에 대한 확률 정의하는 함수다]- 확률밀도함수 : 특정 표본값 근처 미세 구간 dx 길이에 대한 확률값 정의하는 함수 [확률변숫 값이 연속적. 갯수가 무한할 때 사용]- 누적분포함수 : 음의 무한대~x까지 특수한 구간 확률 정의하는 함수다시 정리 : 확률변수 개념을 이용할 때- 확률질량함수는 이산확률변수일 때 사용한다. 각 이산확률변숫값 하나하나에 대한 확률 정의한다.- 확률밀도함수는 연속확률변수일 때 사용한다. 각 연속확률변숫값 하나하나에 대한 확률 정의한다.lambda 함수 안에 조건 걸 때 :- [1번째 return문] if 조건 else [2번째 return문] if 조건 else ….- 가장 마지막 조건문은 뒤에 if로 못 끝난다. else [return문] 에서 끝나야 된다.누적분포함수 cdf()구간 끝값 x가 작아지면 확률값 0으로 한없이 작아지고, x가 양의 무한대 쪽으로 커지면 1로 한없이 다가간다." }, { "title": "[데이터시각화/파이썬] matplotlib 을 이용해서 그래프 그리기", "url": "/bioinfo.github.io/posts/data_visualization/", "categories": "Data Science, python, matplotlib", "tags": "data structure, computer science, study, data science, computer engineering", "date": "2021-06-21 00:00:00 +0900", "snippet": "공부 중인 내용을 기록으로 남겨, 나중에 다시 빠르게 ‘불러오기’ 위한 저장소.데이터 시각화 하기데이터사이언스 공부 기반이 되는 필수 수학 공부 중 만난 시각화 방법들을 기록한다. 사용한 라이브러리 : matplotlibimport matplotlib as plt # plt라는 약어로 불러오기 위함. # 지금 시점에서 나는 스타트업 파일을 적용해서, 파이썬3 실행할 때 마다 자동으로 matplotlib을 불러오도록 지정해뒀다. # 스타트업 파일은 내가 파이썬3를 실행할 때, 자동으로 가장 먼저 불러올 코드 뭉치, 모듈 등을 IDLE 등을 통해 기록. 파이썬 스크립트를 만든 뒤, 파이썬이 설치되어 있는 폴더 - 스타트업 폴더 - 에 붙여놓아두면 된다. # 00, 01 이런 식으로 파일 명을 해두는 것이 좋다. 00이면 가장 먼저 로드, 01 이면 그 다음으로 코드 뭉치를 자동 로드해온다. 라인플롯 가장 많이 사용한 그래프이다. 구현이 간단해서 쉽게 사용할 수 있다. 라인플롯 불러오기 plt.plot(x값, y값...) #x값 y값 말고도 수많은 argument를 지정해 줄 수 있다. 가장 기본은 이거다. 라인플롯의 가장 기본 원리는 x점, 그리고 각 x점에 해당하는 y점을 지정받아, (x,y) 점을 2차원 벡터공간 상에 일일이(!) 찍어서 선(라인)으로 된 그래프를 그리는 것이다. 예 :xx = np.linspace(-3,3,1000)def f(a) : return a**2y = f(xx)plt.plot(xx, y)이렇게 라인 플롯을 그릴 수 있다.라인플롯으로 점 찍기 plt.plot(x좌표, y좌표, ‘ro’, ms=점 사이즈)‘ro’ 뿐 아니라 색 이름 머릿글자 + ‘o’ 붙여 지정해주면 점 찍을 수 있다.참고 )색 이름 머릿글자 :r : 빨강g : 초록b : 파랑k : 검정c : cyanm : magentay : 노랑3D 서피스 플롯 2차원 함수를 3차원 벡터공간 상에 나타내서 시각화 할 때 쓰기 좋다. 말 그대로 ‘surface’ 표면을 표현해준다. 2차원 공간상의 x,y 점 &lt;그리드포인트&gt;라고 한다. 을 2차원 함수에 넣어서 나온 결과값인 Z값들을 3차원 공간상에 표현한 것이다. 서피스플롯에 색 입히는 법 : cmap= 인자에 원하는 색상 넣어주면 된다. 색 이름 모르면 cmap=에 아무 값이나 넣고 오류 발생시키자. 가능한 색상 이름 다 알려준다. ax.view_init(각도, 각도) : 각도값들을 넣어주면 3차원 그래프를 돌려가며 여러 각도에서 볼 수 있게 해준다. ax.set_zlabel(‘’) : Z 축 라벨 달 수 있게 해준다. ax.set_xticks([]) : X 축 막대들 설정할 수 있다. 리스트 안에 아무것도 안 넣으면 바bar 모두 제거 가능하다. plt.xticks([]) 도 위와 같이 작동한다. ax.set_yticks([]) : y 축 막대들 설정할 수 있다. plt.yticks([]) 도 위와 같이 작동한다. ax.set_zticks([]) : z 축 막대들 설정할 수 있다.xx = np.linspace(-3,5,100)yy = np.linspace(-3,5,100)def f(a,b) : return a**2+(3*b)X,Y = np.meshgrid(xx,yy) #그리드포인트 생성 #각 (x,y)점들Z = f(X,Y)ax = plt.gca(projection='3d')ax.plot_surface(X,Y,Z, linewidth=0.1)plt.title('서피스 플롯 예시')plt.show()컨투어 플롯(등고선 플롯)# 일반 컨투어 플롯plt.contour(X,Y,Z, colors=, levels=, alpha=)# colors = 색상# levels = 등고선 간격 # alpha = 컨투어플롯 진하고 연한 정도 조정 서피스플롯은 말 그대로 3차원 형상으로 2차원 함수를 시각화했다면, 컨투어 플롯은 2차원 등고선 형상으로 2차원 다변수함수를 표현한다. Z값이 같은 그리드포인트들은 하나의 등고선 라인에 포함된다(원이든. 타원이든 이룬다) 다변수 정규분포 등을 나타내는 데 유용하게 사용한다. levels= : levels 인자에 넣어준 값들에 등고선 표시한다. 등고선은 같은 Z값들이다. plt.clabel(CS=등고선그래프 이름, fmt=) : 등고선들에 해당하는 Z 값들을 등고선에 라벨로 붙여준다. fmt= 인자(format)에 표현 형식 지정해줄 수있다. 예) %d (정수꼴로 표현해라)컨투어플롯을 변수에 담고, CS argument에 플롯을 담은 변수 이름을 넣어주면 된다.xx = np.linspace(-20,20,100)yy = np.linspace(-20,20,100)X,Y = np.meshgrid(xx,yy) #그리드포인트 생성def f(a,b) : return (a-3)**2+(b-2)**2Z = f(X,Y)plt.figure(figsize=(10,5))plt.contour(X,Y,Z)plt.title('컨투어플롯 예시')plt.show()색상 컨투어 플롯# 각 등고선을 색상으로 채운다. plt.contourf(X, Y, Z, alpha=, levels=, colors=)컨투어플롯 여러 개를 한번에 중첩할 수도 있다.plt.contourf(X,Y,Z)plt.contour(X,Y,Z)바 플롯 plt.bar(x값들, y값들) 막대그래프 x값들에 해당하는 y값들을 막대로 표현한다. 라인플롯과 원리는 비슷하다.xx = np.linspace(-3,3,10)plt.bar(np.arange(10), xx)plt.xticks(np.arange(10), ['A','B','C','D','E','F','G','H','I','K'])plt.show()바 플롯 - seaborn matplotlib 말고 seaborn으로 바 플롯 그릴 수도 있다. 기본색이 더 알록달록해서 좋다. sns.barplot(x값들, y값들), matplotlib과 방식 똑같다.xx = np.linspace(-3,3,10)sns.barplot(np.arange(10),xx)plt.xticks(np.arange(10), ['a']*10)plt.show()스캐터플롯 plt.scatter(x값들, y값들, 점 사이즈, 색상) 점들 흩뿌려 놓는 그래프 (x값, y값) 벡터로 만들어서 좌표평면에 점으로 찍는다. 점 1개만 찍을 수도 있다.plt.scatter(1,2, 1000, 'b')xx = np.linspace(0.01, 1,50)yy = np.linspace(4,5,50)plt.scatter(xx, yy, 20, 'r')matplotlib 유용한 메서드 정리plt.figure(figsize=(가로, 세로)) 그래프 그리기 전 그래프 사이즈를 얼만큼으로 할 건지 지정해줄 수 있었다. plt.text(x점, y점, ‘텍스트 내용’, 등등) 벡터공간 x,y좌표 상에 텍스트를 적을 수 있다. plt.xticks(반복가능자) 괄호 안의 반복가능자를 받아 x축에 수직인 축을 그려준다. plt.xticks(np.arange(5), [‘A’,’B’,’C’,’D’,’E’]) 이런 식으로 설정해주면 0에서 4번 인덱스까지 해당하는 x축 이름을 ‘A’에서 ‘E’까지 알파벳으로 바꿀 수 있다.plt.yticks(반복가능자) 괄호 안의 반복가능자 받아 y충게 수직인 축 그려준다. plt.axvline(x좌표,ls=’-.’(라인 스타일),c=’k’(라인 색상)) x축에 수직인 직선을 그어준다. (a x vertical line) c = ‘k’ &lt;검정&gt; c = ‘b’ &lt;파랑&gt; c = ‘r’ &lt;빨강&gt; 등 색상 지정가능했다. y최소, y최대 없이 좌표공간 전체를 가로질러 선 긋는다. plt.axhline(y좌표, ls=’–‘,c=’b’) x축에 수평인(=y축에 수직인) 직선 그어준다. 다른 내용은 axvline() 과 같다. plt.xlim(시작점, 끝점) x축 어디부터 어디까지 나타낼 건지 지정할 수 있다. x.limit제한 plt.ylim(시작점, 끝점) y축 어디부터 어디까지 나타낼 건지 지정할 수 있다. y.limit제한 plt.tight_layout() plt.subplot() 등을 이용해서 여러 개 그래프 한 지면에 그리는 경우 유용하다. 그래프 간 축. 제목 등이 좁은 지면 공간 때문에 겹치는 경우가 생기는데, 그래프 간 간격 적당히 조정해서 이런 문제 해결해준다. plt.subplot(221,222,223,224…) 서브플롯, 그러니까 작은 플롯 여러개를 동시에 한 지면에 나타내준다. 그냥 플롯을 그리면 한 개 플롯이 한 개 지면 전체를 차지하게 된다. 여러 개 서브 플롯을 1개 셀 결과로 동시에 출력할 수 있다. 괄호안에는 플롯 사이즈를 넣어준다. 예륻 들어 221 이면 서브플롯 세로로 2개, 가로로 2개 총 4개를 만들고, 1은 그 중에 첫번째 플롯이다~ 라고 지정하는 숫자다.이거는 plt.subplot(2,2,1) 로 지정해주는거랑 똑같았다. 마찬가지로 세로에서 2개, 가로에서 2개 해서 총 4개 플롯을 그릴거고, 1은 그 중에 첫번째 플롯에 그린다~ 는 의미다.plt.show() 그래프 다 그린 뒤에, 입력해주면 깔끔하게 정돈된 그래프를 출력해준다. plt.title(‘그래프 제목’) 그래프 1개의 제목을 붙여줄 수 있다. plt.xlabel(‘x축에 붙일 이름’) 그래프 x축이 뭘 말하는지 이름 붙여줄 수 있다. plt.ylabel(‘y축에 붙일 이름’) 그래프 y축이 뭘 말하는지 이름 붙여줄 수 있다. plt.suptitle(‘대 제목’) 여러 개 서브플롯이 있는 경우, plt.title()로는 각 서브플롯마다 그래프 제목 붙여줄 수 있고, plt.suptitle(‘대 제목’)으로는 전체 서브플롯들의 1개 대 제목을 붙일 수 있다.plt.annotate(‘’, xy=[a,b], xytext=[c,d], arrowprops={‘facecolor’ : ‘color’}) 2차원 표준기저벡터로 이루어진 좌표평면상에 화살표를 그릴 수 있다. xy : 종점(화살표가 가리키는 지점) $\\vert$ 예 : [2,3] xytext : 시점 $\\vert$ 예 : [0,0] ’ ‘ : 텍스트를 쓸 수 있다. xy 인자에 넣어준 종점 좌표에 텍스트가 찍힌다. arrowprops : 화살표 색 등 설정할 수 있다. $\\vert$ 예 : 딕셔너리 형태로 화살표 색상 지정 가능 {‘facecolor’ : ‘red’}plt.arrow(원점좌표x, 원점좌표y, dx, dy, head_width=, head_length=, fc=화살표머리 색깔, ec=화살표몸통색깔, lw=굵기) plt.arrow는 평행이동해서 원점을 $(0,0)$ 에서 $(x,y)$로 변경한 벡터 $(dx, dy)$ 표현에 적합하다.예) 퀴버플롯에서 그레디언트 벡터설명)벡터 $(dx, dy)$는 본래 $(0,0)$을 원점으로 삼는 벡터다.plt.arrow는 이 벡터 $(dx, dy)$ 를 평행이동해서, 원점을 $(x,y)$ 로 바꿔준다.결과적으로 plt.arrow의 결과물 벡터는$(x,y)$ 를 원점, $(x+dx, y+dy)$ 를 종점으로 삼는 벡터가 그려진다.plt.vlines(‘수직선 그을 x좌표’, ymin=, ymax=, colors=, ls=) x축에 수직인 vertical line 을 긋는 코드다. 따라서 수직선 그을 x 좌표 설정해준다. ymin : 수직선 시작할 y좌표 최솟값 ymax : 수직선 끝날 y좌표 최댓값 colors : 선 색상 ls : 선 스타일 지정plt.hlines(‘수직선 그을 y좌표’, xmin=, xmax=, colors=, ls=) x에 수평인 horizontal line 긋는 코드다. 수평선 그을 y좌표 설정해준다. xmin : 수평선 시작할 x좌표 최솟값 xmax : 수평선 끝날 x좌표 최댓값 colors : 선 색상 ls : 선 스타일 지정plt.fill_between(‘x점’, ‘y1점’, ‘y2점’, alpha=) $[x, y_{1}]$ 에서부터 $[x, y_{2}]$까지 사이 공간을 색으로 채운다. alpha : 색 진한 정도+ 공부하면서 더 더 추가해 나가기" } ]
