---
title : "[Logical Writing Study 01] Subject : Should Generative A.I. Be Regulated by Law?"
excerpt : "Logical Writing Study & Training"

categories : 
- Logical thinking training
- Logical & academic writing training
- English writing training

tags : 
- [writing, study, training, english]

toc : true 
toc_sticky : true 
use_math : true

date : 2024-09-20
last_modified_at : 2024-09-20

---

# Subject 01 : Should Generative A.I. be regulated by law?

### Thesis statement 
Generative A.I. must be regulated by law because it is prone to technological self-destruction and collapses human social systems by spreading social distrust and endangering human life. 

### Why the technology must be regulated
From a technological perspective, indiscreet development of generative A.I. systems carries the risk that train data sets will be filled with A.I.-generated data, leading to poor model performance. From a societal perspective, generative AI can spread disinformation [1]. Also, generative A.I. destroys human jobs, especially those of content creators [2]. The job losses further lead to deepening social inequality. These issues are becoming imminent threats to humanity, so regulations should take place to seek coexistence between the system and humans. 

### The examples of regulations
Labeling of AI-created content [3] and profit sharing between AI service companies and original content creators [2] can be the form of regulations to solve the above problems. First, all AI-created content should be labeled as "the creation of AI" to clarify the creator of the content. The labeling will give people a chance to make discreet decisions based on the information generated by AI. Second, AI service development companies should buy data usage licenses from data creators in the form of profit sharing. The profit sharing can protect the data creators from losing their jobs while producing authentic data sets suitable for model training. Protecting data creators' jobs and preserving their income prevents the social inequality caused by technology. 

### Expected obstacles on the suggested solutions
However, several issues such as geopolitical mistrust, global competition among countries to gain economic interest from the technology, and lack of AI literacy among lawmakers become obstacles that prevent the regulations from becoming effective and practical. The India’s technology minister Rajeev Chandrasekhar insisted that potential beneficiaries of the technology will be the rich, developed countries, not the underdeveloped or developing countries [1]. Such mistrust prevents countries from uniting to make proper universal regulations on the technology. Global competition is also the main obstacle to global cooperation. All countries are focused on gaining economic advantage from the technology and do not want to suppress its potential [1]. Most importantly, the lack of A.I. literacy among lawmakers is becoming a huge obstacle to making proper regulations. For example, members of the U.S. Congress have finally admitted that they don't know how the system works [1]. Big tech companies like Google and OpenAI are lobbying them while giving them lectures on the technology [1]. 

### Summary
In summary, regulating generative AI is crucial to prevent its negative consequences, such as filling global data repositories with poor-quality information, promoting misinformation, and threatening human livelihoods. Potential solutions include mandatory labeling of AI-generated content and profit-sharing mechanisms for content creators to safeguard their work. Since AI has global implications, regulations need to be international and collaborative. However, achieving this faces major hurdles, including geopolitical distrust, international competition for technological dominance, and the insufficient understanding of AI among policymakers, all of which undermine the effectiveness of potential regulations.



## References

[1] Adam Satariano and Cecilia Kang, “How Nations Are Losing a Global Race to Tackle A.I.’s Harms”, The New York Times, 6 December 2023, https://www.nytimes.com/2023/12/06/technology/ai-regulation-policies.html

[2] Nico Grant and Cade Metz, “The Push to Develop Generative A.I. Without All the Lawsuits”, The New York Times, 19 July 2024, https://www.nytimes.com/2024/07/19/technology/generative-ai-getty-shutterstock.html

[3] Cecilia Kang and Adam Satariano, “Five Ways A.I. Could Be Regulated”, The New York Times, 6 December 2023, https://www.nytimes.com/2023/12/06/technology/artificial-intelligence-regulation.html



